title,abstract,published
"The unknotting number, hard unknot diagrams, and reinforcement learning","We have developed a reinforcement learning agent that often finds a minimal
sequence of unknotting crossing changes for a knot diagram with up to 200
crossings, hence giving an upper bound on the unknotting number. We have used
this to determine the unknotting number of 57k knots. We took diagrams of
connected sums of such knots with oppositely signed signatures, where the
summands were overlaid. The agent has found examples where several of the
crossing changes in an unknotting collection of crossings result in hyperbolic
knots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy
some mild assumptions, there is a diagram of their connected sum and $u(K) +
u(K')$ unknotting crossings such that changing any one of them results in a
prime knot. As a by-product, we have obtained a dataset of 2.6 million distinct
hard unknot diagrams; most of them under 35 crossings. Assuming the additivity
of the unknotting number, we have determined the unknotting number of 43 at
most 12-crossing knots for which the unknotting number is unknown.",2024-09-13 17:59:52+00:00
"Agents in Software Engineering: Survey, Landscape, and Vision","In recent years, Large Language Models (LLMs) have achieved remarkable
success and have been widely used in various downstream tasks, especially in
the tasks of the software engineering (SE) field. We find that many studies
combining LLMs with SE have employed the concept of agents either explicitly or
implicitly. However, there is a lack of an in-depth survey to sort out the
development context of existing works, analyze how existing works combine the
LLM-based agent technologies to optimize various tasks, and clarify the
framework of LLM-based agents in SE. In this paper, we conduct the first survey
of the studies on combining LLM-based agents with SE and present a framework of
LLM-based agents in SE which includes three key modules: perception, memory,
and action. We also summarize the current challenges in combining the two
fields and propose future opportunities in response to existing challenges. We
maintain a GitHub repository of the related papers at:
https://github.com/DeepSoftwareAnalytics/Awesome-Agent4SE.",2024-09-13 17:55:58+00:00
Towards Leveraging Contrastively Pretrained Neural Audio Embeddings for Recommender Tasks,"Music recommender systems frequently utilize network-based models to capture
relationships between music pieces, artists, and users. Although these
relationships provide valuable insights for predictions, new music pieces or
artists often face the cold-start problem due to insufficient initial
information. To address this, one can extract content-based information
directly from the music to enhance collaborative-filtering-based methods. While
previous approaches have relied on hand-crafted audio features for this
purpose, we explore the use of contrastively pretrained neural audio embedding
models, which offer a richer and more nuanced representation of music. Our
experiments demonstrate that neural embeddings, particularly those generated
with the Contrastive Language-Audio Pretraining (CLAP) model, present a
promising approach to enhancing music recommendation tasks within graph-based
frameworks.",2024-09-13 17:53:06+00:00
INN-PAR: Invertible Neural Network for PPG to ABP Reconstruction,"Non-invasive and continuous blood pressure (BP) monitoring is essential for
the early prevention of many cardiovascular diseases. Estimating arterial blood
pressure (ABP) from photoplethysmography (PPG) has emerged as a promising
solution. However, existing deep learning approaches for PPG-to-ABP
reconstruction (PAR) encounter certain information loss, impacting the
precision of the reconstructed signal. To overcome this limitation, we
introduce an invertible neural network for PPG to ABP reconstruction (INN-PAR),
which employs a series of invertible blocks to jointly learn the mapping
between PPG and its gradient with the ABP signal and its gradient. INN-PAR
efficiently captures both forward and inverse mappings simultaneously, thereby
preventing information loss. By integrating signal gradients into the learning
process, INN-PAR enhances the network's ability to capture essential
high-frequency details, leading to more accurate signal reconstruction.
Moreover, we propose a multi-scale convolution module (MSCM) within the
invertible block, enabling the model to learn features across multiple scales
effectively. We have experimented on two benchmark datasets, which show that
INN-PAR significantly outperforms the state-of-the-art methods in both waveform
reconstruction and BP measurement accuracy.",2024-09-13 17:48:48+00:00
An Efficient and Streaming Audio Visual Active Speaker Detection System,"This paper delves into the challenging task of Active Speaker Detection
(ASD), where the system needs to determine in real-time whether a person is
speaking or not in a series of video frames. While previous works have made
significant strides in improving network architectures and learning effective
representations for ASD, a critical gap exists in the exploration of real-time
system deployment. Existing models often suffer from high latency and memory
usage, rendering them impractical for immediate applications. To bridge this
gap, we present two scenarios that address the key challenges posed by
real-time constraints. First, we introduce a method to limit the number of
future context frames utilized by the ASD model. By doing so, we alleviate the
need for processing the entire sequence of future frames before a decision is
made, significantly reducing latency. Second, we propose a more stringent
constraint that limits the total number of past frames the model can access
during inference. This tackles the persistent memory issues associated with
running streaming ASD systems. Beyond these theoretical frameworks, we conduct
extensive experiments to validate our approach. Our results demonstrate that
constrained transformer models can achieve performance comparable to or even
better than state-of-the-art recurrent models, such as uni-directional GRUs,
with a significantly reduced number of context frames. Moreover, we shed light
on the temporal memory requirements of ASD systems, revealing that larger past
context has a more profound impact on accuracy than future context. When
profiling on a CPU we find that our efficient architecture is memory bound by
the amount of past context it can use and that the compute cost is negligible
as compared to the memory cost.",2024-09-13 17:45:53+00:00
AI-LieDar: Examine the Trade-off Between Utility and Truthfulness in LLM Agents,"To be safely and successfully deployed, LLMs must simultaneously satisfy
truthfulness and utility goals. Yet, often these two goals compete (e.g., an AI
agent assisting a used car salesman selling a car with flaws), partly due to
ambiguous or misleading user instructions. We propose AI-LieDar, a framework to
study how LLM-based agents navigate scenarios with utility-truthfulness
conflicts in a multi-turn interactive setting. We design a set of realistic
scenarios where language agents are instructed to achieve goals that are in
conflict with being truthful during a multi-turn conversation with simulated
human agents. To evaluate the truthfulness at large scale, we develop a
truthfulness detector inspired by psychological literature to assess the
agents' responses. Our experiment demonstrates that all models are truthful
less than 50% of the time, although truthfulness and goal achievement (utility)
rates vary across models. We further test the steerability of LLMs towards
truthfulness, finding that models follow malicious instructions to deceive, and
even truth-steered models can still lie. These findings reveal the complex
nature of truthfulness in LLMs and underscore the importance of further
research to ensure the safe and reliable deployment of LLMs and AI agents.",2024-09-13 17:41:12+00:00
VAE Explainer: Supplement Learning Variational Autoencoders with Interactive Visualization,"Variational Autoencoders are widespread in Machine Learning, but are
typically explained with dense math notation or static code examples. This
paper presents VAE Explainer, an interactive Variational Autoencoder running in
the browser to supplement existing static documentation (e.g., Keras Code
Examples). VAE Explainer adds interactions to the VAE summary with interactive
model inputs, latent space, and output. VAE Explainer connects the high-level
understanding with the implementation: annotated code and a live computational
graph. The VAE Explainer interactive visualization is live at
https://xnought.github.io/vae-explainer and the code is open source at
https://github.com/xnought/vae-explainer.",2024-09-13 17:40:01+00:00
Contri(e)ve: Context + Retrieve for Scholarly Question Answering,"Scholarly communication is a rapid growing field containing a wealth of
knowledge. However, due to its unstructured and document format, it is
challenging to extract useful information from them through conventional
document retrieval methods. Scholarly knowledge graphs solve this problem, by
representing the documents in a semantic network, providing, hidden insights,
summaries and ease of accessibility through queries. Naturally, question
answering for scholarly graphs expands the accessibility to a wider audience.
But some of the knowledge in this domain is still presented as unstructured
text, thus requiring a hybrid solution for question answering systems. In this
paper, we present a two step solution using open source Large Language
Model(LLM): Llama3.1 for Scholarly-QALD dataset. Firstly, we extract the
context pertaining to the question from different structured and unstructured
data sources: DBLP, SemOpenAlex knowledge graphs and Wikipedia text. Secondly,
we implement prompt engineering to improve the information retrieval
performance of the LLM. Our approach achieved an F1 score of 40% and also
observed some anomalous responses from the LLM, that are discussed in the final
part of the paper.",2024-09-13 17:38:47+00:00
SGFormer: Single-Layer Graph Transformers with Approximation-Free Linear Complexity,"Learning representations on large graphs is a long-standing challenge due to
the inter-dependence nature. Transformers recently have shown promising
performance on small graphs thanks to its global attention for capturing
all-pair interactions beyond observed structures. Existing approaches tend to
inherit the spirit of Transformers in language and vision tasks, and embrace
complicated architectures by stacking deep attention-based propagation layers.
In this paper, we attempt to evaluate the necessity of adopting multi-layer
attentions in Transformers on graphs, which considerably restricts the
efficiency. Specifically, we analyze a generic hybrid propagation layer,
comprised of all-pair attention and graph-based propagation, and show that
multi-layer propagation can be reduced to one-layer propagation, with the same
capability for representation learning. It suggests a new technical path for
building powerful and efficient Transformers on graphs, particularly through
simplifying model architectures without sacrificing expressiveness. As
exemplified by this work, we propose a Simplified Single-layer Graph
Transformers (SGFormer), whose main component is a single-layer global
attention that scales linearly w.r.t. graph sizes and requires none of any
approximation for accommodating all-pair interactions. Empirically, SGFormer
successfully scales to the web-scale graph ogbn-papers100M, yielding
orders-of-magnitude inference acceleration over peer Transformers on
medium-sized graphs, and demonstrates competitiveness with limited labeled
data.",2024-09-13 17:37:34+00:00
Model-independent variable selection via the rule-based variable priorit,"While achieving high prediction accuracy is a fundamental goal in machine
learning, an equally important task is finding a small number of features with
high explanatory power. One popular selection technique is permutation
importance, which assesses a variable's impact by measuring the change in
prediction error after permuting the variable. However, this can be problematic
due to the need to create artificial data, a problem shared by other methods as
well. Another problem is that variable selection methods can be limited by
being model-specific. We introduce a new model-independent approach, Variable
Priority (VarPro), which works by utilizing rules without the need to generate
artificial data or evaluate prediction error. The method is relatively easy to
use, requiring only the calculation of sample averages of simple statistics,
and can be applied to many data settings, including regression, classification,
and survival. We investigate the asymptotic properties of VarPro and show,
among other things, that VarPro has a consistent filtering property for noise
variables. Empirical studies using synthetic and real-world data show the
method achieves a balanced performance and compares favorably to many
state-of-the-art procedures currently used for variable selection.",2024-09-13 17:32:05+00:00
"E2MoCase: A Dataset for Emotional, Event and Moral Observations in News Articles on High-impact Legal Cases","The way media reports on legal cases can significantly shape public opinion,
often embedding subtle biases that influence societal views on justice and
morality. Analyzing these biases requires a holistic approach that captures the
emotional tone, moral framing, and specific events within the narratives. In
this work we introduce E2MoCase, a novel dataset designed to facilitate the
integrated analysis of emotions, moral values, and events within legal
narratives and media coverage. By leveraging advanced models for emotion
detection, moral value identification, and event extraction, E2MoCase offers a
multi-dimensional perspective on how legal cases are portrayed in news
articles.",2024-09-13 17:31:09+00:00
Biomimetic Frontend for Differentiable Audio Processing,"While models in audio and speech processing are becoming deeper and more
end-to-end, they as a consequence need expensive training on large data, and
are often brittle. We build on a classical model of human hearing and make it
differentiable, so that we can combine traditional explainable biomimetic
signal processing approaches with deep-learning frameworks. This allows us to
arrive at an expressive and explainable model that is easily trained on modest
amounts of data. We apply this model to audio processing tasks, including
classification and enhancement. Results show that our differentiable model
surpasses black-box approaches in terms of computational efficiency and
robustness, even with little training data. We also discuss other potential
applications.",2024-09-13 17:23:42+00:00
Clean Label Attacks against SLU Systems,"Poisoning backdoor attacks involve an adversary manipulating the training
data to induce certain behaviors in the victim model by inserting a trigger in
the signal at inference time. We adapted clean label backdoor (CLBD)-data
poisoning attacks, which do not modify the training labels, on state-of-the-art
speech recognition models that support/perform a Spoken Language Understanding
task, achieving 99.8% attack success rate by poisoning 10% of the training
data. We analyzed how varying the signal-strength of the poison, percent of
samples poisoned, and choice of trigger impact the attack. We also found that
CLBD attacks are most successful when applied to training samples that are
inherently hard for a proxy model. Using this strategy, we achieved an attack
success rate of 99.3% by poisoning a meager 1.5% of the training data. Finally,
we applied two previously developed defenses against gradient-based attacks,
and found that they attain mixed success against poisoning.",2024-09-13 16:58:06+00:00
"Predicting Trust In Autonomous Vehicles: Modeling Young Adult Psychosocial Traits, Risk-Benefit Attitudes, And Driving Factors With Machine Learning","Low trust remains a significant barrier to Autonomous Vehicle (AV) adoption.
To design trustworthy AVs, we need to better understand the individual traits,
attitudes, and experiences that impact people's trust judgements. We use
machine learning to understand the most important factors that contribute to
young adult trust based on a comprehensive set of personal factors gathered via
survey (n = 1457). Factors ranged from psychosocial and cognitive attributes to
driving style, experiences, and perceived AV risks and benefits. Using the
explainable AI technique SHAP, we found that perceptions of AV risks and
benefits, attitudes toward feasibility and usability, institutional trust,
prior experience, and a person's mental model are the most important
predictors. Surprisingly, psychosocial and many technology- and
driving-specific factors were not strong predictors. Results highlight the
importance of individual differences for designing trustworthy AVs for diverse
groups and lead to key implications for future design and research.",2024-09-13 16:52:24+00:00
PINNfluence: Influence Functions for Physics-Informed Neural Networks,"Recently, physics-informed neural networks (PINNs) have emerged as a flexible
and promising application of deep learning to partial differential equations in
the physical sciences. While offering strong performance and competitive
inference speeds on forward and inverse problems, their black-box nature limits
interpretability, particularly regarding alignment with expected physical
behavior. In the present work, we explore the application of influence
functions (IFs) to validate and debug PINNs post-hoc. Specifically, we apply
variations of IF-based indicators to gauge the influence of different types of
collocation points on the prediction of PINNs applied to a 2D Navier-Stokes
fluid flow problem. Our results demonstrate how IFs can be adapted to PINNs to
reveal the potential for further studies.",2024-09-13 16:23:17+00:00
A Bayesian Approach to Clustering via the Proper Bayesian Bootstrap: the Bayesian Bagged Clustering (BBC) algorithm,"The paper presents a novel approach for unsupervised techniques in the field
of clustering. A new method is proposed to enhance existing literature models
using the proper Bayesian bootstrap to improve results in terms of robustness
and interpretability. Our approach is organized in two steps: k-means
clustering is used for prior elicitation, then proper Bayesian bootstrap is
applied as resampling method in an ensemble clustering approach. Results are
analyzed introducing measures of uncertainty based on Shannon entropy. The
proposal provides clear indication on the optimal number of clusters, as well
as a better representation of the clustered data. Empirical results are
provided on simulated data showing the methodological and empirical advances
obtained.",2024-09-13 16:14:54+00:00
Pushing the boundaries of event subsampling in event-based video classification using CNNs,"Event cameras offer low-power visual sensing capabilities ideal for
edge-device applications. However, their high event rate, driven by high
temporal details, can be restrictive in terms of bandwidth and computational
resources. In edge AI applications, determining the minimum amount of events
for specific tasks can allow reducing the event rate to improve bandwidth,
memory, and processing efficiency. In this paper, we study the effect of event
subsampling on the accuracy of event data classification using convolutional
neural network (CNN) models. Surprisingly, across various datasets, the number
of events per video can be reduced by an order of magnitude with little drop in
accuracy, revealing the extent to which we can push the boundaries in accuracy
vs. event rate trade-off. Additionally, we also find that lower classification
accuracy in high subsampling rates is not solely attributable to information
loss due to the subsampling of the events, but that the training of CNNs can be
challenging in highly subsampled scenarios, where the sensitivity to
hyperparameters increases. We quantify training instability across multiple
event-based classification datasets using a novel metric for evaluating the
hyperparameter sensitivity of CNNs in different subsampling settings. Finally,
we analyze the weight gradients of the network to gain insight into this
instability.",2024-09-13 16:14:45+00:00
A Diffusion Approach to Radiance Field Relighting using Multi-Illumination Synthesis,"Relighting radiance fields is severely underconstrained for multi-view data,
which is most often captured under a single illumination condition; It is
especially hard for full scenes containing multiple objects. We introduce a
method to create relightable radiance fields using such single-illumination
data by exploiting priors extracted from 2D image diffusion models. We first
fine-tune a 2D diffusion model on a multi-illumination dataset conditioned by
light direction, allowing us to augment a single-illumination capture into a
realistic -- but possibly inconsistent -- multi-illumination dataset from
directly defined light directions. We use this augmented data to create a
relightable radiance field represented by 3D Gaussian splats. To allow direct
control of light direction for low-frequency lighting, we represent appearance
with a multi-layer perceptron parameterized on light direction. To enforce
multi-view consistency and overcome inaccuracies we optimize a per-image
auxiliary feature vector. We show results on synthetic and real multi-view data
under single illumination, demonstrating that our method successfully exploits
2D diffusion model priors to allow realistic 3D relighting for complete scenes.
Project site
https://repo-sam.inria.fr/fungraph/generative-radiance-field-relighting/",2024-09-13 16:07:25+00:00
DELTA: Dual Consistency Delving with Topological Uncertainty for Active Graph Domain Adaptation,"Graph domain adaptation has recently enabled knowledge transfer across
different graphs. However, without the semantic information on target graphs,
the performance on target graphs is still far from satisfactory. To address the
issue, we study the problem of active graph domain adaptation, which selects a
small quantitative of informative nodes on the target graph for extra
annotation. This problem is highly challenging due to the complicated
topological relationships and the distribution discrepancy across graphs. In
this paper, we propose a novel approach named Dual Consistency Delving with
Topological Uncertainty (DELTA) for active graph domain adaptation. Our DELTA
consists of an edge-oriented graph subnetwork and a path-oriented graph
subnetwork, which can explore topological semantics from complementary
perspectives. In particular, our edge-oriented graph subnetwork utilizes the
message passing mechanism to learn neighborhood information, while our
path-oriented graph subnetwork explores high-order relationships from
substructures. To jointly learn from two subnetworks, we roughly select
informative candidate nodes with the consideration of consistency across two
subnetworks. Then, we aggregate local semantics from its K-hop subgraph based
on node degrees for topological uncertainty estimation. To overcome potential
distribution shifts, we compare target nodes and their corresponding source
nodes for discrepancy scores as an additional component for fine selection.
Extensive experiments on benchmark datasets demonstrate that DELTA outperforms
various state-of-the-art approaches.",2024-09-13 16:06:18+00:00
Pushing Joint Image Denoising and Classification to the Edge,"In this paper, we jointly combine image classification and image denoising,
aiming to enhance human perception of noisy images captured by edge devices,
like low-light security cameras. In such settings, it is important to retain
the ability of humans to verify the automatic classification decision and thus
jointly denoise the image to enhance human perception. Since edge devices have
little computational power, we explicitly optimize for efficiency by proposing
a novel architecture that integrates the two tasks. Additionally, we alter a
Neural Architecture Search (NAS) method, which searches for classifiers to
search for the integrated model while optimizing for a target latency,
classification accuracy, and denoising performance. The NAS architectures
outperform our manually designed alternatives in both denoising and
classification, offering a significant improvement to human perception. Our
approach empowers users to construct architectures tailored to domains like
medical imaging, surveillance systems, and industrial inspections.",2024-09-13 16:01:27+00:00
Average-Reward Maximum Entropy Reinforcement Learning for Underactuated Double Pendulum Tasks,"This report presents a solution for the swing-up and stabilisation tasks of
the acrobot and the pendubot, developed for the AI Olympics competition at IROS
2024. Our approach employs the Average-Reward Entropy Advantage Policy
Optimization (AR-EAPO), a model-free reinforcement learning (RL) algorithm that
combines average-reward RL and maximum entropy RL. Results demonstrate that our
controller achieves improved performance and robustness scores compared to
established baseline methods in both the acrobot and pendubot scenarios,
without the need for a heavily engineered reward function or system model. The
current results are applicable exclusively to the simulation stage setup.",2024-09-13 15:56:26+00:00
SynSUM -- Synthetic Benchmark with Structured and Unstructured Medical Records,"We present the SynSUM benchmark, a synthetic dataset linking unstructured
clinical notes to structured background variables. The dataset consists of
10,000 artificial patient records containing tabular variables (like symptoms,
diagnoses and underlying conditions) and related notes describing the fictional
patient encounter in the domain of respiratory diseases. The tabular portion of
the data is generated through a Bayesian network, where both the causal
structure between the variables and the conditional probabilities are proposed
by an expert based on domain knowledge. We then prompt a large language model
(GPT-4o) to generate a clinical note related to this patient encounter,
describing the patient symptoms and additional context. The SynSUM dataset is
primarily designed to facilitate research on clinical information extraction in
the presence of tabular background variables, which can be linked through
domain knowledge to concepts of interest to be extracted from the text - the
symptoms, in the case of SynSUM. Secondary uses include research on the
automation of clinical reasoning over both tabular data and text, causal effect
estimation in the presence of tabular and/or textual confounders, and
multi-modal synthetic data generation. The dataset can be downloaded from
https://github.com/prabaey/SynSUM.",2024-09-13 15:55:15+00:00
Optimization and Generalization Guarantees for Weight Normalization,"Weight normalization (WeightNorm) is widely used in practice for the training
of deep neural networks and modern deep learning libraries have built-in
implementations of it. In this paper, we provide the first theoretical
characterizations of both optimization and generalization of deep WeightNorm
models with smooth activation functions. For optimization, from the form of the
Hessian of the loss, we note that a small Hessian of the predictor leads to a
tractable analysis. Thus, we bound the spectral norm of the Hessian of
WeightNorm networks and show its dependence on the network width and weight
normalization terms--the latter being unique to networks without WeightNorm.
Then, we use this bound to establish training convergence guarantees under
suitable assumptions for gradient decent. For generalization, we use WeightNorm
to get a uniform convergence based generalization bound, which is independent
from the width and depends sublinearly on the depth. Finally, we present
experimental results which illustrate how the normalization terms and other
quantities of theoretical interest relate to the training of WeightNorm
networks.",2024-09-13 15:55:05+00:00
"Yes, Prime Minister, question order does matter -- and it's certainly not classical! But is it quantum?","Response to a poll can be manipulated by means of a series of leading
questions. We show that such phenomena cannot be explained by use of classical
probability theory, whereas quantum probability theory admits a possibility of
offering an explanation. Admissible transformation rules in quantum
probability, however, do impose some constraints on the modelling of cognitive
behaviour, which are highlighted here. Focusing on a recent poll conducted by
Ipsos on a set of questions posed by Sir Humphrey Appleby in an episode of the
British political satire \textit{Yes, Prime Minister}, we show that the
resulting data cannot be explained quite so simply using quantum rules,
although it seems not impossible.",2024-09-13 15:46:57+00:00
ClearDepth: Enhanced Stereo Perception of Transparent Objects for Robotic Manipulation,"Transparent object depth perception poses a challenge in everyday life and
logistics, primarily due to the inability of standard 3D sensors to accurately
capture depth on transparent or reflective surfaces. This limitation
significantly affects depth map and point cloud-reliant applications,
especially in robotic manipulation. We developed a vision transformer-based
algorithm for stereo depth recovery of transparent objects. This approach is
complemented by an innovative feature post-fusion module, which enhances the
accuracy of depth recovery by structural features in images. To address the
high costs associated with dataset collection for stereo camera-based
perception of transparent objects, our method incorporates a parameter-aligned,
domain-adaptive, and physically realistic Sim2Real simulation for efficient
data generation, accelerated by AI algorithm. Our experimental results
demonstrate the model's exceptional Sim2Real generalizability in real-world
scenarios, enabling precise depth mapping of transparent objects to assist in
robotic manipulation. Project details are available at
https://sites.google.com/view/cleardepth/ .",2024-09-13 15:44:38+00:00
Multi forests: Variable importance for multi-class outcomes,"In prediction tasks with multi-class outcomes, identifying covariates
specifically associated with one or more outcome classes can be important.
Conventional variable importance measures (VIMs) from random forests (RFs),
like permutation and Gini importance, focus on overall predictive performance
or node purity, without differentiating between the classes. Therefore, they
can be expected to fail to distinguish class-associated covariates from
covariates that only distinguish between groups of classes. We introduce a VIM
called multi-class VIM, tailored for identifying exclusively class-associated
covariates, via a novel RF variant called multi forests (MuFs). The trees in
MuFs use both multi-way and binary splitting. The multi-way splits generate
child nodes for each class, using a split criterion that evaluates how well
these nodes represent their respective classes. This setup forms the basis of
the multi-class VIM, which measures the discriminatory ability of the splits
performed in the respective covariates with regard to this split criterion.
Alongside the multi-class VIM, we introduce a second VIM, the discriminatory
VIM. This measure, based on the binary splits, assesses the strength of the
general influence of the covariates, irrespective of their
class-associatedness. Simulation studies demonstrate that the multi-class VIM
specifically ranks class-associated covariates highly, unlike conventional VIMs
which also rank other types of covariates highly. Analyses of 121 datasets
reveal that MuFs often have slightly lower predictive performance compared to
conventional RFs. This is, however, not a limiting factor given the algorithm's
primary purpose of calculating the multi-class VIM.",2024-09-13 15:40:29+00:00
XSub: Explanation-Driven Adversarial Attack against Blackbox Classifiers via Feature Substitution,"Despite its significant benefits in enhancing the transparency and
trustworthiness of artificial intelligence (AI) systems, explainable AI (XAI)
has yet to reach its full potential in real-world applications. One key
challenge is that XAI can unintentionally provide adversaries with insights
into black-box models, inevitably increasing their vulnerability to various
attacks. In this paper, we develop a novel explanation-driven adversarial
attack against black-box classifiers based on feature substitution, called
XSub. The key idea of XSub is to strategically replace important features
(identified via XAI) in the original sample with corresponding important
features from a ""golden sample"" of a different label, thereby increasing the
likelihood of the model misclassifying the perturbed sample. The degree of
feature substitution is adjustable, allowing us to control how much of the
original samples information is replaced. This flexibility effectively balances
a trade-off between the attacks effectiveness and its stealthiness. XSub is
also highly cost-effective in that the number of required queries to the
prediction model and the explanation model in conducting the attack is in O(1).
In addition, XSub can be easily extended to launch backdoor attacks in case the
attacker has access to the models training data. Our evaluation demonstrates
that XSub is not only effective and stealthy but also cost-effective, enabling
its application across a wide range of AI models.",2024-09-13 15:33:32+00:00
Latent Space Score-based Diffusion Model for Probabilistic Multivariate Time Series Imputation,"Accurate imputation is essential for the reliability and success of
downstream tasks. Recently, diffusion models have attracted great attention in
this field. However, these models neglect the latent distribution in a
lower-dimensional space derived from the observed data, which limits the
generative capacity of the diffusion model. Additionally, dealing with the
original missing data without labels becomes particularly problematic. To
address these issues, we propose the Latent Space Score-Based Diffusion Model
(LSSDM) for probabilistic multivariate time series imputation. Observed values
are projected onto low-dimensional latent space and coarse values of the
missing data are reconstructed without knowing their ground truth values by
this unsupervised learning approach. Finally, the reconstructed values are fed
into a conditional diffusion model to obtain the precise imputed values of the
time series. In this way, LSSDM not only possesses the power to identify the
latent distribution but also seamlessly integrates the diffusion model to
obtain the high-fidelity imputed values and assess the uncertainty of the
dataset. Experimental results demonstrate that LSSDM achieves superior
imputation performance while also providing a better explanation and
uncertainty analysis of the imputation mechanism. The website of the code is
\textit{https://github.com/gorgen2020/LSSDM\_imputation}.",2024-09-13 15:32:26+00:00
Farmer.Chat: Scaling AI-Powered Agricultural Services for Smallholder Farmers,"Small and medium-sized agricultural holders face challenges like limited
access to localized, timely information, impacting productivity and
sustainability. Traditional extension services, which rely on in-person agents,
struggle with scalability and timely delivery, especially in remote areas. We
introduce Farmer.Chat, a generative AI-powered chatbot designed to address
these issues. Leveraging Generative AI, Farmer.Chat offers personalized,
reliable, and contextually relevant advice, overcoming limitations of previous
chatbots in deterministic dialogue flows, language support, and unstructured
data processing. Deployed in four countries, Farmer.Chat has engaged over
15,000 farmers and answered over 300,000 queries. This paper highlights how
Farmer.Chat's innovative use of GenAI enhances agricultural service scalability
and effectiveness. Our evaluation, combining quantitative analysis and
qualitative insights, highlights Farmer.Chat's effectiveness in improving
farming practices, enhancing trust, response quality, and user engagement.",2024-09-13 15:31:33+00:00
HLTCOE JHU Submission to the Voice Privacy Challenge 2024,"We present a number of systems for the Voice Privacy Challenge, including
voice conversion based systems such as the kNN-VC method and the WavLM voice
Conversion method, and text-to-speech (TTS) based systems including
Whisper-VITS. We found that while voice conversion systems better preserve
emotional content, they struggle to conceal speaker identity in semi-white-box
attack scenarios; conversely, TTS methods perform better at anonymization and
worse at emotion preservation. Finally, we propose a random admixture system
which seeks to balance out the strengths and weaknesses of the two category of
systems, achieving a strong EER of over 40% while maintaining UAR at a
respectable 47%.",2024-09-13 15:29:37+00:00
Affective Computing Has Changed: The Foundation Model Disruption,"The dawn of Foundation Models has on the one hand revolutionised a wide range
of research problems, and, on the other hand, democratised the access and use
of AI-based tools by the general public. We even observe an incursion of these
models into disciplines related to human psychology, such as the Affective
Computing domain, suggesting their affective, emerging capabilities. In this
work, we aim to raise awareness of the power of Foundation Models in the field
of Affective Computing by synthetically generating and analysing multimodal
affective data, focusing on vision, linguistics, and speech (acoustics). We
also discuss some fundamental problems, such as ethical issues and regulatory
aspects, related to the use of Foundation Models in this research area.",2024-09-13 15:20:18+00:00
Gaussian is All You Need: A Unified Framework for Solving Inverse Problems via Diffusion Posterior Sampling,"Diffusion models can generate a variety of high-quality images by modeling
complex data distributions. Trained diffusion models can also be very effective
image priors for solving inverse problems. Most of the existing diffusion-based
methods integrate data consistency steps within the diffusion reverse sampling
process. The data consistency steps rely on an approximate likelihood function.
In this paper, we show that the existing approximations are either insufficient
or computationally inefficient. To address these issues, we propose a unified
likelihood approximation method that incorporates a covariance correction term
to enhance the performance and avoids propagating gradients through the
diffusion model. The correction term, when integrated into the reverse
diffusion sampling process, achieves better convergence towards the true data
posterior for selected distributions and improves performance on real-world
natural image datasets. Furthermore, we present an efficient way to factorize
and invert the covariance matrix of the likelihood function for several inverse
problems. We present comprehensive experiments to demonstrate the effectiveness
of our method over several existing approaches.",2024-09-13 15:20:03+00:00
D2-MLP: Dynamic Decomposed MLP Mixer for Medical Image Segmentation,"Convolutional neural networks are widely used in various segmentation tasks
in medical images. However, they are challenged to learn global features
adaptively due to the inherent locality of convolutional operations. In
contrast, MLP Mixers are proposed as a backbone to learn global information
across channels with low complexity. However, they cannot capture spatial
features efficiently. Additionally, they lack effective mechanisms to fuse and
mix features adaptively. To tackle these limitations, we propose a novel
Dynamic Decomposed Mixer module. It is designed to employ novel Mixers to
extract features and aggregate information across different spatial locations
and channels. Additionally, it employs novel dynamic mixing mechanisms to model
inter-dependencies between channel and spatial feature representations and to
fuse them adaptively. Subsequently, we incorporate it into a U-shaped
Transformer-based architecture to generate a novel network, termed the Dynamic
Decomposed MLP Mixer. We evaluated it for medical image segmentation on two
datasets, and it achieved superior segmentation performance than other
state-of-the-art methods.",2024-09-13 15:16:28+00:00
AnyBipe: An End-to-End Framework for Training and Deploying Bipedal Robots Guided by Large Language Models,"Training and deploying reinforcement learning (RL) policies for robots,
especially in accomplishing specific tasks, presents substantial challenges.
Recent advancements have explored diverse reward function designs, training
techniques, simulation-to-reality (sim-to-real) transfers, and performance
analysis methodologies, yet these still require significant human intervention.
This paper introduces an end-to-end framework for training and deploying RL
policies, guided by Large Language Models (LLMs), and evaluates its
effectiveness on bipedal robots. The framework consists of three interconnected
modules: an LLM-guided reward function design module, an RL training module
leveraging prior work, and a sim-to-real homomorphic evaluation module. This
design significantly reduces the need for human input by utilizing only
essential simulation and deployment platforms, with the option to incorporate
human-engineered strategies and historical data. We detail the construction of
these modules, their advantages over traditional approaches, and demonstrate
the framework's capability to autonomously develop and refine controlling
strategies for bipedal robot locomotion, showcasing its potential to operate
independently of human intervention.",2024-09-13 15:15:45+00:00
Synthetic Human Memories: AI-Edited Images and Videos Can Implant False Memories and Distort Recollection,"AI is increasingly used to enhance images and videos, both intentionally and
unintentionally. As AI editing tools become more integrated into smartphones,
users can modify or animate photos into realistic videos. This study examines
the impact of AI-altered visuals on false memories--recollections of events
that didn't occur or deviate from reality. In a pre-registered study, 200
participants were divided into four conditions of 50 each. Participants viewed
original images, completed a filler task, then saw stimuli corresponding to
their assigned condition: unedited images, AI-edited images, AI-generated
videos, or AI-generated videos of AI-edited images. AI-edited visuals
significantly increased false recollections, with AI-generated videos of
AI-edited images having the strongest effect (2.05x compared to control).
Confidence in false memories was also highest for this condition (1.19x
compared to control). We discuss potential applications in HCI, such as
therapeutic memory reframing, and challenges in ethical, legal, political, and
societal domains.",2024-09-13 15:08:39+00:00
Exploring Action-Centric Representations Through the Lens of Rate-Distortion Theory,"Organisms have to keep track of the information in the environment that is
relevant for adaptive behaviour. Transmitting information in an economical and
efficient way becomes crucial for limited-resourced agents living in
high-dimensional environments. The efficient coding hypothesis claims that
organisms seek to maximize the information about the sensory input in an
efficient manner. Under Bayesian inference, this means that the role of the
brain is to efficiently allocate resources in order to make predictions about
the hidden states that cause sensory data. However, neither of those frameworks
accounts for how that information is exploited downstream, leaving aside the
action-oriented role of the perceptual system. Rate-distortion theory, which
defines optimal lossy compression under constraints, has gained attention as a
formal framework to explore goal-oriented efficient coding. In this work, we
explore action-centric representations in the context of rate-distortion
theory. We also provide a mathematical definition of abstractions and we argue
that, as a summary of the relevant details, they can be used to fix the content
of action-centric representations. We model action-centric representations
using VAEs and we find that such representations i) are efficient lossy
compressions of the data; ii) capture the task-dependent invariances necessary
to achieve successful behaviour; and iii) are not in service of reconstructing
the data. Thus, we conclude that full reconstruction of the data is rarely
needed to achieve optimal behaviour, consistent with a teleological approach to
perception.",2024-09-13 15:07:22+00:00
Visual Language Tracking with Multi-modal Interaction: A Robust Benchmark,"Visual Language Tracking (VLT) enhances tracking by mitigating the
limitations of relying solely on the visual modality, utilizing high-level
semantic information through language. This integration of the language enables
more advanced human-machine interaction. The essence of interaction is
cognitive alignment, which typically requires multiple information exchanges,
especially in the sequential decision-making process of VLT. However, current
VLT benchmarks do not account for multi-round interactions during tracking.
They provide only an initial text and bounding box (bbox) in the first frame,
with no further interaction as tracking progresses, deviating from the original
motivation of the VLT task. To address these limitations, we propose a novel
and robust benchmark, VLT-MI (Visual Language Tracking with Multi-modal
Interaction), which introduces multi-round interaction into the VLT task for
the first time. (1) We generate diverse, multi-granularity texts for
multi-round, multi-modal interaction based on existing mainstream VLT
benchmarks using DTLLM-VLT, leveraging the world knowledge of LLMs. (2) We
propose a new VLT interaction paradigm that achieves multi-round interaction
through text updates and object recovery. When multiple tracking failures
occur, we provide the tracker with more aligned texts and corrected bboxes
through interaction, thereby expanding the scope of VLT downstream tasks. (3)
We conduct comparative experiments on both traditional VLT benchmarks and
VLT-MI, evaluating and analyzing the accuracy and robustness of trackers under
the interactive paradigm. This work offers new insights and paradigms for the
VLT task, enabling a fine-grained evaluation of multi-modal trackers. We
believe this approach can be extended to additional datasets in the future,
supporting broader evaluations and comparisons of video-language model
capabilities.",2024-09-13 14:54:37+00:00
Interactive Masked Image Modeling for Multimodal Object Detection in Remote Sensing,"Object detection in remote sensing imagery plays a vital role in various
Earth observation applications. However, unlike object detection in natural
scene images, this task is particularly challenging due to the abundance of
small, often barely visible objects across diverse terrains. To address these
challenges, multimodal learning can be used to integrate features from
different data modalities, thereby improving detection accuracy. Nonetheless,
the performance of multimodal learning is often constrained by the limited size
of labeled datasets. In this paper, we propose to use Masked Image Modeling
(MIM) as a pre-training technique, leveraging self-supervised learning on
unlabeled data to enhance detection performance. However, conventional MIM such
as MAE which uses masked tokens without any contextual information, struggles
to capture the fine-grained details due to a lack of interactions with other
parts of image. To address this, we propose a new interactive MIM method that
can establish interactions between different tokens, which is particularly
beneficial for object detection in remote sensing. The extensive ablation
studies and evluation demonstrate the effectiveness of our approach.",2024-09-13 14:50:50+00:00
Detect Fake with Fake: Leveraging Synthetic Data-driven Representation for Synthetic Image Detection,"Are general-purpose visual representations acquired solely from synthetic
data useful for detecting fake images? In this work, we show the effectiveness
of synthetic data-driven representations for synthetic image detection. Upon
analysis, we find that vision transformers trained by the latest visual
representation learners with synthetic data can effectively distinguish fake
from real images without seeing any real images during pre-training. Notably,
using SynCLR as the backbone in a state-of-the-art detection method
demonstrates a performance improvement of +10.32 mAP and +4.73% accuracy over
the widely used CLIP, when tested on previously unseen GAN models. Code is
available at https://github.com/cvpaperchallenge/detect-fake-with-fake.",2024-09-13 14:50:14+00:00
Exploring Graph Structure Comprehension Ability of Multimodal Large Language Models: Case Studies,"Large Language Models (LLMs) have shown remarkable capabilities in processing
various data structures, including graphs. While previous research has focused
on developing textual encoding methods for graph representation, the emergence
of multimodal LLMs presents a new frontier for graph comprehension. These
advanced models, capable of processing both text and images, offer potential
improvements in graph understanding by incorporating visual representations
alongside traditional textual data. This study investigates the impact of graph
visualisations on LLM performance across a range of benchmark tasks at node,
edge, and graph levels. Our experiments compare the effectiveness of multimodal
approaches against purely textual graph representations. The results provide
valuable insights into both the potential and limitations of leveraging visual
graph modalities to enhance LLMs' graph structure comprehension abilities.",2024-09-13 14:26:58+00:00
Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control,"Dynamical generative models that produce samples through an iterative
process, such as Flow Matching and denoising diffusion models, have seen
widespread use, but there has not been many theoretically-sound methods for
improving these models with reward fine-tuning. In this work, we cast reward
fine-tuning as stochastic optimal control (SOC). Critically, we prove that a
very specific memoryless noise schedule must be enforced during fine-tuning, in
order to account for the dependency between the noise variable and the
generated samples. We also propose a new algorithm named Adjoint Matching which
outperforms existing SOC algorithms, by casting SOC problems as a regression
problem. We find that our approach significantly improves over existing methods
for reward fine-tuning, achieving better consistency, realism, and
generalization to unseen human preference reward models, while retaining sample
diversity.",2024-09-13 14:22:14+00:00
InstantDrag: Improving Interactivity in Drag-based Image Editing,"Drag-based image editing has recently gained popularity for its interactivity
and precision. However, despite the ability of text-to-image models to generate
samples within a second, drag editing still lags behind due to the challenge of
accurately reflecting user interaction while maintaining image content. Some
existing approaches rely on computationally intensive per-image optimization or
intricate guidance-based methods, requiring additional inputs such as masks for
movable regions and text prompts, thereby compromising the interactivity of the
editing process. We introduce InstantDrag, an optimization-free pipeline that
enhances interactivity and speed, requiring only an image and a drag
instruction as input. InstantDrag consists of two carefully designed networks:
a drag-conditioned optical flow generator (FlowGen) and an optical
flow-conditioned diffusion model (FlowDiffusion). InstantDrag learns motion
dynamics for drag-based image editing in real-world video datasets by
decomposing the task into motion generation and motion-conditioned image
generation. We demonstrate InstantDrag's capability to perform fast,
photo-realistic edits without masks or text prompts through experiments on
facial video datasets and general scenes. These results highlight the
efficiency of our approach in handling drag-based image editing, making it a
promising solution for interactive, real-time applications.",2024-09-13 14:19:27+00:00
Using The Concept Hierarchy for Household Action Recognition,"We propose a method to systematically represent both the static and the
dynamic components of environments, i.e. objects and agents, as well as the
changes that are happening in the environment, i.e. the actions and skills
performed by agents. Our approach, the Concept Hierarchy, provides the
necessary information for autonomous systems to represent environment states,
perform action modeling and recognition, and plan the execution of tasks.
Additionally, the hierarchical structure supports generalization and knowledge
transfer to environments. We rigorously define tasks, actions, skills, and
affordances that enable human-understandable action and skill recognition.",2024-09-13 14:16:41+00:00
DX2CT: Diffusion Model for 3D CT Reconstruction from Bi or Mono-planar 2D X-ray(s),"Computational tomography (CT) provides high-resolution medical imaging, but
it can expose patients to high radiation. X-ray scanners have low radiation
exposure, but their resolutions are low. This paper proposes a new conditional
diffusion model, DX2CT, that reconstructs three-dimensional (3D) CT volumes
from bi or mono-planar X-ray image(s). Proposed DX2CT consists of two key
components: 1) modulating feature maps extracted from two-dimensional (2D)
X-ray(s) with 3D positions of CT volume using a new transformer and 2)
effectively using the modulated 3D position-aware feature maps as conditions of
DX2CT. In particular, the proposed transformer can provide conditions with rich
information of a target CT slice to the conditional diffusion model, enabling
high-quality CT reconstruction. Our experiments with the bi or mono-planar
X-ray(s) benchmark datasets show that proposed DX2CT outperforms several
state-of-the-art methods. Our codes and model will be available at:
https://www.github.com/intyeger/DX2CT.",2024-09-13 14:06:12+00:00
Kinect Calibration and Data Optimization For Anthropometric Parameters,"Recently, through development of several 3d vision systems, widely used in
various applications, medical and biometric fields. Microsoft kinect sensor
have been most of used camera among 3d vision systems. Microsoft kinect sensor
can obtain depth images of a scene and 3d coordinates of human joints. Thus,
anthropometric features can extractable easily. Anthropometric feature and 3d
joint coordinate raw datas which captured from kinect sensor is unstable. The
strongest reason for this, datas vary by distance between joints of individual
and location of kinect sensor. Consequently, usage of this datas without kinect
calibration and data optimization does not result in sufficient and healthy. In
this study, proposed a novel method to calibrating kinect sensor and optimizing
skeleton features. Results indicate that the proposed method is quite effective
and worthy of further study in more general scenarios.",2024-09-13 14:05:26+00:00
FP-VEC: Fingerprinting Large Language Models via Efficient Vector Addition,"Training Large Language Models (LLMs) requires immense computational power
and vast amounts of data. As a result, protecting the intellectual property of
these models through fingerprinting is essential for ownership authentication.
While adding fingerprints to LLMs through fine-tuning has been attempted, it
remains costly and unscalable. In this paper, we introduce FP-VEC, a pilot
study on using fingerprint vectors as an efficient fingerprinting method for
LLMs. Our approach generates a fingerprint vector that represents a
confidential signature embedded in the model, allowing the same fingerprint to
be seamlessly incorporated into an unlimited number of LLMs via vector
addition. Results on several LLMs show that FP-VEC is lightweight by running on
CPU-only devices for fingerprinting, scalable with a single training and
unlimited fingerprinting process, and preserves the model's normal behavior.
The project page is available at https://fingerprintvector.github.io .",2024-09-13 14:04:39+00:00
Direct-CP: Directed Collaborative Perception for Connected and Autonomous Vehicles via Proactive Attention,"Collaborative perception (CP) leverages visual data from connected and
autonomous vehicles (CAV) to enhance an ego vehicle's field of view (FoV).
Despite recent progress, current CP methods expand the ego vehicle's 360-degree
perceptual range almost equally, which faces two key challenges. Firstly, in
areas with uneven traffic distribution, focusing on directions with little
traffic offers limited benefits. Secondly, under limited communication budgets,
allocating excessive bandwidth to less critical directions lowers the
perception accuracy in more vital areas. To address these issues, we propose
Direct-CP, a proactive and direction-aware CP system aiming at improving CP in
specific directions. Our key idea is to enable an ego vehicle to proactively
signal its interested directions and readjust its attention to enhance local
directional CP performance. To achieve this, we first propose an RSU-aided
direction masking mechanism that assists an ego vehicle in identifying vital
directions. Additionally, we design a direction-aware selective attention
module to wisely aggregate pertinent features based on ego vehicle's
directional priorities, communication budget, and the positional data of CAVs.
Moreover, we introduce a direction-weighted detection loss (DWLoss) to capture
the divergence between directional CP outcomes and the ground truth,
facilitating effective model training. Extensive experiments on the V2X-Sim 2.0
dataset demonstrate that our approach achieves 19.8\% higher local perception
accuracy in interested directions and 2.5\% higher overall perception accuracy
than the state-of-the-art methods in collaborative 3D object detection tasks.",2024-09-13 13:53:52+00:00
RF Challenge: The Data-Driven Radio Frequency Signal Separation Challenge,"This paper addresses the critical problem of interference rejection in
radio-frequency (RF) signals using a novel, data-driven approach that leverages
state-of-the-art AI models. Traditionally, interference rejection algorithms
are manually tailored to specific types of interference. This work introduces a
more scalable data-driven solution and contains the following contributions.
First, we present an insightful signal model that serves as a foundation for
developing and analyzing interference rejection algorithms. Second, we
introduce the RF Challenge, a publicly available dataset featuring diverse RF
signals along with code templates, which facilitates data-driven analysis of RF
signal problems. Third, we propose novel AI-based rejection algorithms,
specifically architectures like UNet and WaveNet, and evaluate their
performance across eight different signal mixture types. These models
demonstrate superior performance exceeding traditional methods like matched
filtering and linear minimum mean square error estimation by up to two orders
of magnitude in bit-error rate. Fourth, we summarize the results from an open
competition hosted at 2024 IEEE International Conference on Acoustics, Speech,
and Signal Processing (ICASSP 2024) based on the RF Challenge, highlighting the
significant potential for continued advancements in this area. Our findings
underscore the promise of deep learning algorithms in mitigating interference,
offering a strong foundation for future research.",2024-09-13 13:53:41+00:00
Can Kans (re)discover predictive models for Direct-Drive Laser Fusion?,"The domain of laser fusion presents a unique and challenging predictive
modeling application landscape for machine learning methods due to high problem
complexity and limited training data. Data-driven approaches utilizing
prescribed functional forms, inductive biases and physics-informed learning
(PIL) schemes have been successful in the past for achieving desired
generalization ability and model interpretation that aligns with physics
expectations. In complex multi-physics application domains, however, it is not
always obvious how architectural biases or discriminative penalties can be
formulated. In this work, focusing on nuclear fusion energy using high powered
lasers, we present the use of Kolmogorov-Arnold Networks (KANs) as an
alternative to PIL for developing a new type of data-driven predictive model
which is able to achieve high prediction accuracy and physics interpretability.
A KAN based model, a MLP with PIL, and a baseline MLP model are compared in
generalization ability and interpretation with a domain expert-derived symbolic
regression model. Through empirical studies in this high physics complexity
domain, we show that KANs can potentially provide benefits when developing
predictive models for data-starved physics applications.",2024-09-13 13:48:06+00:00
Breaking reCAPTCHAv2,"Our work examines the efficacy of employing advanced machine learning methods
to solve captchas from Google's reCAPTCHAv2 system. We evaluate the
effectiveness of automated systems in solving captchas by utilizing advanced
YOLO models for image segmentation and classification. Our main result is that
we can solve 100% of the captchas, while previous work only solved 68-71%.
Furthermore, our findings suggest that there is no significant difference in
the number of challenges humans and bots must solve to pass the captchas in
reCAPTCHAv2. This implies that current AI technologies can exploit advanced
image-based captchas. We also look under the hood of reCAPTCHAv2, and find
evidence that reCAPTCHAv2 is heavily based on cookie and browser history data
when evaluating whether a user is human or not. The code is provided alongside
this paper.",2024-09-13 13:47:12+00:00
Pathfinder for Low-altitude Aircraft with Binary Neural Network,"A prior global topological map (e.g., the OpenStreetMap, OSM) can boost the
performance of autonomous mapping by a ground mobile robot. However, the prior
map is usually incomplete due to lacking labeling in partial paths. To solve
this problem, this paper proposes an OSM maker using airborne sensors carried
by low-altitude aircraft, where the core of the OSM maker is a novel efficient
pathfinder approach based on LiDAR and camera data, i.e., a binary dual-stream
road segmentation model. Specifically, a multi-scale feature extraction based
on the UNet architecture is implemented for images and point clouds. To reduce
the effect caused by the sparsity of point cloud, an attention-guided gated
block is designed to integrate image and point-cloud features. For enhancing
the efficiency of the model, we propose a binarization streamline to each model
component, including a variant of vision transformer (ViT) architecture as the
encoder of the image branch, and new focal and perception losses to optimize
the model training. The experimental results on two datasets demonstrate that
our pathfinder method achieves SOTA accuracy with high efficiency in finding
paths from the low-level airborne sensors, and we can create complete OSM prior
maps based on the segmented road skeletons. Code and data are available
at:https://github.com/IMRL/Pathfinder}{https://github.com/IMRL/Pathfinder.",2024-09-13 13:37:33+00:00
AutoIRT: Calibrating Item Response Theory Models with Automated Machine Learning,"Item response theory (IRT) is a class of interpretable factor models that are
widely used in computerized adaptive tests (CATs), such as language proficiency
tests. Traditionally, these are fit using parametric mixed effects models on
the probability of a test taker getting the correct answer to a test item
(i.e., question). Neural net extensions of these models, such as BertIRT,
require specialized architectures and parameter tuning. We propose a multistage
fitting procedure that is compatible with out-of-the-box Automated Machine
Learning (AutoML) tools. It is based on a Monte Carlo EM (MCEM) outer loop with
a two stage inner loop, which trains a non-parametric AutoML grade model using
item features followed by an item specific parametric model. This greatly
accelerates the modeling workflow for scoring tests. We demonstrate its
effectiveness by applying it to the Duolingo English Test, a high stakes,
online English proficiency test. We show that the resulting model is typically
more well calibrated, gets better predictive performance, and more accurate
scores than existing methods (non-explanatory IRT models and explanatory IRT
models like BERT-IRT). Along the way, we provide a brief survey of machine
learning methods for calibration of item parameters for CATs.",2024-09-13 13:36:51+00:00
A RAG Approach for Generating Competency Questions in Ontology Engineering,"Competency question (CQ) formulation is central to several ontology
development and evaluation methodologies. Traditionally, the task of crafting
these competency questions heavily relies on the effort of domain experts and
knowledge engineers which is often time-consuming and labor-intensive. With the
emergence of Large Language Models (LLMs), there arises the possibility to
automate and enhance this process. Unlike other similar works which use
existing ontologies or knowledge graphs as input to LLMs, we present a
retrieval-augmented generation (RAG) approach that uses LLMs for the automatic
generation of CQs given a set of scientific papers considered to be a domain
knowledge base. We investigate its performance and specifically, we study the
impact of different number of papers to the RAG and different temperature
setting of the LLM. We conduct experiments using GPT-4 on two domain ontology
engineering tasks and compare results against ground-truth CQs constructed by
domain experts. Empirical assessments on the results, utilizing evaluation
metrics (precision and consistency), reveal that compared to zero-shot
prompting, adding relevant domain knowledge to the RAG improves the performance
of LLMs on generating CQs for concrete ontology engineering tasks.",2024-09-13 13:34:32+00:00
Deep reinforcement learning for tracking a moving target in jellyfish-like swimming,"We develop a deep reinforcement learning method for training a jellyfish-like
swimmer to effectively track a moving target in a two-dimensional flow. This
swimmer is a flexible object equipped with a muscle model based on torsional
springs. We employ a deep Q-network (DQN) that takes the swimmer's geometry and
dynamic parameters as inputs, and outputs actions which are the forces applied
to the swimmer. In particular, we introduce an action regulation to mitigate
the interference from complex fluid-structure interactions. The goal of these
actions is to navigate the swimmer to a target point in the shortest possible
time. In the DQN training, the data on the swimmer's motions are obtained from
simulations conducted using the immersed boundary method. During tracking a
moving target, there is an inherent delay between the application of forces and
the corresponding response of the swimmer's body due to hydrodynamic
interactions between the shedding vortices and the swimmer's own locomotion.
Our tests demonstrate that the swimmer, with the DQN agent and action
regulation, is able to dynamically adjust its course based on its instantaneous
state. This work extends the application scope of machine learning in
controlling flexible objects within fluid environments.",2024-09-13 13:29:46+00:00
Mutual Theory of Mind in Human-AI Collaboration: An Empirical Study with LLM-driven AI Agents in a Real-time Shared Workspace Task,"Theory of Mind (ToM) significantly impacts human collaboration and
communication as a crucial capability to understand others. When AI agents with
ToM capability collaborate with humans, Mutual Theory of Mind (MToM) arises in
such human-AI teams (HATs). The MToM process, which involves interactive
communication and ToM-based strategy adjustment, affects the team's performance
and collaboration process. To explore the MToM process, we conducted a
mixed-design experiment using a large language model-driven AI agent with ToM
and communication modules in a real-time shared-workspace task. We find that
the agent's ToM capability does not significantly impact team performance but
enhances human understanding of the agent and the feeling of being understood.
Most participants in our study believe verbal communication increases human
burden, and the results show that bidirectional communication leads to lower
HAT performance. We discuss the results' implications for designing AI agents
that collaborate with humans in real-time shared workspace tasks.",2024-09-13 13:19:48+00:00
TabKANet: Tabular Data Modelling with Kolmogorov-Arnold Network and Transformer,"Tabular data is the most common type of data in real-life scenarios. In this
study, we propose a method based on the TabKANet architecture, which utilizes
the Kolmogorov-Arnold network to encode numerical features and merge them with
categorical features, enabling unified modeling of tabular data on the
Transformer architecture. This model demonstrates outstanding performance in
six widely used binary classification tasks, suggesting that TabKANet has the
potential to become a standard approach for tabular modeling, surpassing
traditional neural networks. Furthermore, this research reveals the significant
advantages of the Kolmogorov-Arnold network in encoding numerical features. The
code of our work is available at https://github.com/tsinghuamedgao20/TabKANet.",2024-09-13 13:14:54+00:00
Task-Specific Data Preparation for Deep Learning to Reconstruct Structures of Interest from Severely Truncated CBCT Data,"Cone-beam computed tomography (CBCT) is widely used in interventional
surgeries and radiation oncology. Due to the limited size of flat-panel
detectors, anatomical structures might be missing outside the limited
field-of-view (FOV), which restricts the clinical applications of CBCT systems.
Recently, deep learning methods have been proposed to extend the FOV for
multi-slice CT systems. However, in mobile CBCT system with a smaller FOV size,
projection data is severely truncated and it is challenging for a network to
restore all missing structures outside the FOV. In some applications, only
certain structures outside the FOV are of interest, e.g., ribs in needle path
planning for liver/lung cancer diagnosis. Therefore, a task-specific data
preparation method is proposed in this work, which automatically let the
network focus on structures of interest instead of all the structures. Our
preliminary experiment shows that Pix2pixGAN with a conventional training has
the risk to reconstruct false positive and false negative rib structures from
severely truncated CBCT data, whereas Pix2pixGAN with the proposed
task-specific training can reconstruct all the ribs reliably. The proposed
method is promising to empower CBCT with more clinical applications.",2024-09-13 13:08:24+00:00
Reading ability detection using eye-tracking data with LSTM-based few-shot learning,"Reading ability detection is important in modern educational field. In this
paper, a method of predicting scores of reading ability is proposed, using the
eye-tracking data of a few subjects (e.g., 68 subjects). The proposed method
built a regression model for the score prediction by combining Long Short Time
Memory (LSTM) and light-weighted neural networks. Experiments show that with
few-shot learning strategy, the proposed method achieved higher accuracy than
previous methods of score prediction in reading ability detection. The code can
later be downloaded at
https://github.com/pumpkinLNX/LSTM-eye-tracking-pytorch.git",2024-09-13 13:06:01+00:00
Electrocardiogram Report Generation and Question Answering via Retrieval-Augmented Self-Supervised Modeling,"Interpreting electrocardiograms (ECGs) and generating comprehensive reports
remain challenging tasks in cardiology, often requiring specialized expertise
and significant time investment. To address these critical issues, we propose
ECG-ReGen, a retrieval-based approach for ECG-to-text report generation and
question answering. Our method leverages a self-supervised learning for the ECG
encoder, enabling efficient similarity searches and report retrieval. By
combining pre-training with dynamic retrieval and Large Language Model
(LLM)-based refinement, ECG-ReGen effectively analyzes ECG data and answers
related queries, with the potential of improving patient care. Experiments
conducted on the PTB-XL and MIMIC-IV-ECG datasets demonstrate superior
performance in both in-domain and cross-domain scenarios for report generation.
Furthermore, our approach exhibits competitive performance on ECG-QA dataset
compared to fully supervised methods when utilizing off-the-shelf LLMs for
zero-shot question answering. This approach, effectively combining
self-supervised encoder and LLMs, offers a scalable and efficient solution for
accurate ECG interpretation, holding significant potential to enhance clinical
decision-making.",2024-09-13 12:50:36+00:00
Deep Learning-based Codes for Wiretap Fading Channels,"The wiretap channel is a well-studied problem in the physical layer security
(PLS) literature. Although it is proven that the decoding error probability and
information leakage can be made arbitrarily small in the asymptotic regime,
further research on finite-blocklength codes is required on the path towards
practical, secure communications systems. This work provides the first
experimental characterization of a deep learning-based, finite-blocklength code
construction for multi-tap fading wiretap channels without channel state
information (CSI). In addition to the evaluation of the average probability of
error and information leakage, we illustrate the influence of (i) the number of
fading taps, (ii) differing variances of the fading coefficients and (iii) the
seed selection for the hash function-based security layer.",2024-09-13 12:45:30+00:00
Contactless Fingerprint Recognition Using 3D Graph Matching,"Contactless fingerprint is a newly developed type of fingerprint, and has
gained lots of attention in recent fingerprint studies. However, most existing
contactless fingerprint algorithms treat contactless fingerprints as 2D plain
fingerprints, and utilize similar recognition methods as traditional
contact-based 2D fingerprints. This recognition approach does not consider the
modality difference between contactless and contact fingerprints, especially
the intrinsic 3D characteristic of contactless fingerprints. This paper
proposes a novel contactless fingerprint recognition algorithm that captures
the revealed 3D feature of contactless fingerprints rather than the plain 2D
feature. The proposed method first recovers 3D features from the input
contactless fingerprint, including the 3D shape model and 3D fingerprint
feature (minutiae, orientation, etc.). Then, a novel 3D graph matching is
conducted in 3D space according to the extracted 3D feature. Our method
captures the real 3D nature of contactless fingerprints as the whole feature
extraction and matching algorithms are completed in real 3D space. Experiments
results on contactless fingerprint databases show that the proposed method
successfully improves the matching accuracy of contactless fingerprints.
Exceptionally, our method performs stably across multiple poses of contactless
fingerprints due to 3D graph matching, which is a great advantage compared to
previous contactless fingerprint recognition algorithms.",2024-09-13 12:39:57+00:00
What You Say = What You Want? Teaching Humans to Articulate Requirements for LLMs,"Prompting ChatGPT to achieve complex goals (e.g., creating a customer support
chatbot) often demands meticulous prompt engineering, including aspects like
fluent writing and chain-of-thought techniques. While emerging prompt
optimizers can automatically refine many of these aspects, we argue that
clearly conveying customized requirements (e.g., how to handle diverse inputs)
remains a human-centric challenge. In this work, we introduce
Requirement-Oriented Prompt Engineering (ROPE), a paradigm that focuses human
attention on generating clear, complete requirements during prompting. We
implement ROPE through an assessment and training suite that provides
deliberate practice with LLM-generated feedback. In a study with 30 novices, we
show that requirement-focused training doubles novices' prompting performance,
significantly outperforming conventional prompt engineering training and prompt
optimization. We also demonstrate that high-quality LLM outputs are directly
tied to the quality of input requirements. Our work paves the way for more
effective task delegation in human-LLM collaborative prompting.",2024-09-13 12:34:14+00:00
On the Computation of BD-Rate over a Set of Videos for Fair Assessment of Performance of Learned Video Codecs,"The Bj{\o}ntegaard Delta (BD) measure is widely employed to evaluate and
quantify the variations in the rate-distortion(RD) performance across different
codecs. Many researchers report the average BD value over multiple videos
within a dataset for different codecs. We claim that the current practice in
the learned video compression community of computing the average BD value over
a dataset based on the average RD curve of multiple videos can lead to
misleading conclusions. We show both by analysis of a simplistic case of linear
RD curves and experimental results with two recent learned video codecs that
averaging RD curves can lead to a single video to disproportionately influence
the average BD value especially when the operating bitrate range of different
codecs do not exactly match. Instead, we advocate for calculating the BD
measure per-video basis, as commonly done by the traditional video compression
community, followed by averaging the individual BD values over videos, to
provide a fair comparison of learned video codecs. Our experimental results
demonstrate that the comparison of two recent learned video codecs is affected
by how we evaluate the average BD measure.",2024-09-13 12:30:15+00:00
In-depth Analysis of Low-rank Matrix Factorisation in a Federated Setting,"We analyze a distributed algorithm to compute a low-rank matrix factorization
on $N$ clients, each holding a local dataset $\mathbf{S}^i \in \mathbb{R}^{n_i
\times d}$, mathematically, we seek to solve $min_{\mathbf{U}^i \in
\mathbb{R}^{n_i\times r}, \mathbf{V}\in \mathbb{R}^{d \times r} } \frac{1}{2}
\sum_{i=1}^N \|\mathbf{S}^i - \mathbf{U}^i \mathbf{V}^\top\|^2_{\text{F}}$.
Considering a power initialization of $\mathbf{V}$, we rewrite the previous
smooth non-convex problem into a smooth strongly-convex problem that we solve
using a parallel Nesterov gradient descent potentially requiring a single step
of communication at the initialization step. For any client $i$ in $\{1, \dots,
N\}$, we obtain a global $\mathbf{V}$ in $\mathbb{R}^{d \times r}$ common to
all clients and a local variable $\mathbf{U}^i$ in $\mathbb{R}^{n_i \times r}$.
We provide a linear rate of convergence of the excess loss which depends on
$\sigma_{\max} / \sigma_{r}$, where $\sigma_{r}$ is the $r^{\mathrm{th}}$
singular value of the concatenation $\mathbf{S}$ of the matrices
$(\mathbf{S}^i)_{i=1}^N$. This result improves the rates of convergence given
in the literature, which depend on $\sigma_{\max}^2 / \sigma_{\min}^2$. We
provide an upper bound on the Frobenius-norm error of reconstruction under the
power initialization strategy. We complete our analysis with experiments on
both synthetic and real data.",2024-09-13 12:28:42+00:00
Increasing Both Batch Size and Learning Rate Accelerates Stochastic Gradient Descent,"The performance of mini-batch stochastic gradient descent (SGD) strongly
depends on setting the batch size and learning rate to minimize the empirical
loss in training the deep neural network. In this paper, we present theoretical
analyses of mini-batch SGD with four schedulers: (i) constant batch size and
decaying learning rate scheduler, (ii) increasing batch size and decaying
learning rate scheduler, (iii) increasing batch size and increasing learning
rate scheduler, and (iv) increasing batch size and warm-up decaying learning
rate scheduler. We show that mini-batch SGD using scheduler (i) does not always
minimize the expectation of the full gradient norm of the empirical loss,
whereas it does using any of schedulers (ii), (iii), and (iv). Furthermore,
schedulers (iii) and (iv) accelerate mini-batch SGD. The paper also provides
numerical results of supporting analyses showing that using scheduler (iii) or
(iv) minimizes the full gradient norm of the empirical loss faster than using
scheduler (i) or (ii).",2024-09-13 12:24:12+00:00
Causal Transformer for Fusion and Pose Estimation in Deep Visual Inertial Odometry,"In recent years, transformer-based architectures become the de facto standard
for sequence modeling in deep learning frameworks. Inspired by the successful
examples, we propose a causal visual-inertial fusion transformer (VIFT) for
pose estimation in deep visual-inertial odometry. This study aims to improve
pose estimation accuracy by leveraging the attention mechanisms in
transformers, which better utilize historical data compared to the recurrent
neural network (RNN) based methods seen in recent methods. Transformers
typically require large-scale data for training. To address this issue, we
utilize inductive biases for deep VIO networks. Since latent visual-inertial
feature vectors encompass essential information for pose estimation, we employ
transformers to refine pose estimates by updating latent vectors temporally.
Our study also examines the impact of data imbalance and rotation learning
methods in supervised end-to-end learning of visual inertial odometry by
utilizing specialized gradients in backpropagation for the elements of SE$(3)$
group. The proposed method is end-to-end trainable and requires only a
monocular camera and IMU during inference. Experimental results demonstrate
that VIFT increases the accuracy of monocular VIO networks, achieving
state-of-the-art results when compared to previous methods on the KITTI
dataset. The code will be made available at https://github.com/ybkurt/VIFT.",2024-09-13 12:21:25+00:00
Measure-Theoretic Time-Delay Embedding,"The celebrated Takens' embedding theorem provides a theoretical foundation
for reconstructing the full state of a dynamical system from partial
observations. However, the classical theorem assumes that the underlying system
is deterministic and that observations are noise-free, limiting its
applicability in real-world scenarios. Motivated by these limitations, we
rigorously establish a measure-theoretic generalization that adopts an Eulerian
description of the dynamics and recasts the embedding as a pushforward map
between probability spaces. Our mathematical results leverage recent advances
in optimal transportation theory. Building on our novel measure-theoretic
time-delay embedding theory, we have developed a new computational framework
that forecasts the full state of a dynamical system from time-lagged partial
observations, engineered with better robustness to handle sparse and noisy
data. We showcase the efficacy and versatility of our approach through several
numerical examples, ranging from the classic Lorenz-63 system to large-scale,
real-world applications such as NOAA sea surface temperature forecasting and
ERA5 wind field reconstruction.",2024-09-13 12:20:41+00:00
HOLA-Drone: Hypergraphic Open-ended Learning for Zero-Shot Multi-Drone Cooperative Pursuit,"Zero-shot coordination (ZSC) is a significant challenge in multi-agent
collaboration, aiming to develop agents that can coordinate with unseen
partners they have not encountered before. Recent cutting-edge ZSC methods have
primarily focused on two-player video games such as OverCooked!2 and Hanabi. In
this paper, we extend the scope of ZSC research to the multi-drone cooperative
pursuit scenario, exploring how to construct a drone agent capable of
coordinating with multiple unseen partners to capture multiple evaders. We
propose a novel Hypergraphic Open-ended Learning Algorithm (HOLA-Drone) that
continuously adapts the learning objective based on our hypergraphic-form game
modeling, aiming to improve cooperative abilities with multiple unknown drone
teammates. To empirically verify the effectiveness of HOLA-Drone, we build two
different unseen drone teammate pools to evaluate their performance in
coordination with various unseen partners. The experimental results demonstrate
that HOLA-Drone outperforms the baseline methods in coordination with unseen
drone teammates. Furthermore, real-world experiments validate the feasibility
of HOLA-Drone in physical systems. Videos can be found on the project
homepage~\url{https://sites.google.com/view/hola-drone}.",2024-09-13 12:20:04+00:00
SAUC: Sparsity-Aware Uncertainty Calibration for Spatiotemporal Prediction with Graph Neural Networks,"Quantifying uncertainty is crucial for robust and reliable predictions.
However, existing spatiotemporal deep learning mostly focuses on deterministic
prediction, overlooking the inherent uncertainty in such prediction.
Particularly, highly-granular spatiotemporal datasets are often sparse, posing
extra challenges in prediction and uncertainty quantification. To address these
issues, this paper introduces a novel post-hoc Sparsity-awar Uncertainty
Calibration (SAUC) framework, which calibrates uncertainty in both zero and
non-zero values. To develop SAUC, we firstly modify the state-of-the-art
deterministic spatiotemporal Graph Neural Networks (ST-GNNs) to probabilistic
ones in the pre-calibration phase. Then we calibrate the probabilistic ST-GNNs
for zero and non-zero values using quantile approaches.Through extensive
experiments, we demonstrate that SAUC can effectively fit the variance of
sparse data and generalize across two real-world spatiotemporal datasets at
various granularities. Specifically, our empirical experiments show a 20\%
reduction in calibration errors in zero entries on the sparse traffic accident
and urban crime prediction. Overall, this work demonstrates the theoretical and
empirical values of the SAUC framework, thus bridging a significant gap between
uncertainty quantification and spatiotemporal prediction.",2024-09-13 12:20:02+00:00
Energy Consumption Trends in Sound Event Detection Systems,"Deep learning systems have become increasingly energy- and
computation-intensive, raising concerns about their environmental impact. As
organizers of the Detection and Classification of Acoustic Scenes and Events
(DCASE) challenge, we recognize the importance of addressing this issue. For
the past three years, we have integrated energy consumption metrics into the
evaluation of sound event detection (SED) systems. In this paper, we analyze
the impact of this energy criterion on the challenge results and explore the
evolution of system complexity and energy consumption over the years. We
highlight a shift towards more energy-efficient approaches during training
without compromising performance, while the number of operations and system
complexity continue to grow. Through this analysis, we hope to promote more
environmentally friendly practices within the SED community.",2024-09-13 12:11:42+00:00
"Journalists, Emotions, and the Introduction of Generative AI Chatbots: A Large-Scale Analysis of Tweets Before and After the Launch of ChatGPT","As part of a broader look at the impact of generative AI, this study
investigated the emotional responses of journalists to the release of ChatGPT
at the time of its launch. By analyzing nearly 1 million Tweets from
journalists at major U.S. news outlets, we tracked changes in emotional tone
and sentiment before and after the introduction of ChatGPT in November 2022.
Using various computational and natural language processing techniques to
measure emotional shifts in response to ChatGPT's release, we found an increase
in positive emotion and a more favorable tone post-launch, suggesting initial
optimism toward AI's potential. This research underscores the pivotal role of
journalists as interpreters of technological innovation and disruption,
highlighting how their emotional reactions may shape public narratives around
emerging technologies. The study contributes to understanding the intersection
of journalism, emotion, and AI, offering insights into the broader societal
impact of generative AI tools.",2024-09-13 12:09:20+00:00
Online Network Inference from Graph-Stationary Signals with Hidden Nodes,"Graph learning is the fundamental task of estimating unknown graph
connectivity from available data. Typical approaches assume that not only is
all information available simultaneously but also that all nodes can be
observed. However, in many real-world scenarios, data can neither be known
completely nor obtained all at once. We present a novel method for online graph
estimation that accounts for the presence of hidden nodes. We consider signals
that are stationary on the underlying graph, which provides a model for the
unknown connections to hidden nodes. We then formulate a convex optimization
problem for graph learning from streaming, incomplete graph signals. We solve
the proposed problem through an efficient proximal gradient algorithm that can
run in real-time as data arrives sequentially. Additionally, we provide
theoretical conditions under which our online algorithm is similar to
batch-wise solutions. Through experimental results on synthetic and real-world
data, we demonstrate the viability of our approach for online graph learning in
the presence of missing observations.",2024-09-13 12:09:09+00:00
Uncertainty Estimation by Density Aware Evidential Deep Learning,"Evidential deep learning (EDL) has shown remarkable success in uncertainty
estimation. However, there is still room for improvement, particularly in
out-of-distribution (OOD) detection and classification tasks. The limited OOD
detection performance of EDL arises from its inability to reflect the distance
between the testing example and training data when quantifying uncertainty,
while its limited classification performance stems from its parameterization of
the concentration parameters. To address these limitations, we propose a novel
method called Density Aware Evidential Deep Learning (DAEDL). DAEDL integrates
the feature space density of the testing example with the output of EDL during
the prediction stage, while using a novel parameterization that resolves the
issues in the conventional parameterization. We prove that DAEDL enjoys a
number of favorable theoretical properties. DAEDL demonstrates state-of-the-art
performance across diverse downstream tasks related to uncertainty estimation
and classification",2024-09-13 12:04:45+00:00
A Hybrid Meta-Learning and Multi-Armed Bandit Approach for Context-Specific Multi-Objective Recommendation Optimization,"Recommender systems in online marketplaces face the challenge of balancing
multiple objectives to satisfy various stakeholders, including customers,
providers, and the platform itself. This paper introduces Juggler-MAB, a hybrid
approach that combines meta-learning with Multi-Armed Bandits (MAB) to address
the limitations of existing multi-stakeholder recommendation systems. Our
method extends the Juggler framework, which uses meta-learning to predict
optimal weights for utility and compensation adjustments, by incorporating a
MAB component for real-time, context-specific refinements. We present a
two-stage approach where Juggler provides initial weight predictions, followed
by MAB-based adjustments that adapt to rapid changes in user behavior and
market conditions. Our system leverages contextual features such as device type
and brand to make fine-grained weight adjustments based on specific segments.
To evaluate our approach, we developed a simulation framework using a dataset
of 0.6 million searches from Expedia's lodging booking platform. Results show
that Juggler-MAB outperforms the original Juggler model across all metrics,
with NDCG improvements of 2.9%, a 13.7% reduction in regret, and a 9.8%
improvement in best arm selection rate.",2024-09-13 12:03:23+00:00
Uncertainty and Generalizability in Foundation Models for Earth Observation,"We take the perspective in which we want to design a downstream task (such as
estimating vegetation coverage) on a certain area of interest (AOI) with a
limited labeling budget. By leveraging an existing Foundation Model (FM) we
must decide whether we train a downstream model on a different but label-rich
AOI hoping it generalizes to our AOI, or we split labels in our AOI for
training and validating. In either case, we face choices concerning what FM to
use, how to sample our AOI for labeling, etc. which affect both the performance
and uncertainty of the results. In this work, we perform a large ablative study
using eight existing FMs on either Sentinel 1 or Sentinel 2 as input data, and
the classes from the ESA World Cover product as downstream tasks across eleven
AOIs. We do repeated sampling and training, resulting in an ablation of some
500K simple linear regression models. Our results show both the limits of
spatial generalizability across AOIs and the power of FMs where we are able to
get over 0.9 correlation coefficient between predictions and targets on
different chip level predictive tasks. And still, performance and uncertainty
vary greatly across AOIs, tasks and FMs. We believe this is a key issue in
practice, because there are many design decisions behind each FM and downstream
task (input modalities, sampling, architectures, pretraining, etc.) and usually
a downstream task designer is aware of and can decide upon a few of them.
Through this work, we advocate for the usage of the methodology herein
described (large ablations on reference global labels and simple probes), both
when publishing new FMs, and to make informed decisions when designing
downstream tasks to use them.",2024-09-13 11:52:16+00:00
Adaptive Sampling for Continuous Group Equivariant Neural Networks,"Steerable networks, which process data with intrinsic symmetries, often use
Fourier-based nonlinearities that require sampling from the entire group,
leading to a need for discretization in continuous groups. As the number of
samples increases, both performance and equivariance improve, yet this also
leads to higher computational costs. To address this, we introduce an adaptive
sampling approach that dynamically adjusts the sampling process to the
symmetries in the data, reducing the number of required group samples and
lowering the computational demands. We explore various implementations and
their effects on model performance, equivariance, and computational efficiency.
Our findings demonstrate improved model performance, and a marginal increase in
memory efficiency.",2024-09-13 11:50:09+00:00
Multi-intent Aware Contrastive Learning for Sequential Recommendation,"Intent is a significant latent factor influencing user-item interaction
sequences. Prevalent sequence recommendation models that utilize contrastive
learning predominantly rely on single-intent representations to direct the
training process. However, this paradigm oversimplifies real-world
recommendation scenarios, attempting to encapsulate the diversity of intents
within the single-intent level representation. SR models considering
multi-intent information in their framework are more likely to reflect
real-life recommendation scenarios accurately.",2024-09-13 11:34:28+00:00
Bridging Dynamic Factor Models and Neural Controlled Differential Equations for Nowcasting GDP,"Gross domestic product (GDP) nowcasting is crucial for policy-making as GDP
growth is a key indicator of economic conditions. Dynamic factor models (DFMs)
have been widely adopted by government agencies for GDP nowcasting due to their
ability to handle irregular or missing macroeconomic indicators and their
interpretability. However, DFMs face two main challenges: i) the lack of
capturing economic uncertainties such as sudden recessions or booms, and ii)
the limitation of capturing irregular dynamics from mixed-frequency data. To
address these challenges, we introduce NCDENow, a novel GDP nowcasting
framework that integrates neural controlled differential equations (NCDEs) with
DFMs. This integration effectively handles the dynamics of irregular time
series. NCDENow consists of 3 main modules: i) factor extraction leveraging
DFM, ii) dynamic modeling using NCDE, and iii) GDP growth prediction through
regression. We evaluate NCDENow against 6 baselines on 2 real-world GDP
datasets from South Korea and the United Kingdom, demonstrating its enhanced
predictive capability. Our empirical results favor our method, highlighting the
significant potential of integrating NCDE into nowcasting models. Our code and
dataset are available at https://github.com/sklim84/NCDENow_CIKM2024.",2024-09-13 11:33:57+00:00
Disentangling the sources of cyber risk premia,"We use a methodology based on a machine learning algorithm to quantify firms'
cyber risks based on their disclosures and a dedicated cyber corpus. The model
can identify paragraphs related to determined cyber-threat types and
accordingly attribute several related cyber scores to the firm. The cyber
scores are unrelated to other firms' characteristics. Stocks with high cyber
scores significantly outperform other stocks. The long-short cyber risk factors
have positive risk premia, are robust to all factors' benchmarks, and help
price returns. Furthermore, we suggest the market does not distinguish between
different types of cyber risks but instead views them as a single, aggregate
cyber risk.",2024-09-13 11:30:42+00:00
Quasimetric Value Functions with Dense Rewards,"As a generalization of reinforcement learning (RL) to parametrizable goals,
goal conditioned RL (GCRL) has a broad range of applications, particularly in
challenging tasks in robotics. Recent work has established that the optimal
value function of GCRL $Q^\ast(s,a,g)$ has a quasimetric structure, leading to
targetted neural architectures that respect such structure. However, the
relevant analyses assume a sparse reward setting -- a known aggravating factor
to sample complexity. We show that the key property underpinning a quasimetric,
viz., the triangle inequality, is preserved under a dense reward setting as
well. Contrary to earlier findings where dense rewards were shown to be
detrimental to GCRL, we identify the key condition necessary for triangle
inequality. Dense reward functions that satisfy this condition can only
improve, never worsen, sample complexity. This opens up opportunities to train
efficient neural architectures with dense rewards, compounding their benefits
to sample complexity. We evaluate this proposal in 12 standard benchmark
environments in GCRL featuring challenging continuous control tasks. Our
empirical results confirm that training a quasimetric value function in our
dense reward setting indeed outperforms training with sparse rewards.",2024-09-13 11:26:05+00:00
Distilling Monolingual and Crosslingual Word-in-Context Representations,"In this study, we propose a method that distils representations of word
meaning in context from a pre-trained masked language model in both monolingual
and crosslingual settings. Word representations are the basis for context-aware
lexical semantics and unsupervised semantic textual similarity (STS)
estimation. Different from existing approaches, our method does not require
human-annotated corpora nor updates of the parameters of the pre-trained model.
The latter feature is appealing for practical scenarios where the off-the-shelf
pre-trained model is a common asset among different applications. Specifically,
our method learns to combine the outputs of different hidden layers of the
pre-trained model using self-attention. Our auto-encoder based training only
requires an automatically generated corpus. To evaluate the performance of the
proposed approach, we performed extensive experiments using various benchmark
tasks. The results on the monolingual tasks confirmed that our representations
exhibited a competitive performance compared to that of the previous study for
the context-aware lexical semantic tasks and outperformed it for STS
estimation. The results of the crosslingual tasks revealed that the proposed
method largely improved crosslingual word representations of multilingual
pre-trained models.",2024-09-13 11:10:16+00:00
Layerwise Change of Knowledge in Neural Networks,"This paper aims to explain how a deep neural network (DNN) gradually extracts
new knowledge and forgets noisy features through layers in forward propagation.
Up to now, although the definition of knowledge encoded by the DNN has not
reached a consensus, Previous studies have derived a series of mathematical
evidence to take interactions as symbolic primitive inference patterns encoded
by a DNN. We extend the definition of interactions and, for the first time,
extract interactions encoded by intermediate layers. We quantify and track the
newly emerged interactions and the forgotten interactions in each layer during
the forward propagation, which shed new light on the learning behavior of DNNs.
The layer-wise change of interactions also reveals the change of the
generalization capacity and instability of feature representations of a DNN.",2024-09-13 10:59:24+00:00
Text-To-Speech Synthesis In The Wild,"Text-to-speech (TTS) systems are traditionally trained using modest databases
of studio-quality, prompted or read speech collected in benign acoustic
environments such as anechoic rooms. The recent literature nonetheless shows
efforts to train TTS systems using data collected in the wild. While this
approach allows for the use of massive quantities of natural speech, until now,
there are no common datasets. We introduce the TTS In the Wild (TITW) dataset,
the result of a fully automated pipeline, in this case, applied to the
VoxCeleb1 dataset commonly used for speaker recognition. We further propose two
training sets. TITW-Hard is derived from the transcription, segmentation, and
selection of VoxCeleb1 source data. TITW-Easy is derived from the additional
application of enhancement and additional data selection based on DNSMOS. We
show that a number of recent TTS models can be trained successfully using
TITW-Easy, but that it remains extremely challenging to produce similar results
using TITW-Hard. Both the dataset and protocols are publicly available and
support the benchmarking of TTS systems trained using TITW data.",2024-09-13 10:58:55+00:00
L3Cube-IndicQuest: A Benchmark Questing Answering Dataset for Evaluating Knowledge of LLMs in Indic Context,"Large Language Models (LLMs) have made significant progress in incorporating
Indic languages within multilingual models. However, it is crucial to
quantitatively assess whether these languages perform comparably to globally
dominant ones, such as English. Currently, there is a lack of benchmark
datasets specifically designed to evaluate the regional knowledge of LLMs in
various Indic languages. In this paper, we present the L3Cube-IndicQuest, a
gold-standard question-answering benchmark dataset designed to evaluate how
well multilingual LLMs capture regional knowledge across various Indic
languages. The dataset contains 200 question-answer pairs, each for English and
19 Indic languages, covering five domains specific to the Indic region. We aim
for this dataset to serve as a benchmark, providing ground truth for evaluating
the performance of LLMs in understanding and representing knowledge relevant to
the Indian context. The IndicQuest can be used for both reference-based
evaluation and LLM-as-a-judge evaluation. The dataset is shared publicly at
https://github.com/l3cube-pune/indic-nlp .",2024-09-13 10:48:35+00:00
NeSHFS: Neighborhood Search with Heuristic-based Feature Selection for Click-Through Rate Prediction,"Click-through-rate (CTR) prediction plays an important role in online
advertising and ad recommender systems. In the past decade, maximizing CTR has
been the main focus of model development and solution creation. Therefore,
researchers and practitioners have proposed various models and solutions to
enhance the effectiveness of CTR prediction. Most of the existing literature
focuses on capturing either implicit or explicit feature interactions. Although
implicit interactions are successfully captured in some studies, explicit
interactions present a challenge for achieving high CTR by extracting both
low-order and high-order feature interactions. Unnecessary and irrelevant
features may cause high computational time and low prediction performance.
Furthermore, certain features may perform well with specific predictive models
while underperforming with others. Also, feature distribution may fluctuate due
to traffic variations. Most importantly, in live production environments,
resources are limited, and the time for inference is just as crucial as
training time. Because of all these reasons, feature selection is one of the
most important factors in enhancing CTR prediction model performance. Simple
filter-based feature selection algorithms do not perform well and they are not
sufficient. An effective and efficient feature selection algorithm is needed to
consistently filter the most useful features during live CTR prediction
process. In this paper, we propose a heuristic algorithm named Neighborhood
Search with Heuristic-based Feature Selection (NeSHFS) to enhance CTR
prediction performance while reducing dimensionality and training time costs.
We conduct comprehensive experiments on three public datasets to validate the
efficiency and effectiveness of our proposed solution.",2024-09-13 10:43:18+00:00
DM: Dual-path Magnitude Network for General Speech Restoration,"In this paper, we introduce a novel general speech restoration model: the
Dual-path Magnitude (DM) network, designed to address multiple distortions
including noise, reverberation, and bandwidth degradation effectively. The DM
network employs dual parallel magnitude decoders that share parameters: one
uses a masking-based algorithm for distortion removal and the other employs a
mapping-based approach for speech restoration. A novel aspect of the DM network
is the integration of the magnitude spectrogram output from the masking decoder
into the mapping decoder through a skip connection, enhancing the overall
restoration capability. This integrated approach overcomes the inherent
limitations observed in previous models, as detailed in a step-by-step
analysis. The experimental results demonstrate that the DM network outperforms
other baseline models in the comprehensive aspect of general speech
restoration, achieving substantial restoration with fewer parameters.",2024-09-13 10:42:59+00:00
Personalized Weight Loss Management through Wearable Devices and Artificial Intelligence,"Early detection of chronic and Non-Communicable Diseases (NCDs) is crucial
for effective treatment during the initial stages. This study explores the
application of wearable devices and Artificial Intelligence (AI) in order to
predict weight loss changes in overweight and obese individuals. Using wearable
data from a 1-month trial involving around 100 subjects from the AI4FoodDB
database, including biomarkers, vital signs, and behavioral data, we identify
key differences between those achieving weight loss (>= 2% of their initial
weight) and those who do not. Feature selection techniques and classification
algorithms reveal promising results, with the Gradient Boosting classifier
achieving 84.44% Area Under the Curve (AUC). The integration of multiple data
sources (e.g., vital signs, physical and sleep activity, etc.) enhances
performance, suggesting the potential of wearable devices and AI in
personalized healthcare.",2024-09-13 10:39:36+00:00
Precision Aquaculture: An Integrated Computer Vision and IoT Approach for Optimized Tilapia Feeding,"Traditional fish farming practices often lead to inefficient feeding,
resulting in environmental issues and reduced productivity. We developed an
innovative system combining computer vision and IoT technologies for precise
Tilapia feeding. Our solution uses real-time IoT sensors to monitor water
quality parameters and computer vision algorithms to analyze fish size and
count, determining optimal feed amounts. A mobile app enables remote monitoring
and control. We utilized YOLOv8 for keypoint detection to measure Tilapia
weight from length, achieving \textbf{94\%} precision on 3,500 annotated
images. Pixel-based measurements were converted to centimeters using depth
estimation for accurate feeding calculations. Our method, with data collection
mirroring inference conditions, significantly improved results. Preliminary
estimates suggest this approach could increase production up to 58 times
compared to traditional farms. Our models, code, and dataset are
open-source~\footnote{The code, dataset, and models are available upon
reasonable request.",2024-09-13 10:27:27+00:00
B4: Towards Optimal Assessment of Plausible Code Solutions with Plausible Tests,"Selecting the best code solution from multiple generated ones is an essential
task in code generation, which can be achieved by using some reliable
validators (e.g., developer-written test cases) for assistance. Since reliable
test cases are not always available and can be expensive to build in practice,
researchers propose to automatically generate test cases to assess code
solutions. However, when both code solutions and test cases are plausible and
not reliable, selecting the best solution becomes challenging. Although some
heuristic strategies have been proposed to tackle this problem, they lack a
strong theoretical guarantee and it is still an open question whether an
optimal selection strategy exists. Our work contributes in two ways. First, we
show that within a Bayesian framework, the optimal selection strategy can be
defined based on the posterior probability of the observed passing states
between solutions and tests. The problem of identifying the best solution is
then framed as an integer programming problem. Second, we propose an efficient
approach for approximating this optimal (yet uncomputable) strategy, where the
approximation error is bounded by the correctness of prior knowledge. We then
incorporate effective prior knowledge to tailor code generation tasks. Both
theoretical and empirical studies confirm that existing heuristics are limited
in selecting the best solutions with plausible test cases. Our proposed
approximated optimal strategy B4 significantly surpasses existing heuristics in
selecting code solutions generated by large language models (LLMs) with
LLM-generated tests, achieving a relative performance improvement by up to 50%
over the strongest heuristic and 246% over the random selection in the most
challenging scenarios. Our code is publicly available at
https://github.com/ZJU-CTAG/B4.",2024-09-13 10:22:08+00:00
Autoregressive Sequence Modeling for 3D Medical Image Representation,"Three-dimensional (3D) medical images, such as Computed Tomography (CT) and
Magnetic Resonance Imaging (MRI), are essential for clinical applications.
However, the need for diverse and comprehensive representations is particularly
pronounced when considering the variability across different organs, diagnostic
tasks, and imaging modalities. How to effectively interpret the intricate
contextual information and extract meaningful insights from these images
remains an open challenge to the community. While current self-supervised
learning methods have shown potential, they often consider an image as a whole
thereby overlooking the extensive, complex relationships among local regions
from one or multiple images. In this work, we introduce a pioneering method for
learning 3D medical image representations through an autoregressive
pre-training framework. Our approach sequences various 3D medical images based
on spatial, contrast, and semantic correlations, treating them as
interconnected visual tokens within a token sequence. By employing an
autoregressive sequence modeling task, we predict the next visual token in the
sequence, which allows our model to deeply understand and integrate the
contextual information inherent in 3D medical images. Additionally, we
implement a random startup strategy to avoid overestimating token relationships
and to enhance the robustness of learning. The effectiveness of our approach is
demonstrated by the superior performance over others on nine downstream tasks
in public datasets.",2024-09-13 10:19:10+00:00
GenMapping: Unleashing the Potential of Inverse Perspective Mapping for Robust Online HD Map Construction,"Online High-Definition (HD) maps have emerged as the preferred option for
autonomous driving, overshadowing the counterpart offline HD maps due to
flexible update capability and lower maintenance costs. However, contemporary
online HD map models embed parameters of visual sensors into training,
resulting in a significant decrease in generalization performance when applied
to visual sensors with different parameters. Inspired by the inherent potential
of Inverse Perspective Mapping (IPM), where camera parameters are decoupled
from the training process, we have designed a universal map generation
framework, GenMapping. The framework is established with a triadic synergy
architecture, including principal and dual auxiliary branches. When faced with
a coarse road image with local distortion translated via IPM, the principal
branch learns robust global features under the state space models. The two
auxiliary branches are a dense perspective branch and a sparse prior branch.
The former exploits the correlation information between static and moving
objects, whereas the latter introduces the prior knowledge of OpenStreetMap
(OSM). The triple-enhanced merging module is crafted to synergistically
integrate the unique spatial features from all three branches. To further
improve generalization capabilities, a Cross-View Map Learning (CVML) scheme is
leveraged to realize joint learning within the common space. Additionally, a
Bidirectional Data Augmentation (BiDA) module is introduced to mitigate
reliance on datasets concurrently. A thorough array of experimental results
shows that the proposed model surpasses current state-of-the-art methods in
both semantic mapping and vectorized mapping, while also maintaining a rapid
inference speed. The source code will be publicly available at
https://github.com/lynn-yu/GenMapping.",2024-09-13 10:15:28+00:00
xTED: Cross-Domain Policy Adaptation via Diffusion-Based Trajectory Editing,"Reusing pre-collected data from different domains is an attractive solution
in decision-making tasks where the accessible data is insufficient in the
target domain but relatively abundant in other related domains. Existing
cross-domain policy transfer methods mostly aim at learning domain
correspondences or corrections to facilitate policy learning, which requires
learning domain/task-specific model components, representations, or policies
that are inflexible or not fully reusable to accommodate arbitrary domains and
tasks. These issues make us wonder: can we directly bridge the domain gap at
the data (trajectory) level, instead of devising complicated, domain-specific
policy transfer models? In this study, we propose a Cross-Domain Trajectory
EDiting (xTED) framework with a new diffusion transformer model (Decision
Diffusion Transformer, DDiT) that captures the trajectory distribution from the
target dataset as a prior. The proposed diffusion transformer backbone captures
the intricate dependencies among state, action, and reward sequences, as well
as the transition dynamics within the target data trajectories. With the above
pre-trained diffusion prior, source data trajectories with domain gaps can be
transformed into edited trajectories that closely resemble the target data
distribution through the diffusion-based editing process, which implicitly
corrects the underlying domain gaps, enhancing the state realism and dynamics
reliability in source trajectory data, while enabling flexible choices of
downstream policy learning methods. Despite its simplicity, xTED demonstrates
superior performance against other baselines in extensive simulation and
real-robot experiments.",2024-09-13 10:07:28+00:00
NEST-RQ: Next Token Prediction for Speech Self-Supervised Pre-Training,"Speech self-supervised pre-training can effectively improve the performance
of downstream tasks. However, previous self-supervised learning (SSL) methods
for speech, such as HuBERT and BEST-RQ, focus on utilizing non-causal encoders
with bidirectional context, and lack sufficient support for downstream
streaming models. To address this issue, we introduce the next token prediction
based speech pre-training method with random-projection quantizer (NEST-RQ).
NEST-RQ employs causal encoders with only left context and uses next token
prediction (NTP) as the training task. On the large-scale dataset, compared to
BEST-RQ, the proposed NEST-RQ achieves comparable performance on non-streaming
automatic speech recognition (ASR) and better performance on streaming ASR. We
also conduct analytical experiments in terms of the future context size of
streaming ASR, the codebook quality of SSL and the model size of the encoder.
In summary, the paper demonstrates the feasibility of the NTP in speech SSL and
provides empirical evidence and insights for speech SSL research.",2024-09-13 09:48:11+00:00
Shadow Program Inversion with Differentiable Planning: A Framework for Unified Robot Program Parameter and Trajectory Optimization,"This paper presents SPI-DP, a novel first-order optimizer capable of
optimizing robot programs with respect to both high-level task objectives and
motion-level constraints. To that end, we introduce DGPMP2-ND, a differentiable
collision-free motion planner for serial N-DoF kinematics, and integrate it
into an iterative, gradient-based optimization approach for generic,
parameterized robot program representations. SPI-DP allows first-order
optimization of planned trajectories and program parameters with respect to
objectives such as cycle time or smoothness subject to e.g. collision
constraints, while enabling humans to understand, modify or even certify the
optimized programs. We provide a comprehensive evaluation on two practical
household and industrial applications.",2024-09-13 09:46:41+00:00
Redesigning graph filter-based GNNs to relax the homophily assumption,"Graph neural networks (GNNs) have become a workhorse approach for learning
from data defined over irregular domains, typically by implicitly assuming that
the data structure is represented by a homophilic graph. However, recent works
have revealed that many relevant applications involve heterophilic data where
the performance of GNNs can be notably compromised. To address this challenge,
we present a simple yet effective architecture designed to mitigate the
limitations of the homophily assumption. The proposed architecture reinterprets
the role of graph filters in convolutional GNNs, resulting in a more general
architecture while incorporating a stronger inductive bias than GNNs based on
filter banks. The proposed convolutional layer enhances the expressive capacity
of the architecture enabling it to learn from both homophilic and heterophilic
data and preventing the issue of oversmoothing. From a theoretical standpoint,
we show that the proposed architecture is permutation equivariant. Finally, we
show that the proposed GNNs compares favorably relative to several
state-of-the-art baselines in both homophilic and heterophilic datasets,
showcasing its promising potential.",2024-09-13 09:43:36+00:00
Acoustic identification of individual animals with hierarchical contrastive learning,"Acoustic identification of individual animals (AIID) is closely related to
audio-based species classification but requires a finer level of detail to
distinguish between individual animals within the same species. In this work,
we frame AIID as a hierarchical multi-label classification task and propose the
use of hierarchy-aware loss functions to learn robust representations of
individual identities that maintain the hierarchical relationships among
species and taxa. Our results demonstrate that hierarchical embeddings not only
enhance identification accuracy at the individual level but also at higher
taxonomic levels, effectively preserving the hierarchical structure in the
learned representations. By comparing our approach with non-hierarchical
models, we highlight the advantage of enforcing this structure in the embedding
space. Additionally, we extend the evaluation to the classification of novel
individual classes, demonstrating the potential of our method in open-set
classification scenarios.",2024-09-13 09:37:44+00:00
AdR-Gaussian: Accelerating Gaussian Splatting with Adaptive Radius,"3D Gaussian Splatting (3DGS) is a recent explicit 3D representation that has
achieved high-quality reconstruction and real-time rendering of complex scenes.
However, the rasterization pipeline still suffers from unnecessary overhead
resulting from avoidable serial Gaussian culling, and uneven load due to the
distinct number of Gaussian to be rendered across pixels, which hinders wider
promotion and application of 3DGS. In order to accelerate Gaussian splatting,
we propose AdR-Gaussian, which moves part of serial culling in Render stage
into the earlier Preprocess stage to enable parallel culling, employing
adaptive radius to narrow the rendering pixel range for each Gaussian, and
introduces a load balancing method to minimize thread waiting time during the
pixel-parallel rendering. Our contributions are threefold, achieving a
rendering speed of 310% while maintaining equivalent or even better quality
than the state-of-the-art. Firstly, we propose to early cull Gaussian-Tile
pairs of low splatting opacity based on an adaptive radius in the
Gaussian-parallel Preprocess stage, which reduces the number of affected tile
through the Gaussian bounding circle, thus reducing unnecessary overhead and
achieving faster rendering speed. Secondly, we further propose early culling
based on axis-aligned bounding box for Gaussian splatting, which achieves a
more significant reduction in ineffective expenses by accurately calculating
the Gaussian size in the 2D directions. Thirdly, we propose a balancing
algorithm for pixel thread load, which compresses the information of heavy-load
pixels to reduce thread waiting time, and enhance information of light-load
pixels to hedge against rendering quality loss. Experiments on three datasets
demonstrate that our algorithm can significantly improve the Gaussian Splatting
rendering speed.",2024-09-13 09:32:38+00:00
Test-time Training for Hyperspectral Image Super-resolution,"The progress on Hyperspectral image (HSI) super-resolution (SR) is still
lagging behind the research of RGB image SR. HSIs usually have a high number of
spectral bands, so accurately modeling spectral band interaction for HSI SR is
hard. Also, training data for HSI SR is hard to obtain so the dataset is
usually rather small. In this work, we propose a new test-time training method
to tackle this problem. Specifically, a novel self-training framework is
developed, where more accurate pseudo-labels and more accurate LR-HR
relationships are generated so that the model can be further trained with them
to improve performance. In order to better support our test-time training
method, we also propose a new network architecture to learn HSI SR without
modeling spectral band interaction and propose a new data augmentation method
Spectral Mixup to increase the diversity of the training data at test time. We
also collect a new HSI dataset with a diverse set of images of interesting
objects ranging from food to vegetation, to materials, and to general scenes.
Extensive experiments on multiple datasets show that our method can improve the
performance of pre-trained models significantly after test-time training and
outperform competing methods significantly for HSI SR.",2024-09-13 09:30:19+00:00
"Towards certifiable AI in aviation: landscape, challenges, and opportunities","Artificial Intelligence (AI) methods are powerful tools for various domains,
including critical fields such as avionics, where certification is required to
achieve and maintain an acceptable level of safety. General solutions for
safety-critical systems must address three main questions: Is it suitable? What
drives the system's decisions? Is it robust to errors/attacks? This is more
complex in AI than in traditional methods. In this context, this paper presents
a comprehensive mind map of formal AI certification in avionics. It highlights
the challenges of certifying AI development with an example to emphasize the
need for qualification beyond performance metrics.",2024-09-13 09:27:59+00:00
Investigating Disentanglement in a Phoneme-level Speech Codec for Prosody Modeling,"Most of the prevalent approaches in speech prosody modeling rely on learning
global style representations in a continuous latent space which encode and
transfer the attributes of reference speech. However, recent work on neural
codecs which are based on Residual Vector Quantization (RVQ) already shows
great potential offering distinct advantages. We investigate the prosody
modeling capabilities of the discrete space of such an RVQ-VAE model, modifying
it to operate on the phoneme-level. We condition both the encoder and decoder
of the model on linguistic representations and apply a global speaker embedding
in order to factor out both phonetic and speaker information. We conduct an
extensive set of investigations based on subjective experiments and objective
measures to show that the phoneme-level discrete latent representations
obtained this way achieves a high degree of disentanglement, capturing
fine-grained prosodic information that is robust and transferable. The latent
space turns out to have interpretable structure with its principal components
corresponding to pitch and energy.",2024-09-13 09:27:05+00:00
Online Learning Of Expanding Graphs,"This paper addresses the problem of online network topology inference for
expanding graphs from a stream of spatiotemporal signals. Online algorithms for
dynamic graph learning are crucial in delay-sensitive applications or when
changes in topology occur rapidly. While existing works focus on inferring the
connectivity within a fixed set of nodes, in practice, the graph can grow as
new nodes join the network. This poses additional challenges like modeling
temporal dynamics involving signals and graphs of different sizes. This growth
also increases the computational complexity of the learning process, which may
become prohibitive. To the best of our knowledge, this is the first work to
tackle this setting. We propose a general online algorithm based on projected
proximal gradient descent that accounts for the increasing graph size at each
iteration. Recursively updating the sample covariance matrix is a key aspect of
our approach. We introduce a strategy that enables different types of updates
for nodes that just joined the network and for previously existing nodes. To
provide further insights into the proposed method, we specialize it in Gaussian
Markov random field settings, where we analyze the computational complexity and
characterize the dynamic cumulative regret. Finally, we demonstrate the
effectiveness of the proposed approach using both controlled experiments and
real-world datasets from epidemic and financial networks.",2024-09-13 09:20:42+00:00
Promoting Fairness in Link Prediction with Graph Enhancement,"Link prediction is a crucial task in network analysis, but it has been shown
to be prone to biased predictions, particularly when links are unfairly
predicted between nodes from different sensitive groups. In this paper, we
study the fair link prediction problem, which aims to ensure that the predicted
link probability is independent of the sensitive attributes of the connected
nodes. Existing methods typically incorporate debiasing techniques within graph
embeddings to mitigate this issue. However, training on large real-world graphs
is already challenging, and adding fairness constraints can further complicate
the process. To overcome this challenge, we propose FairLink, a method that
learns a fairness-enhanced graph to bypass the need for debiasing during the
link predictor's training. FairLink maintains link prediction accuracy by
ensuring that the enhanced graph follows a training trajectory similar to that
of the original input graph. Meanwhile, it enhances fairness by minimizing the
absolute difference in link probabilities between node pairs within the same
sensitive group and those between node pairs from different sensitive groups.
Our extensive experiments on multiple large-scale graphs demonstrate that
FairLink not only promotes fairness but also often achieves link prediction
accuracy comparable to baseline methods. Most importantly, the enhanced graph
exhibits strong generalizability across different GNN architectures.",2024-09-13 09:18:29+00:00
LMAC-TD: Producing Time Domain Explanations for Audio Classifiers,"Neural networks are typically black-boxes that remain opaque with regards to
their decision mechanisms. Several works in the literature have proposed
post-hoc explanation methods to alleviate this issue. This paper proposes
LMAC-TD, a post-hoc explanation method that trains a decoder to produce
explanations directly in the time domain. This methodology builds upon the
foundation of L-MAC, Listenable Maps for Audio Classifiers, a method that
produces faithful and listenable explanations. We incorporate SepFormer, a
popular transformer-based time-domain source separation architecture. We show
through a user study that LMAC-TD significantly improves the audio quality of
the produced explanations while not sacrificing from faithfulness.",2024-09-13 09:14:06+00:00
SkinFormer: Learning Statistical Texture Representation with Transformer for Skin Lesion Segmentation,"Accurate skin lesion segmentation from dermoscopic images is of great
importance for skin cancer diagnosis. However, automatic segmentation of
melanoma remains a challenging task because it is difficult to incorporate
useful texture representations into the learning process. Texture
representations are not only related to the local structural information
learned by CNN, but also include the global statistical texture information of
the input image. In this paper, we propose a trans\textbf{Former} network
(\textbf{SkinFormer}) that efficiently extracts and fuses statistical texture
representation for \textbf{Skin} lesion segmentation. Specifically, to quantify
the statistical texture of input features, a Kurtosis-guided Statistical
Counting Operator is designed. We propose Statistical Texture Fusion
Transformer and Statistical Texture Enhance Transformer with the help of
Kurtosis-guided Statistical Counting Operator by utilizing the transformer's
global attention mechanism. The former fuses structural texture information and
statistical texture information, and the latter enhances the statistical
texture of multi-scale features. {Extensive experiments on three publicly
available skin lesion datasets validate that our SkinFormer outperforms other
SOAT methods, and our method achieves 93.2\% Dice score on ISIC 2018. It can be
easy to extend SkinFormer to segment 3D images in the future.} Our code is
available at https://github.com/Rongtao-Xu/SkinFormer.",2024-09-13 09:11:52+00:00
Training Gradient Boosted Decision Trees on Tabular Data Containing Label Noise for Classification Tasks,"Label noise refers to the phenomenon where instances in a data set are
assigned to the wrong label. Label noise is harmful to classifier performance,
increases model complexity and impairs feature selection. Addressing label
noise is crucial, yet current research primarily focuses on image and text data
using deep neural networks. This leaves a gap in the study of tabular data and
gradient-boosted decision trees (GBDTs), the leading algorithm for tabular
data. Different methods have already been developed which either try to filter
label noise, model label noise while simultaneously training a classifier or
use learning algorithms which remain effective even if label noise is present.
This study aims to further investigate the effects of label noise on
gradient-boosted decision trees and methods to mitigate those effects. Through
comprehensive experiments and analysis, the implemented methods demonstrate
state-of-the-art noise detection performance on the Adult dataset and achieve
the highest classification precision and recall on the Adult and Breast Cancer
datasets, respectively. In summary, this paper enhances the understanding of
the impact of label noise on GBDTs and lays the groundwork for future research
in noise detection and correction methods.",2024-09-13 09:09:24+00:00
CPL: Critical Planning Step Learning Boosts LLM Generalization in Reasoning Tasks,"Post-training large language models (LLMs) to develop reasoning capabilities
has proven effective across diverse domains, such as mathematical reasoning and
code generation. However, existing methods primarily focus on improving
task-specific reasoning but have not adequately addressed the model's
generalization capabilities across a broader range of reasoning tasks. To
tackle this challenge, we introduce Critical Planning Step Learning (CPL),
which leverages Monte Carlo Tree Search (MCTS) to explore diverse planning
steps in multi-step reasoning tasks. Based on long-term outcomes, CPL learns
step-level planning preferences to improve the model's planning capabilities
and, consequently, its general reasoning capabilities. Furthermore, while
effective in many scenarios for aligning LLMs, existing preference learning
approaches like Direct Preference Optimization (DPO) struggle with complex
multi-step reasoning tasks due to their inability to capture fine-grained
supervision at each step. We propose Step-level Advantage Preference
Optimization (Step-APO), which integrates an advantage estimate for step-level
preference pairs obtained via MCTS into the DPO. This enables the model to more
effectively learn critical intermediate planning steps, thereby further
improving its generalization in reasoning tasks. Experimental results
demonstrate that our method, trained exclusively on GSM8K and MATH, not only
significantly improves performance on GSM8K (+10.5%) and MATH (+6.5%), but also
enhances out-of-domain reasoning benchmarks, such as ARC-C (+4.0%), BBH
(+1.8%), MMLU-STEM (+2.2%), and MMLU (+0.9%).",2024-09-13 08:59:31+00:00
Developing an Algorithm Selector for Green Configuration in Scheduling Problems,"The Job Shop Scheduling Problem (JSP) is central to operations research,
primarily optimizing energy efficiency due to its profound environmental and
economic implications. Efficient scheduling enhances production metrics and
mitigates energy consumption, thus effectively balancing productivity and
sustainability objectives. Given the intricate and diverse nature of JSP
instances, along with the array of algorithms developed to tackle these
challenges, an intelligent algorithm selection tool becomes paramount. This
paper introduces a framework designed to identify key problem features that
characterize its complexity and guide the selection of suitable algorithms.
Leveraging machine learning techniques, particularly XGBoost, the framework
recommends optimal solvers such as GUROBI, CPLEX, and GECODE for efficient JSP
scheduling. GUROBI excels with smaller instances, while GECODE demonstrates
robust scalability for complex scenarios. The proposed algorithm selector
achieves an accuracy of 84.51\% in recommending the best algorithm for solving
new JSP instances, highlighting its efficacy in algorithm selection. By
refining feature extraction methodologies, the framework aims to broaden its
applicability across diverse JSP scenarios, thereby advancing efficiency and
sustainability in manufacturing logistics.",2024-09-13 08:58:24+00:00
Byzantine-Robust and Communication-Efficient Distributed Learning via Compressed Momentum Filtering,"Distributed learning has become the standard approach for training
large-scale machine learning models across private data silos. While
distributed learning enhances privacy preservation and training efficiency, it
faces critical challenges related to Byzantine robustness and communication
reduction. Existing Byzantine-robust and communication-efficient methods rely
on full gradient information either at every iteration or at certain iterations
with a probability, and they only converge to an unnecessarily large
neighborhood around the solution. Motivated by these issues, we propose a novel
Byzantine-robust and communication-efficient stochastic distributed learning
method that imposes no requirements on batch size and converges to a smaller
neighborhood around the optimal solution than all existing methods, aligning
with the theoretical lower bound. Our key innovation is leveraging Polyak
Momentum to mitigate the noise caused by both biased compressors and stochastic
gradients, thus defending against Byzantine workers under information
compression. We provide proof of tight complexity bounds for our algorithm in
the context of non-convex smooth loss functions, demonstrating that these
bounds match the lower bounds in Byzantine-free scenarios. Finally, we validate
the practical significance of our algorithm through an extensive series of
experiments, benchmarking its performance on both binary classification and
image classification tasks.",2024-09-13 08:53:10+00:00
Utilizing Data Fingerprints for Privacy-Preserving Algorithm Selection in Time Series Classification: Performance and Uncertainty Estimation on Unseen Datasets,"The selection of algorithms is a crucial step in designing AI services for
real-world time series classification use cases. Traditional methods such as
neural architecture search, automated machine learning, combined algorithm
selection, and hyperparameter optimizations are effective but require
considerable computational resources and necessitate access to all data points
to run their optimizations. In this work, we introduce a novel data fingerprint
that describes any time series classification dataset in a privacy-preserving
manner and provides insight into the algorithm selection problem without
requiring training on the (unseen) dataset. By decomposing the multi-target
regression problem, only our data fingerprints are used to estimate algorithm
performance and uncertainty in a scalable and adaptable manner. Our approach is
evaluated on the 112 University of California riverside benchmark datasets,
demonstrating its effectiveness in predicting the performance of 35
state-of-the-art algorithms and providing valuable insights for effective
algorithm selection in time series classification service systems, improving a
naive baseline by 7.32% on average in estimating the mean performance and
15.81% in estimating the uncertainty.",2024-09-13 08:43:42+00:00
Improving Analog Neural Network Robustness: A Noise-Agnostic Approach with Explainable Regularizations,"This work tackles the critical challenge of mitigating ""hardware noise"" in
deep analog neural networks, a major obstacle in advancing analog signal
processing devices. We propose a comprehensive, hardware-agnostic solution to
address both correlated and uncorrelated noise affecting the activation layers
of deep neural models. The novelty of our approach lies in its ability to
demystify the ""black box"" nature of noise-resilient networks by revealing the
underlying mechanisms that reduce sensitivity to noise. In doing so, we
introduce a new explainable regularization framework that harnesses these
mechanisms to significantly enhance noise robustness in deep neural
architectures.",2024-09-13 08:37:23+00:00
Sybil Detection using Graph Neural Networks,"This paper presents SYBILGAT, a novel approach to Sybil detection in social
networks using Graph Attention Networks (GATs). Traditional methods for Sybil
detection primarily leverage structural properties of networks; however, they
tend to struggle with a large number of attack edges and are often unable to
simultaneously utilize both known Sybil and honest nodes. Our proposed method
addresses these limitations by dynamically assigning attention weights to
different nodes during aggregations, enhancing detection performance. We
conducted extensive experiments in various scenarios, including pretraining in
sampled subgraphs, synthetic networks, and networks under targeted attacks. The
results show that SYBILGAT significantly outperforms the state-of-the-art
algorithms, particularly in scenarios with high attack complexity and when the
number of attack edges increases. Our approach shows robust performance across
different network models and sizes, even as the detection task becomes more
challenging. We successfully applied the model to a real-world Twitter graph
with more than 269k nodes and 6.8M edges. The flexibility and generalizability
of SYBILGAT make it a promising tool to defend against Sybil attacks in online
social networks with only structural information.",2024-09-13 08:35:28+00:00
Co-Optimization of Robot Design and Control: Enhancing Performance and Understanding Design Complexity,"The design (shape) of a robot is usually decided before the control is
implemented. This might limit how well the design is adapted to a task, as the
suitability of the design is given by how well the robot performs in the task,
which requires both a design and a controller. The co-optimization or
simultaneous optimization of the design and control of robots addresses this
limitation by producing a design and control that are both adapted to the task.
In this paper, we investigate some of the challenges inherent in the
co-optimization of design and control. We show that retraining the controller
of a robot with additional resources after the co-optimization process
terminates significantly improves the robot's performance. In addition, we
demonstrate that the resources allocated to training the controller for each
design influence the design complexity, where simpler designs are associated
with lower training budgets. The experimentation is conducted in four publicly
available simulation environments for co-optimization of design and control,
making the findings more applicable to the general case. The results presented
in this paper hope to guide other practitioners in the co-optimization of
design and control of robots.",2024-09-13 08:18:01+00:00
Joint image reconstruction and segmentation of real-time cardiac MRI in free-breathing using a model based on disentangled representation learning,"A joint image reconstruction and segmentation approach based on disentangled
representation learning was trained to enable cardiac cine MR imaging in
real-time and under free-breathing. An exploratory feasibility study tested the
proposed method in undersampled real-time acquisitions based on an in-house
developed spiral bSSFP pulse sequence in eight healthy participants and five
patients with intermittent atrial fibrillation. Images and predicted LV
segmentations were compared to the reference standard of ECG-gated segmented
Cartesian cine in repeated breath-holds and corresponding manual segmentation.
On a 5-point Likert scale, image quality of the real-time breath-hold approach
and Cartesian cine was comparable in healthy participants (RT-BH: 1.99 $\pm$
.98, Cartesian: 1.94 $\pm$ .86, p=.052), but slightly inferior in
free-breathing (RT-FB: 2.40 $\pm$ .98, p<.001). In patients with arrhythmia,
image quality from both real-time approaches was favourable (RT-BH: 2.10 $\pm$
1.28, p<.001, RT-FB: 2.40 $\pm$ 1.13, p<.001, Cartesian: 2.68 $\pm$ 1.13).
Intra-observer reliability was good (ICC=.77, 95%-confidence interval [.75,
.79], p<.001). In functional analysis, a positive bias was observed for
ejection fractions derived from the proposed model compared to the clinical
reference standard (RT-BH mean EF: 58.5 $\pm$ 5.6%, bias: +3.47%,
95%-confidence interval [-.86, 7.79%], RT-FB mean: 57.9 $\pm$ 10.6%, bias:
+1.45%, [-3.02, 5.91%], Cartesian mean: 54.9 $\pm$ 6.7%). The introduced
real-time MR imaging technique is capable of acquiring high-quality cardiac
cine data in 1-2 minutes without the need for ECG gating and breath-holds. It
thus offers a promising alternative to the current clinical practice of
segmented acquisition, with shorter scan times, higher patient comfort and
increased robustness to arrhythmia and patient incompliance.",2024-09-13 08:17:51+00:00
TapToTab : Video-Based Guitar Tabs Generation using AI and Audio Analysis,"The automation of guitar tablature generation from video inputs holds
significant promise for enhancing music education, transcription accuracy, and
performance analysis. Existing methods face challenges with consistency and
completeness, particularly in detecting fretboards and accurately identifying
notes. To address these issues, this paper introduces an advanced approach
leveraging deep learning, specifically YOLO models for real-time fretboard
detection, and Fourier Transform-based audio analysis for precise note
identification. Experimental results demonstrate substantial improvements in
detection accuracy and robustness compared to traditional techniques. This
paper outlines the development, implementation, and evaluation of these
methodologies, aiming to revolutionize guitar instruction by automating the
creation of guitar tabs from video recordings.",2024-09-13 08:17:15+00:00
Dense Point Clouds Matter: Dust-GS for Scene Reconstruction from Sparse Viewpoints,"3D Gaussian Splatting (3DGS) has demonstrated remarkable performance in scene
synthesis and novel view synthesis tasks. Typically, the initialization of 3D
Gaussian primitives relies on point clouds derived from Structure-from-Motion
(SfM) methods. However, in scenarios requiring scene reconstruction from sparse
viewpoints, the effectiveness of 3DGS is significantly constrained by the
quality of these initial point clouds and the limited number of input images.
In this study, we present Dust-GS, a novel framework specifically designed to
overcome the limitations of 3DGS in sparse viewpoint conditions. Instead of
relying solely on SfM, Dust-GS introduces an innovative point cloud
initialization technique that remains effective even with sparse input data.
Our approach leverages a hybrid strategy that integrates an adaptive
depth-based masking technique, thereby enhancing the accuracy and detail of
reconstructed scenes. Extensive experiments conducted on several benchmark
datasets demonstrate that Dust-GS surpasses traditional 3DGS methods in
scenarios with sparse viewpoints, achieving superior scene reconstruction
quality with a reduced number of input images.",2024-09-13 07:59:15+00:00
Optimizing Item-based Marketing Promotion Efficiency in C2C Marketplace with Dynamic Sequential Coupon Allocation Framework,"In e-commerce platforms, coupons play a crucial role in boosting
transactions. In the customer-to-customer (C2C) marketplace, ensuring the
satisfaction of both buyers and sellers is essential. While buyer-focused
marketing strategies often receive more attention, addressing the needs of
sellers is equally important. Additionally, the existing strategies tend to
optimize each promotion independently, resulting in a lack of continuity
between promotions and unnecessary costs in the pursuit of short-term impact
within each promotion period.
  We introduce a Dynamic Sequential Coupon Allocation Framework (DSCAF) to
optimize item coupon allocation strategies across a series of promotions. DSCAF
provides sequential recommendations for coupon configurations and timing to
target items. In cases where initial suggestions do not lead to sales, it
dynamically adjusts the strategy and offers subsequent solutions. It integrates
two predictors for estimating the sale propensity in the current and subsequent
rounds of coupon allocation, and a decision-making process to determine the
coupon allocation solution. It runs iteratively until the item is sold. The
goal of the framework is to maximize Return on Investment (ROI) while ensuring
lift Sell-through Rate (STR) remains above a specified threshold. DSCAF aims to
optimize sequential coupon efficiency with a long-term perspective rather than
solely focusing on the lift achieved in each individual promotion. It has been
applied for item coupon allocation in Mercari.",2024-09-13 07:52:45+00:00
Using Convolutional Neural Networks for Denoising and Deblending of Marine Seismic Data,"Processing marine seismic data is computationally demanding and consists of
multiple time-consuming steps. Neural network based processing can, in theory,
significantly reduce processing time and has the potential to change the way
seismic processing is done. In this paper we are using deep convolutional
neural networks (CNNs) to remove seismic interference noise and to deblend
seismic data. To train such networks, a significant amount of computational
memory is needed since a single shot gather consists of more than 106 data
samples. Preliminary results are promising both for denoising and deblending.
However, we also observed that the results are affected by the signal-to-noise
ratio (SnR). Moving to common channel domain is a way of breaking the coherency
of the noise while also reducing the input volume size. This makes it easier
for the network to distinguish between signal and noise. It also increases the
efficiency of the GPU memory usage by enabling better utilization of multi core
processing. Deblending in common channel domain with the use of a CNN yields
relatively good results and is an improvement compared to shot domain.",2024-09-13 07:35:30+00:00
Deep learning-based shot-domain seismic deblending,"To streamline fast-track processing of large data volumes, we have developed
a deep learning approach to deblend seismic data in the shot domain based on a
practical strategy for generating high-quality training data along with a list
of data conditioning techniques to improve performance of the data-driven
model. We make use of unblended shot gathers acquired at the end of each sail
line, to which the access requires no additional time or labor costs beyond the
blended acquisition. By manually blending these data we obtain training data
with good control of the ground truth and fully adapted to the given survey.
Furthermore, we train a deep neural network using multi-channel inputs that
include adjacent blended shot gathers as additional channels. The prediction of
the blending noise is added in as a related and auxiliary task with the main
task of the network being the prediction of the primary-source events. Blending
noise in the ground truth is scaled down during the training and validation
process due to its excessively strong amplitudes. As part of the process, the
to-be-deblended shot gathers are aligned by the blending noise. Implementation
on field blended-by-acquisition data demonstrates that introducing the
suggested data conditioning steps can considerably reduce the leakage of
primary-source events in the deep part of the blended section. The complete
proposed approach performs almost as well as a conventional algorithm in the
shallow section and shows great advantage in efficiency. It performs slightly
worse for larger traveltimes, but still removes the blending noise efficiently.",2024-09-13 07:32:31+00:00
Knowledge-Enhanced Facial Expression Recognition with Emotional-to-Neutral Transformation,"Existing facial expression recognition (FER) methods typically fine-tune a
pre-trained visual encoder using discrete labels. However, this form of
supervision limits to specify the emotional concept of different facial
expressions. In this paper, we observe that the rich knowledge in text
embeddings, generated by vision-language models, is a promising alternative for
learning discriminative facial expression representations. Inspired by this, we
propose a novel knowledge-enhanced FER method with an emotional-to-neutral
transformation. Specifically, we formulate the FER problem as a process to
match the similarity between a facial expression representation and text
embeddings. Then, we transform the facial expression representation to a
neutral representation by simulating the difference in text embeddings from
textual facial expression to textual neutral. Finally, a self-contrast
objective is introduced to pull the facial expression representation closer to
the textual facial expression, while pushing it farther from the neutral
representation. We conduct evaluation with diverse pre-trained visual encoders
including ResNet-18 and Swin-T on four challenging facial expression datasets.
Extensive experiments demonstrate that our method significantly outperforms
state-of-the-art FER methods. The code will be publicly available.",2024-09-13 07:28:57+00:00
Large Language Model Can Transcribe Speech in Multi-Talker Scenarios with Versatile Instructions,"Recent advancements in large language models (LLMs) have revolutionized
various domains, bringing significant progress and new opportunities. Despite
progress in speech-related tasks, LLMs have not been sufficiently explored in
multi-talker scenarios. In this work, we present a pioneering effort to
investigate the capability of LLMs in transcribing speech in multi-talker
environments, following versatile instructions related to multi-talker
automatic speech recognition (ASR), target talker ASR, and ASR based on
specific talker attributes such as sex, occurrence order, language, and keyword
spoken. Our approach utilizes WavLM and Whisper encoder to extract
multi-faceted speech representations that are sensitive to speaker
characteristics and semantic context. These representations are then fed into
an LLM fine-tuned using LoRA, enabling the capabilities for speech
comprehension and transcription. Comprehensive experiments reveal the promising
performance of our proposed system, MT-LLM, in cocktail party scenarios,
highlighting the potential of LLM to handle speech-related tasks based on user
instructions in such complex settings.",2024-09-13 07:28:28+00:00
Automatic Generation of Fast and Accurate Performance Models for Deep Neural Network Accelerators,"Implementing Deep Neural Networks (DNNs) on resource-constrained edge devices
is a challenging task that requires tailored hardware accelerator architectures
and a clear understanding of their performance characteristics when executing
the intended AI workload. To facilitate this, we present an automated
generation approach for fast performance models to accurately estimate the
latency of a DNN mapped onto systematically modeled and concisely described
accelerator architectures. Using our accelerator architecture description
method, we modeled representative DNN accelerators such as Gemmini, UltraTrail,
Plasticine-derived, and a parameterizable systolic array. Together with DNN
mappings for those modeled architectures, we perform a combined DNN/hardware
dependency graph analysis, which enables us, in the best case, to evaluate only
154 loop kernel iterations to estimate the performance for 4.19 billion
instructions achieving a significant speedup. We outperform regression and
analytical models in terms of mean absolute percentage error (MAPE) compared to
simulation results, while being several magnitudes faster than an RTL
simulation.",2024-09-13 07:27:55+00:00
Improved Unet model for brain tumor image segmentation based on ASPP-coordinate attention mechanism,"In this paper, we propose an improved Unet model for brain tumor image
segmentation, which combines coordinate attention mechanism and ASPP module to
improve the segmentation effect. After the data set is divided, we do the
necessary preprocessing to the image and use the improved model to experiment.
First, we trained and validated the traditional Unet model. By analyzing the
loss curve of the training set and the validation set, we can see that the loss
value continues to decline at the first epoch and becomes stable at the eighth
epoch. This process shows that the model constantly optimizes its parameters to
improve performance. At the same time, the change in the miou (mean
Intersection over Union) index shows that the miou value exceeded 0.6 at the
15th epoch, remained above 0.6 thereafter, and reached above 0.7 at the 46th
epoch. These results indicate that the basic Unet model is effective in brain
tumor image segmentation. Next, we introduce an improved Unet algorithm based
on coordinate attention mechanism and ASPP module for experiments. By observing
the loss change curves of the training set and the verification set, it is
found that the loss value reaches the lowest point at the sixth epoch and then
remains relatively stable. At the same time, the miou indicator has stabilized
above 0.7 since the 20th epoch and has reached a maximum of 0.76. These results
show that the new mechanism introduced significantly improves the segmentation
ability of the model. Finally, we apply the trained traditional Unet model and
the improved Unet model based on the coordinate attention mechanism and ASPP
module to the test set for brain tumor image segmentation prediction. Compared
to the traditional Unet, the enhanced model offers superior segmentation and
edge accuracy, providing a more reliable method for medical image analysis with
the coordinate attention mechanism and ASPP module.",2024-09-13 07:08:48+00:00
Optimizing 4D Lookup Table for Low-light Video Enhancement via Wavelet Priori,"Low-light video enhancement is highly demanding in maintaining spatiotemporal
color consistency. Therefore, improving the accuracy of color mapping and
keeping the latency low is challenging. Based on this, we propose incorporating
Wavelet-priori for 4D Lookup Table (WaveLUT), which effectively enhances the
color coherence between video frames and the accuracy of color mapping while
maintaining low latency. Specifically, we use the wavelet low-frequency domain
to construct an optimized lookup prior and achieve an adaptive enhancement
effect through a designed Wavelet-prior 4D lookup table. To effectively
compensate the a priori loss in the low light region, we further explore a
dynamic fusion strategy that adaptively determines the spatial weights based on
the correlation between the wavelet lighting prior and the target intensity
structure. In addition, during the training phase, we devise a text-driven
appearance reconstruction method that dynamically balances brightness and
content through multimodal semantics-driven Fourier spectra. Extensive
experiments on a wide range of benchmark datasets show that this method
effectively enhances the previous method's ability to perceive the color space
and achieves metric-favorable and perceptually oriented real-time enhancement
while maintaining high efficiency.",2024-09-13 07:04:05+00:00
CompressedMediQ: Hybrid Quantum Machine Learning Pipeline for High-Dimentional Neuroimaging Data,"This paper introduces CompressedMediQ, a novel hybrid quantum-classical
machine learning pipeline specifically developed to address the computational
challenges associated with high-dimensional multi-class neuroimaging data
analysis. Standard neuroimaging datasets, such as 4D MRI data from the
Alzheimer's Disease Neuroimaging Initiative (ADNI) and Neuroimaging in
Frontotemporal Dementia (NIFD), present significant hurdles due to their vast
size and complexity. CompressedMediQ integrates classical high-performance
computing (HPC) nodes for advanced MRI pre-processing and Convolutional Neural
Network (CNN)-PCA-based feature extraction and reduction, addressing the
limited-qubit availability for quantum data encoding in the NISQ (Noisy
Intermediate-Scale Quantum) era. This is followed by Quantum Support Vector
Machine (QSVM) classification. By utilizing quantum kernel methods, the
pipeline optimizes feature mapping and classification, enhancing data
separability and outperforming traditional neuroimaging analysis techniques.
Experimental results highlight the pipeline's superior accuracy in dementia
staging, validating the practical use of quantum machine learning in clinical
diagnostics. Despite the limitations of NISQ devices, this proof-of-concept
demonstrates the transformative potential of quantum-enhanced learning, paving
the way for scalable and precise diagnostic tools in healthcare and signal
processing.",2024-09-13 07:03:01+00:00
LHQ-SVC: Lightweight and High Quality Singing Voice Conversion Modeling,"Singing Voice Conversion (SVC) has emerged as a significant subfield of Voice
Conversion (VC), enabling the transformation of one singer's voice into another
while preserving musical elements such as melody, rhythm, and timbre.
Traditional SVC methods have limitations in terms of audio quality, data
requirements, and computational complexity. In this paper, we propose LHQ-SVC,
a lightweight, CPU-compatible model based on the SVC framework and diffusion
model, designed to reduce model size and computational demand without
sacrificing performance. We incorporate features to improve inference quality,
and optimize for CPU execution by using performance tuning tools and parallel
computing frameworks. Our experiments demonstrate that LHQ-SVC maintains
competitive performance, with significant improvements in processing speed and
efficiency across different devices. The results suggest that LHQ-SVC can meet",2024-09-13 07:02:36+00:00
ChangeChat: An Interactive Model for Remote Sensing Change Analysis via Multimodal Instruction Tuning,"Remote sensing (RS) change analysis is vital for monitoring Earth's dynamic
processes by detecting alterations in images over time. Traditional change
detection excels at identifying pixel-level changes but lacks the ability to
contextualize these alterations. While recent advancements in change captioning
offer natural language descriptions of changes, they do not support
interactive, user-specific queries. To address these limitations, we introduce
ChangeChat, the first bitemporal vision-language model (VLM) designed
specifically for RS change analysis. ChangeChat utilizes multimodal instruction
tuning, allowing it to handle complex queries such as change captioning,
category-specific quantification, and change localization. To enhance the
model's performance, we developed the ChangeChat-87k dataset, which was
generated using a combination of rule-based methods and GPT-assisted
techniques. Experiments show that ChangeChat offers a comprehensive,
interactive solution for RS change analysis, achieving performance comparable
to or even better than state-of-the-art (SOTA) methods on specific tasks, and
significantly surpassing the latest general-domain model, GPT-4. Code and
pre-trained weights are available at https://github.com/hanlinwu/ChangeChat.",2024-09-13 07:00:44+00:00
Learning Short Codes for Fading Channels with No or Receiver-Only Channel State Information,"In next-generation wireless networks, low latency often necessitates
short-length codewords that either do not use channel state information (CSI)
or rely solely on CSI at the receiver (CSIR). Gaussian codes that achieve
capacity for AWGN channels may be unsuitable for these no-CSI and CSIR-only
cases. In this work, we design short-length codewords for these cases using an
autoencoder architecture. From the designed codes, we observe the following: In
the no-CSI case, the learned codes are mutually orthogonal when the
distribution of the real and imaginary parts of the fading random variable has
support over the entire real line. However, when the support is limited to the
non-negative real line, the codes are not mutually orthogonal. For the
CSIR-only case, deep learning-based codes designed for AWGN channels perform
worse in fading channels with optimal coherent detection compared to codes
specifically designed for fading channels with CSIR, where the autoencoder
jointly learns encoding, coherent combining, and decoding. In both no-CSI and
CSIR-only cases, the codes perform at least as well as or better than classical
codes of the same block length.",2024-09-13 07:00:18+00:00
Molecular Graph Representation Learning via Structural Similarity Information,"Graph Neural Networks (GNNs) have been widely employed for feature
representation learning in molecular graphs. Therefore, it is crucial to
enhance the expressiveness of feature representation to ensure the
effectiveness of GNNs. However, a significant portion of current research
primarily focuses on the structural features within individual molecules, often
overlooking the structural similarity between molecules, which is a crucial
aspect encapsulating rich information on the relationship between molecular
properties and structural characteristics. Thus, these approaches fail to
capture the rich semantic information at the molecular structure level. To
bridge this gap, we introduce the \textbf{Molecular Structural Similarity Motif
GNN (MSSM-GNN)}, a novel molecular graph representation learning method that
can capture structural similarity information among molecules from a global
perspective. In particular, we propose a specially designed graph that
leverages graph kernel algorithms to represent the similarity between molecules
quantitatively. Subsequently, we employ GNNs to learn feature representations
from molecular graphs, aiming to enhance the accuracy of property prediction by
incorporating additional molecular representation information. Finally, through
a series of experiments conducted on both small-scale and large-scale molecular
datasets, we demonstrate that our model consistently outperforms eleven
state-of-the-art baselines. The codes are available at
https://github.com/yaoyao-yaoyao-cell/MSSM-GNN.",2024-09-13 06:59:10+00:00
HTR-VT: Handwritten Text Recognition with Vision Transformer,"We explore the application of Vision Transformer (ViT) for handwritten text
recognition. The limited availability of labeled data in this domain poses
challenges for achieving high performance solely relying on ViT. Previous
transformer-based models required external data or extensive pre-training on
large datasets to excel. To address this limitation, we introduce a
data-efficient ViT method that uses only the encoder of the standard
transformer. We find that incorporating a Convolutional Neural Network (CNN)
for feature extraction instead of the original patch embedding and employ
Sharpness-Aware Minimization (SAM) optimizer to ensure that the model can
converge towards flatter minima and yield notable enhancements. Furthermore,
our introduction of the span mask technique, which masks interconnected
features in the feature map, acts as an effective regularizer. Empirically, our
approach competes favorably with traditional CNN-based models on small datasets
like IAM and READ2016. Additionally, it establishes a new benchmark on the LAM
dataset, currently the largest dataset with 19,830 training text lines. The
code is publicly available at: https://github.com/YutingLi0606/HTR-VT.",2024-09-13 06:46:23+00:00
DiffFAS: Face Anti-Spoofing via Generative Diffusion Models,"Face anti-spoofing (FAS) plays a vital role in preventing face recognition
(FR) systems from presentation attacks. Nowadays, FAS systems face the
challenge of domain shift, impacting the generalization performance of existing
FAS methods. In this paper, we rethink about the inherence of domain shift and
deconstruct it into two factors: image style and image quality. Quality
influences the purity of the presentation of spoof information, while style
affects the manner in which spoof information is presented. Based on our
analysis, we propose DiffFAS framework, which quantifies quality as prior
information input into the network to counter image quality shift, and performs
diffusion-based high-fidelity cross-domain and cross-attack types generation to
counter image style shift. DiffFAS transforms easily collectible live faces
into high-fidelity attack faces with precise labels while maintaining
consistency between live and spoof face identities, which can also alleviate
the scarcity of labeled data with novel type attacks faced by nowadays FAS
system. We demonstrate the effectiveness of our framework on challenging
cross-domain and cross-attack FAS datasets, achieving the state-of-the-art
performance. Available at https://github.com/murphytju/DiffFAS.",2024-09-13 06:45:23+00:00
Batch Ensemble for Variance Dependent Regret in Stochastic Bandits,"Efficiently trading off exploration and exploitation is one of the key
challenges in online Reinforcement Learning (RL). Most works achieve this by
carefully estimating the model uncertainty and following the so-called
optimistic model. Inspired by practical ensemble methods, in this work we
propose a simple and novel batch ensemble scheme that provably achieves
near-optimal regret for stochastic Multi-Armed Bandits (MAB). Crucially, our
algorithm has just a single parameter, namely the number of batches, and its
value does not depend on distributional properties such as the scale and
variance of the losses. We complement our theoretical results by demonstrating
the effectiveness of our algorithm on synthetic benchmarks.",2024-09-13 06:40:56+00:00
Hybrid-TTA: Continual Test-time Adaptation via Dynamic Domain Shift Detection,"Continual Test Time Adaptation (CTTA) has emerged as a critical approach for
bridging the domain gap between the controlled training environments and the
real-world scenarios, enhancing model adaptability and robustness. Existing
CTTA methods, typically categorized into Full-Tuning (FT) and Efficient-Tuning
(ET), struggle with effectively addressing domain shifts. To overcome these
challenges, we propose Hybrid-TTA, a holistic approach that dynamically selects
instance-wise tuning method for optimal adaptation. Our approach introduces the
Dynamic Domain Shift Detection (DDSD) strategy, which identifies domain shifts
by leveraging temporal correlations in input sequences and dynamically switches
between FT and ET to adapt to varying domain shifts effectively. Additionally,
the Masked Image Modeling based Adaptation (MIMA) framework is integrated to
ensure domain-agnostic robustness with minimal computational overhead. Our
Hybrid-TTA achieves a notable 1.6%p improvement in mIoU on the
Cityscapes-to-ACDC benchmark dataset, surpassing previous state-of-the-art
methods and offering a robust solution for real-world continual adaptation
challenges.",2024-09-13 06:36:31+00:00
Second-order difference subspace,"Subspace representation is a fundamental technique in various fields of
machine learning. Analyzing a geometrical relationship among multiple subspaces
is essential for understanding subspace series' temporal and/or spatial
dynamics. This paper proposes the second-order difference subspace, a
higher-order extension of the first-order difference subspace between two
subspaces that can analyze the geometrical difference between them. As a
preliminary for that, we extend the definition of the first-order difference
subspace to the more general setting that two subspaces with different
dimensions have an intersection. We then define the second-order difference
subspace by combining the concept of first-order difference subspace and
principal component subspace (Karcher mean) between two subspaces, motivated by
the second-order central difference method. We can understand that the
first/second-order difference subspaces correspond to the velocity and
acceleration of subspace dynamics from the viewpoint of a geodesic on a
Grassmann manifold. We demonstrate the validity and naturalness of our
second-order difference subspace by showing numerical results on two
applications: temporal shape analysis of a 3D object and time series analysis
of a biometric signal.",2024-09-13 06:33:41+00:00
CSS: Overcoming Pose and Scene Challenges in Crowd-Sourced 3D Gaussian Splatting,"We introduce Crowd-Sourced Splatting (CSS), a novel 3D Gaussian Splatting
(3DGS) pipeline designed to overcome the challenges of pose-free scene
reconstruction using crowd-sourced imagery. The dream of reconstructing
historically significant but inaccessible scenes from collections of
photographs has long captivated researchers. However, traditional 3D techniques
struggle with missing camera poses, limited viewpoints, and inconsistent
lighting. CSS addresses these challenges through robust geometric priors and
advanced illumination modeling, enabling high-quality novel view synthesis
under complex, real-world conditions. Our method demonstrates clear
improvements over existing approaches, paving the way for more accurate and
flexible applications in AR, VR, and large-scale 3D reconstruction.",2024-09-13 06:29:45+00:00
Expediting and Elevating Large Language Model Reasoning via Hidden Chain-of-Thought Decoding,"Large language models (LLMs) have demonstrated remarkable capabilities in
tasks requiring reasoning and multi-step problem-solving through the use of
chain-of-thought (CoT) prompting. However, generating the full CoT process
results in significantly longer output sequences, leading to increased
computational costs and latency during inference. To address this challenge, we
propose a novel approach to compress the CoT process through semantic
alignment, enabling more efficient decoding while preserving the benefits of
CoT reasoning. Our method introduces an auxiliary CoT model that learns to
generate and compress the full thought process into a compact special token
representation semantically aligned with the original CoT output. This
compressed representation is then integrated into the input of the Hidden
Chain-of-Thought (HCoT) model. The training process follows a two-stage
procedure: First, the CoT model is optimized to generate the compressed token
representations aligned with the ground-truth CoT outputs using a contrastive
loss. Subsequently, with the CoT model parameters frozen, the HCoT model is
fine-tuned to generate accurate subsequent predictions conditioned on the
prefix instruction and the compressed CoT representations from the CoT model.
Extensive experiments across three challenging domains - mathematical
reasoning, agent invocation, and question answering - demonstrate that our
semantic compression approach achieves competitive or improved performance
compared to the full CoT baseline, while providing significant speedups of at
least 1.5x in decoding time. Moreover, incorporating contrastive learning
objectives further enhances the quality of the compressed representations,
leading to better CoT prompting and improved task accuracy. Our work paves the
way for more efficient exploitation of multi-step reasoning capabilities in
LLMs across a wide range of applications.",2024-09-13 06:29:20+00:00
Fair CoVariance Neural Networks,"Covariance-based data processing is widespread across signal processing and
machine learning applications due to its ability to model data
interconnectivities and dependencies. However, harmful biases in the data may
become encoded in the sample covariance matrix and cause data-driven methods to
treat different subpopulations unfairly. Existing works such as fair principal
component analysis (PCA) mitigate these effects, but remain unstable in low
sample regimes, which in turn may jeopardize the fairness goal. To address both
biases and instability, we propose Fair coVariance Neural Networks (FVNNs),
which perform graph convolutions on the covariance matrix for both fair and
accurate predictions. Our FVNNs provide a flexible model compatible with
several existing bias mitigation techniques. In particular, FVNNs allow for
mitigating the bias in two ways: first, they operate on fair covariance
estimates that remove biases from their principal components; second, they are
trained in an end-to-end fashion via a fairness regularizer in the loss
function so that the model parameters are tailored to solve the task directly
in a fair manner. We prove that FVNNs are intrinsically fairer than analogous
PCA approaches thanks to their stability in low sample regimes. We validate the
robustness and fairness of our model on synthetic and real-world data,
showcasing the flexibility of FVNNs along with the tradeoff between fair and
accurate performance.",2024-09-13 06:24:18+00:00
DICS: Find Domain-Invariant and Class-Specific Features for Out-of-Distribution Generalization,"While deep neural networks have made remarkable progress in various vision
tasks, their performance typically deteriorates when tested in
out-of-distribution (OOD) scenarios. Many OOD methods focus on extracting
domain-invariant features but neglect whether these features are unique to each
class. Even if some features are domain-invariant, they cannot serve as key
classification criteria if shared across different classes. In OOD tasks, both
domain-related and class-shared features act as confounders that hinder
generalization. In this paper, we propose a DICS model to extract
Domain-Invariant and Class-Specific features, including Domain Invariance
Testing (DIT) and Class Specificity Testing (CST), which mitigate the effects
of spurious correlations introduced by confounders. DIT learns domain-related
features of each source domain and removes them from inputs to isolate
domain-invariant class-related features. DIT ensures domain invariance by
aligning same-class features across different domains. Then, CST calculates
soft labels for those features by comparing them with features learned in
previous steps. We optimize the cross-entropy between the soft labels and their
true labels, which enhances same-class similarity and different-class
distinctiveness, thereby reinforcing class specificity. Extensive experiments
on widely-used benchmarks demonstrate the effectiveness of our proposed
algorithm. Additional visualizations further demonstrate that DICS effectively
identifies the key features of each class in target domains.",2024-09-13 06:20:21+00:00
Think Twice Before You Act: Improving Inverse Problem Solving With MCMC,"Recent studies demonstrate that diffusion models can serve as a strong prior
for solving inverse problems. A prominent example is Diffusion Posterior
Sampling (DPS), which approximates the posterior distribution of data given the
measure using Tweedie's formula. Despite the merits of being versatile in
solving various inverse problems without re-training, the performance of DPS is
hindered by the fact that this posterior approximation can be inaccurate
especially for high noise levels. Therefore, we propose \textbf{D}iffusion
\textbf{P}osterior \textbf{MC}MC (\textbf{DPMC}), a novel inference algorithm
based on Annealed MCMC to solve inverse problems with pretrained diffusion
models. We define a series of intermediate distributions inspired by the
approximated conditional distributions used by DPS. Through annealed MCMC
sampling, we encourage the samples to follow each intermediate distribution
more closely before moving to the next distribution at a lower noise level, and
therefore reduce the accumulated error along the path. We test our algorithm in
various inverse problems, including super resolution, Gaussian deblurring,
motion deblurring, inpainting, and phase retrieval. Our algorithm outperforms
DPS with less number of evaluations across nearly all tasks, and is competitive
among existing approaches.",2024-09-13 06:10:54+00:00
Causal GNNs: A GNN-Driven Instrumental Variable Approach for Causal Inference in Networks,"As network data applications continue to expand, causal inference within
networks has garnered increasing attention. However, hidden confounders
complicate the estimation of causal effects. Most methods rely on the strong
ignorability assumption, which presumes the absence of hidden confounders-an
assumption that is both difficult to validate and often unrealistic in
practice. To address this issue, we propose CgNN, a novel approach that
leverages network structure as instrumental variables (IVs), combined with
graph neural networks (GNNs) and attention mechanisms, to mitigate hidden
confounder bias and improve causal effect estimation. By utilizing network
structure as IVs, we reduce confounder bias while preserving the correlation
with treatment. Our integration of attention mechanisms enhances robustness and
improves the identification of important nodes. Validated on two real-world
datasets, our results demonstrate that CgNN effectively mitigates hidden
confounder bias and offers a robust GNN-driven IV framework for causal
inference in complex network data.",2024-09-13 05:39:00+00:00
ATFLRec: A Multimodal Recommender System with Audio-Text Fusion and Low-Rank Adaptation via Instruction-Tuned Large Language Model,"Recommender Systems (RS) play a pivotal role in boosting user satisfaction by
providing personalized product suggestions in domains such as e-commerce and
entertainment. This study examines the integration of multimodal data text and
audio into large language models (LLMs) with the aim of enhancing
recommendation performance. Traditional text and audio recommenders encounter
limitations such as the cold-start problem, and recent advancements in LLMs,
while promising, are computationally expensive. To address these issues,
Low-Rank Adaptation (LoRA) is introduced, which enhances efficiency without
compromising performance. The ATFLRec framework is proposed to integrate audio
and text modalities into a multimodal recommendation system, utilizing various
LoRA configurations and modality fusion techniques. Results indicate that
ATFLRec outperforms baseline models, including traditional and graph neural
network-based approaches, achieving higher AUC scores. Furthermore, separate
fine-tuning of audio and text data with distinct LoRA modules yields optimal
performance, with different pooling methods and Mel filter bank numbers
significantly impacting performance. This research offers valuable insights
into optimizing multimodal recommender systems and advancing the integration of
diverse data modalities in LLMs.",2024-09-13 05:33:09+00:00
An Efficient Privacy-aware Split Learning Framework for Satellite Communications,"In the rapidly evolving domain of satellite communications, integrating
advanced machine learning techniques, particularly split learning, is crucial
for enhancing data processing and model training efficiency across satellites,
space stations, and ground stations. Traditional ML approaches often face
significant challenges within satellite networks due to constraints such as
limited bandwidth and computational resources. To address this gap, we propose
a novel framework for more efficient SL in satellite communications. Our
approach, Dynamic Topology Informed Pruning, namely DTIP, combines differential
privacy with graph and model pruning to optimize graph neural networks for
distributed learning. DTIP strategically applies differential privacy to raw
graph data and prunes GNNs, thereby optimizing both model size and
communication load across network tiers. Extensive experiments across diverse
datasets demonstrate DTIP's efficacy in enhancing privacy, accuracy, and
computational efficiency. Specifically, on Amazon2M dataset, DTIP maintains an
accuracy of 0.82 while achieving a 50% reduction in floating-point operations
per second. Similarly, on ArXiv dataset, DTIP achieves an accuracy of 0.85
under comparable conditions. Our framework not only significantly improves the
operational efficiency of satellite communications but also establishes a new
benchmark in privacy-aware distributed learning, potentially revolutionizing
data handling in space-based networks.",2024-09-13 04:59:35+00:00
SRE-CNN: A Spatiotemporal Rotation-Equivariant CNN for Cardiac Cine MR Imaging,"Dynamic MR images possess various transformation symmetries,including the
rotation symmetry of local features within the image and along the temporal
dimension. Utilizing these symmetries as prior knowledge can facilitate dynamic
MR imaging with high spatiotemporal resolution. Equivariant CNN is an effective
tool to leverage the symmetry priors. However, current equivariant CNN methods
fail to fully exploit these symmetry priors in dynamic MR imaging. In this
work, we propose a novel framework of Spatiotemporal Rotation-Equivariant CNN
(SRE-CNN), spanning from the underlying high-precision filter design to the
construction of the temporal-equivariant convolutional module and imaging
model, to fully harness the rotation symmetries inherent in dynamic MR images.
The temporal-equivariant convolutional module enables exploitation the rotation
symmetries in both spatial and temporal dimensions, while the high-precision
convolutional filter, based on parametrization strategy, enhances the
utilization of rotation symmetry of local features to improve the
reconstruction of detailed anatomical structures. Experiments conducted on
highly undersampled dynamic cardiac cine data (up to 20X) have demonstrated the
superior performance of our proposed approach, both quantitatively and
qualitatively.",2024-09-13 04:54:34+00:00
Integration of Mamba and Transformer -- MAT for Long-Short Range Time Series Forecasting with Application to Weather Dynamics,"Long-short range time series forecasting is essential for predicting future
trends and patterns over extended periods. While deep learning models such as
Transformers have made significant strides in advancing time series
forecasting, they often encounter difficulties in capturing long-term
dependencies and effectively managing sparse semantic features. The state-space
model, Mamba, addresses these issues through its adept handling of selective
input and parallel computing, striking a balance between computational
efficiency and prediction accuracy. This article examines the advantages and
disadvantages of both Mamba and Transformer models, and introduces a combined
approach, MAT, which leverages the strengths of each model to capture unique
long-short range dependencies and inherent evolutionary patterns in
multivariate time series. Specifically, MAT harnesses the long-range dependency
capabilities of Mamba and the short-range characteristics of Transformers.
Experimental results on benchmark weather datasets demonstrate that MAT
outperforms existing comparable methods in terms of prediction accuracy,
scalability, and memory efficiency.",2024-09-13 04:23:54+00:00
MAPX: An explainable model-agnostic framework for the detection of false information on social media networks,"The automated detection of false information has become a fundamental task in
combating the spread of ""fake news"" on online social media networks (OSMN) as
it reduces the need for manual discernment by individuals. In the literature,
leveraging various content or context features of OSMN documents have been
found useful. However, most of the existing detection models often utilise
these features in isolation without regard to the temporal and dynamic changes
oft-seen in reality, thus, limiting the robustness of the models. Furthermore,
there has been little to no consideration of the impact of the quality of
documents' features on the trustworthiness of the final prediction. In this
paper, we introduce a novel model-agnostic framework, called MAPX, which allows
evidence based aggregation of predictions from existing models in an
explainable manner. Indeed, the developed aggregation method is adaptive,
dynamic and considers the quality of OSMN document features. Further, we
perform extensive experiments on benchmarked fake news datasets to demonstrate
the effectiveness of MAPX using various real-world data quality scenarios. Our
empirical results show that the proposed framework consistently outperforms all
state-of-the-art models evaluated. For reproducibility, a demo of MAPX is
available at \href{https://github.com/SCondran/MAPX_framework}{this link}",2024-09-13 03:45:10+00:00
Optimal Classification-based Anomaly Detection with Neural Networks: Theory and Practice,"Anomaly detection is an important problem in many application areas, such as
network security. Many deep learning methods for unsupervised anomaly detection
produce good empirical performance but lack theoretical guarantees. By casting
anomaly detection into a binary classification problem, we establish
non-asymptotic upper bounds and a convergence rate on the excess risk on
rectified linear unit (ReLU) neural networks trained on synthetic anomalies.
Our convergence rate on the excess risk matches the minimax optimal rate in the
literature. Furthermore, we provide lower and upper bounds on the number of
synthetic anomalies that can attain this optimality. For practical
implementation, we relax some conditions to improve the search for the
empirical risk minimizer, which leads to competitive performance to other
classification-based methods for anomaly detection. Overall, our work provides
the first theoretical guarantees of unsupervised neural network-based anomaly
detectors and empirical insights on how to design them well.",2024-09-13 03:43:30+00:00
GroundingBooth: Grounding Text-to-Image Customization,"Recent studies in text-to-image customization show great success in
generating personalized object variants given several images of a subject.
While existing methods focus more on preserving the identity of the subject,
they often fall short of controlling the spatial relationship between objects.
In this work, we introduce GroundingBooth, a framework that achieves zero-shot
instance-level spatial grounding on both foreground subjects and background
objects in the text-to-image customization task. Our proposed text-image
grounding module and masked cross-attention layer allow us to generate
personalized images with both accurate layout alignment and identity
preservation while maintaining text-image coherence. With such layout control,
our model inherently enables the customization of multiple subjects at once.
Our model is evaluated on both layout-guided image synthesis and
reference-based customization tasks, showing strong results compared to
existing methods. Our work is the first work to achieve a joint grounding of
both subject-driven foreground generation and text-driven background
generation.",2024-09-13 03:40:58+00:00
Anytime Continual Learning for Open Vocabulary Classification,"We propose an approach for anytime continual learning (AnytimeCL) for open
vocabulary image classification. The AnytimeCL problem aims to break away from
batch training and rigid models by requiring that a system can predict any set
of labels at any time and efficiently update and improve when receiving one or
more training samples at any time. Despite the challenging goal, we achieve
substantial improvements over recent methods. We propose a dynamic weighting
between predictions of a partially fine-tuned model and a fixed open vocabulary
model that enables continual improvement when training samples are available
for a subset of a task's labels. We also propose an attention-weighted PCA
compression of training features that reduces storage and computation with
little impact to model accuracy. Our methods are validated with experiments
that test flexibility of learning and inference. Code is available at
https://github.com/jessemelpolio/AnytimeCL.",2024-09-13 03:34:37+00:00
AWF: Adaptive Weight Fusion for Enhanced Class Incremental Semantic Segmentation,"Class Incremental Semantic Segmentation (CISS) aims to mitigate catastrophic
forgetting by maintaining a balance between previously learned and newly
introduced knowledge. Existing methods, primarily based on regularization
techniques like knowledge distillation, help preserve old knowledge but often
face challenges in effectively integrating new knowledge, resulting in limited
overall improvement. Endpoints Weight Fusion (EWF) method, while simple,
effectively addresses some of these limitations by dynamically fusing the model
weights from previous steps with those from the current step, using a fusion
parameter alpha determined by the relative number of previously known classes
and newly introduced classes. However, the simplicity of the alpha calculation
may limit its ability to fully capture the complexities of different task
scenarios, potentially leading to suboptimal fusion outcomes. In this paper, we
propose an enhanced approach called Adaptive Weight Fusion (AWF), which
introduces an alternating training strategy for the fusion parameter, allowing
for more flexible and adaptive weight integration. AWF achieves superior
performance by better balancing the retention of old knowledge with the
learning of new classes, significantly improving results on benchmark CISS
tasks compared to the original EWF. And our experiment code will be released on
Github.",2024-09-13 03:29:16+00:00
Apollo: Band-sequence Modeling for High-Quality Audio Restoration,"Audio restoration has become increasingly significant in modern society, not
only due to the demand for high-quality auditory experiences enabled by
advanced playback devices, but also because the growing capabilities of
generative audio models necessitate high-fidelity audio. Typically, audio
restoration is defined as a task of predicting undistorted audio from damaged
input, often trained using a GAN framework to balance perception and
distortion. Since audio degradation is primarily concentrated in mid- and
high-frequency ranges, especially due to codecs, a key challenge lies in
designing a generator capable of preserving low-frequency information while
accurately reconstructing high-quality mid- and high-frequency content.
Inspired by recent advancements in high-sample-rate music separation, speech
enhancement, and audio codec models, we propose Apollo, a generative model
designed for high-sample-rate audio restoration. Apollo employs an explicit
frequency band split module to model the relationships between different
frequency bands, allowing for more coherent and higher-quality restored audio.
Evaluated on the MUSDB18-HQ and MoisesDB datasets, Apollo consistently
outperforms existing SR-GAN models across various bit rates and music genres,
particularly excelling in complex scenarios involving mixtures of multiple
instruments and vocals. Apollo significantly improves music restoration quality
while maintaining computational efficiency. The source code for Apollo is
publicly available at https://github.com/JusperLee/Apollo.",2024-09-13 03:25:34+00:00
Mamba-YOLO-World: Marrying YOLO-World with Mamba for Open-Vocabulary Detection,"Open-vocabulary detection (OVD) aims to detect objects beyond a predefined
set of categories. As a pioneering model incorporating the YOLO series into
OVD, YOLO-World is well-suited for scenarios prioritizing speed and
efficiency.However, its performance is hindered by its neck feature fusion
mechanism, which causes the quadratic complexity and the limited guided
receptive fields.To address these limitations, we present Mamba-YOLO-World, a
novel YOLO-based OVD model employing the proposed MambaFusion Path Aggregation
Network (MambaFusion-PAN) as its neck architecture. Specifically, we introduce
an innovative State Space Model-based feature fusion mechanism consisting of a
Parallel-Guided Selective Scan algorithm and a Serial-Guided Selective Scan
algorithm with linear complexity and globally guided receptive fields. It
leverages multi-modal input sequences and mamba hidden states to guide the
selective scanning process.Experiments demonstrate that our model outperforms
the original YOLO-World on the COCO and LVIS benchmarks in both zero-shot and
fine-tuning settings while maintaining comparable parameters and FLOPs.
Additionally, it surpasses existing state-of-the-art OVD methods with fewer
parameters and FLOPs.",2024-09-13 03:23:52+00:00
CasDyF-Net: Image Dehazing via Cascaded Dynamic Filters,"Image dehazing aims to restore image clarity and visual quality by reducing
atmospheric scattering and absorption effects. While deep learning has made
significant strides in this area, more and more methods are constrained by
network depth. Consequently, lots of approaches have adopted parallel branching
strategies. however, they often prioritize aspects such as resolution,
receptive field, or frequency domain segmentation without dynamically
partitioning branches based on the distribution of input features. Inspired by
dynamic filtering, we propose using cascaded dynamic filters to create a
multi-branch network by dynamically generating filter kernels based on feature
map distribution. To better handle branch features, we propose a residual
multiscale block (RMB), combining different receptive fields. Furthermore, we
also introduce a dynamic convolution-based local fusion method to merge
features from adjacent branches. Experiments on RESIDE, Haze4K, and O-Haze
datasets validate our method's effectiveness, with our model achieving a PSNR
of 43.21dB on the RESIDE-Indoor dataset. The code is available at
https://github.com/dauing/CasDyF-Net.",2024-09-13 03:20:38+00:00
Exploiting Supervised Poison Vulnerability to Strengthen Self-Supervised Defense,"Availability poisons exploit supervised learning (SL) algorithms by
introducing class-related shortcut features in images such that models trained
on poisoned data are useless for real-world datasets. Self-supervised learning
(SSL), which utilizes augmentations to learn instance discrimination, is
regarded as a strong defense against poisoned data. However, by extending the
study of SSL across multiple poisons on the CIFAR-10 and ImageNet-100 datasets,
we demonstrate that it often performs poorly, far below that of training on
clean data. Leveraging the vulnerability of SL to poison attacks, we introduce
adversarial training (AT) on SL to obfuscate poison features and guide robust
feature learning for SSL. Our proposed defense, designated VESPR (Vulnerability
Exploitation of Supervised Poisoning for Robust SSL), surpasses the performance
of six previous defenses across seven popular availability poisons. VESPR
displays superior performance over all previous defenses, boosting the minimum
and average ImageNet-100 test accuracies of poisoned models by 16% and 9%,
respectively. Through analysis and ablation studies, we elucidate the
mechanisms by which VESPR learns robust class features.",2024-09-13 03:12:58+00:00
Identifying Human Indoor Daily Life Behavior employing Thermal Sensor Arrays (TSAs),"Daily activity monitoring systems used in households provide vital
information for health status, particularly with aging residents. Multiple
approaches have been introduced to achieve such goals, typically obtrusive and
non-obtrusive. Amongst the obtrusive approaches are the wearable devices, and
among the non-obtrusive approaches are the movement detection systems,
including motion sensors and thermal sensor arrays (TSAs). TSA systems are
advantageous when preserving a person's privacy and picking his precise spatial
location. In this study, human daily living activities were monitored day and
night, constructing the corresponding activity time series and spatial
probability distribution and employing a TSA system. The monitored activities
are classified into two categories: sleeping and daily activity. Results showed
the possibility of distinguishing between classes regardless of day and night.
The obtained sleep activity duration was compared with previous research using
the same raw data. Results showed that the duration of sleep activity, on
average, was 9 hours/day, and daily life activity was 7 hours/day. The person's
spatial probability distribution was determined using the bivariate
distribution for the monitored location. In conclusion, the results showed that
sleeping activity was dominant. Our study showed that TSAs were the optimum
choice when monitoring human activity. Our proposed approach tackled
limitations encountered by previous human activity monitoring systems, such as
preserving human privacy while knowing his precise spatial location.",2024-09-13 03:12:10+00:00
Enhancing Privacy in ControlNet and Stable Diffusion via Split Learning,"With the emerging trend of large generative models, ControlNet is introduced
to enable users to fine-tune pre-trained models with their own data for various
use cases. A natural question arises: how can we train ControlNet models while
ensuring users' data privacy across distributed devices? Exploring different
distributed training schemes, we find conventional federated learning and split
learning unsuitable. Instead, we propose a new distributed learning structure
that eliminates the need for the server to send gradients back. Through a
comprehensive evaluation of existing threats, we discover that in the context
of training ControlNet with split learning, most existing attacks are
ineffective, except for two mentioned in previous literature. To counter these
threats, we leverage the properties of diffusion models and design a new
timestep sampling policy during forward processes. We further propose a
privacy-preserving activation function and a method to prevent private text
prompts from leaving clients, tailored for image generation with diffusion
models. Our experimental results demonstrate that our algorithms and systems
greatly enhance the efficiency of distributed training for ControlNet while
ensuring users' data privacy without compromising image generation quality.",2024-09-13 02:55:22+00:00
PSTNet: Enhanced Polyp Segmentation with Multi-scale Alignment and Frequency Domain Integration,"Accurate segmentation of colorectal polyps in colonoscopy images is crucial
for effective diagnosis and management of colorectal cancer (CRC). However,
current deep learning-based methods primarily rely on fusing RGB information
across multiple scales, leading to limitations in accurately identifying polyps
due to restricted RGB domain information and challenges in feature misalignment
during multi-scale aggregation. To address these limitations, we propose the
Polyp Segmentation Network with Shunted Transformer (PSTNet), a novel approach
that integrates both RGB and frequency domain cues present in the images.
PSTNet comprises three key modules: the Frequency Characterization Attention
Module (FCAM) for extracting frequency cues and capturing polyp
characteristics, the Feature Supplementary Alignment Module (FSAM) for aligning
semantic information and reducing misalignment noise, and the Cross Perception
localization Module (CPM) for synergizing frequency cues with high-level
semantics to achieve efficient polyp segmentation. Extensive experiments on
challenging datasets demonstrate PSTNet's significant improvement in polyp
segmentation accuracy across various metrics, consistently outperforming
state-of-the-art methods. The integration of frequency domain cues and the
novel architectural design of PSTNet contribute to advancing computer-assisted
polyp segmentation, facilitating more accurate diagnosis and management of CRC.",2024-09-13 02:52:25+00:00
Cross-conditioned Diffusion Model for Medical Image to Image Translation,"Multi-modal magnetic resonance imaging (MRI) provides rich, complementary
information for analyzing diseases. However, the practical challenges of
acquiring multiple MRI modalities, such as cost, scan time, and safety
considerations, often result in incomplete datasets. This affects both the
quality of diagnosis and the performance of deep learning models trained on
such data. Recent advancements in generative adversarial networks (GANs) and
denoising diffusion models have shown promise in natural and medical
image-to-image translation tasks. However, the complexity of training GANs and
the computational expense associated with diffusion models hinder their
development and application in this task. To address these issues, we introduce
a Cross-conditioned Diffusion Model (CDM) for medical image-to-image
translation. The core idea of CDM is to use the distribution of target
modalities as guidance to improve synthesis quality while achieving higher
generation efficiency compared to conventional diffusion models. First, we
propose a Modality-specific Representation Model (MRM) to model the
distribution of target modalities. Then, we design a Modality-decoupled
Diffusion Network (MDN) to efficiently and effectively learn the distribution
from MRM. Finally, a Cross-conditioned UNet (C-UNet) with a Condition Embedding
module is designed to synthesize the target modalities with the source
modalities as input and the target distribution for guidance. Extensive
experiments conducted on the BraTS2023 and UPenn-GBM benchmark datasets
demonstrate the superiority of our method.",2024-09-13 02:48:56+00:00
WheelPoser: Sparse-IMU Based Body Pose Estimation for Wheelchair Users,"Despite researchers having extensively studied various ways to track body
pose on-the-go, most prior work does not take into account wheelchair users,
leading to poor tracking performance. Wheelchair users could greatly benefit
from this pose information to prevent injuries, monitor their health, identify
environmental accessibility barriers, and interact with gaming and VR
experiences. In this work, we present WheelPoser, a real-time pose estimation
system specifically designed for wheelchair users. Our system uses only four
strategically placed IMUs on the user's body and wheelchair, making it far more
practical than prior systems using cameras and dense IMU arrays. WheelPoser is
able to track a wheelchair user's pose with a mean joint angle error of 14.30
degrees and a mean joint position error of 6.74 cm, more than three times
better than similar systems using sparse IMUs. To train our system, we collect
a novel WheelPoser-IMU dataset, consisting of 167 minutes of paired IMU sensor
and motion capture data of people in wheelchairs, including wheelchair-specific
motions such as propulsion and pressure relief. Finally, we explore the
potential application space enabled by our system and discuss future
opportunities. Open-source code, models, and dataset can be found here:
https://github.com/axle-lab/WheelPoser.",2024-09-13 02:41:49+00:00
Tri-Plane Mamba: Efficiently Adapting Segment Anything Model for 3D Medical Images,"General networks for 3D medical image segmentation have recently undergone
extensive exploration. Behind the exceptional performance of these networks
lies a significant demand for a large volume of pixel-level annotated data,
which is time-consuming and labor-intensive. The emergence of the Segment
Anything Model (SAM) has enabled this model to achieve superior performance in
2D medical image segmentation tasks via parameter- and data-efficient feature
adaptation. However, the introduction of additional depth channels in 3D
medical images not only prevents the sharing of 2D pre-trained features but
also results in a quadratic increase in the computational cost for adapting
SAM. To overcome these challenges, we present the Tri-Plane Mamba (TP-Mamba)
adapters tailored for the SAM, featuring two major innovations: 1) multi-scale
3D convolutional adapters, optimized for efficiently processing local
depth-level information, 2) a tri-plane mamba module, engineered to capture
long-range depth-level representation without significantly increasing
computational costs. This approach achieves state-of-the-art performance in 3D
CT organ segmentation tasks. Remarkably, this superior performance is
maintained even with scarce training data. Specifically using only three CT
training samples from the BTCV dataset, it surpasses conventional 3D
segmentation networks, attaining a Dice score that is up to 12% higher.",2024-09-13 02:37:13+00:00
Sub-graph Based Diffusion Model for Link Prediction,"Denoising Diffusion Probabilistic Models (DDPMs) represent a contemporary
class of generative models with exceptional qualities in both synthesis and
maximizing the data likelihood. These models work by traversing a forward
Markov Chain where data is perturbed, followed by a reverse process where a
neural network learns to undo the perturbations and recover the original data.
There have been increasing efforts exploring the applications of DDPMs in the
graph domain. However, most of them have focused on the generative perspective.
In this paper, we aim to build a novel generative model for link prediction. In
particular, we treat link prediction between a pair of nodes as a conditional
likelihood estimation of its enclosing sub-graph. With a dedicated design to
decompose the likelihood estimation process via the Bayesian formula, we are
able to separate the estimation of sub-graph structure and its node features.
Such designs allow our model to simultaneously enjoy the advantages of
inductive learning and the strong generalization capability. Remarkably,
comprehensive experiments across various datasets validate that our proposed
method presents numerous advantages: (1) transferability across datasets
without retraining, (2) promising generalization on limited training data, and
(3) robustness against graph adversarial attacks.",2024-09-13 02:23:55+00:00
A BERT-Based Summarization approach for depression detection,"Depression is a globally prevalent mental disorder with potentially severe
repercussions if not addressed, especially in individuals with recurrent
episodes. Prior research has shown that early intervention has the potential to
mitigate or alleviate symptoms of depression. However, implementing such
interventions in a real-world setting may pose considerable challenges. A
promising strategy involves leveraging machine learning and artificial
intelligence to autonomously detect depression indicators from diverse data
sources. One of the most widely available and informative data sources is text,
which can reveal a person's mood, thoughts, and feelings. In this context,
virtual agents programmed to conduct interviews using clinically validated
questionnaires, such as those found in the DAIC-WOZ dataset, offer a robust
means for depression detection through linguistic analysis. Utilizing
BERT-based models, which are powerful and versatile yet use fewer resources
than contemporary large language models, to convert text into numerical
representations significantly enhances the precision of depression diagnosis.
These models adeptly capture complex semantic and syntactic nuances, improving
the detection accuracy of depressive symptoms. Given the inherent limitations
of these models concerning text length, our study proposes text summarization
as a preprocessing technique to diminish the length and intricacies of input
texts. Implementing this method within our uniquely developed framework for
feature extraction and classification yielded an F1-score of 0.67 on the test
set surpassing all prior benchmarks and 0.81 on the validation set exceeding
most previous results on the DAIC-WOZ dataset. Furthermore, we have devised a
depression lexicon to assess summary quality and relevance. This lexicon
constitutes a valuable asset for ongoing research in depression detection.",2024-09-13 02:14:34+00:00
Risks When Sharing LoRA Fine-Tuned Diffusion Model Weights,"With the emerging trend in generative models and convenient public access to
diffusion models pre-trained on large datasets, users can fine-tune these
models to generate images of personal faces or items in new contexts described
by natural language. Parameter efficient fine-tuning (PEFT) such as Low Rank
Adaptation (LoRA) has become the most common way to save memory and computation
usage on the user end during fine-tuning. However, a natural question is
whether the private images used for fine-tuning will be leaked to adversaries
when sharing model weights. In this paper, we study the issue of privacy
leakage of a fine-tuned diffusion model in a practical setting, where
adversaries only have access to model weights, rather than prompts or images
used for fine-tuning. We design and build a variational network autoencoder
that takes model weights as input and outputs the reconstruction of private
images. To improve the efficiency of training such an autoencoder, we propose a
training paradigm with the help of timestep embedding. The results give a
surprising answer to this research question: an adversary can generate images
containing the same identities as the private images. Furthermore, we
demonstrate that no existing defense method, including differential
privacy-based methods, can preserve the privacy of private data used for
fine-tuning a diffusion model without compromising the utility of a fine-tuned
model.",2024-09-13 02:13:26+00:00
USTC-TD: A Test Dataset and Benchmark for Image and Video Coding in 2020s,"Image/video coding has been a remarkable research area for both academia and
industry for many years. Testing datasets, especially high-quality image/video
datasets are desirable for the justified evaluation of coding-related research,
practical applications, and standardization activities. We put forward a test
dataset namely USTC-TD, which has been successfully adopted in the practical
end-to-end image/video coding challenge of the IEEE International Conference on
Visual Communications and Image Processing in 2022 and 2023. USTC-TD contains
40 images at 4K spatial resolution and 10 video sequences at 1080p spatial
resolution, featuring various content due to the diverse environmental factors
(scene type, texture, motion, view) and the designed imaging factors
(illumination, shadow, lens). We quantitatively evaluate USTC-TD on different
image/video features (spatial, temporal, color, lightness), and compare it with
the previous image/video test datasets, which verifies the wider coverage and
more diversity of the proposed dataset. We also evaluate both classic
standardized and recent learned image/video coding schemes on USTC-TD with PSNR
and MS-SSIM, and provide an extensive benchmark for the evaluated schemes.
Based on the characteristics and specific design of the proposed test dataset,
we analyze the benchmark performance and shed light on the future research and
development of image/video coding. All the data are released online:
https://esakak.github.io/USTC-TD.",2024-09-13 02:13:11+00:00
Exploring Information Retrieval Landscapes: An Investigation of a Novel Evaluation Techniques and Comparative Document Splitting Methods,"The performance of Retrieval-Augmented Generation (RAG) systems in
information retrieval is significantly influenced by the characteristics of the
documents being processed. In this study, the structured nature of textbooks,
the conciseness of articles, and the narrative complexity of novels are shown
to require distinct retrieval strategies. A comparative evaluation of multiple
document-splitting methods reveals that the Recursive Character Splitter
outperforms the Token-based Splitter in preserving contextual integrity. A
novel evaluation technique is introduced, utilizing an open-source model to
generate a comprehensive dataset of question-and-answer pairs, simulating
realistic retrieval scenarios to enhance testing efficiency and metric
reliability. The evaluation employs weighted scoring metrics, including
SequenceMatcher, BLEU, METEOR, and BERT Score, to assess the system's accuracy
and relevance. This approach establishes a refined standard for evaluating the
precision of RAG systems, with future research focusing on optimizing chunk and
overlap sizes to improve retrieval accuracy and efficiency.",2024-09-13 02:08:47+00:00
Integrating Neural Operators with Diffusion Models Improves Spectral Representation in Turbulence Modeling,"We integrate neural operators with diffusion models to address the spectral
limitations of neural operators in surrogate modeling of turbulent flows. While
neural operators offer computational efficiency, they exhibit deficiencies in
capturing high-frequency flow dynamics, resulting in overly smooth
approximations. To overcome this, we condition diffusion models on neural
operators to enhance the resolution of turbulent structures. Our approach is
validated for different neural operators on diverse datasets, including a high
Reynolds number jet flow simulation and experimental Schlieren velocimetry. The
proposed method significantly improves the alignment of predicted energy
spectra with true distributions compared to neural operators alone.
Additionally, proper orthogonal decomposition analysis demonstrates enhanced
spectral fidelity in space-time. This work establishes a new paradigm for
combining generative models with neural operators to advance surrogate modeling
of turbulent systems, and it can be used in other scientific applications that
involve microstructure and high-frequency content. See our project page:
vivekoommen.github.io/NO_DM",2024-09-13 02:07:20+00:00
RT-DETRv3: Real-time End-to-End Object Detection with Hierarchical Dense Positive Supervision,"RT-DETR is the first real-time end-to-end transformer-based object detector.
Its efficiency comes from the framework design and the Hungarian matching.
However, compared to dense supervision detectors like the YOLO series, the
Hungarian matching provides much sparser supervision, leading to insufficient
model training and difficult to achieve optimal results. To address these
issues, we proposed a hierarchical dense positive supervision method based on
RT-DETR, named RT-DETRv3. Firstly, we introduce a CNN-based auxiliary branch
that provides dense supervision that collaborates with the original decoder to
enhance the encoder feature representation. Secondly, to address insufficient
decoder training, we propose a novel learning strategy involving self-attention
perturbation. This strategy diversifies label assignment for positive samples
across multiple query groups, thereby enriching positive supervisions.
Additionally, we introduce a shared-weight decoder branch for dense positive
supervision to ensure more high-quality queries matching each ground truth.
Notably, all aforementioned modules are training-only. We conduct extensive
experiments to demonstrate the effectiveness of our approach on COCO val2017.
RT-DETRv3 significantly outperforms existing real-time detectors, including the
RT-DETR series and the YOLO series. For example, RT-DETRv3-R18 achieves 48.1%
AP (+1.6%/+1.4%) compared to RT-DETR-R18/RT-DETRv2-R18 while maintaining the
same latency. Meanwhile, it requires only half of epochs to attain a comparable
performance. Furthermore, RT-DETRv3-R101 can attain an impressive 54.6% AP
outperforming YOLOv10-X. Code will be released soon.",2024-09-13 02:02:07+00:00
Rethinking Meta-Learning from a Learning Lens,"Meta-learning has emerged as a powerful approach for leveraging knowledge
from previous tasks to solve new tasks. The mainstream methods focus on
training a well-generalized model initialization, which is then adapted to
different tasks with limited data and updates. However, it pushes the model
overfitting on the training tasks. Previous methods mainly attributed this to
the lack of data and used augmentations to address this issue, but they were
limited by sufficient training and effective augmentation strategies. In this
work, we focus on the more fundamental ``learning to learn'' strategy of
meta-learning to explore what causes errors and how to eliminate these errors
without changing the environment. Specifically, we first rethink the
algorithmic procedure of meta-learning from a ``learning'' lens. Through
theoretical and empirical analyses, we find that (i) this paradigm faces the
risk of both overfitting and underfitting and (ii) the model adapted to
different tasks promote each other where the effect is stronger if the tasks
are more similar. Based on this insight, we propose using task relations to
calibrate the optimization process of meta-learning and propose a plug-and-play
method called Task Relation Learner (TRLearner) to achieve this goal.
Specifically, it first obtains task relation matrices from the extracted
task-specific meta-data. Then, it uses the obtained matrices with
relation-aware consistency regularization to guide optimization. Extensive
theoretical and empirical analyses demonstrate the effectiveness of TRLearner.",2024-09-13 02:00:16+00:00
An Intent Modeling and Inference Framework for Autonomous and Remotely Piloted Aerial Systems,"An intent modelling and inference framework is presented to assist the
defense planning for protecting a geo-fence against unauthorized flights.
First, a novel mathematical definition for the intent of an uncrewed aircraft
system (UAS) is presented. The concepts of critical waypoints and critical
waypoint patterns are introduced and associated with a motion process to fully
characterize an intent. This modelling framework consists of representations of
a UAS mission planner, used to plan the aircraft's motion sequence, as well as
a defense planner, defined to protect the geo-fence. It is applicable to
autonomous, semi-autonomous, and piloted systems in 2D and 3D environments with
obstacles. The framework is illustrated by defining a library of intents for a
security application. Detection and tracking of the target are presumed for
formulating the intent inference problem. Multiple formulations of the decision
maker's objective are discussed as part of a deep-learning-based methodology.
Further, a multi-modal dynamic model for characterizing the UAS flight is
discussed. This is later utilized to extract features using the interacting
multiple model (IMM) filter for training the intent classifier. Finally, as
part of the simulation study, an attention-based bi-directional long short-term
memory (Bi-LSTM) network for intent inference is presented. The simulation
experiments illustrate various aspects of the framework, including trajectory
generation, radar measurement simulation, etc., in 2D and 3D environments.",2024-09-13 01:57:37+00:00
Improved Finite-Particle Convergence Rates for Stein Variational Gradient Descent,"We provide finite-particle convergence rates for the Stein Variational
Gradient Descent (SVGD) algorithm in the Kernel Stein Discrepancy
($\mathsf{KSD}$) and Wasserstein-2 metrics. Our key insight is the observation
that the time derivative of the relative entropy between the joint density of
$N$ particle locations and the $N$-fold product target measure, starting from a
regular initial distribution, splits into a dominant `negative part'
proportional to $N$ times the expected $\mathsf{KSD}^2$ and a smaller `positive
part'. This observation leads to $\mathsf{KSD}$ rates of order $1/\sqrt{N}$,
providing a near optimal double exponential improvement over the recent result
by~\cite{shi2024finite}. Under mild assumptions on the kernel and potential,
these bounds also grow linearly in the dimension $d$. By adding a bilinear
component to the kernel, the above approach is used to further obtain
Wasserstein-2 convergence. For the case of `bilinear + Mat\'ern' kernels, we
derive Wasserstein-2 rates that exhibit a curse-of-dimensionality similar to
the i.i.d. setting. We also obtain marginal convergence and long-time
propagation of chaos results for the time-averaged particle laws.",2024-09-13 01:49:19+00:00
Generalization Boosted Adapter for Open-Vocabulary Segmentation,"Vision-language models (VLMs) have demonstrated remarkable open-vocabulary
object recognition capabilities, motivating their adaptation for dense
prediction tasks like segmentation. However, directly applying VLMs to such
tasks remains challenging due to their lack of pixel-level granularity and the
limited data available for fine-tuning, leading to overfitting and poor
generalization. To address these limitations, we propose Generalization Boosted
Adapter (GBA), a novel adapter strategy that enhances the generalization and
robustness of VLMs for open-vocabulary segmentation. GBA comprises two core
components: (1) a Style Diversification Adapter (SDA) that decouples features
into amplitude and phase components, operating solely on the amplitude to
enrich the feature space representation while preserving semantic consistency;
and (2) a Correlation Constraint Adapter (CCA) that employs cross-attention to
establish tighter semantic associations between text categories and target
regions, suppressing irrelevant low-frequency ``noise'' information and
avoiding erroneous associations. Through the synergistic effect of the shallow
SDA and the deep CCA, GBA effectively alleviates overfitting issues and
enhances the semantic relevance of feature representations. As a simple,
efficient, and plug-and-play component, GBA can be flexibly integrated into
various CLIP-based methods, demonstrating broad applicability and achieving
state-of-the-art performance on multiple open-vocabulary segmentation
benchmarks.",2024-09-13 01:49:12+00:00
Explaining Datasets in Words: Statistical Models with Natural Language Parameters,"To make sense of massive data, we often fit simplified models and then
interpret the parameters; for example, we cluster the text embeddings and then
interpret the mean parameters of each cluster. However, these parameters are
often high-dimensional and hard to interpret. To make model parameters directly
interpretable, we introduce a family of statistical models -- including
clustering, time series, and classification models -- parameterized by natural
language predicates. For example, a cluster of text about COVID could be
parameterized by the predicate ""discusses COVID"". To learn these statistical
models effectively, we develop a model-agnostic algorithm that optimizes
continuous relaxations of predicate parameters with gradient descent and
discretizes them by prompting language models (LMs). Finally, we apply our
framework to a wide range of problems: taxonomizing user chat dialogues,
characterizing how they evolve across time, finding categories where one
language model is better than the other, clustering math problems based on
subareas, and explaining visual features in memorable images. Our framework is
highly versatile, applicable to both textual and visual domains, can be easily
steered to focus on specific properties (e.g. subareas), and explains
sophisticated concepts that classical methods (e.g. n-gram analysis) struggle
to produce.",2024-09-13 01:40:20+00:00
VLTP: Vision-Language Guided Token Pruning for Task-Oriented Segmentation,"Vision Transformers (ViTs) have emerged as the backbone of many segmentation
models, consistently achieving state-of-the-art (SOTA) performance. However,
their success comes at a significant computational cost. Image token pruning is
one of the most effective strategies to address this complexity. However,
previous approaches fall short when applied to more complex task-oriented
segmentation (TOS), where the class of each image patch is not predefined but
dependent on the specific input task. This work introduces the Vision Language
Guided Token Pruning (VLTP), a novel token pruning mechanism that can
accelerate ViTbased segmentation models, particularly for TOS guided by
multi-modal large language model (MLLM). We argue that ViT does not need to
process every image token through all of its layers only the tokens related to
reasoning tasks are necessary. We design a new pruning decoder to take both
image tokens and vision-language guidance as input to predict the relevance of
each image token to the task. Only image tokens with high relevance are passed
to deeper layers of the ViT. Experiments show that the VLTP framework reduces
the computational costs of ViT by approximately 25% without performance
degradation and by around 40% with only a 1% performance drop.",2024-09-13 01:30:24+00:00
VistaFormer: Scalable Vision Transformers for Satellite Image Time Series Segmentation,"We introduce VistaFormer, a lightweight Transformer-based model architecture
for the semantic segmentation of remote-sensing images. This model uses a
multi-scale Transformer-based encoder with a lightweight decoder that
aggregates global and local attention captured in the encoder blocks.
VistaFormer uses position-free self-attention layers which simplifies the model
architecture and removes the need to interpolate temporal and spatial codes,
which can reduce model performance when training and testing image resolutions
differ. We investigate simple techniques for filtering noisy input signals like
clouds and demonstrate that improved model scalability can be achieved by
substituting Multi-Head Self-Attention (MHSA) with Neighbourhood Attention
(NA). Experiments on the PASTIS and MTLCC crop-type segmentation benchmarks
show that VistaFormer achieves better performance than comparable models and
requires only 8% of the floating point operations using MHSA and 11% using NA
while also using fewer trainable parameters. VistaFormer with MHSA improves on
state-of-the-art mIoU scores by 0.1% on the PASTIS benchmark and 3% on the
MTLCC benchmark while VistaFormer with NA improves on the MTLCC benchmark by
3.7%.",2024-09-13 01:19:53+00:00
Inter Observer Variability Assessment through Ordered Weighted Belief Divergence Measure in MAGDM Application to the Ensemble Classifier Feature Fusion,"A large number of multi-attribute group decisionmaking (MAGDM) have been
widely introduced to obtain consensus results. However, most of the
methodologies ignore the conflict among the experts opinions and only consider
equal or variable priorities of them. Therefore, this study aims to propose an
Evidential MAGDM method by assessing the inter-observational variability and
handling uncertainty that emerges between the experts. The proposed framework
has fourfold contributions. First, the basic probability assignment (BPA)
generation method is introduced to consider the inherent characteristics of
each alternative by computing the degree of belief. Second, the ordered
weighted belief and plausibility measure is constructed to capture the overall
intrinsic information of the alternative by assessing the inter-observational
variability and addressing the conflicts emerging between the group of experts.
An ordered weighted belief divergence measure is constructed to acquire the
weighted support for each group of experts to obtain the final preference
relationship. Finally, we have shown an illustrative example of the proposed
Evidential MAGDM framework. Further, we have analyzed the interpretation of
Evidential MAGDM in the real-world application for ensemble classifier feature
fusion to diagnose retinal disorders using optical coherence tomography images.",2024-09-13 00:53:00+00:00
Towards Unified Facial Action Unit Recognition Framework by Large Language Models,"Facial Action Units (AUs) are of great significance in the realm of affective
computing. In this paper, we propose AU-LLaVA, the first unified AU recognition
framework based on the Large Language Model (LLM). AU-LLaVA consists of a
visual encoder, a linear projector layer, and a pre-trained LLM. We
meticulously craft the text descriptions and fine-tune the model on various AU
datasets, allowing it to generate different formats of AU recognition results
for the same input image. On the BP4D and DISFA datasets, AU-LLaVA delivers the
most accurate recognition results for nearly half of the AUs. Our model
achieves improvements of F1-score up to 11.4% in specific AU recognition
compared to previous benchmark results. On the FEAFA dataset, our method
achieves significant improvements over all 24 AUs compared to previous
benchmark results. AU-LLaVA demonstrates exceptional performance and
versatility in AU recognition.",2024-09-13 00:26:09+00:00
CF-PRNet: Coarse-to-Fine Prototype Refining Network for Point Cloud Completion and Reconstruction,"In modern agriculture, precise monitoring of plants and fruits is crucial for
tasks such as high-throughput phenotyping and automated harvesting. This paper
addresses the challenge of reconstructing accurate 3D shapes of fruits from
partial views, which is common in agricultural settings. We introduce CF-PRNet,
a coarse-to-fine prototype refining network, leverages high-resolution 3D data
during the training phase but requires only a single RGB-D image for real-time
inference. Our approach begins by extracting the incomplete point cloud data
that constructed from a partial view of a fruit with a series of convolutional
blocks. The extracted features inform the generation of scaling vectors that
refine two sequentially constructed 3D mesh prototypes - one coarse and one
fine-grained. This progressive refinement facilitates the detailed completion
of the final point clouds, achieving detailed and accurate reconstructions.
CF-PRNet demonstrates excellent performance metrics with a Chamfer Distance of
3.78, an F1 Score of 66.76%, a Precision of 56.56%, and a Recall of 85.31%, and
win the first place in the Shape Completion and Reconstruction of Sweet Peppers
Challenge.",2024-09-13 00:20:10+00:00
Input-to-State Stable Coupled Oscillator Networks for Closed-form Model-based Control in Latent Space,"Even though a variety of methods (e.g., RL, MPC, LQR) have been proposed in
the literature, efficient and effective latent-space control of physical
systems remains an open challenge. A promising avenue would be to leverage
powerful and well-understood closed-form strategies from control theory
literature in combination with learned dynamics, such as potential-energy
shaping. We identify three fundamental shortcomings in existing latent-space
models that have so far prevented this powerful combination: (i) they lack the
mathematical structure of a physical system, (ii) they do not inherently
conserve the stability properties of the real systems. Furthermore, (iii) these
methods do not have an invertible mapping between input and latent-space
forcing. This work proposes a novel Coupled Oscillator Network (CON) model that
simultaneously tackles all these issues. More specifically, (i) we show
analytically that CON is a Lagrangian system - i.e., it presses well-defined
potential and kinetic energy terms. Then, (ii) we provide formal proof of
global Input-to-State stability using Lyapunov arguments. Moving to the
experimental side, (iii) we demonstrate that CON reaches SoA performance when
learning complex nonlinear dynamics of mechanical systems directly from images.
An additional methodological innovation contributing to achieving this third
goal is an approximated closed-form solution for efficient integration of
network dynamics, which eases efficient training. We tackle (iv) by
approximating the forcing-to-input mapping with a decoder that is trained to
reconstruct the input based on the encoded latent space force. Finally, we
leverage these four properties and show that they enable latent-space control.
We use an integral-saturated PID with potential force compensation and
demonstrate high-quality performance on a soft robot using raw pixels as the
only feedback information.",2024-09-13 00:11:09+00:00
When Context Leads but Parametric Memory Follows in Large Language Models,"Large language models (LLMs) have demonstrated remarkable progress in
leveraging diverse knowledge sources. This study investigates how nine widely
used LLMs allocate knowledge between local context and global parameters when
answering open-ended questions in knowledge-consistent scenarios. We introduce
a novel dataset, WikiAtomic, and systematically vary context sizes to analyze
how LLMs prioritize and utilize the provided information and their parametric
knowledge in knowledge-consistent scenarios. Additionally, we also study their
tendency to hallucinate under varying context sizes. Our findings reveal
consistent patterns across models, including a consistent reliance on both
contextual (around 70%) and parametric (around 30%) knowledge, and a decrease
in hallucinations with increasing context. These insights highlight the
importance of more effective context organization and developing models that
use input more deterministically for robust performance.",2024-09-13 00:03:19+00:00
Predictive Control and Regret Analysis of Non-Stationary MDP with Look-ahead Information,"Policy design in non-stationary Markov Decision Processes (MDPs) is
inherently challenging due to the complexities introduced by time-varying
system transition and reward, which make it difficult for learners to determine
the optimal actions for maximizing cumulative future rewards. Fortunately, in
many practical applications, such as energy systems, look-ahead predictions are
available, including forecasts for renewable energy generation and demand. In
this paper, we leverage these look-ahead predictions and propose an algorithm
designed to achieve low regret in non-stationary MDPs by incorporating such
predictions. Our theoretical analysis demonstrates that, under certain
assumptions, the regret decreases exponentially as the look-ahead window
expands. When the system prediction is subject to error, the regret does not
explode even if the prediction error grows sub-exponentially as a function of
the prediction horizon. We validate our approach through simulations,
confirming the efficacy of our algorithm in non-stationary environments.",2024-09-13 00:01:58+00:00
Fitted Q-Iteration via Max-Plus-Linear Approximation,"In this study, we consider the application of max-plus-linear approximators
for Q-function in offline reinforcement learning of discounted Markov decision
processes. In particular, we incorporate these approximators to propose novel
fitted Q-iteration (FQI) algorithms with provable convergence. Exploiting the
compatibility of the Bellman operator with max-plus operations, we show that
the max-plus-linear regression within each iteration of the proposed FQI
algorithm reduces to simple max-plus matrix-vector multiplications. We also
consider the variational implementation of the proposed algorithm which leads
to a per-iteration complexity that is independent of the number of samples.",2024-09-12 22:51:08+00:00
Introducing CausalBench: A Flexible Benchmark Framework for Causal Analysis and Machine Learning,"While witnessing the exceptional success of machine learning (ML)
technologies in many applications, users are starting to notice a critical
shortcoming of ML: correlation is a poor substitute for causation. The
conventional way to discover causal relationships is to use randomized
controlled experiments (RCT); in many situations, however, these are
impractical or sometimes unethical. Causal learning from observational data
offers a promising alternative. While being relatively recent, causal learning
aims to go far beyond conventional machine learning, yet several major
challenges remain. Unfortunately, advances are hampered due to the lack of
unified benchmark datasets, algorithms, metrics, and evaluation service
interfaces for causal learning. In this paper, we introduce {\em CausalBench},
a transparent, fair, and easy-to-use evaluation platform, aiming to (a) enable
the advancement of research in causal learning by facilitating scientific
collaboration in novel algorithms, datasets, and metrics and (b) promote
scientific objectivity, reproducibility, fairness, and awareness of bias in
causal learning research. CausalBench provides services for benchmarking data,
algorithms, models, and metrics, impacting the needs of a broad of scientific
and engineering disciplines.",2024-09-12 22:45:10+00:00
Wasserstein Distributionally Robust Multiclass Support Vector Machine,"We study the problem of multiclass classification for settings where data
features $\mathbf{x}$ and their labels $\mathbf{y}$ are uncertain. We identify
that distributionally robust one-vs-all (OVA) classifiers often struggle in
settings with imbalanced data. To address this issue, we use Wasserstein
distributionally robust optimization to develop a robust version of the
multiclass support vector machine (SVM) characterized by the Crammer-Singer
(CS) loss. First, we prove that the CS loss is bounded from above by a
Lipschitz continuous function for all $\mathbf{x} \in \mathcal{X}$ and
$\mathbf{y} \in \mathcal{Y}$, then we exploit strong duality results to express
the dual of the worst-case risk problem, and we show that the worst-case risk
minimization problem admits a tractable convex reformulation due to the
regularity of the CS loss. Moreover, we develop a kernel version of our
proposed model to account for nonlinear class separation, and we show that it
admits a tractable convex upper bound. We also propose a projected subgradient
method algorithm for a special case of our proposed linear model to improve
scalability. Our numerical experiments demonstrate that our model outperforms
state-of-the art OVA models in settings where the training data is highly
imbalanced. We also show through experiments on popular real-world datasets
that our proposed model often outperforms its regularized counterpart as the
first accounts for uncertain labels unlike the latter.",2024-09-12 21:40:04+00:00
Knowledge Tagging with Large Language Model based Multi-Agent System,"Knowledge tagging for questions is vital in modern intelligent educational
applications, including learning progress diagnosis, practice question
recommendations, and course content organization. Traditionally, these
annotations have been performed by pedagogical experts, as the task demands not
only a deep semantic understanding of question stems and knowledge definitions
but also a strong ability to link problem-solving logic with relevant knowledge
concepts. With the advent of advanced natural language processing (NLP)
algorithms, such as pre-trained language models and large language models
(LLMs), pioneering studies have explored automating the knowledge tagging
process using various machine learning models. In this paper, we investigate
the use of a multi-agent system to address the limitations of previous
algorithms, particularly in handling complex cases involving intricate
knowledge definitions and strict numerical constraints. By demonstrating its
superior performance on the publicly available math question knowledge tagging
dataset, MathKnowCT, we highlight the significant potential of an LLM-based
multi-agent system in overcoming the challenges that previous methods have
encountered. Finally, through an in-depth discussion of the implications of
automating knowledge tagging, we underscore the promising results of deploying
LLM-based algorithms in educational contexts.",2024-09-12 21:39:01+00:00
Scores as Actions: a framework of fine-tuning diffusion models by continuous-time reinforcement learning,"Reinforcement Learning from human feedback (RLHF) has been shown a promising
direction for aligning generative models with human intent and has also been
explored in recent works for alignment of diffusion generative models. In this
work, we provide a rigorous treatment by formulating the task of fine-tuning
diffusion models, with reward functions learned from human feedback, as an
exploratory continuous-time stochastic control problem. Our key idea lies in
treating the score-matching functions as controls/actions, and upon this, we
develop a unified framework from a continuous-time perspective, to employ
reinforcement learning (RL) algorithms in terms of improving the generation
quality of diffusion models. We also develop the corresponding continuous-time
RL theory for policy optimization and regularization under assumptions of
stochastic different equations driven environment. Experiments on the
text-to-image (T2I) generation will be reported in the accompanied paper.",2024-09-12 21:12:21+00:00
360PanT: Training-Free Text-Driven 360-Degree Panorama-to-Panorama Translation,"Preserving boundary continuity in the translation of 360-degree panoramas
remains a significant challenge for existing text-driven image-to-image
translation methods. These methods often produce visually jarring
discontinuities at the translated panorama's boundaries, disrupting the
immersive experience. To address this issue, we propose 360PanT, a
training-free approach to text-based 360-degree panorama-to-panorama
translation with boundary continuity. Our 360PanT achieves seamless
translations through two key components: boundary continuity encoding and
seamless tiling translation with spatial control. Firstly, the boundary
continuity encoding embeds critical boundary continuity information of the
input 360-degree panorama into the noisy latent representation by constructing
an extended input image. Secondly, leveraging this embedded noisy latent
representation and guided by a target prompt, the seamless tiling translation
with spatial control enables the generation of a translated image with
identical left and right halves while adhering to the extended input's
structure and semantic layout. This process ensures a final translated
360-degree panorama with seamless boundary continuity. Experimental results on
both real-world and synthesized datasets demonstrate the effectiveness of our
360PanT in translating 360-degree panoramas. Code is available at
\href{https://github.com/littlewhitesea/360PanT}{https://github.com/littlewhitesea/360PanT}.",2024-09-12 20:56:16+00:00
Federated One-Shot Ensemble Clustering,"Cluster analysis across multiple institutions poses significant challenges
due to data-sharing restrictions. To overcome these limitations, we introduce
the Federated One-shot Ensemble Clustering (FONT) algorithm, a novel solution
tailored for multi-site analyses under such constraints. FONT requires only a
single round of communication between sites and ensures privacy by exchanging
only fitted model parameters and class labels. The algorithm combines locally
fitted clustering models into a data-adaptive ensemble, making it broadly
applicable to various clustering techniques and robust to differences in
cluster proportions across sites. Our theoretical analysis validates the
effectiveness of the data-adaptive weights learned by FONT, and simulation
studies demonstrate its superior performance compared to existing benchmark
methods. We applied FONT to identify subgroups of patients with rheumatoid
arthritis across two health systems, revealing improved consistency of patient
clusters across sites, while locally fitted clusters proved less transferable.
FONT is particularly well-suited for real-world applications with stringent
communication and privacy constraints, offering a scalable and practical
solution for multi-site clustering.",2024-09-12 20:55:21+00:00
Graphical Structural Learning of rs-fMRI data in Heavy Smokers,"Recent studies revealed structural and functional brain changes in heavy
smokers. However, the specific changes in topological brain connections are not
well understood. We used Gaussian Undirected Graphs with the graphical lasso
algorithm on rs-fMRI data from smokers and non-smokers to identify significant
changes in brain connections. Our results indicate high stability in the
estimated graphs and identify several brain regions significantly affected by
smoking, providing valuable insights for future clinical research.",2024-09-12 20:48:28+00:00
Higher-Order Topological Directionality and Directed Simplicial Neural Networks,"Topological Deep Learning (TDL) has emerged as a paradigm to process and
learn from signals defined on higher-order combinatorial topological spaces,
such as simplicial or cell complexes. Although many complex systems have an
asymmetric relational structure, most TDL models forcibly symmetrize these
relationships. In this paper, we first introduce a novel notion of higher-order
directionality and we then design Directed Simplicial Neural Networks
(Dir-SNNs) based on it. Dir-SNNs are message-passing networks operating on
directed simplicial complexes able to leverage directed and possibly asymmetric
interactions among the simplices. To our knowledge, this is the first TDL model
using a notion of higher-order directionality. We theoretically and empirically
prove that Dir-SNNs are more expressive than their directed graph counterpart
in distinguishing isomorphic directed graphs. Experiments on a synthetic source
localization task demonstrate that Dir-SNNs outperform undirected SNNs when the
underlying complex is directed, and perform comparably when the underlying
complex is undirected.",2024-09-12 20:37:14+00:00
Continual Learning in 3D Point Clouds: Employing Spectral Techniques for Exemplar Selection,"We introduce a novel framework for Continual Learning in 3D object
classification (CL3D). Our approach is based on the selection of prototypes
from each class using spectral clustering. For non-Euclidean data such as point
clouds, spectral clustering can be employed as long as one can define a
distance measure between pairs of samples. Choosing the appropriate distance
measure enables us to leverage 3D geometric characteristics to identify
representative prototypes for each class. We explore the effectiveness of
clustering in the input space (3D points), local feature space
(1024-dimensional points), and global feature space. We conduct experiments on
the ModelNet40, ShapeNet, and ScanNet datasets, achieving state-of-the-art
accuracy exclusively through the use of input space features. By leveraging the
combined input, local, and global features, we have improved the
state-of-the-art on ModelNet and ShapeNet, utilizing nearly half the memory
used by competing approaches. For the challenging ScanNet dataset, our method
enhances accuracy by 4.1% while consuming just 28% of the memory used by our
competitors, demonstrating the scalability of our approach.",2024-09-12 20:34:34+00:00
Self-Supervised Inference of Agents in Trustless Environments,"In this paper, we propose a novel approach where agents can form swarms to
produce high-quality responses effectively. This is accomplished by utilizing
agents capable of data inference and ranking, which can be effectively
implemented using LLMs as response classifiers. We assess existing approaches
for trustless agent inference, define our methodology, estimate practical
parameters, and model various types of malicious agent attacks. Our method
leverages the collective intelligence of swarms, ensuring robust and efficient
decentralized AI inference with better accuracy, security, and reliability. We
show that our approach is an order of magnitude faster than other trustless
inference strategies reaching less than 125 ms validation latency.",2024-09-12 20:32:07+00:00
Noisy Low Rank Column-wise Sensing,"This letter studies the AltGDmin algorithm for solving the noisy low rank
column-wise sensing (LRCS) problem. Our sample complexity guarantee improves
upon the best existing one by a factor $\max(r, \log(1/\epsilon))/r$ where $r$
is the rank of the unknown matrix and $\epsilon$ is the final desired accuracy.
A second contribution of this work is a detailed comparison of guarantees from
all work that studies the exact same mathematical problem as LRCS, but refers
to it by different names.",2024-09-12 20:21:00+00:00
Stochastic Reinforcement Learning with Stability Guarantees for Control of Unknown Nonlinear Systems,"Designing a stabilizing controller for nonlinear systems is a challenging
task, especially for high-dimensional problems with unknown dynamics.
Traditional reinforcement learning algorithms applied to stabilization tasks
tend to drive the system close to the equilibrium point. However, these
approaches often fall short of achieving true stabilization and result in
persistent oscillations around the equilibrium point. In this work, we propose
a reinforcement learning algorithm that stabilizes the system by learning a
local linear representation ofthe dynamics. The main component of the algorithm
is integrating the learned gain matrix directly into the neural policy. We
demonstrate the effectiveness of our algorithm on several challenging
high-dimensional dynamical systems. In these simulations, our algorithm
outperforms popular reinforcement learning algorithms, such as soft
actor-critic (SAC) and proximal policy optimization (PPO), and successfully
stabilizes the system. To support the numerical results, we provide a
theoretical analysis of the feasibility of the learned algorithm for both
deterministic and stochastic reinforcement learning settings, along with a
convergence analysis of the proposed learning algorithm. Furthermore, we verify
that the learned control policies indeed provide asymptotic stability for the
nonlinear systems.",2024-09-12 20:07:54+00:00
Rethinking Prompting Strategies for Multi-Label Recognition with Partial Annotations,"Vision-language models (VLMs) like CLIP have been adapted for Multi-Label
Recognition (MLR) with partial annotations by leveraging prompt-learning, where
positive and negative prompts are learned for each class to associate their
embeddings with class presence or absence in the shared vision-text feature
space. While this approach improves MLR performance by relying on VLM priors,
we hypothesize that learning negative prompts may be suboptimal, as the
datasets used to train VLMs lack image-caption pairs explicitly focusing on
class absence. To analyze the impact of positive and negative prompt learning
on MLR, we introduce PositiveCoOp and NegativeCoOp, where only one prompt is
learned with VLM guidance while the other is replaced by an embedding vector
learned directly in the shared feature space without relying on the text
encoder. Through empirical analysis, we observe that negative prompts degrade
MLR performance, and learning only positive prompts, combined with learned
negative embeddings (PositiveCoOp), outperforms dual prompt learning
approaches. Moreover, we quantify the performance benefits that prompt-learning
offers over a simple vision-features-only baseline, observing that the baseline
displays strong performance comparable to dual prompt learning approach
(DualCoOp), when the proportion of missing labels is low, while requiring half
the training compute and 16 times fewer parameters",2024-09-12 20:02:51+00:00
The Impact of Large Language Models on Open-source Innovation: Evidence from GitHub Copilot,"Generative AI (GenAI) has been shown to enhance individual productivity in a
guided setting. While it is also likely to transform processes in a
collaborative work setting, it is unclear what trajectory this transformation
will follow. Collaborative environment is characterized by a blend of
origination tasks that involve building something from scratch and iteration
tasks that involve refining on others' work. Whether GenAI affects these two
aspects of collaborative work and to what extent is an open empirical question.
We study this question within the open-source development landscape, a prime
example of collaborative innovation, where contributions are voluntary and
unguided. Specifically, we focus on the launch of GitHub Copilot in October
2021 and leverage a natural experiment in which GitHub Copilot (a
programming-focused LLM) selectively rolled out support for Python, but not for
R. We observe a significant jump in overall contributions, suggesting that
GenAI effectively augments collaborative innovation in an unguided setting.
Interestingly, Copilot's launch increased maintenance-related contributions,
which are mostly iterative tasks involving building on others' work,
significantly more than code-development contributions, which are mostly
origination tasks involving standalone contributions. This disparity was
exacerbated in active projects with extensive coding activity, raising concerns
that, as GenAI models improve to accommodate richer context, the gap between
origination and iterative solutions may widen. We discuss practical and policy
implications to incentivize high-value innovative solutions.",2024-09-12 19:59:54+00:00
Learned Compression for Images and Point Clouds,"Over the last decade, deep learning has shown great success at performing
computer vision tasks, including classification, super-resolution, and style
transfer. Now, we apply it to data compression to help build the next
generation of multimedia codecs. This thesis provides three primary
contributions to this new field of learned compression. First, we present an
efficient low-complexity entropy model that dynamically adapts the encoding
distribution to a specific input by compressing and transmitting the encoding
distribution itself as side information. Secondly, we propose a novel
lightweight low-complexity point cloud codec that is highly specialized for
classification, attaining significant reductions in bitrate compared to
non-specialized codecs. Lastly, we explore how motion within the input domain
between consecutive video frames is manifested in the corresponding
convolutionally-derived latent space.",2024-09-12 19:57:44+00:00
FedProphet: Memory-Efficient Federated Adversarial Training via Theoretic-Robustness and Low-Inconsistency Cascade Learning,"Federated Learning (FL) provides a strong privacy guarantee by enabling local
training across edge devices without training data sharing, and Federated
Adversarial Training (FAT) further enhances the robustness against adversarial
examples, promoting a step toward trustworthy artificial intelligence. However,
FAT requires a large model to preserve high accuracy while achieving strong
robustness, and it is impractically slow when directly training with
memory-constrained edge devices due to the memory-swapping latency. Moreover,
existing memory-efficient FL methods suffer from poor accuracy and weak
robustness in FAT because of inconsistent local and global models, i.e.,
objective inconsistency.
  In this paper, we propose FedProphet, a novel FAT framework that can achieve
memory efficiency, adversarial robustness, and objective consistency
simultaneously. FedProphet partitions the large model into small cascaded
modules such that the memory-constrained devices can conduct adversarial
training module-by-module. A strong convexity regularization is derived to
theoretically guarantee the robustness of the whole model, and we show that the
strong robustness implies low objective inconsistency in FedProphet. We also
develop a training coordinator on the server of FL, with Adaptive Perturbation
Adjustment for utility-robustness balance and Differentiated Module Assignment
for objective inconsistency mitigation. FedProphet empirically shows a
significant improvement in both accuracy and robustness compared to previous
memory-efficient methods, achieving almost the same performance of end-to-end
FAT with 80% memory reduction and up to 10.8x speedup in training time.",2024-09-12 19:39:14+00:00
E-QUARTIC: Energy Efficient Edge Ensemble of Convolutional Neural Networks for Resource-Optimized Learning,"Ensemble learning is a meta-learning approach that combines the predictions
of multiple learners, demonstrating improved accuracy and robustness.
Nevertheless, ensembling models like Convolutional Neural Networks (CNNs)
result in high memory and computing overhead, preventing their deployment in
embedded systems. These devices are usually equipped with small batteries that
provide power supply and might include energy-harvesting modules that extract
energy from the environment. In this work, we propose E-QUARTIC, a novel Energy
Efficient Edge Ensembling framework to build ensembles of CNNs targeting
Artificial Intelligence (AI)-based embedded systems. Our design outperforms
single-instance CNN baselines and state-of-the-art edge AI solutions, improving
accuracy and adapting to varying energy conditions while maintaining similar
memory requirements. Then, we leverage the multi-CNN structure of the designed
ensemble to implement an energy-aware model selection policy in
energy-harvesting AI systems. We show that our solution outperforms the
state-of-the-art by reducing system failure rate by up to 40% while ensuring
higher average output qualities. Ultimately, we show that the proposed design
enables concurrent on-device training and high-quality inference execution at
the edge, limiting the performance and energy overheads to less than 0.04%.",2024-09-12 19:30:22+00:00
An Experimental Study of Competitive Market Behavior Through LLMs,"This study explores the potential of large language models (LLMs) to conduct
market experiments, aiming to understand their capability to comprehend
competitive market dynamics. We model the behavior of market agents in a
controlled experimental setting, assessing their ability to converge toward
competitive equilibria. The results reveal the challenges current LLMs face in
replicating the dynamic decision-making processes characteristic of human
trading behavior. Unlike humans, LLMs lacked the capacity to achieve market
equilibrium. The research demonstrates that while LLMs provide a valuable tool
for scalable and reproducible market simulations, their current limitations
necessitate further advancements to fully capture the complexities of market
behavior. Future work that enhances dynamic learning capabilities and
incorporates elements of behavioral economics could improve the effectiveness
of LLMs in the economic domain, providing new insights into market dynamics and
aiding in the refinement of economic policies.",2024-09-12 18:50:13+00:00
COMEX Copper Futures Volatility Forecasting: Econometric Models and Deep Learning,"This paper investigates the forecasting performance of COMEX copper futures
realized volatility across various high-frequency intervals using both
econometric volatility models and deep learning recurrent neural network
models. The econometric models considered are GARCH and HAR, while the deep
learning models include RNN (Recurrent Neural Network), LSTM (Long Short-Term
Memory), and GRU (Gated Recurrent Unit). In forecasting daily realized
volatility for COMEX copper futures with a rolling window approach, the
econometric models, particularly HAR, outperform recurrent neural networks
overall, with HAR achieving the lowest QLIKE loss function value. However, when
the data is replaced with hourly high-frequency realized volatility, the deep
learning models outperform the GARCH model, and HAR attains a comparable QLIKE
loss function value. Despite the black-box nature of machine learning models,
the deep learning models demonstrate superior forecasting performance,
surpassing the fixed QLIKE value of HAR in the experiment. Moreover, as the
forecast horizon extends for daily realized volatility, deep learning models
gradually close the performance gap with the GARCH model in certain loss
function metrics. Nonetheless, HAR remains the most effective model overall for
daily realized volatility forecasting in copper futures.",2024-09-12 18:44:31+00:00
Robust Dual Gaussian Splatting for Immersive Human-centric Volumetric Videos,"Volumetric video represents a transformative advancement in visual media,
enabling users to freely navigate immersive virtual experiences and narrowing
the gap between digital and real worlds. However, the need for extensive manual
intervention to stabilize mesh sequences and the generation of excessively
large assets in existing workflows impedes broader adoption. In this paper, we
present a novel Gaussian-based approach, dubbed \textit{DualGS}, for real-time
and high-fidelity playback of complex human performance with excellent
compression ratios. Our key idea in DualGS is to separately represent motion
and appearance using the corresponding skin and joint Gaussians. Such an
explicit disentanglement can significantly reduce motion redundancy and enhance
temporal coherence. We begin by initializing the DualGS and anchoring skin
Gaussians to joint Gaussians at the first frame. Subsequently, we employ a
coarse-to-fine training strategy for frame-by-frame human performance modeling.
It includes a coarse alignment phase for overall motion prediction as well as a
fine-grained optimization for robust tracking and high-fidelity rendering. To
integrate volumetric video seamlessly into VR environments, we efficiently
compress motion using entropy encoding and appearance using codec compression
coupled with a persistent codebook. Our approach achieves a compression ratio
of up to 120 times, only requiring approximately 350KB of storage per frame. We
demonstrate the efficacy of our representation through photo-realistic,
free-view experiences on VR headsets, enabling users to immersively watch
musicians in performance and feel the rhythm of the notes at the performers'
fingertips.",2024-09-12 18:33:13+00:00
Bayesian Inverse Graphics for Few-Shot Concept Learning,"Humans excel at building generalizations of new concepts from just one single
example. Contrary to this, current computer vision models typically require
large amount of training samples to achieve a comparable accuracy. In this work
we present a Bayesian model of perception that learns using only minimal data,
a prototypical probabilistic program of an object. Specifically, we propose a
generative inverse graphics model of primitive shapes, to infer posterior
distributions over physically consistent parameters from one or several images.
We show how this representation can be used for downstream tasks such as
few-shot classification and pose estimation. Our model outperforms existing
few-shot neural-only classification algorithms and demonstrates generalization
across varying lighting conditions, backgrounds, and out-of-distribution
shapes. By design, our model is uncertainty-aware and uses our new
differentiable renderer for optimizing global scene parameters through gradient
descent, sampling posterior distributions over object parameters with Markov
Chain Monte Carlo (MCMC), and using a neural based likelihood function.",2024-09-12 18:30:41+00:00
Towards Quantifying and Reducing Language Mismatch Effects in Cross-Lingual Speech Anti-Spoofing,"The effects of language mismatch impact speech anti-spoofing systems, while
investigations and quantification of these effects remain limited. Existing
anti-spoofing datasets are mainly in English, and the high cost of acquiring
multilingual datasets hinders training language-independent models. We initiate
this work by evaluating top-performing speech anti-spoofing systems that are
trained on English data but tested on other languages, observing notable
performance declines. We propose an innovative approach - Accent-based data
expansion via TTS (ACCENT), which introduces diverse linguistic knowledge to
monolingual-trained models, improving their cross-lingual capabilities. We
conduct experiments on a large-scale dataset consisting of over 3 million
samples, including 1.8 million training samples and nearly 1.2 million testing
samples across 12 languages. The language mismatch effects are preliminarily
quantified and remarkably reduced over 15% by applying the proposed ACCENT.
This easily implementable method shows promise for multilingual and
low-resource language scenarios.",2024-09-12 18:18:22+00:00
SIG: A Synthetic Identity Generation Pipeline for Generating Evaluation Datasets for Face Recognition,"As Artificial Intelligence applications expand, the evaluation of models
faces heightened scrutiny. Ensuring public readiness requires evaluation
datasets, which differ from training data by being disjoint and ethically
sourced in compliance with privacy regulations. The performance and fairness of
face recognition systems depend significantly on the quality and
representativeness of these evaluation datasets. This data is sometimes scraped
from the internet without user's consent, causing ethical concerns that can
prohibit its use without proper releases. In rare cases, data is collected in a
controlled environment with consent, however, this process is time-consuming,
expensive, and logistically difficult to execute. This creates a barrier for
those unable to conjure the immense resources required to gather ethically
sourced evaluation datasets. To address these challenges, we introduce the
Synthetic Identity Generation pipeline, or SIG, that allows for the targeted
creation of ethical, balanced datasets for face recognition evaluation. Our
proposed and demonstrated pipeline generates high-quality images of synthetic
identities with controllable pose, facial features, and demographic attributes,
such as race, gender, and age. We also release an open-source evaluation
dataset named ControlFace10k, consisting of 10,008 face images of 3,336 unique
synthetic identities balanced across race, gender, and age, generated using the
proposed SIG pipeline. We analyze ControlFace10k along with a non-synthetic
BUPT dataset using state-of-the-art face recognition algorithms to demonstrate
its effectiveness as an evaluation tool. This analysis highlights the dataset's
characteristics and its utility in assessing algorithmic bias across different
demographic groups.",2024-09-12 18:18:02+00:00
Digital Volumetric Biopsy Cores Improve Gleason Grading of Prostate Cancer Using Deep Learning,"Prostate cancer (PCa) was the most frequently diagnosed cancer among American
men in 2023. The histological grading of biopsies is essential for diagnosis,
and various deep learning-based solutions have been developed to assist with
this task. Existing deep learning frameworks are typically applied to
individual 2D cross-sections sliced from 3D biopsy tissue specimens. This
process impedes the analysis of complex tissue structures such as glands, which
can vary depending on the tissue slice examined. We propose a novel digital
pathology data source called a ""volumetric core,"" obtained via the extraction
and co-alignment of serially sectioned tissue sections using a novel
morphology-preserving alignment framework. We trained an attention-based
multiple-instance learning (ABMIL) framework on deep features extracted from
volumetric patches to automatically classify the Gleason Grade Group (GGG). To
handle volumetric patches, we used a modified video transformer with a deep
feature extractor pretrained using self-supervised learning. We ran our
morphology-preserving alignment framework to construct 10,210 volumetric cores,
leaving out 30% for pretraining. The rest of the dataset was used to train
ABMIL, which resulted in a 0.958 macro-average AUC, 0.671 F1 score, 0.661
precision, and 0.695 recall averaged across all five GGG significantly
outperforming the 2D baselines.",2024-09-12 18:00:25+00:00
DreamHOI: Subject-Driven Generation of 3D Human-Object Interactions with Diffusion Priors,"We present DreamHOI, a novel method for zero-shot synthesis of human-object
interactions (HOIs), enabling a 3D human model to realistically interact with
any given object based on a textual description. This task is complicated by
the varying categories and geometries of real-world objects and the scarcity of
datasets encompassing diverse HOIs. To circumvent the need for extensive data,
we leverage text-to-image diffusion models trained on billions of image-caption
pairs. We optimize the articulation of a skinned human mesh using Score
Distillation Sampling (SDS) gradients obtained from these models, which predict
image-space edits. However, directly backpropagating image-space gradients into
complex articulation parameters is ineffective due to the local nature of such
gradients. To overcome this, we introduce a dual implicit-explicit
representation of a skinned mesh, combining (implicit) neural radiance fields
(NeRFs) with (explicit) skeleton-driven mesh articulation. During optimization,
we transition between implicit and explicit forms, grounding the NeRF
generation while refining the mesh articulation. We validate our approach
through extensive experiments, demonstrating its effectiveness in generating
realistic HOIs.",2024-09-12 17:59:49+00:00
Depth on Demand: Streaming Dense Depth from a Low Frame Rate Active Sensor,"High frame rate and accurate depth estimation plays an important role in
several tasks crucial to robotics and automotive perception. To date, this can
be achieved through ToF and LiDAR devices for indoor and outdoor applications,
respectively. However, their applicability is limited by low frame rate, energy
consumption, and spatial sparsity. Depth on Demand (DoD) allows for accurate
temporal and spatial depth densification achieved by exploiting a high frame
rate RGB sensor coupled with a potentially lower frame rate and sparse active
depth sensor. Our proposal jointly enables lower energy consumption and denser
shape reconstruction, by significantly reducing the streaming requirements on
the depth sensor thanks to its three core stages: i) multi-modal encoding, ii)
iterative multi-modal integration, and iii) depth decoding. We present extended
evidence assessing the effectiveness of DoD on indoor and outdoor video
datasets, covering both environment scanning and automotive perception use
cases.",2024-09-12 17:59:46+00:00
AnySkin: Plug-and-play Skin Sensing for Robotic Touch,"While tactile sensing is widely accepted as an important and useful sensing
modality, its use pales in comparison to other sensory modalities like vision
and proprioception. AnySkin addresses the critical challenges that impede the
use of tactile sensing -- versatility, replaceability, and data reusability.
Building on the simplistic design of ReSkin, and decoupling the sensing
electronics from the sensing interface, AnySkin simplifies integration making
it as straightforward as putting on a phone case and connecting a charger.
Furthermore, AnySkin is the first uncalibrated tactile-sensor with
cross-instance generalizability of learned manipulation policies. To summarize,
this work makes three key contributions: first, we introduce a streamlined
fabrication process and a design tool for creating an adhesive-free, durable
and easily replaceable magnetic tactile sensor; second, we characterize slip
detection and policy learning with the AnySkin sensor; and third, we
demonstrate zero-shot generalization of models trained on one instance of
AnySkin to new instances, and compare it with popular existing tactile
solutions like DIGIT and ReSkin.https://any-skin.github.io/",2024-09-12 17:59:44+00:00
DeCLIP: Decoding CLIP representations for deepfake localization,"Generative models can create entirely new images, but they can also partially
modify real images in ways that are undetectable to the human eye. In this
paper, we address the challenge of automatically detecting such local
manipulations. One of the most pressing problems in deepfake detection remains
the ability of models to generalize to different classes of generators. In the
case of fully manipulated images, representations extracted from large
self-supervised models (such as CLIP) provide a promising direction towards
more robust detectors. Here, we introduce DeCLIP, a first attempt to leverage
such large pretrained features for detecting local manipulations. We show that,
when combined with a reasonably large convolutional decoder, pretrained
self-supervised representations are able to perform localization and improve
generalization capabilities over existing methods. Unlike previous work, our
approach is able to perform localization on the challenging case of latent
diffusion models, where the entire image is affected by the fingerprint of the
generator. Moreover, we observe that this type of data, which combines local
semantic information with a global fingerprint, provides more stable
generalization than other categories of generative methods.",2024-09-12 17:59:08+00:00
Hand-Object Interaction Pretraining from Videos,"We present an approach to learn general robot manipulation priors from 3D
hand-object interaction trajectories. We build a framework to use in-the-wild
videos to generate sensorimotor robot trajectories. We do so by lifting both
the human hand and the manipulated object in a shared 3D space and retargeting
human motions to robot actions. Generative modeling on this data gives us a
task-agnostic base policy. This policy captures a general yet flexible
manipulation prior. We empirically demonstrate that finetuning this policy,
with both reinforcement learning (RL) and behavior cloning (BC), enables
sample-efficient adaptation to downstream tasks and simultaneously improves
robustness and generalizability compared to prior approaches. Qualitative
experiments are available at: \url{https://hgaurav2k.github.io/hop/}.",2024-09-12 17:59:07+00:00
Click2Mask: Local Editing with Dynamic Mask Generation,"Recent advancements in generative models have revolutionized image generation
and editing, making these tasks accessible to non-experts. This paper focuses
on local image editing, particularly the task of adding new content to a
loosely specified area. Existing methods often require a precise mask or a
detailed description of the location, which can be cumbersome and prone to
errors. We propose Click2Mask, a novel approach that simplifies the local
editing process by requiring only a single point of reference (in addition to
the content description). A mask is dynamically grown around this point during
a Blended Latent Diffusion (BLD) process, guided by a masked CLIP-based
semantic loss. Click2Mask surpasses the limitations of segmentation-based and
fine-tuning dependent methods, offering a more user-friendly and contextually
accurate solution. Our experiments demonstrate that Click2Mask not only
minimizes user effort but also delivers competitive or superior local image
manipulation results compared to SoTA methods, according to both human
judgement and automatic metrics. Key contributions include the simplification
of user input, the ability to freely add objects unconstrained by existing
segments, and the integration potential of our dynamic mask approach within
other editing methods.",2024-09-12 17:59:04+00:00
DreamBeast: Distilling 3D Fantastical Animals with Part-Aware Knowledge Transfer,"We present DreamBeast, a novel method based on score distillation sampling
(SDS) for generating fantastical 3D animal assets composed of distinct parts.
Existing SDS methods often struggle with this generation task due to a limited
understanding of part-level semantics in text-to-image diffusion models. While
recent diffusion models, such as Stable Diffusion 3, demonstrate a better
part-level understanding, they are prohibitively slow and exhibit other common
problems associated with single-view diffusion models. DreamBeast overcomes
this limitation through a novel part-aware knowledge transfer mechanism. For
each generated asset, we efficiently extract part-level knowledge from the
Stable Diffusion 3 model into a 3D Part-Affinity implicit representation. This
enables us to instantly generate Part-Affinity maps from arbitrary camera
views, which we then use to modulate the guidance of a multi-view diffusion
model during SDS to create 3D assets of fantastical animals. DreamBeast
significantly enhances the quality of generated 3D creatures with
user-specified part compositions while reducing computational overhead, as
demonstrated by extensive quantitative and qualitative evaluations.",2024-09-12 17:58:31+00:00
FlashSplat: 2D to 3D Gaussian Splatting Segmentation Solved Optimally,"This study addresses the challenge of accurately segmenting 3D Gaussian
Splatting from 2D masks. Conventional methods often rely on iterative gradient
descent to assign each Gaussian a unique label, leading to lengthy optimization
and sub-optimal solutions. Instead, we propose a straightforward yet globally
optimal solver for 3D-GS segmentation. The core insight of our method is that,
with a reconstructed 3D-GS scene, the rendering of the 2D masks is essentially
a linear function with respect to the labels of each Gaussian. As such, the
optimal label assignment can be solved via linear programming in closed form.
This solution capitalizes on the alpha blending characteristic of the splatting
process for single step optimization. By incorporating the background bias in
our objective function, our method shows superior robustness in 3D segmentation
against noises. Remarkably, our optimization completes within 30 seconds, about
50$\times$ faster than the best existing methods. Extensive experiments
demonstrate the efficiency and robustness of our method in segmenting various
scenes, and its superior performance in downstream tasks such as object removal
and inpainting. Demos and code will be available at
https://github.com/florinshen/FlashSplat.",2024-09-12 17:58:13+00:00
Windows Agent Arena: Evaluating Multi-Modal OS Agents at Scale,"Large language models (LLMs) show remarkable potential to act as computer
agents, enhancing human productivity and software accessibility in multi-modal
tasks that require planning and reasoning. However, measuring agent performance
in realistic environments remains a challenge since: (i) most benchmarks are
limited to specific modalities or domains (e.g. text-only, web navigation, Q&A,
coding) and (ii) full benchmark evaluations are slow (on order of magnitude of
days) given the multi-step sequential nature of tasks. To address these
challenges, we introduce the Windows Agent Arena: a reproducible, general
environment focusing exclusively on the Windows operating system (OS) where
agents can operate freely within a real Windows OS and use the same wide range
of applications, tools, and web browsers available to human users when solving
tasks. We adapt the OSWorld framework (Xie et al., 2024) to create 150+ diverse
Windows tasks across representative domains that require agent abilities in
planning, screen understanding, and tool usage. Our benchmark is scalable and
can be seamlessly parallelized in Azure for a full benchmark evaluation in as
little as 20 minutes. To demonstrate Windows Agent Arena's capabilities, we
also introduce a new multi-modal agent, Navi. Our agent achieves a success rate
of 19.5% in the Windows domain, compared to 74.5% performance of an unassisted
human. Navi also demonstrates strong performance on another popular web-based
benchmark, Mind2Web. We offer extensive quantitative and qualitative analysis
of Navi's performance, and provide insights into the opportunities for future
research in agent development and data generation using Windows Agent Arena.
  Webpage: https://microsoft.github.io/WindowsAgentArena
  Code: https://github.com/microsoft/WindowsAgentArena",2024-09-12 17:56:43+00:00
Learning incomplete factorization preconditioners for GMRES,"In this paper, we develop a data-driven approach to generate incomplete LU
factorizations of large-scale sparse matrices. The learned approximate
factorization is utilized as a preconditioner for the corresponding linear
equation system in the GMRES method. Incomplete factorization methods are one
of the most commonly applied algebraic preconditioners for sparse linear
equation systems and are able to speed up the convergence of Krylov subspace
methods. However, they are sensitive to hyper-parameters and might suffer from
numerical breakdown or lead to slow convergence when not properly applied. We
replace the typically hand-engineered algorithms with a graph neural network
based approach that is trained against data to predict an approximate
factorization. This allows us to learn preconditioners tailored for a specific
problem distribution. We analyze and empirically evaluate different loss
functions to train the learned preconditioners and show their effectiveness to
decrease the number of GMRES iterations and improve the spectral properties on
our synthetic dataset. The code is available at
https://github.com/paulhausner/neural-incomplete-factorization.",2024-09-12 17:55:44+00:00
Improving Text-guided Object Inpainting with Semantic Pre-inpainting,"Recent years have witnessed the success of large text-to-image diffusion
models and their remarkable potential to generate high-quality images. The
further pursuit of enhancing the editability of images has sparked significant
interest in the downstream task of inpainting a novel object described by a
text prompt within a designated region in the image. Nevertheless, the problem
is not trivial from two aspects: 1) Solely relying on one single U-Net to align
text prompt and visual object across all the denoising timesteps is
insufficient to generate desired objects; 2) The controllability of object
generation is not guaranteed in the intricate sampling space of diffusion
model. In this paper, we propose to decompose the typical single-stage object
inpainting into two cascaded processes: 1) semantic pre-inpainting that infers
the semantic features of desired objects in a multi-modal feature space; 2)
high-fieldity object generation in diffusion latent space that pivots on such
inpainted semantic features. To achieve this, we cascade a Transformer-based
semantic inpainter and an object inpainting diffusion model, leading to a novel
CAscaded Transformer-Diffusion (CAT-Diffusion) framework for text-guided object
inpainting. Technically, the semantic inpainter is trained to predict the
semantic features of the target object conditioning on unmasked context and
text prompt. The outputs of the semantic inpainter then act as the informative
visual prompts to guide high-fieldity object generation through a reference
adapter layer, leading to controllable object inpainting. Extensive evaluations
on OpenImages-V6 and MSCOCO validate the superiority of CAT-Diffusion against
the state-of-the-art methods. Code is available at
\url{https://github.com/Nnn-s/CATdiffusion}.",2024-09-12 17:55:37+00:00
Improving Virtual Try-On with Garment-focused Diffusion Models,"Diffusion models have led to the revolutionizing of generative modeling in
numerous image synthesis tasks. Nevertheless, it is not trivial to directly
apply diffusion models for synthesizing an image of a target person wearing a
given in-shop garment, i.e., image-based virtual try-on (VTON) task. The
difficulty originates from the aspect that the diffusion process should not
only produce holistically high-fidelity photorealistic image of the target
person, but also locally preserve every appearance and texture detail of the
given garment. To address this, we shape a new Diffusion model, namely GarDiff,
which triggers the garment-focused diffusion process with amplified guidance of
both basic visual appearance and detailed textures (i.e., high-frequency
details) derived from the given garment. GarDiff first remoulds a pre-trained
latent diffusion model with additional appearance priors derived from the CLIP
and VAE encodings of the reference garment. Meanwhile, a novel garment-focused
adapter is integrated into the UNet of diffusion model, pursuing local
fine-grained alignment with the visual appearance of reference garment and
human pose. We specifically design an appearance loss over the synthesized
garment to enhance the crucial, high-frequency details. Extensive experiments
on VITON-HD and DressCode datasets demonstrate the superiority of our GarDiff
when compared to state-of-the-art VTON approaches. Code is publicly available
at:
\href{https://github.com/siqi0905/GarDiff/tree/master}{https://github.com/siqi0905/GarDiff/tree/master}.",2024-09-12 17:55:11+00:00
LoRID: Low-Rank Iterative Diffusion for Adversarial Purification,"This work presents an information-theoretic examination of diffusion-based
purification methods, the state-of-the-art adversarial defenses that utilize
diffusion models to remove malicious perturbations in adversarial examples. By
theoretically characterizing the inherent purification errors associated with
the Markov-based diffusion purifications, we introduce LoRID, a novel Low-Rank
Iterative Diffusion purification method designed to remove adversarial
perturbation with low intrinsic purification errors. LoRID centers around a
multi-stage purification process that leverages multiple rounds of
diffusion-denoising loops at the early time-steps of the diffusion models, and
the integration of Tucker decomposition, an extension of matrix factorization,
to remove adversarial noise at high-noise regimes. Consequently, LoRID
increases the effective diffusion time-steps and overcomes strong adversarial
attacks, achieving superior robustness performance in CIFAR-10/100, CelebA-HQ,
and ImageNet datasets under both white-box and black-box settings.",2024-09-12 17:51:25+00:00
Dynamic Prompting of Frozen Text-to-Image Diffusion Models for Panoptic Narrative Grounding,"Panoptic narrative grounding (PNG), whose core target is fine-grained
image-text alignment, requires a panoptic segmentation of referred objects
given a narrative caption. Previous discriminative methods achieve only weak or
coarse-grained alignment by panoptic segmentation pretraining or CLIP model
adaptation. Given the recent progress of text-to-image Diffusion models,
several works have shown their capability to achieve fine-grained image-text
alignment through cross-attention maps and improved general segmentation
performance. However, the direct use of phrase features as static prompts to
apply frozen Diffusion models to the PNG task still suffers from a large task
gap and insufficient vision-language interaction, yielding inferior
performance. Therefore, we propose an Extractive-Injective Phrase Adapter
(EIPA) bypass within the Diffusion UNet to dynamically update phrase prompts
with image features and inject the multimodal cues back, which leverages the
fine-grained image-text alignment capability of Diffusion models more
sufficiently. In addition, we also design a Multi-Level Mutual Aggregation
(MLMA) module to reciprocally fuse multi-level image and phrase features for
segmentation refinement. Extensive experiments on the PNG benchmark show that
our method achieves new state-of-the-art performance.",2024-09-12 17:48:22+00:00
OmniQuery: Contextually Augmenting Captured Multimodal Memory to Enable Personal Question Answering,"People often capture memories through photos, screenshots, and videos. While
existing AI-based tools enable querying this data using natural language, they
mostly only support retrieving individual pieces of information like certain
objects in photos and struggle with answering more complex queries that involve
interpreting interconnected memories like event sequences. We conducted a
one-month diary study to collect realistic user queries and generated a
taxonomy of necessary contextual information for integrating with captured
memories. We then introduce OmniQuery, a novel system that is able to answer
complex personal memory-related questions that require extracting and inferring
contextual information. OmniQuery augments single captured memories through
integrating scattered contextual information from multiple interconnected
memories, retrieves relevant memories, and uses a large language model (LLM) to
comprehensive answers. In human evaluations, we show the effectiveness of
OmniQuery with an accuracy of 71.5%, and it outperformed a conventional RAG
system, winning or tying in 74.5% of the time.",2024-09-12 17:48:08+00:00
TextBoost: Towards One-Shot Personalization of Text-to-Image Models via Fine-tuning Text Encoder,"Recent breakthroughs in text-to-image models have opened up promising
research avenues in personalized image generation, enabling users to create
diverse images of a specific subject using natural language prompts. However,
existing methods often suffer from performance degradation when given only a
single reference image. They tend to overfit the input, producing highly
similar outputs regardless of the text prompt. This paper addresses the
challenge of one-shot personalization by mitigating overfitting, enabling the
creation of controllable images through text prompts. Specifically, we propose
a selective fine-tuning strategy that focuses on the text encoder. Furthermore,
we introduce three key techniques to enhance personalization performance: (1)
augmentation tokens to encourage feature disentanglement and alleviate
overfitting, (2) a knowledge-preservation loss to reduce language drift and
promote generalizability across diverse prompts, and (3) SNR-weighted sampling
for efficient training. Extensive experiments demonstrate that our approach
efficiently generates high-quality, diverse images using only a single
reference image while significantly reducing memory and storage requirements.",2024-09-12 17:47:51+00:00
Style Based Clustering of Visual Artworks,"Clustering artworks based on style has many potential real-world applications
like art recommendations, style-based search and retrieval, and the study of
artistic style evolution in an artwork corpus. However, clustering artworks
based on style is largely an unaddressed problem. A few present methods for
clustering artworks principally rely on generic image feature representations
derived from deep neural networks and do not specifically deal with the
artistic style. In this paper, we introduce and deliberate over the notion of
style-based clustering of visual artworks. Our main objective is to explore
neural feature representations and architectures that can be used for
style-based clustering and observe their impact and effectiveness. We develop
different methods and assess their relative efficacy for style-based clustering
through qualitative and quantitative analysis by applying them to four artwork
corpora and four curated synthetically styled datasets. Our analysis provides
some key novel insights on architectures, feature representations, and
evaluation methods suitable for style-based clustering.",2024-09-12 17:44:07+00:00
IFAdapter: Instance Feature Control for Grounded Text-to-Image Generation,"While Text-to-Image (T2I) diffusion models excel at generating visually
appealing images of individual instances, they struggle to accurately position
and control the features generation of multiple instances. The Layout-to-Image
(L2I) task was introduced to address the positioning challenges by
incorporating bounding boxes as spatial control signals, but it still falls
short in generating precise instance features. In response, we propose the
Instance Feature Generation (IFG) task, which aims to ensure both positional
accuracy and feature fidelity in generated instances. To address the IFG task,
we introduce the Instance Feature Adapter (IFAdapter). The IFAdapter enhances
feature depiction by incorporating additional appearance tokens and utilizing
an Instance Semantic Map to align instance-level features with spatial
locations. The IFAdapter guides the diffusion process as a plug-and-play
module, making it adaptable to various community models. For evaluation, we
contribute an IFG benchmark and develop a verification pipeline to objectively
compare models' abilities to generate instances with accurate positioning and
features. Experimental results demonstrate that IFAdapter outperforms other
models in both quantitative and qualitative evaluations.",2024-09-12 17:39:23+00:00
Source2Synth: Synthetic Data Generation and Curation Grounded in Real Data Sources,"Large Language Models still struggle in challenging scenarios that leverage
structured data, complex reasoning, or tool usage. In this paper, we propose
Source2Synth: a new method that can be used for teaching LLMs new skills
without relying on costly human annotations. Source2Synth takes as input a
custom data source and produces synthetic data points with intermediate
reasoning steps grounded in real-world sources. Source2Synth improves the
dataset quality by discarding low-quality generations based on their
answerability. We demonstrate the generality of this approach by applying it to
two challenging domains: we test reasoning abilities in multi-hop question
answering (MHQA), and tool usage in tabular question answering (TQA). Our
method improves performance by 25.51% for TQA on WikiSQL and 22.57% for MHQA on
HotPotQA compared to the fine-tuned baselines.",2024-09-12 17:39:08+00:00
Multi-Model based Federated Learning Against Model Poisoning Attack: A Deep Learning Based Model Selection for MEC Systems,"Federated Learning (FL) enables training of a global model from distributed
data, while preserving data privacy. However, the singular-model based
operation of FL is open with uploading poisoned models compatible with the
global model structure and can be exploited as a vulnerability to conduct model
poisoning attacks. This paper proposes a multi-model based FL as a proactive
mechanism to enhance the opportunity of model poisoning attack mitigation. A
master model is trained by a set of slave models. To enhance the opportunity of
attack mitigation, the structure of client models dynamically change within
learning epochs, and the supporter FL protocol is provided. For a MEC system,
the model selection problem is modeled as an optimization to minimize loss and
recognition time, while meeting a robustness confidence. In adaption with
dynamic network condition, a deep reinforcement learning based model selection
is proposed. For a DDoS attack detection scenario, results illustrate a
competitive accuracy gain under poisoning attack with the scenario that the
system is without attack, and also a potential of recognition time improvement.",2024-09-12 17:36:26+00:00
LLM Honeypot: Leveraging Large Language Models as Advanced Interactive Honeypot Systems,"The rapid evolution of cyber threats necessitates innovative solutions for
detecting and analyzing malicious activity. Honeypots, which are decoy systems
designed to lure and interact with attackers, have emerged as a critical
component in cybersecurity. In this paper, we present a novel approach to
creating realistic and interactive honeypot systems using Large Language Models
(LLMs). By fine-tuning a pre-trained open-source language model on a diverse
dataset of attacker-generated commands and responses, we developed a honeypot
capable of sophisticated engagement with attackers. Our methodology involved
several key steps: data collection and processing, prompt engineering, model
selection, and supervised fine-tuning to optimize the model's performance.
Evaluation through similarity metrics and live deployment demonstrated that our
approach effectively generates accurate and informative responses. The results
highlight the potential of LLMs to revolutionize honeypot technology, providing
cybersecurity professionals with a powerful tool to detect and analyze
malicious activity, thereby enhancing overall security infrastructure.",2024-09-12 17:33:06+00:00
Model Ensemble for Brain Tumor Segmentation in Magnetic Resonance Imaging,"Segmenting brain tumors in multi-parametric magnetic resonance imaging
enables performing quantitative analysis in support of clinical trials and
personalized patient care. This analysis provides the potential to impact
clinical decision-making processes, including diagnosis and prognosis. In 2023,
the well-established Brain Tumor Segmentation (BraTS) challenge presented a
substantial expansion with eight tasks and 4,500 brain tumor cases. In this
paper, we present a deep learning-based ensemble strategy that is evaluated for
newly included tumor cases in three tasks: pediatric brain tumors (PED),
intracranial meningioma (MEN), and brain metastases (MET). In particular, we
ensemble outputs from state-of-the-art nnU-Net and Swin UNETR models on a
region-wise basis. Furthermore, we implemented a targeted post-processing
strategy based on a cross-validated threshold search to improve the
segmentation results for tumor sub-regions. The evaluation of our proposed
method on unseen test cases for the three tasks resulted in lesion-wise Dice
scores for PED: 0.653, 0.809, 0.826; MEN: 0.876, 0.867, 0.849; and MET: 0.555,
0.6, 0.58; for the enhancing tumor, tumor core, and whole tumor, respectively.
Our method was ranked first for PED, third for MEN, and fourth for MET,
respectively.",2024-09-12 17:24:50+00:00
Design Optimization of Nuclear Fusion Reactor through Deep Reinforcement Learning,"This research explores the application of Deep Reinforcement Learning (DRL)
to optimize the design of a nuclear fusion reactor. DRL can efficiently address
the challenging issues attributed to multiple physics and engineering
constraints for steady-state operation. The fusion reactor design computation
and the optimization code applicable to parallelization with DRL are developed.
The proposed framework enables finding the optimal reactor design that
satisfies the operational requirements while reducing building costs.
Multi-objective design optimization for a fusion reactor is now simplified by
DRL, indicating the high potential of the proposed framework for advancing the
efficient and sustainable design of future reactors.",2024-09-12 17:23:01+00:00
Photonic Quantum Computers,"In the pursuit of scalable and fault-tolerant quantum computing
architectures, photonic-based quantum computers have emerged as a leading
frontier. This article provides a comprehensive overview of advancements in
photonic quantum computing, developed by leading industry players, examining
current performance, architectural designs, and strategies for developing
large-scale, fault-tolerant photonic quantum computers. It also highlights
recent groundbreaking experiments that leverage the unique advantages of
photonic technologies, underscoring their transformative potential. This review
captures a pivotal moment of photonic quantum computing in the noisy
intermediate-scale quantum (NISQ) era, offering insights into how photonic
quantum computers might reshape the future of quantum computing.",2024-09-12 17:16:38+00:00
CliquePH: Higher-Order Information for Graph Neural Networks through Persistent Homology on Clique Graphs,"Graph neural networks have become the default choice by practitioners for
graph learning tasks such as graph classification and node classification.
Nevertheless, popular graph neural network models still struggle to capture
higher-order information, i.e., information that goes \emph{beyond} pairwise
interactions. Recent work has shown that persistent homology, a tool from
topological data analysis, can enrich graph neural networks with topological
information that they otherwise could not capture. Calculating such features is
efficient for dimension 0 (connected components) and dimension 1 (cycles).
However, when it comes to higher-order structures, it does not scale well, with
a complexity of $O(n^d)$, where $n$ is the number of nodes and $d$ is the order
of the structures. In this work, we introduce a novel method that extracts
information about higher-order structures in the graph while still using the
efficient low-dimensional persistent homology algorithm. On standard benchmark
datasets, we show that our method can lead to up to $31\%$ improvements in test
accuracy.",2024-09-12 16:56:26+00:00
LT3SD: Latent Trees for 3D Scene Diffusion,"We present LT3SD, a novel latent diffusion model for large-scale 3D scene
generation. Recent advances in diffusion models have shown impressive results
in 3D object generation, but are limited in spatial extent and quality when
extended to 3D scenes. To generate complex and diverse 3D scene structures, we
introduce a latent tree representation to effectively encode both
lower-frequency geometry and higher-frequency detail in a coarse-to-fine
hierarchy. We can then learn a generative diffusion process in this latent 3D
scene space, modeling the latent components of a scene at each resolution
level. To synthesize large-scale scenes with varying sizes, we train our
diffusion model on scene patches and synthesize arbitrary-sized output 3D
scenes through shared diffusion generation across multiple scene patches.
Through extensive experiments, we demonstrate the efficacy and benefits of
LT3SD for large-scale, high-quality unconditional 3D scene generation and for
probabilistic completion for partial scene observations.",2024-09-12 16:55:51+00:00
Adaptive Language-Guided Abstraction from Contrastive Explanations,"Many approaches to robot learning begin by inferring a reward function from a
set of human demonstrations. To learn a good reward, it is necessary to
determine which features of the environment are relevant before determining how
these features should be used to compute reward. End-to-end methods for joint
feature and reward learning (e.g., using deep networks or program synthesis
techniques) often yield brittle reward functions that are sensitive to spurious
state features. By contrast, humans can often generalizably learn from a small
number of demonstrations by incorporating strong priors about what features of
a demonstration are likely meaningful for a task of interest. How do we build
robots that leverage this kind of background knowledge when learning from new
demonstrations? This paper describes a method named ALGAE (Adaptive
Language-Guided Abstraction from [Contrastive] Explanations) which alternates
between using language models to iteratively identify human-meaningful features
needed to explain demonstrated behavior, then standard inverse reinforcement
learning techniques to assign weights to these features. Experiments across a
variety of both simulated and real-world robot environments show that ALGAE
learns generalizable reward functions defined on interpretable features using
only small numbers of demonstrations. Importantly, ALGAE can recognize when
features are missing, then extract and define those features without any human
input -- making it possible to quickly and efficiently acquire rich
representations of user behavior.",2024-09-12 16:51:58+00:00
Graph Laplacian-based Bayesian Multi-fidelity Modeling,"We present a novel probabilistic approach for generating multi-fidelity data
while accounting for errors inherent in both low- and high-fidelity data. In
this approach a graph Laplacian constructed from the low-fidelity data is used
to define a multivariate Gaussian prior density for the coordinates of the true
data points. In addition, few high-fidelity data points are used to construct a
conjugate likelihood term. Thereafter, Bayes rule is applied to derive an
explicit expression for the posterior density which is also multivariate
Gaussian. The maximum \textit{a posteriori} (MAP) estimate of this density is
selected to be the optimal multi-fidelity estimate. It is shown that the MAP
estimate and the covariance of the posterior density can be determined through
the solution of linear systems of equations. Thereafter, two methods, one based
on spectral truncation and another based on a low-rank approximation, are
developed to solve these equations efficiently. The multi-fidelity approach is
tested on a variety of problems in solid and fluid mechanics with data that
represents vectors of quantities of interest and discretized spatial fields in
one and two dimensions. The results demonstrate that by utilizing a small
fraction of high-fidelity data, the multi-fidelity approach can significantly
improve the accuracy of a large collection of low-fidelity data points.",2024-09-12 16:51:55+00:00
VI3DRM:Towards meticulous 3D Reconstruction from Sparse Views via Photo-Realistic Novel View Synthesis,"Recently, methods like Zero-1-2-3 have focused on single-view based 3D
reconstruction and have achieved remarkable success. However, their predictions
for unseen areas heavily rely on the inductive bias of large-scale pretrained
diffusion models. Although subsequent work, such as DreamComposer, attempts to
make predictions more controllable by incorporating additional views, the
results remain unrealistic due to feature entanglement in the vanilla latent
space, including factors such as lighting, material, and structure. To address
these issues, we introduce the Visual Isotropy 3D Reconstruction Model
(VI3DRM), a diffusion-based sparse views 3D reconstruction model that operates
within an ID consistent and perspective-disentangled 3D latent space. By
facilitating the disentanglement of semantic information, color, material
properties and lighting, VI3DRM is capable of generating highly realistic
images that are indistinguishable from real photographs. By leveraging both
real and synthesized images, our approach enables the accurate construction of
pointmaps, ultimately producing finely textured meshes or point clouds. On the
NVS task, tested on the GSO dataset, VI3DRM significantly outperforms
state-of-the-art method DreamComposer, achieving a PSNR of 38.61, an SSIM of
0.929, and an LPIPS of 0.027. Code will be made available upon publication.",2024-09-12 16:47:57+00:00
ComAlign: Compositional Alignment in Vision-Language Models,"Vision-language models (VLMs) like CLIP have showcased a remarkable ability
to extract transferable features for downstream tasks. Nonetheless, the
training process of these models is usually based on a coarse-grained
contrastive loss between the global embedding of images and texts which may
lose the compositional structure of these modalities. Many recent studies have
shown VLMs lack compositional understandings like attribute binding and
identifying object relationships. Although some recent methods have tried to
achieve finer-level alignments, they either are not based on extracting
meaningful components of proper granularity or don't properly utilize the
modalities' correspondence (especially in image-text pairs with more
ingredients). Addressing these limitations, we introduce Compositional
Alignment (ComAlign), a fine-grained approach to discover more exact
correspondence of text and image components using only the weak supervision in
the form of image-text pairs. Our methodology emphasizes that the compositional
structure (including entities and relations) extracted from the text modality
must also be retained in the image modality. To enforce correspondence of
fine-grained concepts in image and text modalities, we train a lightweight
network lying on top of existing visual and language encoders using a small
dataset. The network is trained to align nodes and edges of the structure
across the modalities. Experimental results on various VLMs and datasets
demonstrate significant improvements in retrieval and compositional benchmarks,
affirming the effectiveness of our plugin model.",2024-09-12 16:46:41+00:00
What Makes a Maze Look Like a Maze?,"A unique aspect of human visual understanding is the ability to flexibly
interpret abstract concepts: acquiring lifted rules explaining what they
symbolize, grounding them across familiar and unfamiliar contexts, and making
predictions or reasoning about them. While off-the-shelf vision-language models
excel at making literal interpretations of images (e.g., recognizing object
categories such as tree branches), they still struggle to make sense of such
visual abstractions (e.g., how an arrangement of tree branches may form the
walls of a maze). To address this challenge, we introduce Deep Schema Grounding
(DSG), a framework that leverages explicit structured representations of visual
abstractions for grounding and reasoning. At the core of DSG are
schemas--dependency graph descriptions of abstract concepts that decompose them
into more primitive-level symbols. DSG uses large language models to extract
schemas, then hierarchically grounds concrete to abstract components of the
schema onto images with vision-language models. The grounded schema is used to
augment visual abstraction understanding. We systematically evaluate DSG and
different methods in reasoning on our new Visual Abstractions Dataset, which
consists of diverse, real-world images of abstract concepts and corresponding
question-answer pairs labeled by humans. We show that DSG significantly
improves the abstract visual reasoning performance of vision-language models,
and is a step toward human-aligned understanding of visual abstractions.",2024-09-12 16:41:47+00:00
Machine Learning for Two-Sample Testing under Right-Censored Data: A Simulation Study,"The focus of this study is to evaluate the effectiveness of Machine Learning
(ML) methods for two-sample testing with right-censored observations. To
achieve this, we develop several ML-based methods with varying architectures
and implement them as two-sample tests. Each method is an ensemble (stacking)
that combines predictions from classical two-sample tests. This paper presents
the results of training the proposed ML methods, examines their statistical
power compared to classical two-sample tests, analyzes the distribution of test
statistics for the proposed methods when the null hypothesis is true, and
evaluates the significance of the features incorporated into the proposed
methods. All results from numerical experiments were obtained from a synthetic
dataset generated using the Smirnov transform (Inverse Transform Sampling) and
replicated multiple times through Monte Carlo simulation. To test the
two-sample problem with right-censored observations, one can use the proposed
two-sample methods. All necessary materials (source code, example scripts,
dataset, and samples) are available on GitHub and Hugging Face.",2024-09-12 16:38:20+00:00
AudioBERT: Audio Knowledge Augmented Language Model,"Recent studies have identified that language models, pretrained on text-only
datasets, often lack elementary visual knowledge, \textit{e.g.,} colors of
everyday objects. Motivated by this observation, we ask whether a similar
shortcoming exists in terms of the \textit{auditory} knowledge. To answer this
question, we construct a new dataset called AuditoryBench, which consists of
two novel tasks for evaluating auditory knowledge. Based on our analysis using
the benchmark, we find that language models also suffer from a severe lack of
auditory knowledge. To address this limitation, we propose AudioBERT, a novel
method to augment the auditory knowledge of BERT through a retrieval-based
approach. First, we detect auditory knowledge spans in prompts to query our
retrieval model efficiently. Then, we inject audio knowledge into BERT and
switch on low-rank adaptation for effective adaptation when audio knowledge is
required. Our experiments demonstrate that AudioBERT is quite effective,
achieving superior performance on the AuditoryBench. The dataset and code are
available at \bulurl{https://github.com/HJ-Ok/AudioBERT}.",2024-09-12 16:36:39+00:00
Gaussian Garments: Reconstructing Simulation-Ready Clothing with Photorealistic Appearance from Multi-View Video,"We introduce Gaussian Garments, a novel approach for reconstructing realistic
simulation-ready garment assets from multi-view videos. Our method represents
garments with a combination of a 3D mesh and a Gaussian texture that encodes
both the color and high-frequency surface details. This representation enables
accurate registration of garment geometries to multi-view videos and helps
disentangle albedo textures from lighting effects. Furthermore, we demonstrate
how a pre-trained graph neural network (GNN) can be fine-tuned to replicate the
real behavior of each garment. The reconstructed Gaussian Garments can be
automatically combined into multi-garment outfits and animated with the
fine-tuned GNN.",2024-09-12 16:26:47+00:00
Fine-tuning Large Language Models for Entity Matching,"Generative large language models (LLMs) are a promising alternative to
pre-trained language models for entity matching due to their high zero-shot
performance and their ability to generalize to unseen entities. Existing
research on using LLMs for entity matching has focused on prompt engineering
and in-context learning. This paper explores the potential of fine-tuning LLMs
for entity matching. We analyze fine-tuning along two dimensions: 1) The
representation of training examples, where we experiment with adding different
types of LLM-generated explanations to the training set, and 2) the selection
and generation of training examples using LLMs. In addition to the matching
performance on the source dataset, we investigate how fine-tuning affects the
model's ability to generalize to other in-domain datasets as well as across
topical domains. Our experiments show that fine-tuning significantly improves
the performance of the smaller models while the results for the larger models
are mixed. Fine-tuning also improves the generalization to in-domain datasets
while hurting cross-domain transfer. We show that adding structured
explanations to the training set has a positive impact on the performance of
three out of four LLMs, while the proposed example selection and generation
methods only improve the performance of Llama 3.1 8B while decreasing the
performance of GPT-4o Mini.",2024-09-12 16:20:57+00:00
Enhancing Canine Musculoskeletal Diagnoses: Leveraging Synthetic Image Data for Pre-Training AI-Models on Visual Documentations,"The examination of the musculoskeletal system in dogs is a challenging task
in veterinary practice. In this work, a novel method has been developed that
enables efficient documentation of a dog's condition through a visual
representation. However, since the visual documentation is new, there is no
existing training data. The objective of this work is therefore to mitigate the
impact of data scarcity in order to develop an AI-based diagnostic support
system. To this end, the potential of synthetic data that mimics realistic
visual documentations of diseases for pre-training AI models is investigated.
We propose a method for generating synthetic image data that mimics realistic
visual documentations. Initially, a basic dataset containing three distinct
classes is generated, followed by the creation of a more sophisticated dataset
containing 36 different classes. Both datasets are used for the pre-training of
an AI model. Subsequently, an evaluation dataset is created, consisting of 250
manually created visual documentations for five different diseases. This
dataset, along with a subset containing 25 examples. The obtained results on
the evaluation dataset containing 25 examples demonstrate a significant
enhancement of approximately 10% in diagnosis accuracy when utilizing generated
synthetic images that mimic real-world visual documentations. However, these
results do not hold true for the larger evaluation dataset containing 250
examples, indicating that the advantages of using synthetic data for
pre-training an AI model emerge primarily when dealing with few examples of
visual documentations for a given disease. Overall, this work provides valuable
insights into mitigating the limitations imposed by limited training data
through the strategic use of generated synthetic data, presenting an approach
applicable beyond the canine musculoskeletal assessment domain.",2024-09-12 16:13:07+00:00
"Identification of head impact locations, speeds, and force based on head kinematics","Objective: Head impact information including impact directions, speeds and
force are important to study traumatic brain injury, design and evaluate
protective gears. This study presents a deep learning model developed to
accurately predict head impact information, including location, speed,
orientation, and force, based on head kinematics during helmeted impacts.
Methods: Leveraging a dataset of 16,000 simulated helmeted head impacts using
the Riddell helmet finite element model, we implemented a Long Short-Term
Memory (LSTM) network to process the head kinematics: tri-axial linear
accelerations and angular velocities. Results: The models accurately predict
the impact parameters describing impact location, direction, speed, and the
impact force profile with R2 exceeding 70% for all tasks. Further validation
was conducted using an on-field dataset recorded by instrumented mouthguards
and videos, consisting of 79 head impacts in which the impact location can be
clearly identified. The deep learning model significantly outperformed existing
methods, achieving a 79.7% accuracy in identifying impact locations, compared
to lower accuracies with traditional methods (the highest accuracy of existing
methods is 49.4%). Conclusion: The precision underscores the model's potential
in enhancing helmet design and safety in sports by providing more accurate
impact data. Future studies should test the models across various helmets and
sports on large in vivo datasets to validate the accuracy of the models,
employing techniques like transfer learning to broaden its effectiveness.",2024-09-12 16:07:15+00:00
Low-Cost Tree Crown Dieback Estimation Using Deep Learning-Based Segmentation,"The global increase in observed forest dieback, characterised by the death of
tree foliage, heralds widespread decline in forest ecosystems. This degradation
causes significant changes to ecosystem services and functions, including
habitat provision and carbon sequestration, which can be difficult to detect
using traditional monitoring techniques, highlighting the need for large-scale
and high-frequency monitoring. Contemporary developments in the instruments and
methods to gather and process data at large-scales mean this monitoring is now
possible. In particular, the advancement of low-cost drone technology and deep
learning on consumer-level hardware provide new opportunities. Here, we use an
approach based on deep learning and vegetation indices to assess crown dieback
from RGB aerial data without the need for expensive instrumentation such as
LiDAR. We use an iterative approach to match crown footprints predicted by deep
learning with field-based inventory data from a Mediterranean ecosystem
exhibiting drought-induced dieback, and compare expert field-based crown
dieback estimation with vegetation index-based estimates. We obtain high
overall segmentation accuracy (mAP: 0.519) without the need for additional
technical development of the underlying Mask R-CNN model, underscoring the
potential of these approaches for non-expert use and proving their
applicability to real-world conservation. We also find colour-coordinate based
estimates of dieback correlate well with expert field-based estimation.
Substituting ground truth for Mask R-CNN model predictions showed negligible
impact on dieback estimates, indicating robustness. Our findings demonstrate
the potential of automated data collection and processing, including the
application of deep learning, to improve the coverage, speed and cost of forest
dieback monitoring.",2024-09-12 16:03:56+00:00
AD-Lite Net: A Lightweight and Concatenated CNN Model for Alzheimer's Detection from MRI Images,"Alzheimer's Disease (AD) is a non-curable progressive neurodegenerative
disorder that affects the human brain, leading to a decline in memory,
cognitive abilities, and eventually, the ability to carry out daily tasks.
Manual diagnosis of Alzheimer's disease from MRI images is fraught with less
sensitivity and it is a very tedious process for neurologists. Therefore, there
is a need for an automatic Computer Assisted Diagnosis (CAD) system, which can
detect AD at early stages with higher accuracy. In this research, we have
proposed a novel AD-Lite Net model (trained from scratch), that could alleviate
the aforementioned problem. The novelties we bring here in this research are,
(I) We have proposed a very lightweight CNN model by incorporating Depth Wise
Separable Convolutional (DWSC) layers and Global Average Pooling (GAP) layers.
(II) We have leveraged a ``parallel concatenation block'' (pcb), in the
proposed AD-Lite Net model. This pcb consists of a Transformation layer
(Tx-layer), followed by two convolutional layers, which are thereby
concatenated with the original base model. This Tx-layer converts the features
into very distinct kind of features, which are imperative for the Alzheimer's
disease. As a consequence, the proposed AD-Lite Net model with ``parallel
concatenation'' converges faster and automatically mitigates the class
imbalance problem from the MRI datasets in a very generalized way. For the
validity of our proposed model, we have implemented it on three different MRI
datasets. Furthermore, we have combined the ADNI and AD datasets and
subsequently performed a 10-fold cross-validation experiment to verify the
model's generalization ability. Extensive experimental results showed that our
proposed model has outperformed all the existing CNN models, and one recent
trend Vision Transformer (ViT) model by a significant margin.",2024-09-12 16:00:51+00:00
Learning to Match 2D Keypoints Across Preoperative MR and Intraoperative Ultrasound,"We propose in this paper a texture-invariant 2D keypoints descriptor
specifically designed for matching preoperative Magnetic Resonance (MR) images
with intraoperative Ultrasound (US) images. We introduce a
matching-by-synthesis strategy, where intraoperative US images are synthesized
from MR images accounting for multiple MR modalities and intraoperative US
variability. We build our training set by enforcing keypoints localization over
all images then train a patient-specific descriptor network that learns
texture-invariant discriminant features in a supervised contrastive manner,
leading to robust keypoints descriptors. Our experiments on real cases with
ground truth show the effectiveness of the proposed approach, outperforming the
state-of-the-art methods and achieving 80.35% matching precision on average.",2024-09-12 16:00:22+00:00
High-Frequency Anti-DreamBooth: Robust Defense Against Image Synthesis,"Recently, text-to-image generative models have been misused to create
unauthorized malicious images of individuals, posing a growing social problem.
Previous solutions, such as Anti-DreamBooth, add adversarial noise to images to
protect them from being used as training data for malicious generation.
However, we found that the adversarial noise can be removed by adversarial
purification methods such as DiffPure. Therefore, we propose a new adversarial
attack method that adds strong perturbation on the high-frequency areas of
images to make it more robust to adversarial purification. Our experiment
showed that the adversarial images retained noise even after adversarial
purification, hindering malicious image generation.",2024-09-12 15:58:28+00:00
Open Source Infrastructure for Automatic Cell Segmentation,"Automated cell segmentation is crucial for various biological and medical
applications, facilitating tasks like cell counting, morphology analysis, and
drug discovery. However, manual segmentation is time-consuming and prone to
subjectivity, necessitating robust automated methods. This paper presents
open-source infrastructure, utilizing the UNet model, a deep-learning
architecture noted for its effectiveness in image segmentation tasks. This
implementation is integrated into the open-source DeepChem package, enhancing
accessibility and usability for researchers and practitioners. The resulting
tool offers a convenient and user-friendly interface, reducing the barrier to
entry for cell segmentation while maintaining high accuracy. Additionally, we
benchmark this model against various datasets, demonstrating its robustness and
versatility across different imaging conditions and cell types.",2024-09-12 15:56:17+00:00
Cross-Attention Based Influence Model for Manual and Nonmanual Sign Language Analysis,"Both manual (relating to the use of hands) and non-manual markers (NMM), such
as facial expressions or mouthing cues, are important for providing the
complete meaning of phrases in American Sign Language (ASL). Efforts have been
made in advancing sign language to spoken/written language understanding, but
most of these have primarily focused on manual features only. In this work,
using advanced neural machine translation methods, we examine and report on the
extent to which facial expressions contribute to understanding sign language
phrases. We present a sign language translation architecture consisting of
two-stream encoders, with one encoder handling the face and the other handling
the upper body (with hands). We propose a new parallel cross-attention decoding
mechanism that is useful for quantifying the influence of each input modality
on the output. The two streams from the encoder are directed simultaneously to
different attention stacks in the decoder. Examining the properties of the
parallel cross-attention weights allows us to analyze the importance of facial
markers compared to body and hand features during a translating task.",2024-09-12 15:55:39+00:00
On the Role of Context in Reading Time Prediction,"We present a new perspective on how readers integrate context during
real-time language comprehension. Our proposals build on surprisal theory,
which posits that the processing effort of a linguistic unit (e.g., a word) is
an affine function of its in-context information content. We first observe that
surprisal is only one out of many potential ways that a contextual predictor
can be derived from a language model. Another one is the pointwise mutual
information (PMI) between a unit and its context, which turns out to yield the
same predictive power as surprisal when controlling for unigram frequency.
Moreover, both PMI and surprisal are correlated with frequency. This means that
neither PMI nor surprisal contains information about context alone. In response
to this, we propose a technique where we project surprisal onto the orthogonal
complement of frequency, yielding a new contextual predictor that is
uncorrelated with frequency. Our experiments show that the proportion of
variance in reading times explained by context is a lot smaller when context is
represented by the orthogonalized predictor. From an interpretability
standpoint, this indicates that previous studies may have overstated the role
that context has in predicting reading times.",2024-09-12 15:52:22+00:00
SDformer: Efficient End-to-End Transformer for Depth Completion,"Depth completion aims to predict dense depth maps with sparse depth
measurements from a depth sensor. Currently, Convolutional Neural Network (CNN)
based models are the most popular methods applied to depth completion tasks.
However, despite the excellent high-end performance, they suffer from a limited
representation area. To overcome the drawbacks of CNNs, a more effective and
powerful method has been presented: the Transformer, which is an adaptive
self-attention setting sequence-to-sequence model. While the standard
Transformer quadratically increases the computational cost from the key-query
dot-product of input resolution which improperly employs depth completion
tasks. In this work, we propose a different window-based Transformer
architecture for depth completion tasks named Sparse-to-Dense Transformer
(SDformer). The network consists of an input module for the depth map and RGB
image features extraction and concatenation, a U-shaped encoder-decoder
Transformer for extracting deep features, and a refinement module.
Specifically, we first concatenate the depth map features with the RGB image
features through the input model. Then, instead of calculating self-attention
with the whole feature maps, we apply different window sizes to extract the
long-range depth dependencies. Finally, we refine the predicted features from
the input module and the U-shaped encoder-decoder Transformer module to get the
enriching depth features and employ a convolution layer to obtain the dense
depth map. In practice, the SDformer obtains state-of-the-art results against
the CNN-based depth completion models with lower computing loads and parameters
on the NYU Depth V2 and KITTI DC datasets.",2024-09-12 15:52:08+00:00
MagicStyle: Portrait Stylization Based on Reference Image,"The development of diffusion models has significantly advanced the research
on image stylization, particularly in the area of stylizing a content image
based on a given style image, which has attracted many scholars. The main
challenge in this reference image stylization task lies in how to maintain the
details of the content image while incorporating the color and texture features
of the style image. This challenge becomes even more pronounced when the
content image is a portrait which has complex textural details. To address this
challenge, we propose a diffusion model-based reference image stylization
method specifically for portraits, called MagicStyle. MagicStyle consists of
two phases: Content and Style DDIM Inversion (CSDI) and Feature Fusion Forward
(FFF). The CSDI phase involves a reverse denoising process, where DDIM
Inversion is performed separately on the content image and the style image,
storing the self-attention query, key and value features of both images during
the inversion process. The FFF phase executes forward denoising, harmoniously
integrating the texture and color information from the pre-stored feature
queries, keys and values into the diffusion generation process based on our
Well-designed Feature Fusion Attention (FFA). We conducted comprehensive
comparative and ablation experiments to validate the effectiveness of our
proposed MagicStyle and FFA.",2024-09-12 15:51:09+00:00
Effective Segmentation of Post-Treatment Gliomas Using Simple Approaches: Artificial Sequence Generation and Ensemble Models,"Segmentation is a crucial task in the medical imaging field and is often an
important primary step or even a prerequisite to the analysis of medical
volumes. Yet treatments such as surgery complicate the accurate delineation of
regions of interest. The BraTS Post-Treatment 2024 Challenge published the
first public dataset for post-surgery glioma segmentation and addresses the
aforementioned issue by fostering the development of automated segmentation
tools for glioma in MRI data. In this effort, we propose two straightforward
approaches to enhance the segmentation performances of deep learning-based
methodologies. First, we incorporate an additional input based on a simple
linear combination of the available MRI sequences input, which highlights
enhancing tumors. Second, we employ various ensembling methods to weigh the
contribution of a battery of models. Our results demonstrate that these
approaches significantly improve segmentation performance compared to baseline
models, underscoring the effectiveness of these simple approaches in improving
medical image segmentation tasks.",2024-09-12 15:34:31+00:00
The JPEG Pleno Learning-based Point Cloud Coding Standard: Serving Man and Machine,"Efficient point cloud coding has become increasingly critical for multiple
applications such as virtual reality, autonomous driving, and digital twin
systems, where rich and interactive 3D data representations may functionally
make the difference. Deep learning has emerged as a powerful tool in this
domain, offering advanced techniques for compressing point clouds more
efficiently than conventional coding methods while also allowing effective
computer vision tasks performed in the compressed domain thus, for the first
time, making available a common compressed visual representation effective for
both man and machine. Taking advantage of this potential, JPEG has recently
finalized the JPEG Pleno Learning-based Point Cloud Coding (PCC) standard
offering efficient lossy coding of static point clouds, targeting both human
visualization and machine processing by leveraging deep learning models for
geometry and color coding. The geometry is processed directly in its original
3D form using sparse convolutional neural networks, while the color data is
projected onto 2D images and encoded using the also learning-based JPEG AI
standard. The goal of this paper is to provide a complete technical description
of the JPEG PCC standard, along with a thorough benchmarking of its performance
against the state-of-the-art, while highlighting its main strengths and
weaknesses. In terms of compression performance, JPEG PCC outperforms the
conventional MPEG PCC standards, especially in geometry coding, achieving
significant rate reductions. Color compression performance is less competitive
but this is overcome by the power of a full learning-based coding framework for
both geometry and color and the associated effective compressed domain
processing.",2024-09-12 15:20:23+00:00
Theoretical guarantees in KL for Diffusion Flow Matching,"Flow Matching (FM) (also referred to as stochastic interpolants or rectified
flows) stands out as a class of generative models that aims to bridge in finite
time the target distribution $\nu^\star$ with an auxiliary distribution $\mu$,
leveraging a fixed coupling $\pi$ and a bridge which can either be
deterministic or stochastic. These two ingredients define a path measure which
can then be approximated by learning the drift of its Markovian projection. The
main contribution of this paper is to provide relatively mild assumptions on
$\nu^\star$, $\mu$ and $\pi$ to obtain non-asymptotics guarantees for Diffusion
Flow Matching (DFM) models using as bridge the conditional distribution
associated with the Brownian motion. More precisely, we establish bounds on the
Kullback-Leibler divergence between the target distribution and the one
generated by such DFM models under moment conditions on the score of
$\nu^\star$, $\mu$ and $\pi$, and a standard $L^2$-drift-approximation error
assumption.",2024-09-12 15:19:00+00:00
GAZEploit: Remote Keystroke Inference Attack by Gaze Estimation from Avatar Views in VR/MR Devices,"The advent and growing popularity of Virtual Reality (VR) and Mixed Reality
(MR) solutions have revolutionized the way we interact with digital platforms.
The cutting-edge gaze-controlled typing methods, now prevalent in high-end
models of these devices, e.g., Apple Vision Pro, have not only improved user
experience but also mitigated traditional keystroke inference attacks that
relied on hand gestures, head movements and acoustic side-channels. However,
this advancement has paradoxically given birth to a new, potentially more
insidious cyber threat, GAZEploit.
  In this paper, we unveil GAZEploit, a novel eye-tracking based attack
specifically designed to exploit these eye-tracking information by leveraging
the common use of virtual appearances in VR applications. This widespread usage
significantly enhances the practicality and feasibility of our attack compared
to existing methods. GAZEploit takes advantage of this vulnerability to
remotely extract gaze estimations and steal sensitive keystroke information
across various typing scenarios-including messages, passwords, URLs, emails,
and passcodes. Our research, involving 30 participants, achieved over 80%
accuracy in keystroke inference. Alarmingly, our study also identified over 15
top-rated apps in the Apple Store as vulnerable to the GAZEploit attack,
emphasizing the urgent need for bolstered security measures for this
state-of-the-art VR/MR text entry method.",2024-09-12 15:11:35+00:00
Towards a graph-based foundation model for network traffic analysis,"Foundation models have shown great promise in various fields of study. A
potential application of such models is in computer network traffic analysis,
where these models can grasp the complexities of network traffic dynamics and
adapt to any specific task or network environment with minimal fine-tuning.
Previous approaches have used tokenized hex-level packet data and the model
architecture of large language transformer models. We propose a new, efficient
graph-based alternative at the flow-level. Our approach represents network
traffic as a dynamic spatio-temporal graph, employing a self-supervised link
prediction pretraining task to capture the spatial and temporal dynamics in
this network graph framework. To evaluate the effectiveness of our approach, we
conduct a few-shot learning experiment for three distinct downstream network
tasks: intrusion detection, traffic classification, and botnet classification.
Models finetuned from our pretrained base achieve an average performance
increase of 6.87\% over training from scratch, demonstrating their ability to
effectively learn general network traffic dynamics during pretraining. This
success suggests the potential for a large-scale version to serve as an
operational foundational model.",2024-09-12 15:04:34+00:00
WhisperNER: Unified Open Named Entity and Speech Recognition,"Integrating named entity recognition (NER) with automatic speech recognition
(ASR) can significantly enhance transcription accuracy and informativeness. In
this paper, we introduce WhisperNER, a novel model that allows joint speech
transcription and entity recognition. WhisperNER supports open-type NER,
enabling recognition of diverse and evolving entities at inference. Building on
recent advancements in open NER research, we augment a large synthetic dataset
with synthetic speech samples. This allows us to train WhisperNER on a large
number of examples with diverse NER tags. During training, the model is
prompted with NER labels and optimized to output the transcribed utterance
along with the corresponding tagged entities. To evaluate WhisperNER, we
generate synthetic speech for commonly used NER benchmarks and annotate
existing ASR datasets with open NER tags. Our experiments demonstrate that
WhisperNER outperforms natural baselines on both out-of-domain open type NER
and supervised finetuning.",2024-09-12 15:00:56+00:00
"DEMAU: Decompose, Explore, Model and Analyse Uncertainties","Recent research in machine learning has given rise to a flourishing
literature on the quantification and decomposition of model uncertainty. This
information can be very useful during interactions with the learner, such as in
active learning or adaptive learning, and especially in uncertainty sampling.
To allow a simple representation of these total, epistemic (reducible) and
aleatoric (irreducible) uncertainties, we offer DEMAU, an open-source
educational, exploratory and analytical tool allowing to visualize and explore
several types of uncertainty for classification models in machine learning.",2024-09-12 14:57:28+00:00
Bayesian Self-Training for Semi-Supervised 3D Segmentation,"3D segmentation is a core problem in computer vision and, similarly to many
other dense prediction tasks, it requires large amounts of annotated data for
adequate training. However, densely labeling 3D point clouds to employ
fully-supervised training remains too labor intensive and expensive.
Semi-supervised training provides a more practical alternative, where only a
small set of labeled data is given, accompanied by a larger unlabeled set. This
area thus studies the effective use of unlabeled data to reduce the performance
gap that arises due to the lack of annotations. In this work, inspired by
Bayesian deep learning, we first propose a Bayesian self-training framework for
semi-supervised 3D semantic segmentation. Employing stochastic inference, we
generate an initial set of pseudo-labels and then filter these based on
estimated point-wise uncertainty. By constructing a heuristic $n$-partite
matching algorithm, we extend the method to semi-supervised 3D instance
segmentation, and finally, with the same building blocks, to dense 3D visual
grounding. We demonstrate state-of-the-art results for our semi-supervised
method on SemanticKITTI and ScribbleKITTI for 3D semantic segmentation and on
ScanNet and S3DIS for 3D instance segmentation. We further achieve substantial
improvements in dense 3D visual grounding over supervised-only baselines on
ScanRefer. Our project page is available at ouenal.github.io/bst/.",2024-09-12 14:54:31+00:00
The CLC-UKET Dataset: Benchmarking Case Outcome Prediction for the UK Employment Tribunal,"This paper explores the intersection of technological innovation and access
to justice by developing a benchmark for predicting case outcomes in the UK
Employment Tribunal (UKET). To address the challenge of extensive manual
annotation, the study employs a large language model (LLM) for automatic
annotation, resulting in the creation of the CLC-UKET dataset. The dataset
consists of approximately 19,000 UKET cases and their metadata. Comprehensive
legal annotations cover facts, claims, precedent references, statutory
references, case outcomes, reasons and jurisdiction codes. Facilitated by the
CLC-UKET data, we examine a multi-class case outcome prediction task in the
UKET. Human predictions are collected to establish a performance reference for
model comparison. Empirical results from baseline models indicate that
finetuned transformer models outperform zero-shot and few-shot LLMs on the UKET
prediction task. The performance of zero-shot LLMs can be enhanced by
integrating task-related information into few-shot examples. We hope that the
CLC-UKET dataset, along with human annotations and empirical findings, can
serve as a valuable benchmark for employment-related dispute resolution.",2024-09-12 14:51:43+00:00
Optimizing Falsification for Learning-Based Control Systems: A Multi-Fidelity Bayesian Approach,"Testing controllers in safety-critical systems is vital for ensuring their
safety and preventing failures. In this paper, we address the falsification
problem within learning-based closed-loop control systems through simulation.
This problem involves the identification of counterexamples that violate system
safety requirements and can be formulated as an optimization task based on
these requirements. Using full-fidelity simulator data in this optimization
problem can be computationally expensive. To improve efficiency, we propose a
multi-fidelity Bayesian optimization falsification framework that harnesses
simulators with varying levels of accuracy. Our proposed framework can
transition between different simulators and establish meaningful relationships
between them. Through multi-fidelity Bayesian optimization, we determine both
the optimal system input likely to be a counterexample and the appropriate
fidelity level for assessment. We evaluated our approach across various Gym
environments, each featuring different levels of fidelity. Our experiments
demonstrate that multi-fidelity Bayesian optimization is more computationally
efficient than full-fidelity Bayesian optimization and other baseline methods
in detecting counterexamples. A Python implementation of the algorithm is
available at https://github.com/SAILRIT/MFBO_Falsification.",2024-09-12 14:51:03+00:00
EZIGen: Enhancing zero-shot subject-driven image generation with precise subject encoding and decoupled guidance,"Zero-shot subject-driven image generation aims to produce images that
incorporate a subject from a given example image. The challenge lies in
preserving the subject's identity while aligning with the text prompt, which
often requires modifying certain aspects of the subject's appearance. Despite
advancements in diffusion model based methods, existing approaches still
struggle to balance identity preservation with text prompt alignment. In this
study, we conducted an in-depth investigation into this issue and uncovered key
insights for achieving effective identity preservation while maintaining a
strong balance. Our key findings include: (1) the design of the subject image
encoder significantly impacts identity preservation quality, and (2) generating
an initial layout is crucial for both text alignment and identity preservation.
Building on these insights, we introduce a new approach called EZIGen, which
employs two main strategies: a carefully crafted subject image Encoder based on
the UNet architecture of the pretrained Stable Diffusion model to ensure
high-quality identity transfer, following a process that decouples the guidance
stages and iteratively refines the initial image layout. Through these
strategies, EZIGen achieves state-of-the-art results on multiple subject-driven
benchmarks with a unified model and 100 times less training data.",2024-09-12 14:44:45+00:00
SimMAT: Exploring Transferability from Vision Foundation Models to Any Image Modality,"Foundation models like ChatGPT and Sora that are trained on a huge scale of
data have made a revolutionary social impact. However, it is extremely
challenging for sensors in many different fields to collect similar scales of
natural images to train strong foundation models. To this end, this work
presents a simple and effective framework SimMAT to study an open problem: the
transferability from vision foundation models trained on natural RGB images to
other image modalities of different physical properties (e.g., polarization).
SimMAT consists of a modality-agnostic transfer layer (MAT) and a pretrained
foundation model. We apply SimMAT to a representative vision foundation model
Segment Anything Model (SAM) to support any evaluated new image modality. Given
the absence of relevant benchmarks, we construct a new benchmark to evaluate
the transfer learning performance. Our experiments confirm the intriguing
potential of transferring vision foundation models in enhancing other sensors'
performance. Specifically, SimMAT can improve the segmentation performance
(mIoU) from 22.15% to 53.88% on average for evaluated modalities and
consistently outperforms other baselines. We hope that SimMAT can raise
awareness of cross-modal transfer learning and benefit various fields for
better results with vision foundation models.",2024-09-12 14:38:21+00:00
Diffusion-Based Image-to-Image Translation by Noise Correction via Prompt Interpolation,"We propose a simple but effective training-free approach tailored to
diffusion-based image-to-image translation. Our approach revises the original
noise prediction network of a pretrained diffusion model by introducing a noise
correction term. We formulate the noise correction term as the difference
between two noise predictions; one is computed from the denoising network with
a progressive interpolation of the source and target prompt embeddings, while
the other is the noise prediction with the source prompt embedding. The final
noise prediction network is given by a linear combination of the standard
denoising term and the noise correction term, where the former is designed to
reconstruct must-be-preserved regions while the latter aims to effectively edit
regions of interest relevant to the target prompt. Our approach can be easily
incorporated into existing image-to-image translation methods based on
diffusion models. Extensive experiments verify that the proposed technique
achieves outstanding performance with low latency and consistently improves
existing frameworks when combined with them.",2024-09-12 14:30:45+00:00
TravelAgent: An AI Assistant for Personalized Travel Planning,"As global tourism expands and artificial intelligence technology advances,
intelligent travel planning services have emerged as a significant research
focus. Within dynamic real-world travel scenarios with multi-dimensional
constraints, services that support users in automatically creating practical
and customized travel itineraries must address three key objectives:
Rationality, Comprehensiveness, and Personalization. However, existing systems
with rule-based combinations or LLM-based planning methods struggle to fully
satisfy these criteria. To overcome the challenges, we introduce TravelAgent, a
travel planning system powered by large language models (LLMs) designed to
provide reasonable, comprehensive, and personalized travel itineraries grounded
in dynamic scenarios. TravelAgent comprises four modules: Tool-usage,
Recommendation, Planning, and Memory Module. We evaluate TravelAgent's
performance with human and simulated users, demonstrating its overall
effectiveness in three criteria and confirming the accuracy of personalized
recommendations.",2024-09-12 14:24:45+00:00
AutoPET Challenge: Tumour Synthesis for Data Augmentation,"Accurate lesion segmentation in whole-body PET/CT scans is crucial for cancer
diagnosis and treatment planning, but limited datasets often hinder the
performance of automated segmentation models. In this paper, we explore the
potential of leveraging the deep prior from a generative model to serve as a
data augmenter for automated lesion segmentation in PET/CT scans. We adapt the
DiffTumor method, originally designed for CT images, to generate synthetic
PET-CT images with lesions. Our approach trains the generative model on the
AutoPET dataset and uses it to expand the training data. We then compare the
performance of segmentation models trained on the original and augmented
datasets. Our findings show that the model trained on the augmented dataset
achieves a higher Dice score, demonstrating the potential of our data
augmentation approach. In a nutshell, this work presents a promising direction
for improving lesion segmentation in whole-body PET/CT scans with limited
datasets, potentially enhancing the accuracy and reliability of cancer
diagnostics.",2024-09-12 14:23:19+00:00
Self-Supervised Learning of Iterative Solvers for Constrained Optimization,"Obtaining the solution of constrained optimization problems as a function of
parameters is very important in a multitude of applications, such as control
and planning. Solving such parametric optimization problems in real time can
present significant challenges, particularly when it is necessary to obtain
highly accurate solutions or batches of solutions. To solve these challenges,
we propose a learning-based iterative solver for constrained optimization which
can obtain very fast and accurate solutions by customizing the solver to a
specific parametric optimization problem. For a given set of parameters of the
constrained optimization problem, we propose a first step with a neural network
predictor that outputs primal-dual solutions of a reasonable degree of
accuracy. This primal-dual solution is then improved to a very high degree of
accuracy in a second step by a learned iterative solver in the form of a neural
network. A novel loss function based on the Karush-Kuhn-Tucker conditions of
optimality is introduced, enabling fully self-supervised training of both
neural networks without the necessity of prior sampling of optimizer solutions.
The evaluation of a variety of quadratic and nonlinear parametric test problems
demonstrates that the predictor alone is already competitive with recent
self-supervised schemes for approximating optimal solutions. The second step of
our proposed learning-based iterative constrained optimizer achieves solutions
with orders of magnitude better accuracy than other learning-based approaches,
while being faster to evaluate than state-of-the-art solvers and natively
allowing for GPU parallelization.",2024-09-12 14:17:23+00:00
AI-accelerated discovery of high critical temperature superconductors,"The discovery of new superconducting materials, particularly those exhibiting
high critical temperature ($T_c$), has been a vibrant area of study within the
field of condensed matter physics. Conventional approaches primarily rely on
physical intuition to search for potential superconductors within the existing
databases. However, the known materials only scratch the surface of the
extensive array of possibilities within the realm of materials. Here, we
develop an AI search engine that integrates deep model pre-training and
fine-tuning techniques, diffusion models, and physics-based approaches (e.g.,
first-principles electronic structure calculation) for discovery of high-$T_c$
superconductors. Utilizing this AI search engine, we have obtained 74
dynamically stable materials with critical temperatures predicted by the AI
model to be $T_c \geq$ 15 K based on a very small set of samples. Notably,
these materials are not contained in any existing dataset. Furthermore, we
analyze trends in our dataset and individual materials including B$_4$CN$_3$
and B$_5$CN$_2$ whose $T_c$s are 24.08 K and 15.93 K, respectively. We
demonstrate that AI technique can discover a set of new high-$T_c$
superconductors, outline its potential for accelerating discovery of the
materials with targeted properties.",2024-09-12 14:16:56+00:00
Q-value Regularized Decision ConvFormer for Offline Reinforcement Learning,"As a data-driven paradigm, offline reinforcement learning (Offline RL) has
been formulated as sequence modeling, where the Decision Transformer (DT) has
demonstrated exceptional capabilities. Unlike previous reinforcement learning
methods that fit value functions or compute policy gradients, DT adjusts the
autoregressive model based on the expected returns, past states, and actions,
using a causally masked Transformer to output the optimal action. However, due
to the inconsistency between the sampled returns within a single trajectory and
the optimal returns across multiple trajectories, it is challenging to set an
expected return to output the optimal action and stitch together suboptimal
trajectories. Decision ConvFormer (DC) is easier to understand in the context
of modeling RL trajectories within a Markov Decision Process compared to DT. We
propose the Q-value Regularized Decision ConvFormer (QDC), which combines the
understanding of RL trajectories by DC and incorporates a term that maximizes
action values using dynamic programming methods during training. This ensures
that the expected returns of the sampled actions are consistent with the
optimal returns. QDC achieves excellent performance on the D4RL benchmark,
outperforming or approaching the optimal level in all tested environments. It
particularly demonstrates outstanding competitiveness in trajectory stitching
capability.",2024-09-12 14:10:22+00:00
Spatial Adaptation Layer: Interpretable Domain Adaptation For Biosignal Sensor Array Applications,"Biosignal acquisition is key for healthcare applications and wearable
devices, with machine learning offering promising methods for processing
signals like surface electromyography (sEMG) and electroencephalography (EEG).
Despite high within-session performance, intersession performance is hindered
by electrode shift, a known issue across modalities. Existing solutions often
require large and expensive datasets and/or lack robustness and
interpretability. Thus, we propose the Spatial Adaptation Layer (SAL), which
can be prepended to any biosignal array model and learns a parametrized affine
transformation at the input between two recording sessions. We also introduce
learnable baseline normalization (LBN) to reduce baseline fluctuations. Tested
on two HD-sEMG gesture recognition datasets, SAL and LBN outperform standard
fine-tuning on regular arrays, achieving competitive performance even with a
logistic regressor, with orders of magnitude less, physically interpretable
parameters. Our ablation study shows that forearm circumferential translations
account for the majority of performance improvements, in line with sEMG
physiological expectations.",2024-09-12 14:06:12+00:00
Expansive Supervision for Neural Radiance Field,"Neural Radiance Fields have achieved success in creating powerful 3D media
representations with their exceptional reconstruction capabilities. However,
the computational demands of volume rendering pose significant challenges
during model training. Existing acceleration techniques often involve
redesigning the model architecture, leading to limitations in compatibility
across different frameworks. Furthermore, these methods tend to overlook the
substantial memory costs incurred. In response to these challenges, we
introduce an expansive supervision mechanism that efficiently balances
computational load, rendering quality and flexibility for neural radiance field
training. This mechanism operates by selectively rendering a small but crucial
subset of pixels and expanding their values to estimate the error across the
entire area for each iteration. Compare to conventional supervision, our method
effectively bypasses redundant rendering processes, resulting in notable
reductions in both time and memory consumption. Experimental results
demonstrate that integrating expansive supervision within existing
state-of-the-art acceleration frameworks can achieve 69% memory savings and 42%
time savings, with negligible compromise in visual quality.",2024-09-12 14:05:13+00:00
Predicting and Accelerating Nanomaterials Synthesis Using Machine Learning Featurization,"Solving for the complex conditions of materials synthesis and processing
requires analyzing information gathered from multiple modes of
characterization. Currently, quantitative information is extracted serially
with manual tools and intuition, constraining the feedback cycle for process
optimization. We use machine learning to automate and generalize feature
extraction for in-situ reflection high-energy electron diffraction (RHEED) data
to establish quantitatively predictive relationships in small sets ($\sim$10)
of expert-labeled data, and apply these to save significant time on subsequent
epitaxially grown samples. The fidelity of these relationships is tested on a
representative material system ($W_{1-x}V_xSe2$ growth on c-plane sapphire
substrate (0001)) at two stages of synthesis with two aims: 1) predicting the
grain alignment of the deposited film from the pre-growth substrate surface
data, and 2) estimating the vanadium (V) dopant concentration using in-situ
RHEED as a proxy for ex-situ methods (e.g. x-ray photoelectron spectroscopy).
Both tasks are accomplished using the same set of materials agnostic core
features, eliminating the need to retrain for specific systems and leading to a
potential 80\% time saving over a 100 sample synthesis campaign. These
predictions provide guidance for recipe adjustments to avoid doomed trials,
reduce follow-on characterization, and improve control resolution for materials
synthesis, ultimately accelerating materials discovery and commercial scale-up.",2024-09-12 14:03:55+00:00
Unleashing Worms and Extracting Data: Escalating the Outcome of Attacks against RAG-based Inference in Scale and Severity Using Jailbreaking,"In this paper, we show that with the ability to jailbreak a GenAI model,
attackers can escalate the outcome of attacks against RAG-based GenAI-powered
applications in severity and scale. In the first part of the paper, we show
that attackers can escalate RAG membership inference attacks and RAG entity
extraction attacks to RAG documents extraction attacks, forcing a more severe
outcome compared to existing attacks. We evaluate the results obtained from
three extraction methods, the influence of the type and the size of five
embeddings algorithms employed, the size of the provided context, and the GenAI
engine. We show that attackers can extract 80%-99.8% of the data stored in the
database used by the RAG of a Q&A chatbot. In the second part of the paper, we
show that attackers can escalate the scale of RAG data poisoning attacks from
compromising a single GenAI-powered application to compromising the entire
GenAI ecosystem, forcing a greater scale of damage. This is done by crafting an
adversarial self-replicating prompt that triggers a chain reaction of a
computer worm within the ecosystem and forces each affected application to
perform a malicious activity and compromise the RAG of additional applications.
We evaluate the performance of the worm in creating a chain of confidential
data extraction about users within a GenAI ecosystem of GenAI-powered email
assistants and analyze how the performance of the worm is affected by the size
of the context, the adversarial self-replicating prompt used, the type and size
of the embeddings algorithm employed, and the number of hops in the
propagation. Finally, we review and analyze guardrails to protect RAG-based
inference and discuss the tradeoffs.",2024-09-12 13:50:22+00:00
Thermal3D-GS: Physics-induced 3D Gaussians for Thermal Infrared Novel-view Synthesis,"Novel-view synthesis based on visible light has been extensively studied. In
comparison to visible light imaging, thermal infrared imaging offers the
advantage of all-weather imaging and strong penetration, providing increased
possibilities for reconstruction in nighttime and adverse weather scenarios.
However, thermal infrared imaging is influenced by physical characteristics
such as atmospheric transmission effects and thermal conduction, hindering the
precise reconstruction of intricate details in thermal infrared scenes,
manifesting as issues of floaters and indistinct edge features in synthesized
images. To address these limitations, this paper introduces a physics-induced
3D Gaussian splatting method named Thermal3D-GS. Thermal3D-GS begins by
modeling atmospheric transmission effects and thermal conduction in
three-dimensional media using neural networks. Additionally, a temperature
consistency constraint is incorporated into the optimization objective to
enhance the reconstruction accuracy of thermal infrared images. Furthermore, to
validate the effectiveness of our method, the first large-scale benchmark
dataset for this field named Thermal Infrared Novel-view Synthesis Dataset
(TI-NSD) is created. This dataset comprises 20 authentic thermal infrared video
scenes, covering indoor, outdoor, and UAV(Unmanned Aerial Vehicle) scenarios,
totaling 6,664 frames of thermal infrared image data. Based on this dataset,
this paper experimentally verifies the effectiveness of Thermal3D-GS. The
results indicate that our method outperforms the baseline method with a 3.03 dB
improvement in PSNR and significantly addresses the issues of floaters and
indistinct edge features present in the baseline method. Our dataset and
codebase will be released in
\href{https://github.com/mzzcdf/Thermal3DGS}{\textcolor{red}{Thermal3DGS}}.",2024-09-12 13:46:53+00:00
Heterogeneous Sheaf Neural Networks,"Heterogeneous graphs, with nodes and edges of different types, are commonly
used to model relational structures in many real-world applications. Standard
Graph Neural Networks (GNNs) struggle to process heterogeneous data due to
oversmoothing. Instead, current approaches have focused on accounting for the
heterogeneity in the model architecture, leading to increasingly complex
models. Inspired by recent work, we propose using cellular sheaves to model the
heterogeneity in the graph's underlying topology. Instead of modelling the data
as a graph, we represent it as cellular sheaves, which allows us to encode the
different data types directly in the data structure, eliminating the need to
inject them into the architecture. We introduce HetSheaf, a general framework
for heterogeneous sheaf neural networks, and a series of heterogeneous sheaf
predictors to better encode the data's heterogeneity into the sheaf structure.
Finally, we empirically evaluate HetSheaf on several standard heterogeneous
graph benchmarks, achieving competitive results whilst being more
parameter-efficient.",2024-09-12 13:38:08+00:00
LED: Light Enhanced Depth Estimation at Night,"Nighttime camera-based depth estimation is a highly challenging task,
especially for autonomous driving applications, where accurate depth perception
is essential for ensuring safe navigation. We aim to improve the reliability of
perception systems at night time, where models trained on daytime data often
fail in the absence of precise but costly LiDAR sensors. In this work, we
introduce Light Enhanced Depth (LED), a novel cost-effective approach that
significantly improves depth estimation in low-light environments by harnessing
a pattern projected by high definition headlights available in modern vehicles.
LED leads to significant performance boosts across multiple depth-estimation
architectures (encoder-decoder, Adabins, DepthFormer) both on synthetic and
real datasets. Furthermore, increased performances beyond illuminated areas
reveal a holistic enhancement in scene understanding. Finally, we release the
Nighttime Synthetic Drive Dataset, a new synthetic and photo-realistic
nighttime dataset, which comprises 49,990 comprehensively annotated images.",2024-09-12 13:23:24+00:00
"From Explanations to Action: A Zero-Shot, Theory-Driven LLM Framework for Student Performance Feedback","Recent advances in eXplainable AI (XAI) for education have highlighted a
critical challenge: ensuring that explanations for state-of-the-art AI models
are understandable for non-technical users such as educators and students. In
response, we introduce iLLuMinaTE, a zero-shot, chain-of-prompts LLM-XAI
pipeline inspired by Miller's cognitive model of explanation. iLLuMinaTE is
designed to deliver theory-driven, actionable feedback to students in online
courses. iLLuMinaTE navigates three main stages - causal connection,
explanation selection, and explanation presentation - with variations drawing
from eight social science theories (e.g. Abnormal Conditions, Pearl's Model of
Explanation, Necessity and Robustness Selection, Contrastive Explanation). We
extensively evaluate 21,915 natural language explanations of iLLuMinaTE
extracted from three LLMs (GPT-4o, Gemma2-9B, Llama3-70B), with three different
underlying XAI methods (LIME, Counterfactuals, MC-LIME), across students from
three diverse online courses. Our evaluation involves analyses of explanation
alignment to the social science theory, understandability of the explanation,
and a real-world user preference study with 114 university students containing
a novel actionability simulation. We find that students prefer iLLuMinaTE
explanations over traditional explainers 89.52% of the time. Our work provides
a robust, ready-to-use framework for effectively communicating hybrid
XAI-driven insights in education, with significant generalization potential for
other human-centric fields.",2024-09-12 13:18:41+00:00
Scribble-Guided Diffusion for Training-free Text-to-Image Generation,"Recent advancements in text-to-image diffusion models have demonstrated
remarkable success, yet they often struggle to fully capture the user's intent.
Existing approaches using textual inputs combined with bounding boxes or region
masks fall short in providing precise spatial guidance, often leading to
misaligned or unintended object orientation. To address these limitations, we
propose Scribble-Guided Diffusion (ScribbleDiff), a training-free approach that
utilizes simple user-provided scribbles as visual prompts to guide image
generation. However, incorporating scribbles into diffusion models presents
challenges due to their sparse and thin nature, making it difficult to ensure
accurate orientation alignment. To overcome these challenges, we introduce
moment alignment and scribble propagation, which allow for more effective and
flexible alignment between generated images and scribble inputs. Experimental
results on the PASCAL-Scribble dataset demonstrate significant improvements in
spatial control and consistency, showcasing the effectiveness of scribble-based
guidance in diffusion models. Our code is available at
https://github.com/kaist-cvml-lab/scribble-diffusion.",2024-09-12 13:13:07+00:00
Edge-Wise Graph-Instructed Neural Networks,"The problem of multi-task regression over graph nodes has been recently
approached through Graph-Instructed Neural Network (GINN), which is a promising
architecture belonging to the subset of message-passing graph neural networks.
In this work, we discuss the limitations of the Graph-Instructed (GI) layer,
and we formalize a novel edge-wise GI (EWGI) layer. We discuss the advantages
of the EWGI layer and we provide numerical evidence that EWGINNs perform better
than GINNs over graph-structured input data with chaotic connectivity, like the
ones inferred from the Erdos-R\'enyi graph.",2024-09-12 13:05:28+00:00
Network Anomaly Traffic Detection via Multi-view Feature Fusion,"Traditional anomalous traffic detection methods are based on single-view
analysis, which has obvious limitations in dealing with complex attacks and
encrypted communications. In this regard, we propose a Multi-view Feature
Fusion (MuFF) method for network anomaly traffic detection. MuFF models the
temporal and interactive relationships of packets in network traffic based on
the temporal and interactive viewpoints respectively. It learns temporal and
interactive features. These features are then fused from different perspectives
for anomaly traffic detection. Extensive experiments on six real traffic
datasets show that MuFF has excellent performance in network anomalous traffic
detection, which makes up for the shortcomings of detection under a single
perspective.",2024-09-12 13:04:40+00:00
Learning Causally Invariant Reward Functions from Diverse Demonstrations,"Inverse reinforcement learning methods aim to retrieve the reward function of
a Markov decision process based on a dataset of expert demonstrations. The
commonplace scarcity and heterogeneous sources of such demonstrations can lead
to the absorption of spurious correlations in the data by the learned reward
function. Consequently, this adaptation often exhibits behavioural overfitting
to the expert data set when a policy is trained on the obtained reward function
under distribution shift of the environment dynamics. In this work, we explore
a novel regularization approach for inverse reinforcement learning methods
based on the causal invariance principle with the goal of improved reward
function generalization. By applying this regularization to both exact and
approximate formulations of the learning task, we demonstrate superior policy
performance when trained using the recovered reward functions in a transfer
setting",2024-09-12 12:56:24+00:00
Multiplex Graph Contrastive Learning with Soft Negatives,"Graph Contrastive Learning (GCL) seeks to learn nodal or graph
representations that contain maximal consistent information from
graph-structured data. While node-level contrasting modes are dominating, some
efforts commence to explore consistency across different scales. Yet, they tend
to lose consistent information and be contaminated by disturbing features.
Here, we introduce MUX-GCL, a novel cross-scale contrastive learning paradigm
that utilizes multiplex representations as effective patches. While this
learning mode minimizes contaminating noises, a commensurate contrasting
strategy using positional affinities further avoids information loss by
correcting false negative pairs across scales. Extensive downstream experiments
demonstrate that MUX-GCL yields multiple state-of-the-art results on public
datasets. Our theoretical analysis further guarantees the new objective
function as a stricter lower bound of mutual information of raw input features
and output embeddings, which rationalizes this paradigm. Code is available at
https://github.com/MUX-GCL/Code.",2024-09-12 12:55:49+00:00
OCTAMamba: A State-Space Model Approach for Precision OCTA Vasculature Segmentation,"Optical Coherence Tomography Angiography (OCTA) is a crucial imaging
technique for visualizing retinal vasculature and diagnosing eye diseases such
as diabetic retinopathy and glaucoma. However, precise segmentation of OCTA
vasculature remains challenging due to the multi-scale vessel structures and
noise from poor image quality and eye lesions. In this study, we proposed
OCTAMamba, a novel U-shaped network based on the Mamba architecture, designed
to segment vasculature in OCTA accurately. OCTAMamba integrates a Quad Stream
Efficient Mining Embedding Module for local feature extraction, a Multi-Scale
Dilated Asymmetric Convolution Module to capture multi-scale vasculature, and a
Focused Feature Recalibration Module to filter noise and highlight target
areas. Our method achieves efficient global modeling and local feature
extraction while maintaining linear complexity, making it suitable for
low-computation medical applications. Extensive experiments on the OCTA 3M,
OCTA 6M, and ROSSA datasets demonstrated that OCTAMamba outperforms
state-of-the-art methods, providing a new reference for efficient OCTA
segmentation. Code is available at https://github.com/zs1314/OCTAMamba",2024-09-12 12:47:34+00:00
Privacy-preserving federated prediction of pain intensity change based on multi-center survey data,"Background: Patient-reported survey data are used to train prognostic models
aimed at improving healthcare. However, such data are typically available
multi-centric and, for privacy reasons, cannot easily be centralized in one
data repository. Models trained locally are less accurate, robust, and
generalizable. We present and apply privacy-preserving federated machine
learning techniques for prognostic model building, where local survey data
never leaves the legally safe harbors of the medical centers. Methods: We used
centralized, local, and federated learning techniques on two healthcare
datasets (GLA:D data from the five health regions of Denmark and international
SHARE data of 27 countries) to predict two different health outcomes. We
compared linear regression, random forest regression, and random forest
classification models trained on local data with those trained on the entire
data in a centralized and in a federated fashion. Results: In GLA:D data,
federated linear regression (R2 0.34, RMSE 18.2) and federated random forest
regression (R2 0.34, RMSE 18.3) models outperform their local counterparts
(i.e., R2 0.32, RMSE 18.6, R2 0.30, RMSE 18.8) with statistical significance.
We also found that centralized models (R2 0.34, RMSE 18.2, R2 0.32, RMSE 18.5,
respectively) did not perform significantly better than the federated models.
In SHARE, the federated model (AC 0.78, AUROC: 0.71) and centralized model (AC
0.84, AUROC: 0.66) perform significantly better than the local models (AC:
0.74, AUROC: 0.69). Conclusion: Federated learning enables the training of
prognostic models from multi-center surveys without compromising privacy and
with only minimal or no compromise regarding model performance.",2024-09-12 12:41:58+00:00
Depth Matters: Exploring Deep Interactions of RGB-D for Semantic Segmentation in Traffic Scenes,"RGB-D has gradually become a crucial data source for understanding complex
scenes in assisted driving. However, existing studies have paid insufficient
attention to the intrinsic spatial properties of depth maps. This oversight
significantly impacts the attention representation, leading to prediction
errors caused by attention shift issues. To this end, we propose a novel
learnable Depth interaction Pyramid Transformer (DiPFormer) to explore the
effectiveness of depth. Firstly, we introduce Depth Spatial-Aware Optimization
(Depth SAO) as offset to represent real-world spatial relationships. Secondly,
the similarity in the feature space of RGB-D is learned by Depth Linear
Cross-Attention (Depth LCA) to clarify spatial differences at the pixel level.
Finally, an MLP Decoder is utilized to effectively fuse multi-scale features
for meeting real-time requirements. Comprehensive experiments demonstrate that
the proposed DiPFormer significantly addresses the issue of attention
misalignment in both road detection (+7.5%) and semantic segmentation (+4.9% /
+1.5%) tasks. DiPFormer achieves state-of-the-art performance on the KITTI
(97.57% F-score on KITTI road and 68.74% mIoU on KITTI-360) and Cityscapes
(83.4% mIoU) datasets.",2024-09-12 12:39:34+00:00
Enhancing Few-Shot Image Classification through Learnable Multi-Scale Embedding and Attention Mechanisms,"In the context of few-shot classification, the goal is to train a classifier
using a limited number of samples while maintaining satisfactory performance.
However, traditional metric-based methods exhibit certain limitations in
achieving this objective. These methods typically rely on a single distance
value between the query feature and support feature, thereby overlooking the
contribution of shallow features. To overcome this challenge, we propose a
novel approach in this paper. Our approach involves utilizing multi-output
embedding network that maps samples into distinct feature spaces. The proposed
method extract feature vectors at different stages, enabling the model to
capture both global and abstract features. By utilizing these diverse feature
spaces, our model enhances its performance. Moreover, employing a
self-attention mechanism improves the refinement of features at each stage,
leading to even more robust representations and improved overall performance.
Furthermore, assigning learnable weights to each stage significantly improved
performance and results. We conducted comprehensive evaluations on the
MiniImageNet and FC100 datasets, specifically in the 5-way 1-shot and 5-way
5-shot scenarios. Additionally, we performed a cross-domain task from
MiniImageNet to the CUB dataset, achieving high accuracy in the testing domain.
These evaluations demonstrate the efficacy of our proposed method in comparison
to state-of-the-art approaches. https://github.com/FatemehAskari/MSENet",2024-09-12 12:34:29+00:00
Games for AI Control: Models of Safety Evaluations of AI Deployment Protocols,"To evaluate the safety and usefulness of deployment protocols for untrusted
AIs, AI Control uses a red-teaming exercise played between a protocol designer
and an adversary. This paper introduces AI-Control Games, a formal
decision-making model of the red-teaming exercise as a multi-objective,
partially observable, stochastic game. We also introduce methods for finding
optimal protocols in AI-Control Games, by reducing them to a set of zero-sum
partially observable stochastic games. We apply our formalism to model,
evaluate and synthesise protocols for deploying untrusted language models as
programming assistants, focusing on Trusted Monitoring protocols, which use
weaker language models and limited human assistance. Finally, we demonstrate
the utility of our formalism by showcasing improvements over empirical studies
in existing settings, evaluating protocols in new settings, and analysing how
modelling assumptions affect the safety and usefulness of protocols.",2024-09-12 12:30:07+00:00
SPARK: Self-supervised Personalized Real-time Monocular Face Capture,"Feedforward monocular face capture methods seek to reconstruct posed faces
from a single image of a person. Current state of the art approaches have the
ability to regress parametric 3D face models in real-time across a wide range
of identities, lighting conditions and poses by leveraging large image datasets
of human faces. These methods however suffer from clear limitations in that the
underlying parametric face model only provides a coarse estimation of the face
shape, thereby limiting their practical applicability in tasks that require
precise 3D reconstruction (aging, face swapping, digital make-up, ...). In this
paper, we propose a method for high-precision 3D face capture taking advantage
of a collection of unconstrained videos of a subject as prior information. Our
proposal builds on a two stage approach. We start with the reconstruction of a
detailed 3D face avatar of the person, capturing both precise geometry and
appearance from a collection of videos. We then use the encoder from a
pre-trained monocular face reconstruction method, substituting its decoder with
our personalized model, and proceed with transfer learning on the video
collection. Using our pre-estimated image formation model, we obtain a more
precise self-supervision objective, enabling improved expression and pose
alignment. This results in a trained encoder capable of efficiently regressing
pose and expression parameters in real-time from previously unseen images,
which combined with our personalized geometry model yields more accurate and
high fidelity mesh inference. Through extensive qualitative and quantitative
evaluation, we showcase the superiority of our final model as compared to
state-of-the-art baselines, and demonstrate its generalization ability to
unseen pose, expression and lighting.",2024-09-12 12:30:04+00:00
Sparse R-CNN OBB: Ship Target Detection in SAR Images Based on Oriented Sparse Proposals,"We present Sparse R-CNN OBB, a novel framework for the detection of oriented
objects in SAR images leveraging sparse learnable proposals. The Sparse R-CNN
OBB has streamlined architecture and ease of training as it utilizes a sparse
set of 300 proposals instead of training a proposals generator on hundreds of
thousands of anchors. To the best of our knowledge, Sparse R-CNN OBB is the
first to adopt the concept of sparse learnable proposals for the detection of
oriented objects, as well as for the detection of ships in Synthetic Aperture
Radar (SAR) images. The detection head of the baseline model, Sparse R-CNN, is
re-designed to enable the model to capture object orientation. We also
fine-tune the model on RSDD-SAR dataset and provide a performance comparison to
state-of-the-art models. Experimental results shows that Sparse R-CNN OBB
achieves outstanding performance, surpassing other models on both inshore and
offshore scenarios. The code is available at:
www.github.com/ka-mirul/Sparse-R-CNN-OBB.",2024-09-12 12:12:46+00:00
Deep Height Decoupling for Precise Vision-based 3D Occupancy Prediction,"The task of vision-based 3D occupancy prediction aims to reconstruct 3D
geometry and estimate its semantic classes from 2D color images, where the
2D-to-3D view transformation is an indispensable step. Most previous methods
conduct forward projection, such as BEVPooling and VoxelPooling, both of which
map the 2D image features into 3D grids. However, the current grid representing
features within a certain height range usually introduces many confusing
features that belong to other height ranges. To address this challenge, we
present Deep Height Decoupling (DHD), a novel framework that incorporates
explicit height prior to filter out the confusing features. Specifically, DHD
first predicts height maps via explicit supervision. Based on the height
distribution statistics, DHD designs Mask Guided Height Sampling (MGHS) to
adaptively decoupled the height map into multiple binary masks. MGHS projects
the 2D image features into multiple subspaces, where each grid contains
features within reasonable height ranges. Finally, a Synergistic Feature
Aggregation (SFA) module is deployed to enhance the feature representation
through channel and spatial affinities, enabling further occupancy refinement.
On the popular Occ3D-nuScenes benchmark, our method achieves state-of-the-art
performance even with minimal input frames. Code is available at
https://github.com/yanzq95/DHD.",2024-09-12 12:12:19+00:00
Localized Schrödinger Bridge Sampler,"We consider the generative problem of sampling from an unknown distribution
for which only a sufficiently large number of training samples are available.
In this paper, we build on previous work combining Schr\""odinger bridges and
Langevin dynamics. A key bottleneck of this approach is the exponential
dependence of the required training samples on the dimension, $d$, of the
ambient state space. We propose a localization strategy which exploits
conditional independence of conditional expectation values. Localization thus
replaces a single high-dimensional Schr\""odinger bridge problem by $d$
low-dimensional Schr\""odinger bridge problems over the available training
samples. As for the original approach, the localized sampler is stable and
geometric ergodic. The sampler also naturally extends to conditional sampling
and to Bayesian inference. We demonstrate the performance of our proposed
scheme through experiments on a Gaussian problem with increasing dimensions and
on a stochastic subgrid-scale parametrization conditional sampling problem.",2024-09-12 12:02:51+00:00
Locality-aware Cross-modal Correspondence Learning for Dense Audio-Visual Events Localization,"Dense-localization Audio-Visual Events (DAVE) aims to identify time
boundaries and corresponding categories for events that can be heard and seen
concurrently in an untrimmed video. Existing methods typically encode audio and
visual representation separately without any explicit cross-modal alignment
constraint. Then they adopt dense cross-modal attention to integrate multimodal
information for DAVE. Thus these methods inevitably aggregate irrelevant noise
and events, especially in complex and long videos, leading to imprecise
detection. In this paper, we present LOCO, a Locality-aware cross-modal
Correspondence learning framework for DAVE. The core idea is to explore local
temporal continuity nature of audio-visual events, which serves as informative
yet free supervision signals to guide the filtering of irrelevant information
and inspire the extraction of complementary multimodal information during both
unimodal and cross-modal learning stages. i) Specifically, LOCO applies
Locality-aware Correspondence Correction (LCC) to uni-modal features via
leveraging cross-modal local-correlated properties without any extra
annotations. This enforces uni-modal encoders to highlight similar semantics
shared by audio and visual features. ii) To better aggregate such audio and
visual features, we further customize Cross-modal Dynamic Perception layer
(CDP) in cross-modal feature pyramid to understand local temporal patterns of
audio-visual events by imposing local consistency within multimodal features in
a data-driven manner. By incorporating LCC and CDP, LOCO provides solid
performance gains and outperforms existing methods for DAVE. The source code
will be released.",2024-09-12 11:54:25+00:00
ProbTalk3D: Non-Deterministic Emotion Controllable Speech-Driven 3D Facial Animation Synthesis Using VQ-VAE,"Audio-driven 3D facial animation synthesis has been an active field of
research with attention from both academia and industry. While there are
promising results in this area, recent approaches largely focus on lip-sync and
identity control, neglecting the role of emotions and emotion control in the
generative process. That is mainly due to the lack of emotionally rich facial
animation data and algorithms that can synthesize speech animations with
emotional expressions at the same time. In addition, majority of the models are
deterministic, meaning given the same audio input, they produce the same output
motion. We argue that emotions and non-determinism are crucial to generate
diverse and emotionally-rich facial animations. In this paper, we propose
ProbTalk3D a non-deterministic neural network approach for emotion controllable
speech-driven 3D facial animation synthesis using a two-stage VQ-VAE model and
an emotionally rich facial animation dataset 3DMEAD. We provide an extensive
comparative analysis of our model against the recent 3D facial animation
synthesis approaches, by evaluating the results objectively, qualitatively, and
with a perceptual user study. We highlight several objective metrics that are
more suitable for evaluating stochastic outputs and use both in-the-wild and
ground truth data for subjective evaluation. To our knowledge, that is the
first non-deterministic 3D facial animation synthesis method incorporating a
rich emotion dataset and emotion control with emotion labels and intensity
levels. Our evaluation demonstrates that the proposed model achieves superior
performance compared to state-of-the-art emotion-controlled, deterministic and
non-deterministic models. We recommend watching the supplementary video for
quality judgement. The entire codebase is publicly available
(https://github.com/uuembodiedsocialai/ProbTalk3D/).",2024-09-12 11:53:05+00:00
Autonomous Vehicle Controllers From End-to-End Differentiable Simulation,"Current methods to learn controllers for autonomous vehicles (AVs) focus on
behavioural cloning. Being trained only on exact historic data, the resulting
agents often generalize poorly to novel scenarios. Simulators provide the
opportunity to go beyond offline datasets, but they are still treated as
complicated black boxes, only used to update the global simulation state. As a
result, these RL algorithms are slow, sample-inefficient, and prior-agnostic.
In this work, we leverage a differentiable simulator and design an analytic
policy gradients (APG) approach to training AV controllers on the large-scale
Waymo Open Motion Dataset. Our proposed framework brings the differentiable
simulator into an end-to-end training loop, where gradients of the environment
dynamics serve as a useful prior to help the agent learn a more grounded
policy. We combine this setup with a recurrent architecture that can
efficiently propagate temporal information across long simulated trajectories.
This APG method allows us to learn robust, accurate, and fast policies, while
only requiring widely-available expert trajectories, instead of scarce expert
actions. We compare to behavioural cloning and find significant improvements in
performance and robustness to noise in the dynamics, as well as overall more
intuitive human-like handling.",2024-09-12 11:50:06+00:00
WirelessAgent: Large Language Model Agents for Intelligent Wireless Networks,"Wireless networks are increasingly facing challenges due to their expanding
scale and complexity. These challenges underscore the need for advanced
AI-driven strategies, particularly in the upcoming 6G networks. In this
article, we introduce WirelessAgent, a novel approach leveraging large language
models (LLMs) to develop AI agents capable of managing complex tasks in
wireless networks. It can effectively improve network performance through
advanced reasoning, multimodal data processing, and autonomous decision making.
Thereafter, we demonstrate the practical applicability and benefits of
WirelessAgent for network slicing management. The experimental results show
that WirelessAgent is capable of accurately understanding user intent,
effectively allocating slice resources, and consistently maintaining optimal
performance.",2024-09-12 11:48:01+00:00
Estimating Atmospheric Variables from Digital Typhoon Satellite Images via Conditional Denoising Diffusion Models,"This study explores the application of diffusion models in the field of
typhoons, predicting multiple ERA5 meteorological variables simultaneously from
Digital Typhoon satellite images. The focus of this study is taken to be
Taiwan, an area very vulnerable to typhoons. By comparing the performance of
Conditional Denoising Diffusion Probability Model (CDDPM) with Convolutional
Neural Networks (CNN) and Squeeze-and-Excitation Networks (SENet), results
suggest that the CDDPM performs best in generating accurate and realistic
meteorological data. Specifically, CDDPM achieved a PSNR of 32.807, which is
approximately 7.9% higher than CNN and 5.5% higher than SENet. Furthermore,
CDDPM recorded an RMSE of 0.032, showing a 11.1% improvement over CNN and 8.6%
improvement over SENet. A key application of this research can be for
imputation purposes in missing meteorological datasets and generate additional
high-quality meteorological data using satellite images. It is hoped that the
results of this analysis will enable more robust and detailed forecasting,
reducing the impact of severe weather events on vulnerable regions. Code
accessible at https://github.com/TammyLing/Typhoon-forecasting.",2024-09-12 11:42:40+00:00
Do Vision Foundation Models Enhance Domain Generalization in Medical Image Segmentation?,"Neural networks achieve state-of-the-art performance in many supervised
learning tasks when the training data distribution matches the test data
distribution. However, their performance drops significantly under domain
(covariate) shift, a prevalent issue in medical image segmentation due to
varying acquisition settings across different scanner models and protocols.
Recently, foundational models (FMs) trained on large datasets have gained
attention for their ability to be adapted for downstream tasks and achieve
state-of-the-art performance with excellent generalization capabilities on
natural images. However, their effectiveness in medical image segmentation
remains underexplored. In this paper, we investigate the domain generalization
performance of various FMs, including DinoV2, SAM, MedSAM, and MAE, when
fine-tuned using various parameter-efficient fine-tuning (PEFT) techniques such
as Ladder and Rein (+LoRA) and decoder heads. We introduce a novel decode head
architecture, HQHSAM, which simply integrates elements from two
state-of-the-art decoder heads, HSAM and HQSAM, to enhance segmentation
performance. Our extensive experiments on multiple datasets, encompassing
various anatomies and modalities, reveal that FMs, particularly with the HQHSAM
decode head, improve domain generalization for medical image segmentation.
Moreover, we found that the effectiveness of PEFT techniques varies across
different FMs. These findings underscore the potential of FMs to enhance the
domain generalization performance of neural networks in medical image
segmentation across diverse clinical settings, providing a solid foundation for
future research. Code and models are available for research purposes at
\url{https://github.com/kerem-cekmeceli/Foundation-Models-for-Medical-Imagery}.",2024-09-12 11:41:35+00:00
Enhanced Online Grooming Detection Employing Context Determination and Message-Level Analysis,"Online Grooming (OG) is a prevalent threat facing predominately children
online, with groomers using deceptive methods to prey on the vulnerability of
children on social media/messaging platforms. These attacks can have severe
psychological and physical impacts, including a tendency towards
revictimization. Current technical measures are inadequate, especially with the
advent of end-to-end encryption which hampers message monitoring. Existing
solutions focus on the signature analysis of child abuse media, which does not
effectively address real-time OG detection. This paper proposes that OG attacks
are complex, requiring the identification of specific communication patterns
between adults and children. It introduces a novel approach leveraging advanced
models such as BERT and RoBERTa for Message-Level Analysis and a Context
Determination approach for classifying actor interactions, including the
introduction of Actor Significance Thresholds and Message Significance
Thresholds. The proposed method aims to enhance accuracy and robustness in
detecting OG by considering the dynamic and multi-faceted nature of these
attacks. Cross-dataset experiments evaluate the robustness and versatility of
our approach. This paper's contributions include improved detection
methodologies and the potential for application in various scenarios,
addressing gaps in current literature and practices.",2024-09-12 11:37:34+00:00
Rapid Parameter Estimation for Extreme Mass Ratio Inspirals Using Machine Learning,"Extreme-mass-ratio inspiral (EMRI) signals pose significant challenges in
gravitational wave (GW) astronomy owing to their low-frequency nature and
highly complex waveforms, which occupy a high-dimensional parameter space with
numerous variables. Given their extended inspiral timescales and low
signal-to-noise ratios, EMRI signals warrant prolonged observation periods.
Parameter estimation becomes particularly challenging due to non-local
parameter degeneracies, arising from multiple local maxima, as well as flat
regions and ridges inherent in the likelihood function. These factors lead to
exceptionally high time complexity for parameter analysis while employing
traditional matched filtering and random sampling methods. To address these
challenges, the present study applies machine learning to Bayesian posterior
estimation of EMRI signals, leveraging the recently developed flow matching
technique based on ODE neural networks. Our approach demonstrates computational
efficiency several orders of magnitude faster than the traditional Markov Chain
Monte Carlo (MCMC) methods, while preserving the unbiasedness of parameter
estimation. We show that machine learning technology has the potential to
efficiently handle the vast parameter space, involving up to seventeen
parameters, associated with EMRI signals. Furthermore, to our knowledge, this
is the first instance of applying machine learning, specifically the Continuous
Normalizing Flows (CNFs), to EMRI signal analysis. Our findings highlight the
promising potential of machine learning in EMRI waveform analysis, offering new
perspectives for the advancement of space-based GW detection and GW astronomy.",2024-09-12 11:36:23+00:00
What is the Relationship between Tensor Factorizations and Circuits (and How Can We Exploit it)?,"This paper establishes a rigorous connection between circuit representations
and tensor factorizations, two seemingly distinct yet fundamentally related
areas. By connecting these fields, we highlight a series of opportunities that
can benefit both communities. Our work generalizes popular tensor
factorizations within the circuit language, and unifies various circuit
learning algorithms under a single, generalized hierarchical factorization
framework. Specifically, we introduce a modular ""Lego block"" approach to build
tensorized circuit architectures. This, in turn, allows us to systematically
construct and explore various circuit and tensor factorization models while
maintaining tractability. This connection not only clarifies similarities and
differences in existing models, but also enables the development of a
comprehensive pipeline for building and optimizing new circuit/tensor
factorization architectures. We show the effectiveness of our framework through
extensive empirical evaluations, and highlight new research opportunities for
tensor factorizations in probabilistic modeling.",2024-09-12 11:32:01+00:00
Taylor-Sensus Network: Embracing Noise to Enlighten Uncertainty for Scientific Data,"Uncertainty estimation is crucial in scientific data for machine learning.
Current uncertainty estimation methods mainly focus on the model's inherent
uncertainty, while neglecting the explicit modeling of noise in the data.
Furthermore, noise estimation methods typically rely on temporal or spatial
dependencies, which can pose a significant challenge in structured scientific
data where such dependencies among samples are often absent. To address these
challenges in scientific research, we propose the Taylor-Sensus Network
(TSNet). TSNet innovatively uses a Taylor series expansion to model complex,
heteroscedastic noise and proposes a deep Taylor block for aware noise
distribution. TSNet includes a noise-aware contrastive learning module and a
data density perception module for aleatoric and epistemic uncertainty.
Additionally, an uncertainty combination operator is used to integrate these
uncertainties, and the network is trained using a novel heteroscedastic mean
square error loss. TSNet demonstrates superior performance over mainstream and
state-of-the-art methods in experiments, highlighting its potential in
scientific research and noise resistance. It will be open-source to facilitate
the community of ""AI for Science"".",2024-09-12 11:10:27+00:00
Control+Shift: Generating Controllable Distribution Shifts,"We propose a new method for generating realistic datasets with distribution
shifts using any decoder-based generative model. Our approach systematically
creates datasets with varying intensities of distribution shifts, facilitating
a comprehensive analysis of model performance degradation. We then use these
generated datasets to evaluate the performance of various commonly used
networks and observe a consistent decline in performance with increasing shift
intensity, even when the effect is almost perceptually unnoticeable to the
human eye. We see this degradation even when using data augmentations. We also
find that enlarging the training dataset beyond a certain point has no effect
on the robustness and that stronger inductive biases increase robustness.",2024-09-12 11:07:53+00:00
Modeling Human Responses by Ordinal Archetypal Analysis,"This paper introduces a novel framework for Archetypal Analysis (AA) tailored
to ordinal data, particularly from questionnaires. Unlike existing methods, the
proposed method, Ordinal Archetypal Analysis (OAA), bypasses the two-step
process of transforming ordinal data into continuous scales and operates
directly on the ordinal data. We extend traditional AA methods to handle the
subjective nature of questionnaire-based data, acknowledging individual
differences in scale perception. We introduce the Response Bias Ordinal
Archetypal Analysis (RBOAA), which learns individualized scales for each
subject during optimization. The effectiveness of these methods is demonstrated
on synthetic data and the European Social Survey dataset, highlighting their
potential to provide deeper insights into human behavior and perception. The
study underscores the importance of considering response bias in cross-national
research and offers a principled approach to analyzing ordinal data through
Archetypal Analysis.",2024-09-12 10:58:26+00:00
Reinforcement Learning Discovers Efficient Decentralized Graph Path Search Strategies,"Graph path search is a classic computer science problem that has been
recently approached with Reinforcement Learning (RL) due to its potential to
outperform prior methods. Existing RL techniques typically assume a global view
of the network, which is not suitable for large-scale, dynamic, and
privacy-sensitive settings. An area of particular interest is search in social
networks due to its numerous applications. Inspired by seminal work in
experimental sociology, which showed that decentralized yet efficient search is
possible in social networks, we frame the problem as a collaborative task
between multiple agents equipped with a limited local view of the network. We
propose a multi-agent approach for graph path search that successfully
leverages both homophily and structural heterogeneity. Our experiments, carried
out over synthetic and real-world social networks, demonstrate that our model
significantly outperforms learned and heuristic baselines. Furthermore, our
results show that meaningful embeddings for graph navigation can be constructed
using reward-driven learning.",2024-09-12 10:56:38+00:00
Task-Augmented Cross-View Imputation Network for Partial Multi-View Incomplete Multi-Label Classification,"In real-world scenarios, multi-view multi-label learning often encounters the
challenge of incomplete training data due to limitations in data collection and
unreliable annotation processes. The absence of multi-view features impairs the
comprehensive understanding of samples, omitting crucial details essential for
classification. To address this issue, we present a task-augmented cross-view
imputation network (TACVI-Net) for the purpose of handling partial multi-view
incomplete multi-label classification. Specifically, we employ a two-stage
network to derive highly task-relevant features to recover the missing views.
In the first stage, we leverage the information bottleneck theory to obtain a
discriminative representation of each view by extracting task-relevant
information through a view-specific encoder-classifier architecture. In the
second stage, an autoencoder based multi-view reconstruction network is
utilized to extract high-level semantic representation of the augmented
features and recover the missing data, thereby aiding the final classification
task. Extensive experiments on five datasets demonstrate that our TACVI-Net
outperforms other state-of-the-art methods.",2024-09-12 10:56:11+00:00
A convolutional neural network approach to deblending seismic data,"For economic and efficiency reasons, blended acquisition of seismic data is
becoming more and more commonplace. Seismic deblending methods are always
computationally demanding and normally consist of multiple processing steps.
Besides, the parameter setting is not always trivial. Machine learning-based
processing has the potential to significantly reduce processing time and to
change the way seismic deblending is carried out. We present a data-driven deep
learning-based method for fast and efficient seismic deblending. The blended
data are sorted from the common source to the common channel domain to
transform the character of the blending noise from coherent events to
incoherent distributions. A convolutional neural network (CNN) is designed
according to the special character of seismic data, and performs deblending
with comparable results to those obtained with conventional industry deblending
algorithms. To ensure authenticity, the blending was done numerically and only
field seismic data were employed, including more than 20000 training examples.
After training and validation of the network, seismic deblending can be
performed in near real time. Experiments also show that the initial signal to
noise ratio (SNR) is the major factor controlling the quality of the final
deblended result. The network is also demonstrated to be robust and adaptive by
using the trained model to firstly deblend a new data set from a different
geological area with a slightly different delay time setting, and secondly
deblend shots with blending noise in the top part of the data.",2024-09-12 10:54:35+00:00
A framework for measuring the training efficiency of a neural architecture,"Measuring Efficiency in neural network system development is an open research
problem. This paper presents an experimental framework to measure the training
efficiency of a neural architecture. To demonstrate our approach, we analyze
the training efficiency of Convolutional Neural Networks and Bayesian
equivalents on the MNIST and CIFAR-10 tasks. Our results show that training
efficiency decays as training progresses and varies across different stopping
criteria for a given neural model and learning task. We also find a non-linear
relationship between training stopping criteria, training Efficiency, model
size, and training Efficiency.
  Furthermore, we illustrate the potential confounding effects of overtraining
on measuring the training efficiency of a neural architecture. Regarding
relative training efficiency across different architectures, our results
indicate that CNNs are more efficient than BCNNs on both datasets. More
generally, as a learning task becomes more complex, the relative difference in
training efficiency between different architectures becomes more pronounced.",2024-09-12 10:45:38+00:00
Tidal MerzA: Combining affective modelling and autonomous code generation through Reinforcement Learning,"This paper presents Tidal-MerzA, a novel system designed for collaborative
performances between humans and a machine agent in the context of live coding,
specifically focusing on the generation of musical patterns. Tidal-MerzA fuses
two foundational models: ALCAA (Affective Live Coding Autonomous Agent) and
Tidal Fuzz, a computational framework. By integrating affective modelling with
computational generation, this system leverages reinforcement learning
techniques to dynamically adapt music composition parameters within the
TidalCycles framework, ensuring both affective qualities to the patterns and
syntactical correctness. The development of Tidal-MerzA introduces two distinct
agents: one focusing on the generation of mini-notation strings for musical
expression, and another on the alignment of music with targeted affective
states through reinforcement learning. This approach enhances the adaptability
and creative potential of live coding practices and allows exploration of
human-machine creative interactions. Tidal-MerzA advances the field of
computational music generation, presenting a novel methodology for
incorporating artificial intelligence into artistic practices.",2024-09-12 10:38:55+00:00
InterACT: Inter-dependency Aware Action Chunking with Hierarchical Attention Transformers for Bimanual Manipulation,"We present InterACT: Inter-dependency aware Action Chunking with Hierarchical
Attention Transformers, a novel imitation learning framework for bimanual
manipulation that integrates hierarchical attention to capture
inter-dependencies between dual-arm joint states and visual inputs. InterACT
consists of a Hierarchical Attention Encoder and a Multi-arm Decoder, both
designed to enhance information aggregation and coordination. The encoder
processes multi-modal inputs through segment-wise and cross-segment attention
mechanisms, while the decoder leverages synchronization blocks to refine
individual action predictions, providing the counterpart's prediction as
context. Our experiments on a variety of simulated and real-world bimanual
manipulation tasks demonstrate that InterACT significantly outperforms existing
methods. Detailed ablation studies validate the contributions of key components
of our work, including the impact of CLS tokens, cross-segment encoders, and
synchronization blocks.",2024-09-12 10:30:44+00:00
UGAD: Universal Generative AI Detector utilizing Frequency Fingerprints,"In the wake of a fabricated explosion image at the Pentagon, an ability to
discern real images from fake counterparts has never been more critical. Our
study introduces a novel multi-modal approach to detect AI-generated images
amidst the proliferation of new generation methods such as Diffusion models.
Our method, UGAD, encompasses three key detection steps: First, we transform
the RGB images into YCbCr channels and apply an Integral Radial Operation to
emphasize salient radial features. Secondly, the Spatial Fourier Extraction
operation is used for a spatial shift, utilizing a pre-trained deep learning
network for optimal feature extraction. Finally, the deep neural network
classification stage processes the data through dense layers using softmax for
classification. Our approach significantly enhances the accuracy of
differentiating between real and AI-generated images, as evidenced by a 12.64%
increase in accuracy and 28.43% increase in AUC compared to existing
state-of-the-art methods.",2024-09-12 10:29:37+00:00
Tera-SpaceCom: GNN-based Deep Reinforcement Learning for Joint Resource Allocation and Task Offloading in TeraHertz Band Space Networks,"Terahertz (THz) space communications (Tera-SpaceCom) is envisioned as a
promising technology to enable various space science and communication
applications. Mainly, the realm of Tera-SpaceCom consists of THz sensing for
space exploration, data centers in space providing cloud services for space
exploration tasks, and a low earth orbit (LEO) mega-constellation relaying
these tasks to ground stations (GSs) or data centers via THz links. Moreover,
to reduce the computational burden on data centers as well as resource
consumption and latency in the relaying process, the LEO mega-constellation
provides satellite edge computing (SEC) services to directly compute space
exploration tasks without relaying these tasks to data centers. The LEO
satellites that receive space exploration tasks offload (i.e., distribute)
partial tasks to their neighboring LEO satellites, to further reduce their
computational burden. However, efficient joint communication resource
allocation and computing task offloading for the Tera-SpaceCom SEC network is
an NP-hard mixed-integer nonlinear programming problem (MINLP), due to the
discrete nature of space exploration tasks and sub-arrays as well as the
continuous nature of transmit power. To tackle this challenge, a graph neural
network (GNN)-deep reinforcement learning (DRL)-based joint resource allocation
and task offloading (GRANT) algorithm is proposed with the target of long-term
resource efficiency (RE). Particularly, GNNs learn relationships among
different satellites from their connectivity information. Furthermore,
multi-agent and multi-task mechanisms cooperatively train task offloading and
resource allocation. Compared with benchmark solutions, GRANT not only achieves
the highest RE with relatively low latency, but realizes the fewest trainable
parameters and the shortest running time.",2024-09-12 10:26:17+00:00
From COCO to COCO-FP: A Deep Dive into Background False Positives for COCO Detectors,"Reducing false positives is essential for enhancing object detector
performance, as reflected in the mean Average Precision (mAP) metric. Although
object detectors have achieved notable improvements and high mAP scores on the
COCO dataset, analysis reveals limited progress in addressing false positives
caused by non-target visual clutter-background objects not included in the
annotated categories. This issue is particularly critical in real-world
applications, such as fire and smoke detection, where minimizing false alarms
is crucial. In this study, we introduce COCO-FP, a new evaluation dataset
derived from the ImageNet-1K dataset, designed to address this issue. By
extending the original COCO validation dataset, COCO-FP specifically assesses
object detectors' performance in mitigating background false positives. Our
evaluation of both standard and advanced object detectors shows a significant
number of false positives in both closed-set and open-set scenarios. For
example, the AP50 metric for YOLOv9-E decreases from 72.8 to 65.7 when shifting
from COCO to COCO-FP. The dataset is available at
https://github.com/COCO-FP/COCO-FP.",2024-09-12 10:22:12+00:00
FACT: Feature Adaptive Continual-learning Tracker for Multiple Object Tracking,"Multiple object tracking (MOT) involves identifying multiple targets and
assigning them corresponding IDs within a video sequence, where occlusions are
often encountered. Recent methods address occlusions using appearance cues
through online learning techniques to improve adaptivity or offline learning
techniques to utilize temporal information from videos. However, most existing
online learning-based MOT methods are unable to learn from all past tracking
information to improve adaptivity on long-term occlusions while maintaining
real-time tracking speed. On the other hand, temporal information-based offline
learning methods maintain a long-term memory to store past tracking
information, but this approach restricts them to use only local past
information during tracking. To address these challenges, we propose a new MOT
framework called the Feature Adaptive Continual-learning Tracker (FACT), which
enables real-time tracking and feature learning for targets by utilizing all
past tracking information. We demonstrate that the framework can be integrated
with various state-of-the-art feature-based trackers, thereby improving their
tracking ability. Specifically, we develop the feature adaptive
continual-learning (FAC) module, a neural network that can be trained online to
learn features adaptively using all past tracking information during tracking.
Moreover, we also introduce a two-stage association module specifically
designed for the proposed continual learning-based tracking. Extensive
experiment results demonstrate that the proposed method achieves
state-of-the-art online tracking performance on MOT17 and MOT20 benchmarks. The
code will be released upon acceptance.",2024-09-12 10:14:48+00:00
Conformal Distributed Remote Inference in Sensor Networks Under Reliability and Communication Constraints,"This paper presents communication-constrained distributed conformal risk
control (CD-CRC) framework, a novel decision-making framework for sensor
networks under communication constraints. Targeting multi-label classification
problems, such as segmentation, CD-CRC dynamically adjusts local and global
thresholds used to identify significant labels with the goal of ensuring a
target false negative rate (FNR), while adhering to communication capacity
limits. CD-CRC builds on online exponentiated gradient descent to estimate the
relative quality of the observations of different sensors, and on online
conformal risk control (CRC) as a mechanism to control local and global
thresholds. CD-CRC is proved to offer deterministic worst-case performance
guarantees in terms of FNR and communication overhead, while the regret
performance in terms of false positive rate (FPR) is characterized as a
function of the key hyperparameters. Simulation results highlight the
effectiveness of CD-CRC, particularly in communication resource-constrained
environments, making it a valuable tool for enhancing the performance and
reliability of distributed sensor networks.",2024-09-12 10:12:43+00:00
Microscopic-Mamba: Revealing the Secrets of Microscopic Images with Just 4M Parameters,"In the field of medical microscopic image classification (MIC), CNN-based and
Transformer-based models have been extensively studied. However, CNNs struggle
with modeling long-range dependencies, limiting their ability to fully utilize
semantic information in images. Conversely, Transformers are hampered by the
complexity of quadratic computations. To address these challenges, we propose a
model based on the Mamba architecture: Microscopic-Mamba. Specifically, we
designed the Partially Selected Feed-Forward Network (PSFFN) to replace the
last linear layer of the Visual State Space Module (VSSM), enhancing Mamba's
local feature extraction capabilities. Additionally, we introduced the
Modulation Interaction Feature Aggregation (MIFA) module to effectively
modulate and dynamically aggregate global and local features. We also
incorporated a parallel VSSM mechanism to improve inter-channel information
interaction while reducing the number of parameters. Extensive experiments have
demonstrated that our method achieves state-of-the-art performance on five
public datasets. Code is available at
https://github.com/zs1314/Microscopic-Mamba",2024-09-12 10:01:33+00:00
BLens: Contrastive Captioning of Binary Functions using Ensemble Embedding,"Function names can greatly aid human reverse engineers, which has spurred
development of machine learning-based approaches to predicting function names
in stripped binaries. Much current work in this area now uses transformers,
applying a metaphor of machine translation from code to function names. Still,
function naming models face challenges in generalizing to projects completely
unrelated to the training set. In this paper, we take a completely new approach
by transferring advances in automated image captioning to the domain of binary
reverse engineering, such that different parts of a binary function can be
associated with parts of its name. We propose BLens, which combines multiple
binary function embeddings into a new ensemble representation, aligns it with
the name representation latent space via a contrastive learning approach, and
generates function names with a transformer architecture tailored for function
names. In our experiments, we demonstrate that BLens significantly outperforms
the state of the art. In the usual setting of splitting per binary, we achieve
an $F_1$ score of 0.77 compared to 0.67. Moreover, in the cross-project
setting, which emphasizes generalizability, we achieve an $F_1$ score of 0.46
compared to 0.29.",2024-09-12 09:49:34+00:00
UNIT: Unsupervised Online Instance Segmentation through Time,"Online object segmentation and tracking in Lidar point clouds enables
autonomous agents to understand their surroundings and make safe decisions.
Unfortunately, manual annotations for these tasks are prohibitively costly. We
tackle this problem with the task of class-agnostic unsupervised online
instance segmentation and tracking. To that end, we leverage an instance
segmentation backbone and propose a new training recipe that enables the online
tracking of objects. Our network is trained on pseudo-labels, eliminating the
need for manual annotations. We conduct an evaluation using metrics adapted for
temporal instance segmentation. Computing these metrics requires
temporally-consistent instance labels. When unavailable, we construct these
labels using the available 3D bounding boxes and semantic labels in the
dataset. We compare our method against strong baselines and demonstrate its
superiority across two different outdoor Lidar datasets.",2024-09-12 09:47:45+00:00
Graph Neural Networks for Parkinsons Disease Detection,"Despite the promising performance of state of the art approaches for
Parkinsons Disease (PD) detection, these approaches often analyze individual
speech segments in isolation, which can lead to suboptimal results. Dysarthric
cues that characterize speech impairments from PD patients are expected to be
related across segments from different speakers. Isolated segment analysis
fails to exploit these inter segment relationships. Additionally, not all
speech segments from PD patients exhibit clear dysarthric symptoms, introducing
label noise that can negatively affect the performance and generalizability of
current approaches. To address these challenges, we propose a novel PD
detection framework utilizing Graph Convolutional Networks (GCNs). By
representing speech segments as nodes and capturing the similarity between
segments through edges, our GCN model facilitates the aggregation of dysarthric
cues across the graph, effectively exploiting segment relationships and
mitigating the impact of label noise. Experimental results demonstrate
theadvantages of the proposed GCN model for PD detection and provide insights
into its underlying mechanisms",2024-09-12 09:44:13+00:00
Non-negative Weighted DAG Structure Learning,"We address the problem of learning the topology of directed acyclic graphs
(DAGs) from nodal observations, which adhere to a linear structural equation
model. Recent advances framed the combinatorial DAG structure learning task as
a continuous optimization problem, yet existing methods must contend with the
complexities of non-convex optimization. To overcome this limitation, we assume
that the latent DAG contains only non-negative edge weights. Leveraging this
additional structure, we argue that cycles can be effectively characterized
(and prevented) using a convex acyclicity function based on the log-determinant
of the adjacency matrix. This convexity allows us to relax the task of learning
the non-negative weighted DAG as an abstract convex optimization problem. We
propose a DAG recovery algorithm based on the method of multipliers, that is
guaranteed to return a global minimizer. Furthermore, we prove that in the
infinite sample size regime, the convexity of our approach ensures the recovery
of the true DAG structure. We empirically validate the performance of our
algorithm in several reproducible synthetic-data test cases, showing that it
outperforms state-of-the-art alternatives.",2024-09-12 09:41:29+00:00
Randomized Spline Trees for Functional Data Classification: Theory and Application to Environmental Time Series,"Functional data analysis (FDA) and ensemble learning can be powerful tools
for analyzing complex environmental time series. Recent literature has
highlighted the key role of diversity in enhancing accuracy and reducing
variance in ensemble methods.This paper introduces Randomized Spline Trees
(RST), a novel algorithm that bridges these two approaches by incorporating
randomized functional representations into the Random Forest framework. RST
generates diverse functional representations of input data using randomized
B-spline parameters, creating an ensemble of decision trees trained on these
varied representations. We provide a theoretical analysis of how this
functional diversity contributes to reducing generalization error and present
empirical evaluations on six environmental time series classification tasks
from the UCR Time Series Archive. Results show that RST variants outperform
standard Random Forests and Gradient Boosting on most datasets, improving
classification accuracy by up to 14\%. The success of RST demonstrates the
potential of adaptive functional representations in capturing complex temporal
patterns in environmental data. This work contributes to the growing field of
machine learning techniques focused on functional data and opens new avenues
for research in environmental time series analysis.",2024-09-12 09:38:16+00:00
Context-Aware Optimal Transport Learning for Retinal Fundus Image Enhancement,"Retinal fundus photography offers a non-invasive way to diagnose and monitor
a variety of retinal diseases, but is prone to inherent quality glitches
arising from systemic imperfections or operator/patient-related factors.
However, high-quality retinal images are crucial for carrying out accurate
diagnoses and automated analyses. The fundus image enhancement is typically
formulated as a distribution alignment problem, by finding a one-to-one mapping
between a low-quality image and its high-quality counterpart. This paper
proposes a context-informed optimal transport (OT) learning framework for
tackling unpaired fundus image enhancement. In contrast to standard generative
image enhancement methods, which struggle with handling contextual information
(e.g., over-tampered local structures and unwanted artifacts), the proposed
context-aware OT learning paradigm better preserves local structures and
minimizes unwanted artifacts. Leveraging deep contextual features, we derive
the proposed context-aware OT using the earth mover's distance and show that
the proposed context-OT has a solid theoretical guarantee. Experimental results
on a large-scale dataset demonstrate the superiority of the proposed method
over several state-of-the-art supervised and unsupervised methods in terms of
signal-to-noise ratio, structural similarity index, as well as two downstream
tasks. The code is available at
\url{https://github.com/Retinal-Research/Contextual-OT}.",2024-09-12 09:14:37+00:00
Audio Decoding by Inverse Problem Solving,"We consider audio decoding as an inverse problem and solve it through
diffusion posterior sampling. Explicit conditioning functions are developed for
input signal measurements provided by an example of a transform domain
perceptual audio codec. Viability is demonstrated by evaluating arbitrary
pairings of a set of bitrates and task-agnostic prior models. For instance, we
observe significant improvements on piano while maintaining speech performance
when a speech model is replaced by a joint model trained on both speech and
piano. With a more general music model, improved decoding compared to legacy
methods is obtained for a broad range of content types and bitrates. The noisy
mean model, underlying the proposed derivation of conditioning, enables a
significant reduction of gradient evaluations for diffusion posterior sampling,
compared to methods based on Tweedie's mean. Combining Tweedie's mean with our
conditioning functions improves the objective performance. An audio demo is
available at https://dpscodec-demo.github.io/.",2024-09-12 09:05:18+00:00
Improve Machine Learning carbon footprint using Nvidia GPU and Mixed Precision training for classification algorithms,"This study was part of my dissertation for my master degree and compares the
power consumption using the default floating point (32bit) and Nvidia mixed
precision (16bit and 32bit) while training a classification ML model. A custom
PC with specific hardware was built to perform the experiments, and different
ML hyper-parameters, such as batch size, neurons, and epochs, were chosen to
build Deep Neural Networks (DNN). Additionally, various software was used
during the experiments to collect the power consumption data in Watts from the
Graphics Processing Unit (GPU), Central Processing Unit (CPU), Random Access
Memory (RAM) and manually from a wattmeter connected to the wall. A
benchmarking test with default hyper parameter values for the DNN was used as a
reference, while the experiments used a combination of different settings. The
results were recorded in Excel, and descriptive statistics were chosen to
calculate the mean between the groups and compare them using graphs and tables.
The outcome was positive when using mixed precision combined with specific
hyper-parameters. Compared to the benchmarking, the optimisation for the
classification reduced the power consumption between 7 and 11 Watts. Similarly,
the carbon footprint is reduced because the calculation uses the same power
consumption data. Still, a consideration is required when configuring
hyper-parameters because it can negatively affect hardware performance.
However, this research required inferential statistics, specifically ANOVA and
T-test, to compare the relationship between the means. Furthermore, tests
indicated no statistical significance of the relationship between the
benchmarking and experiments. However, a more extensive implementation with a
cluster of GPUs can increase the sample size significantly, as it is an
essential factor and can change the outcome of the statistical analysis.",2024-09-12 08:59:53+00:00
Enhancing Cross-Market Recommendation System with Graph Isomorphism Networks: A Novel Approach to Personalized User Experience,"In today's world of globalized commerce, cross-market recommendation systems
(CMRs) are crucial for providing personalized user experiences across diverse
market segments. However, traditional recommendation algorithms have
difficulties dealing with market specificity and data sparsity, especially in
new or emerging markets. In this paper, we propose the CrossGR model, which
utilizes Graph Isomorphism Networks (GINs) to improve CMR systems. It
outperforms existing benchmarks in NDCG@10 and HR@10 metrics, demonstrating its
adaptability and accuracy in handling diverse market segments. The CrossGR
model is adaptable and accurate, making it well-suited for handling the
complexities of cross-market recommendation tasks. Its robustness is
demonstrated by consistent performance across different evaluation timeframes,
indicating its potential to cater to evolving market trends and user
preferences. Our findings suggest that GINs represent a promising direction for
CMRs, paving the way for more sophisticated, personalized, and context-aware
recommendation systems in the dynamic landscape of global e-commerce.",2024-09-12 08:53:11+00:00
Real-time Multi-view Omnidirectional Depth Estimation System for Robots and Autonomous Driving on Real Scenes,"Omnidirectional Depth Estimation has broad application prospects in fields
such as robotic navigation and autonomous driving. In this paper, we propose a
robotic prototype system and corresponding algorithm designed to validate
omnidirectional depth estimation for navigation and obstacle avoidance in
real-world scenarios for both robots and vehicles. The proposed HexaMODE system
captures 360$^\circ$ depth maps using six surrounding arranged fisheye cameras.
We introduce a combined spherical sweeping method and optimize the model
architecture for proposed RtHexa-OmniMVS algorithm to achieve real-time
omnidirectional depth estimation. To ensure high accuracy, robustness, and
generalization in real-world environments, we employ a teacher-student
self-training strategy, utilizing large-scale unlabeled real-world data for
model training. The proposed algorithm demonstrates high accuracy in various
complex real-world scenarios, both indoors and outdoors, achieving an inference
speed of 15 fps on edge computing platforms.",2024-09-12 08:44:35+00:00
TSELM: Target Speaker Extraction using Discrete Tokens and Language Models,"We propose TSELM, a novel target speaker extraction network that leverages
discrete tokens and language models. TSELM utilizes multiple discretized layers
from WavLM as input tokens and incorporates cross-attention mechanisms to
integrate target speaker information. Language models are employed to capture
the sequence dependencies, while a scalable HiFi-GAN is used to reconstruct the
audio from the tokens. By applying a cross-entropy loss, TSELM models the
probability distribution of output tokens, thus converting the complex
regression problem of audio generation into a classification task. Experimental
results show that TSELM achieves excellent results in speech quality and
comparable results in speech intelligibility.",2024-09-12 08:41:07+00:00
FPMT: Enhanced Semi-Supervised Model for Traffic Incident Detection,"For traffic incident detection, the acquisition of data and labels is notably
resource-intensive, rendering semi-supervised traffic incident detection both a
formidable and consequential challenge. Thus, this paper focuses on traffic
incident detection with a semi-supervised learning way. It proposes a
semi-supervised learning model named FPMT within the framework of MixText. The
data augmentation module introduces Generative Adversarial Networks to balance
and expand the dataset. During the mix-up process in the hidden space, it
employs a probabilistic pseudo-mixing mechanism to enhance regularization and
elevate model precision. In terms of training strategy, it initiates with
unsupervised training on all data, followed by supervised fine-tuning on a
subset of labeled data, and ultimately completing the goal of semi-supervised
training. Through empirical validation on four authentic datasets, our FPMT
model exhibits outstanding performance across various metrics. Particularly
noteworthy is its robust performance even in scenarios with low label rates.",2024-09-12 08:38:42+00:00
Structured Pruning for Efficient Visual Place Recognition,"Visual Place Recognition (VPR) is fundamental for the global re-localization
of robots and devices, enabling them to recognize previously visited locations
based on visual inputs. This capability is crucial for maintaining accurate
mapping and localization over large areas. Given that VPR methods need to
operate in real-time on embedded systems, it is critical to optimize these
systems for minimal resource consumption. While the most efficient VPR
approaches employ standard convolutional backbones with fixed descriptor
dimensions, these often lead to redundancy in the embedding space as well as in
the network architecture. Our work introduces a novel structured pruning
method, to not only streamline common VPR architectures but also to
strategically remove redundancies within the feature embedding space. This dual
focus significantly enhances the efficiency of the system, reducing both map
and model memory requirements and decreasing feature extraction and retrieval
latencies. Our approach has reduced memory usage and latency by 21% and 16%,
respectively, across models, while minimally impacting recall@1 accuracy by
less than 1%. This significant improvement enhances real-time applications on
edge devices with negligible accuracy loss.",2024-09-12 08:32:25+00:00
Efficient and Reliable Vector Similarity Search Using Asymmetric Encoding with NAND-Flash for Many-Class Few-Shot Learning,"While memory-augmented neural networks (MANNs) offer an effective solution
for few-shot learning (FSL) by integrating deep neural networks with external
memory, the capacity requirements and energy overhead of data movement become
enormous due to the large number of support vectors in many-class FSL
scenarios. Various in-memory search solutions have emerged to improve the
energy efficiency of MANNs. NAND-based multi-bit content addressable memory
(MCAM) is a promising option due to its high density and large capacity.
Despite its potential, MCAM faces limitations such as a restricted number of
word lines, limited quantization levels, and non-ideal effects like varying
string currents and bottleneck effects, which lead to significant accuracy
drops. To address these issues, we propose several innovative methods. First,
the Multi-bit Thermometer Code (MTMC) leverages the extensive capacity of MCAM
to enhance vector precision using cumulative encoding rules, thereby mitigating
the bottleneck effect. Second, the Asymmetric vector similarity search (AVSS)
reduces the precision of the query vector while maintaining that of the support
vectors, thereby minimizing the search iterations and improving efficiency in
many-class scenarios. Finally, the Hardware-Aware Training (HAT) method
optimizes controller training by modeling the hardware characteristics of MCAM,
thus enhancing the reliability of the system. Our integrated framework reduces
search iterations by up to 32 times, and increases overall accuracy by 1.58% to
6.94%.",2024-09-12 08:29:37+00:00
ReGentS: Real-World Safety-Critical Driving Scenario Generation Made Stable,"Machine learning based autonomous driving systems often face challenges with
safety-critical scenarios that are rare in real-world data, hindering their
large-scale deployment. While increasing real-world training data coverage
could address this issue, it is costly and dangerous. This work explores
generating safety-critical driving scenarios by modifying complex real-world
regular scenarios through trajectory optimization. We propose ReGentS, which
stabilizes generated trajectories and introduces heuristics to avoid obvious
collisions and optimization problems. Our approach addresses unrealistic
diverging trajectories and unavoidable collision scenarios that are not useful
for training robust planner. We also extend the scenario generation framework
to handle real-world data with up to 32 agents. Additionally, by using a
differentiable simulator, our approach simplifies gradient descent-based
optimization involving a simulator, paving the way for future advancements. The
code is available at https://github.com/valeoai/ReGentS.",2024-09-12 08:26:33+00:00
Bridging Paintings and Music -- Exploring Emotion based Music Generation through Paintings,"Rapid advancements in artificial intelligence have significantly enhanced
generative tasks involving music and images, employing both unimodal and
multimodal approaches. This research develops a model capable of generating
music that resonates with the emotions depicted in visual arts, integrating
emotion labeling, image captioning, and language models to transform visual
inputs into musical compositions. Addressing the scarcity of aligned art and
music data, we curated the Emotion Painting Music Dataset, pairing paintings
with corresponding music for effective training and evaluation. Our dual-stage
framework converts images to text descriptions of emotional content and then
transforms these descriptions into music, facilitating efficient learning with
minimal data. Performance is evaluated using metrics such as Fr\'echet Audio
Distance (FAD), Total Harmonic Distortion (THD), Inception Score (IS), and KL
divergence, with audio-emotion text similarity confirmed by the pre-trained
CLAP model to demonstrate high alignment between generated music and text. This
synthesis tool bridges visual art and music, enhancing accessibility for the
visually impaired and opening avenues in educational and therapeutic
applications by providing enriched multi-sensory experiences.",2024-09-12 08:19:25+00:00
A Comprehensive Survey on Deep Multimodal Learning with Missing Modality,"During multimodal model training and reasoning, data samples may miss certain
modalities and lead to compromised model performance due to sensor limitations,
cost constraints, privacy concerns, data loss, and temporal and spatial
factors. This survey provides an overview of recent progress in Multimodal
Learning with Missing Modality (MLMM), focusing on deep learning techniques. It
is the first comprehensive survey that covers the historical background and the
distinction between MLMM and standard multimodal learning setups, followed by a
detailed analysis of current MLMM methods, applications, and datasets,
concluding with a discussion about challenges and potential future directions
in the field.",2024-09-12 08:15:39+00:00
Over-the-Air Federated Learning via Weighted Aggregation,"This paper introduces a new federated learning scheme that leverages
over-the-air computation. A novel feature of this scheme is the proposal to
employ adaptive weights during aggregation, a facet treated as predefined in
other over-the-air schemes. This can mitigate the impact of wireless channel
conditions on learning performance, without needing channel state information
at transmitter side (CSIT). We provide a mathematical methodology to derive the
convergence bound for the proposed scheme in the context of computational
heterogeneity and general loss functions, supplemented with design insights.
Accordingly, we propose aggregation cost metrics and efficient algorithms to
find optimized weights for the aggregation. Finally, through numerical
experiments, we validate the effectiveness of the proposed scheme. Even with
the challenges posed by channel conditions and device heterogeneity, the
proposed scheme surpasses other over-the-air strategies by an accuracy
improvement of 15% over the scheme using CSIT and 30% compared to the one
without CSIT.",2024-09-12 08:07:11+00:00
Selling Joint Ads: A Regret Minimization Perspective,"Motivated by online retail, we consider the problem of selling one item
(e.g., an ad slot) to two non-excludable buyers (say, a merchant and a brand).
This problem captures, for example, situations where a merchant and a brand
cooperatively bid in an auction to advertise a product, and both benefit from
the ad being shown. A mechanism collects bids from the two and decides whether
to allocate and which payments the two parties should make. This gives rise to
intricate incentive compatibility constraints, e.g., on how to split payments
between the two parties. We approach the problem of finding a
revenue-maximizing incentive-compatible mechanism from an online learning
perspective; this poses significant technical challenges. First, the action
space (the class of all possible mechanisms) is huge; second, the function that
maps mechanisms to revenue is highly irregular, ruling out standard
discretization-based approaches.
  In the stochastic setting, we design an efficient learning algorithm
achieving a regret bound of $O(T^{3/4})$. Our approach is based on an adaptive
discretization scheme of the space of mechanisms, as any non-adaptive
discretization fails to achieve sublinear regret. In the adversarial setting,
we exploit the non-Lipschitzness of the problem to prove a strong negative
result, namely that no learning algorithm can achieve more than half of the
revenue of the best fixed mechanism in hindsight. We then consider the
$\sigma$-smooth adversary; we construct an efficient learning algorithm that
achieves a regret bound of $O(T^{2/3})$ and builds on a succinct encoding of
exponentially many experts. Finally, we prove that no learning algorithm can
achieve less than $\Omega(\sqrt T)$ regret in both the stochastic and the
smooth setting, thus narrowing the range where the minimax regret rates for
these two problems lie.",2024-09-12 07:59:10+00:00
What is YOLOv9: An In-Depth Exploration of the Internal Features of the Next-Generation Object Detector,"This study provides a comprehensive analysis of the YOLOv9 object detection
model, focusing on its architectural innovations, training methodologies, and
performance improvements over its predecessors. Key advancements, such as the
Generalized Efficient Layer Aggregation Network GELAN and Programmable Gradient
Information PGI, significantly enhance feature extraction and gradient flow,
leading to improved accuracy and efficiency. By incorporating Depthwise
Convolutions and the lightweight C3Ghost architecture, YOLOv9 reduces
computational complexity while maintaining high precision. Benchmark tests on
Microsoft COCO demonstrate its superior mean Average Precision mAP and faster
inference times, outperforming YOLOv8 across multiple metrics. The model
versatility is highlighted by its seamless deployment across various hardware
platforms, from edge devices to high performance GPUs, with built in support
for PyTorch and TensorRT integration. This paper provides the first in depth
exploration of YOLOv9s internal features and their real world applicability,
establishing it as a state of the art solution for real time object detection
across industries, from IoT devices to large scale industrial applications.",2024-09-12 07:46:58+00:00
Controllable Synthetic Clinical Note Generation with Privacy Guarantees,"In the field of machine learning, domain-specific annotated data is an
invaluable resource for training effective models. However, in the medical
domain, this data often includes Personal Health Information (PHI), raising
significant privacy concerns. The stringent regulations surrounding PHI limit
the availability and sharing of medical datasets, which poses a substantial
challenge for researchers and practitioners aiming to develop advanced machine
learning models. In this paper, we introduce a novel method to ""clone"" datasets
containing PHI. Our approach ensures that the cloned datasets retain the
essential characteristics and utility of the original data without compromising
patient privacy. By leveraging differential-privacy techniques and a novel
fine-tuning task, our method produces datasets that are free from identifiable
information while preserving the statistical properties necessary for model
training. We conduct utility testing to evaluate the performance of machine
learning models trained on the cloned datasets. The results demonstrate that
our cloned datasets not only uphold privacy standards but also enhance model
performance compared to those trained on traditional anonymized datasets. This
work offers a viable solution for the ethical and effective utilization of
sensitive medical data in machine learning, facilitating progress in medical
research and the development of robust predictive models.",2024-09-12 07:38:34+00:00
FedHide: Federated Learning by Hiding in the Neighbors,"We propose a prototype-based federated learning method designed for embedding
networks in classification or verification tasks. Our focus is on scenarios
where each client has data from a single class. The main challenge is to
develop an embedding network that can distinguish between different classes
while adhering to privacy constraints. Sharing true class prototypes with the
server or other clients could potentially compromise sensitive information. To
tackle this issue, we propose a proxy class prototype that will be shared among
clients instead of the true class prototype. Our approach generates proxy class
prototypes by linearly combining them with their nearest neighbors. This
technique conceals the true class prototype while enabling clients to learn
discriminative embedding networks. We compare our method to alternative
techniques, such as adding random Gaussian noise and using random selection
with cosine similarity constraints. Furthermore, we evaluate the robustness of
our approach against gradient inversion attacks and introduce a measure for
prototype leakage. This measure quantifies the extent of private information
revealed when sharing the proposed proxy class prototype. Moreover, we provide
a theoretical analysis of the convergence properties of our approach. Our
proposed method for federated learning from scratch demonstrates its
effectiveness through empirical results on three benchmark datasets: CIFAR-100,
VoxCeleb1, and VGGFace2.",2024-09-12 07:37:49+00:00
Detection of Electric Motor Damage Through Analysis of Sound Signals Using Bayesian Neural Networks,"Fault monitoring and diagnostics are important to ensure reliability of
electric motors. Efficient algorithms for fault detection improve reliability,
yet development of cost-effective and reliable classifiers for diagnostics of
equipment is challenging, in particular due to unavailability of well-balanced
datasets, with signals from properly functioning equipment and those from
faulty equipment. Thus, we propose to use a Bayesian neural network to detect
and classify faults in electric motors, given its efficacy with imbalanced
training data. The performance of the proposed network is demonstrated on real
life signals, and a robustness analysis of the proposed solution is provided.",2024-09-12 07:15:59+00:00
SURGIVID: Annotation-Efficient Surgical Video Object Discovery,"Surgical scenes convey crucial information about the quality of surgery.
Pixel-wise localization of tools and anatomical structures is the first task
towards deeper surgical analysis for microscopic or endoscopic surgical views.
This is typically done via fully-supervised methods which are annotation greedy
and in several cases, demanding medical expertise. Considering the profusion of
surgical videos obtained through standardized surgical workflows, we propose an
annotation-efficient framework for the semantic segmentation of surgical
scenes. We employ image-based self-supervised object discovery to identify the
most salient tools and anatomical structures in surgical videos. These
proposals are further refined within a minimally supervised fine-tuning step.
Our unsupervised setup reinforced with only 36 annotation labels indicates
comparable localization performance with fully-supervised segmentation models.
Further, leveraging surgical phase labels as weak labels can better guide model
attention towards surgical tools, leading to $\sim 2\%$ improvement in tool
localization. Extensive ablation studies on the CaDIS dataset validate the
effectiveness of our proposed solution in discovering relevant surgical objects
with minimal or no supervision.",2024-09-12 07:12:20+00:00
GateAttentionPose: Enhancing Pose Estimation with Agent Attention and Improved Gated Convolutions,"This paper introduces GateAttentionPose, an innovative approach that enhances
the UniRepLKNet architecture for pose estimation tasks. We present two key
contributions: the Agent Attention module and the Gate-Enhanced Feedforward
Block (GEFB). The Agent Attention module replaces large kernel convolutions,
significantly improving computational efficiency while preserving global
context modeling. The GEFB augments feature extraction and processing
capabilities, particularly in complex scenes. Extensive evaluations on COCO and
MPII datasets demonstrate that GateAttentionPose outperforms existing
state-of-the-art methods, including the original UniRepLKNet, achieving
superior or comparable results with improved efficiency. Our approach offers a
robust solution for pose estimation across diverse applications, including
autonomous driving, human motion capture, and virtual reality.",2024-09-12 07:04:26+00:00
Quaternion Nuclear Norm minus Frobenius Norm Minimization for color image reconstruction,"Color image restoration methods typically represent images as vectors in
Euclidean space or combinations of three monochrome channels. However, they
often overlook the correlation between these channels, leading to color
distortion and artifacts in the reconstructed image. To address this, we
present Quaternion Nuclear Norm Minus Frobenius Norm Minimization (QNMF), a
novel approach for color image reconstruction. QNMF utilizes quaternion algebra
to capture the relationships among RGB channels comprehensively. By employing a
regularization technique that involves nuclear norm minus Frobenius norm, QNMF
approximates the underlying low-rank structure of quaternion-encoded color
images. Theoretical proofs are provided to ensure the method's mathematical
integrity. Demonstrating versatility and efficacy, the QNMF regularizer excels
in various color low-level vision tasks, including denoising, deblurring,
inpainting, and random impulse noise removal, achieving state-of-the-art
results.",2024-09-12 06:57:00+00:00
In-Situ Fine-Tuning of Wildlife Models in IoT-Enabled Camera Traps for Efficient Adaptation,"Wildlife monitoring via camera traps has become an essential tool in ecology,
but the deployment of machine learning models for on-device animal
classification faces significant challenges due to domain shifts and resource
constraints. This paper introduces WildFit, a novel approach that reconciles
the conflicting goals of achieving high domain generalization performance and
ensuring efficient inference for camera trap applications. WildFit leverages
continuous background-aware model fine-tuning to deploy ML models tailored to
the current location and time window, allowing it to maintain robust
classification accuracy in the new environment without requiring significant
computational resources. This is achieved by background-aware data synthesis,
which generates training images representing the new domain by blending
background images with animal images from the source domain. We further enhance
fine-tuning effectiveness through background drift detection and class
distribution drift detection, which optimize the quality of synthesized data
and improve generalization performance. Our extensive evaluation across
multiple camera trap datasets demonstrates that WildFit achieves significant
improvements in classification accuracy and computational efficiency compared
to traditional approaches.",2024-09-12 06:56:52+00:00
Efficient Learning of Balanced Signed Graphs via Iterative Linear Programming,"Signed graphs are equipped with both positive and negative edge weights,
encoding pairwise correlations as well as anti-correlations in data. A balanced
signed graph has no cycles of odd number of negative edges. Laplacian of a
balanced signed graph has eigenvectors that map simply to ones in a
similarity-transformed positive graph Laplacian, thus enabling reuse of
well-studied spectral filters designed for positive graphs. We propose a fast
method to learn a balanced signed graph Laplacian directly from data.
Specifically, for each node $i$, to determine its polarity $\beta_i \in
\{-1,1\}$ and edge weights $\{w_{i,j}\}_{j=1}^N$, we extend a sparse inverse
covariance formulation based on linear programming (LP) called CLIME, by adding
linear constraints to enforce ``consistent"" signs of edge weights
$\{w_{i,j}\}_{j=1}^N$ with the polarities of connected nodes -- i.e.,
positive/negative edges connect nodes of same/opposing polarities. For each LP,
we adapt projections on convex set (POCS) to determine a suitable CLIME
parameter $\rho > 0$ that guarantees LP feasibility. We solve the resulting LP
via an off-the-shelf LP solver in $\mathcal{O}(N^{2.055})$. Experiments on
synthetic and real-world datasets show that our balanced graph learning method
outperforms competing methods and enables the use of spectral filters and graph
convolutional networks (GCNs) designed for positive graphs on signed graphs.",2024-09-12 06:53:50+00:00
Lagrange Duality and Compound Multi-Attention Transformer for Semi-Supervised Medical Image Segmentation,"Medical image segmentation, a critical application of semantic segmentation
in healthcare, has seen significant advancements through specialized computer
vision techniques. While deep learning-based medical image segmentation is
essential for assisting in medical diagnosis, the lack of diverse training data
causes the long-tail problem. Moreover, most previous hybrid CNN-ViT
architectures have limited ability to combine various attentions in different
layers of the Convolutional Neural Network. To address these issues, we propose
a Lagrange Duality Consistency (LDC) Loss, integrated with Boundary-Aware
Contrastive Loss, as the overall training objective for semi-supervised
learning to mitigate the long-tail problem. Additionally, we introduce
CMAformer, a novel network that synergizes the strengths of ResUNet and
Transformer. The cross-attention block in CMAformer effectively integrates
spatial attention and channel attention for multi-scale feature fusion.
Overall, our results indicate that CMAformer, combined with the feature fusion
framework and the new consistency loss, demonstrates strong complementarity in
semi-supervised learning ensembles. We achieve state-of-the-art results on
multiple public medical image datasets. Example code are available at:
\url{https://github.com/lzeeorno/Lagrange-Duality-and-CMAformer}.",2024-09-12 06:52:46+00:00
XMOL: Explainable Multi-property Optimization of Molecules,"Molecular optimization is a key challenge in drug discovery and material
science domain, involving the design of molecules with desired properties.
Existing methods focus predominantly on single-property optimization,
necessitating repetitive runs to target multiple properties, which is
inefficient and computationally expensive. Moreover, these methods often lack
transparency, making it difficult for researchers to understand and control the
optimization process. To address these issues, we propose a novel framework,
Explainable Multi-property Optimization of Molecules (XMOL), to optimize
multiple molecular properties simultaneously while incorporating
explainability. Our approach builds on state-of-the-art geometric diffusion
models, extending them to multi-property optimization through the introduction
of spectral normalization and enhanced molecular constraints for stabilized
training. Additionally, we integrate interpretive and explainable techniques
throughout the optimization process. We evaluated XMOL on the real-world
molecular datasets i.e., QM9, demonstrating its effectiveness in both single
property and multiple properties optimization while offering interpretable
results, paving the way for more efficient and reliable molecular design.",2024-09-12 06:35:04+00:00
ASSNet: Adaptive Semantic Segmentation Network for Microtumors and Multi-Organ Segmentation,"Medical image segmentation, a crucial task in computer vision, facilitates
the automated delineation of anatomical structures and pathologies, supporting
clinicians in diagnosis, treatment planning, and disease monitoring. Notably,
transformers employing shifted window-based self-attention have demonstrated
exceptional performance. However, their reliance on local window attention
limits the fusion of local and global contextual information, crucial for
segmenting microtumors and miniature organs. To address this limitation, we
propose the Adaptive Semantic Segmentation Network (ASSNet), a transformer
architecture that effectively integrates local and global features for precise
medical image segmentation. ASSNet comprises a transformer-based U-shaped
encoder-decoder network. The encoder utilizes shifted window self-attention
across five resolutions to extract multi-scale features, which are then
propagated to the decoder through skip connections. We introduce an augmented
multi-layer perceptron within the encoder to explicitly model long-range
dependencies during feature extraction. Recognizing the constraints of
conventional symmetrical encoder-decoder designs, we propose an Adaptive
Feature Fusion (AFF) decoder to complement our encoder. This decoder
incorporates three key components: the Long Range Dependencies (LRD) block, the
Multi-Scale Feature Fusion (MFF) block, and the Adaptive Semantic Center (ASC)
block. These components synergistically facilitate the effective fusion of
multi-scale features extracted by the decoder while capturing long-range
dependencies and refining object boundaries. Comprehensive experiments on
diverse medical image segmentation tasks, including multi-organ, liver tumor,
and bladder tumor segmentation, demonstrate that ASSNet achieves
state-of-the-art results. Code and models are available at:
\url{https://github.com/lzeeorno/ASSNet}.",2024-09-12 06:25:44+00:00
Training Spiking Neural Networks via Augmented Direct Feedback Alignment,"Spiking neural networks (SNNs), the models inspired by the mechanisms of real
neurons in the brain, transmit and represent information by employing discrete
action potentials or spikes. The sparse, asynchronous properties of information
processing make SNNs highly energy efficient, leading to SNNs being promising
solutions for implementing neural networks in neuromorphic devices. However,
the nondifferentiable nature of SNN neurons makes it a challenge to train them.
The current training methods of SNNs that are based on error backpropagation
(BP) and precisely designing surrogate gradient are difficult to implement and
biologically implausible, hindering the implementation of SNNs on neuromorphic
devices. Thus, it is important to train SNNs with a method that is both
physically implementatable and biologically plausible. In this paper, we
propose using augmented direct feedback alignment (aDFA), a gradient-free
approach based on random projection, to train SNNs. This method requires only
partial information of the forward process during training, so it is easy to
implement and biologically plausible. We systematically demonstrate the
feasibility of the proposed aDFA-SNNs scheme, propose its effective working
range, and analyze its well-performing settings by employing genetic algorithm.
We also analyze the impact of crucial features of SNNs on the scheme, thus
demonstrating its superiority and stability over BP and conventional direct
feedback alignment. Our scheme can achieve competitive performance without
accurate prior knowledge about the utilized system, thus providing a valuable
reference for physically training SNNs.",2024-09-12 06:22:44+00:00
A Spatiotemporal Stealthy Backdoor Attack against Cooperative Multi-Agent Deep Reinforcement Learning,"Recent studies have shown that cooperative multi-agent deep reinforcement
learning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor
trigger is observed, it will perform abnormal actions leading to failures or
malicious goals. However, existing proposed backdoors suffer from several
issues, e.g., fixed visual trigger patterns lack stealthiness, the backdoor is
trained or activated by an additional network, or all agents are backdoored. To
this end, in this paper, we propose a novel backdoor attack against c-MADRL,
which attacks the entire multi-agent team by embedding the backdoor only in a
single agent. Firstly, we introduce adversary spatiotemporal behavior patterns
as the backdoor trigger rather than manual-injected fixed visual patterns or
instant status and control the attack duration. This method can guarantee the
stealthiness and practicality of injected backdoors. Secondly, we hack the
original reward function of the backdoored agent via reward reverse and
unilateral guidance during training to ensure its adverse influence on the
entire team. We evaluate our backdoor attacks on two classic c-MADRL algorithms
VDN and QMIX, in a popular c-MADRL environment SMAC. The experimental results
demonstrate that our backdoor attacks are able to reach a high attack success
rate (91.6\%) while maintaining a low clean performance variance rate (3.7\%).",2024-09-12 06:17:37+00:00
ROCAS: Root Cause Analysis of Autonomous Driving Accidents via Cyber-Physical Co-mutation,"As Autonomous driving systems (ADS) have transformed our daily life, safety
of ADS is of growing significance. While various testing approaches have
emerged to enhance the ADS reliability, a crucial gap remains in understanding
the accidents causes. Such post-accident analysis is paramount and beneficial
for enhancing ADS safety and reliability. Existing cyber-physical system (CPS)
root cause analysis techniques are mainly designed for drones and cannot handle
the unique challenges introduced by more complex physical environments and deep
learning models deployed in ADS. In this paper, we address the gap by offering
a formal definition of ADS root cause analysis problem and introducing ROCAS, a
novel ADS root cause analysis framework featuring cyber-physical co-mutation.
Our technique uniquely leverages both physical and cyber mutation that can
precisely identify the accident-trigger entity and pinpoint the
misconfiguration of the target ADS responsible for an accident. We further
design a differential analysis to identify the responsible module to reduce
search space for the misconfiguration. We study 12 categories of ADS accidents
and demonstrate the effectiveness and efficiency of ROCAS in narrowing down
search space and pinpointing the misconfiguration. We also show detailed case
studies on how the identified misconfiguration helps understand rationale
behind accidents.",2024-09-12 06:14:53+00:00
Alignment with Preference Optimization Is All You Need for LLM Safety,"We demonstrate that preference optimization methods can effectively enhance
LLM safety. Applying various alignment techniques to the Falcon 11B model using
safety datasets, we achieve a significant boost in global safety score (from
$57.64\%$ to $99.90\%$) as measured by LlamaGuard 3 8B, competing with
state-of-the-art models. On toxicity benchmarks, average scores in adversarial
settings dropped from over $0.6$ to less than $0.07$. However, this safety
improvement comes at the cost of reduced general capabilities, particularly in
math, suggesting a trade-off. We identify noise contrastive alignment
(Safe-NCA) as an optimal method for balancing safety and performance. Our study
ultimately shows that alignment techniques can be sufficient for building safe
and robust models.",2024-09-12 06:10:15+00:00
DiReDi: Distillation and Reverse Distillation for AIoT Applications,"Typically, the significant efficiency can be achieved by deploying different
edge AI models in various real world scenarios while a few large models manage
those edge AI models remotely from cloud servers. However, customizing edge AI
models for each user's specific application or extending current models to new
application scenarios remains a challenge. Inappropriate local training or fine
tuning of edge AI models by users can lead to model malfunction, potentially
resulting in legal issues for the manufacturer. To address aforementioned
issues, this paper proposes an innovative framework called ""DiReD"", which
involves knowledge DIstillation & REverse DIstillation. In the initial step, an
edge AI model is trained with presumed data and a KD process using the cloud AI
model in the upper management cloud server. This edge AI model is then
dispatched to edge AI devices solely for inference in the user's application
scenario. When the user needs to update the edge AI model to better fit the
actual scenario, the reverse distillation (RD) process is employed to extract
the knowledge: the difference between user preferences and the manufacturer's
presumptions from the edge AI model using the user's exclusive data. Only the
extracted knowledge is reported back to the upper management cloud server to
update the cloud AI model, thus protecting user privacy by not using any
exclusive data. The updated cloud AI can then update the edge AI model with the
extended knowledge. Simulation results demonstrate that the proposed ""DiReDi""
framework allows the manufacturer to update the user model by learning new
knowledge from the user's actual scenario with private data. The initial
redundant knowledge is reduced since the retraining emphasizes user private
data.",2024-09-12 06:02:44+00:00
Universal Pooling Method of Multi-layer Features from Pretrained Models for Speaker Verification,"Recent advancements in automatic speaker verification (ASV) studies have been
achieved by leveraging large-scale pretrained networks. In this study, we
analyze the approaches toward such a paradigm and underline the significance of
interlayer information processing as a result. Accordingly, we present a novel
approach for exploiting the multilayered nature of pretrained models for ASV,
which comprises a layer/frame-level network and two steps of pooling
architectures for each layer and frame axis. Specifically, we let convolutional
architecture directly processes a stack of layer outputs.Then, we present a
channel attention-based scheme of gauging layer significance and squeeze the
layer level with the most representative value. Finally, attentive statistics
over frame-level representations yield a single vector speaker embedding.
Comparative experiments are designed using versatile data environments and
diverse pretraining models to validate the proposed approach. The experimental
results demonstrate the stability of the approach using multi-layer outputs in
leveraging pretrained architectures. Then, we verify the superiority of the
proposed ASV backend structure, which involves layer-wise operations, in terms
of performance improvement along with cost efficiency compared to the
conventional method. The ablation study shows how the proposed interlayer
processing aids in maximizing the advantage of utilizing pretrained models.",2024-09-12 05:55:32+00:00
Mesh-based Super-Resolution of Fluid Flows with Multiscale Graph Neural Networks,"A graph neural network (GNN) approach is introduced in this work which
enables mesh-based three-dimensional super-resolution of fluid flows. In this
framework, the GNN is designed to operate not on the full mesh-based field at
once, but on localized meshes of elements (or cells) directly. To facilitate
mesh-based GNN representations in a manner similar to spectral (or finite)
element discretizations, a baseline GNN layer (termed a message passing layer,
which updates local node properties) is modified to account for synchronization
of coincident graph nodes, rendering compatibility with commonly used
element-based mesh connectivities. The architecture is multiscale in nature,
and is comprised of a combination of coarse-scale and fine-scale message
passing layer sequences (termed processors) separated by a graph unpooling
layer. The coarse-scale processor embeds a query element (alongside a set
number of neighboring coarse elements) into a single latent graph
representation using coarse-scale synchronized message passing over the element
neighborhood, and the fine-scale processor leverages additional message passing
operations on this latent graph to correct for interpolation errors.
Demonstration studies are performed using hexahedral mesh-based data from
Taylor-Green Vortex flow simulations at Reynolds numbers of 1600 and 3200.
Through analysis of both global and local errors, the results ultimately show
how the GNN is able to produce accurate super-resolved fields compared to
targets in both coarse-scale and multiscale model configurations.
Reconstruction errors for fixed architectures were found to increase in
proportion to the Reynolds number, while the inclusion of surrounding coarse
element neighbors was found to improve predictions at Re=1600, but not at
Re=3200.",2024-09-12 05:52:19+00:00
Reimagining Linear Probing: Kolmogorov-Arnold Networks in Transfer Learning,"This paper introduces Kolmogorov-Arnold Networks (KAN) as an enhancement to
the traditional linear probing method in transfer learning. Linear probing,
often applied to the final layer of pre-trained models, is limited by its
inability to model complex relationships in data. To address this, we propose
substituting the linear probing layer with KAN, which leverages spline-based
representations to approximate intricate functions. In this study, we integrate
KAN with a ResNet-50 model pre-trained on ImageNet and evaluate its performance
on the CIFAR-10 dataset. We perform a systematic hyperparameter search,
focusing on grid size and spline degree (k), to optimize KAN's flexibility and
accuracy. Our results demonstrate that KAN consistently outperforms traditional
linear probing, achieving significant improvements in accuracy and
generalization across a range of configurations. These findings indicate that
KAN offers a more powerful and adaptable alternative to conventional linear
probing techniques in transfer learning.",2024-09-12 05:36:40+00:00
Exploring Kolmogorov-Arnold networks for realistic image sharpness assessment,"Score prediction is crucial in realistic image sharpness assessment after
informative features are collected. Recently, Kolmogorov-Arnold networks (KANs)
have been developed and witnessed remarkable success in data fitting. This
study presents Taylor series based KAN (TaylorKAN). Then, different KANs are
explored on four realistic image databases (BID2011, CID2013, CLIVE, and
KonIQ-10k) for score prediction by using 15 mid-level features and 2048
high-level features. When setting support vector regression as the baseline,
experimental results indicate KANs are generally better or competitive,
TaylorKAN is the best on three databases using mid-level feature input, while
KANs are inferior on CLIVE when high-level features are used. This is the first
study that explores KANs for image quality assessment. It sheds lights on how
to select and improve KANs on related tasks.",2024-09-12 05:35:37+00:00
SwinGS: Sliding Window Gaussian Splatting for Volumetric Video Streaming with Arbitrary Length,"Recent advances in 3D Gaussian Splatting (3DGS) have garnered significant
attention in computer vision and computer graphics due to its high rendering
speed and remarkable quality. While extant research has endeavored to extend
the application of 3DGS from static to dynamic scenes, such efforts have been
consistently impeded by excessive model sizes, constraints on video duration,
and content deviation. These limitations significantly compromise the
streamability of dynamic 3D Gaussian models, thereby restricting their utility
in downstream applications, including volumetric video, autonomous vehicle, and
immersive technologies such as virtual, augmented, and mixed reality.
  This paper introduces SwinGS, a novel framework for training, delivering, and
rendering volumetric video in a real-time streaming fashion. To address the
aforementioned challenges and enhance streamability, SwinGS integrates
spacetime Gaussian with Markov Chain Monte Carlo (MCMC) to adapt the model to
fit various 3D scenes across frames, in the meantime employing a sliding window
captures Gaussian snapshots for each frame in an accumulative way. We implement
a prototype of SwinGS and demonstrate its streamability across various datasets
and scenes. Additionally, we develop an interactive WebGL viewer enabling
real-time volumetric video playback on most devices with modern browsers,
including smartphones and tablets. Experimental results show that SwinGS
reduces transmission costs by 83.6% compared to previous work with ignorable
compromise in PSNR. Moreover, SwinGS easily scales to long video sequences
without compromising quality.",2024-09-12 05:33:15+00:00
From Uncertainty to Clarity: Uncertainty-Guided Class-Incremental Learning for Limited Biomedical Samples via Semantic Expansion,"In real-world clinical settings, data distributions evolve over time, with a
continuous influx of new, limited disease cases. Therefore, class incremental
learning is of great significance, i.e., deep learning models are required to
learn new class knowledge while maintaining accurate recognition of previous
diseases. However, traditional deep neural networks often suffer from severe
forgetting of prior knowledge when adapting to new data unless trained from
scratch, which undesirably costs much time and computational burden.
Additionally, the sample sizes for different diseases can be highly imbalanced,
with newly emerging diseases typically having much fewer instances,
consequently causing the classification bias. To tackle these challenges, we
are the first to propose a class-incremental learning method under limited
samples in the biomedical field. First, we propose a novel cumulative entropy
prediction module to measure the uncertainty of the samples, of which the most
uncertain samples are stored in a memory bank as exemplars for the model's
later review. Furthermore, we theoretically demonstrate its effectiveness in
measuring uncertainty. Second, we developed a fine-grained semantic expansion
module through various augmentations, leading to more compact distributions
within the feature space and creating sufficient room for generalization to new
classes. Besides, a cosine classifier is utilized to mitigate classification
bias caused by imbalanced datasets. Across four imbalanced data distributions
over two datasets, our method achieves optimal performance, surpassing
state-of-the-art methods by as much as 53.54% in accuracy.",2024-09-12 05:22:45+00:00
DiTAS: Quantizing Diffusion Transformers via Enhanced Activation Smoothing,"Diffusion Transformers (DiTs) have recently attracted significant interest
from both industry and academia due to their enhanced capabilities in visual
generation, surpassing the performance of traditional diffusion models that
employ U-Net. However, the improved performance of DiTs comes at the expense of
higher parameter counts and implementation costs, which significantly limits
their deployment on resource-constrained devices like mobile phones. We propose
DiTAS, a data-free post-training quantization (PTQ) method for efficient DiT
inference. DiTAS relies on the proposed temporal-aggregated smoothing
techniques to mitigate the impact of the channel-wise outliers within the input
activations, leading to much lower quantization error under extremely low
bitwidth. To further enhance the performance of the quantized DiT, we adopt the
layer-wise grid search strategy to optimize the smoothing factor. Experimental
results demonstrate that our approach enables 4-bit weight, 8-bit activation
(W4A8) quantization for DiTs while maintaining comparable performance as the
full-precision model.",2024-09-12 05:18:57+00:00
Relevance for Human Robot Collaboration,"Effective human-robot collaboration (HRC) requires the robots to possess
human-like intelligence. Inspired by the human's cognitive ability to
selectively process and filter elements in complex environments, this paper
introduces a novel concept and scene-understanding approach termed `relevance.'
It identifies relevant components in a scene. To accurately and efficiently
quantify relevance, we developed an event-based framework that selectively
triggers relevance determination, along with a probabilistic methodology built
on a structured scene representation. Simulation results demonstrate that the
relevance framework and methodology accurately predict the relevance of a
general HRC setup, achieving a precision of 0.99 and a recall of 0.94.
Relevance can be broadly applied to several areas in HRC to improve task
planning time by 79.56% compared with pure planning for a cereal task, reduce
perception latency by up to 26.53% for an object detector, improve HRC safety
by up to 13.50% and reduce the number of inquiries for HRC by 75.36%. A
real-world demonstration showcases the relevance framework's ability to
intelligently assist humans in everyday tasks.",2024-09-12 04:57:34+00:00
GatedUniPose: A Novel Approach for Pose Estimation Combining UniRepLKNet and Gated Convolution,"Pose estimation is a crucial task in computer vision, with wide applications
in autonomous driving, human motion capture, and virtual reality. However,
existing methods still face challenges in achieving high accuracy, particularly
in complex scenes. This paper proposes a novel pose estimation method,
GatedUniPose, which combines UniRepLKNet and Gated Convolution and introduces
the GLACE module for embedding. Additionally, we enhance the feature map
concatenation method in the head layer by using DySample upsampling. Compared
to existing methods, GatedUniPose excels in handling complex scenes and
occlusion challenges. Experimental results on the COCO, MPII, and CrowdPose
datasets demonstrate that GatedUniPose achieves significant performance
improvements with a relatively small number of parameters, yielding better or
comparable results to models with similar or larger parameter sizes.",2024-09-12 04:57:08+00:00
Efficient Privacy-Preserving KAN Inference Using Homomorphic Encryption,"The recently proposed Kolmogorov-Arnold Networks (KANs) offer enhanced
interpretability and greater model expressiveness. However, KANs also present
challenges related to privacy leakage during inference. Homomorphic encryption
(HE) facilitates privacy-preserving inference for deep learning models,
enabling resource-limited users to benefit from deep learning services while
ensuring data security. Yet, the complex structure of KANs, incorporating
nonlinear elements like the SiLU activation function and B-spline functions,
renders existing privacy-preserving inference techniques inadequate. To address
this issue, we propose an accurate and efficient privacy-preserving inference
scheme tailored for KANs. Our approach introduces a task-specific polynomial
approximation for the SiLU activation function, dynamically adjusting the
approximation range to ensure high accuracy on real-world datasets.
Additionally, we develop an efficient method for computing B-spline functions
within the HE domain, leveraging techniques such as repeat packing, lazy
combination, and comparison functions. We evaluate the effectiveness of our
privacy-preserving KAN inference scheme on both symbolic formula evaluation and
image classification. The experimental results show that our model achieves
accuracy comparable to plaintext KANs across various datasets and outperforms
plaintext MLPs. Additionally, on the CIFAR-10 dataset, our inference latency
achieves over 7 times speedup compared to the naive method.",2024-09-12 04:51:27+00:00
Top-down Activity Representation Learning for Video Question Answering,"Capturing complex hierarchical human activities, from atomic actions (e.g.,
picking up one present, moving to the sofa, unwrapping the present) to
contextual events (e.g., celebrating Christmas) is crucial for achieving
high-performance video question answering (VideoQA). Recent works have expanded
multimodal models (e.g., CLIP, LLaVA) to process continuous video sequences,
enhancing the model's temporal reasoning capabilities. However, these
approaches often fail to capture contextual events that can be decomposed into
multiple atomic actions non-continuously distributed over relatively long-term
sequences. In this paper, to leverage the spatial visual context representation
capability of the CLIP model for obtaining non-continuous visual
representations in terms of contextual events in videos, we convert long-term
video sequences into a spatial image domain and finetune the multimodal model
LLaVA for the VideoQA task. Our approach achieves competitive performance on
the STAR task, in particular, with a 78.4% accuracy score, exceeding the
current state-of-the-art score by 2.8 points on the NExTQA task.",2024-09-12 04:43:27+00:00
Multi-object event graph representation learning for Video Question Answering,"Video question answering (VideoQA) is a task to predict the correct answer to
questions posed about a given video. The system must comprehend spatial and
temporal relationships among objects extracted from videos to perform causal
and temporal reasoning. While prior works have focused on modeling individual
object movements using transformer-based methods, they falter when capturing
complex scenarios involving multiple objects (e.g., ""a boy is throwing a ball
in a hoop""). We propose a contrastive language event graph representation
learning method called CLanG to address this limitation. Aiming to capture
event representations associated with multiple objects, our method employs a
multi-layer GNN-cluster module for adversarial graph representation learning,
enabling contrastive learning between the question text and its relevant
multi-object event graph. Our method outperforms a strong baseline, achieving
up to 2.2% higher accuracy on two challenging VideoQA datasets, NExT-QA and
TGIF-QA-R. In particular, it is 2.8% better than baselines in handling causal
and temporal questions, highlighting its strength in reasoning multiple
object-based events.",2024-09-12 04:42:51+00:00
Learning Brain Tumor Representation in 3D High-Resolution MR Images via Interpretable State Space Models,"Learning meaningful and interpretable representations from high-dimensional
volumetric magnetic resonance (MR) images is essential for advancing
personalized medicine. While Vision Transformers (ViTs) have shown promise in
handling image data, their application to 3D multi-contrast MR images faces
challenges due to computational complexity and interpretability. To address
this, we propose a novel state-space-model (SSM)-based masked autoencoder which
scales ViT-like models to handle high-resolution data effectively while also
enhancing the interpretability of learned representations. We propose a
latent-to-spatial mapping technique that enables direct visualization of how
latent features correspond to specific regions in the input volumes in the
context of SSM. We validate our method on two key neuro-oncology tasks:
identification of isocitrate dehydrogenase mutation status and 1p/19q
co-deletion classification, achieving state-of-the-art accuracy. Our results
highlight the potential of SSM-based self-supervised learning to transform
radiomics analysis by combining efficiency and interpretability.",2024-09-12 04:36:50+00:00
"Transfer Learning Applied to Computer Vision Problems: Survey on Current Progress, Limitations, and Opportunities","The field of Computer Vision (CV) has faced challenges. Initially, it relied
on handcrafted features and rule-based algorithms, resulting in limited
accuracy. The introduction of machine learning (ML) has brought progress,
particularly Transfer Learning (TL), which addresses various CV problems by
reusing pre-trained models. TL requires less data and computing while
delivering nearly equal accuracy, making it a prominent technique in the CV
landscape. Our research focuses on TL development and how CV applications use
it to solve real-world problems. We discuss recent developments, limitations,
and opportunities.",2024-09-12 03:59:15+00:00
DFDG: Data-Free Dual-Generator Adversarial Distillation for One-Shot Federated Learning,"Federated Learning (FL) is a distributed machine learning scheme in which
clients jointly participate in the collaborative training of a global model by
sharing model information rather than their private datasets. In light of
concerns associated with communication and privacy, one-shot FL with a single
communication round has emerged as a de facto promising solution. However,
existing one-shot FL methods either require public datasets, focus on model
homogeneous settings, or distill limited knowledge from local models, making it
difficult or even impractical to train a robust global model. To address these
limitations, we propose a new data-free dual-generator adversarial distillation
method (namely DFDG) for one-shot FL, which can explore a broader local models'
training space via training dual generators. DFDG is executed in an adversarial
manner and comprises two parts: dual-generator training and dual-model
distillation. In dual-generator training, we delve into each generator
concerning fidelity, transferability and diversity to ensure its utility, and
additionally tailor the cross-divergence loss to lessen the overlap of dual
generators' output spaces. In dual-model distillation, the trained dual
generators work together to provide the training data for updates of the global
model. At last, our extensive experiments on various image classification tasks
show that DFDG achieves significant performance gains in accuracy compared to
SOTA baselines.",2024-09-12 03:44:30+00:00
Large Language Models are Pattern Matchers: Editing Semi-Structured and Structured Documents with ChatGPT,"Large Language Models (LLMs) offer numerous applications, the full extent of
which is not yet understood. This paper investigates if LLMs can be applied for
editing structured and semi-structured documents with minimal effort. Using a
qualitative research approach, we conduct two case studies with ChatGPT and
thoroughly analyze the results. Our experiments indicate that LLMs can
effectively edit structured and semi-structured documents when provided with
basic, straightforward prompts. ChatGPT demonstrates a strong ability to
recognize and process the structure of annotated documents. This suggests that
explicitly structuring tasks and data in prompts might enhance an LLM's ability
to understand and solve tasks. Furthermore, the experiments also reveal
impressive pattern matching skills in ChatGPT. This observation deserves
further investigation, as it may contribute to understanding the processes
leading to hallucinations in LLMs.",2024-09-12 03:41:39+00:00
Music auto-tagging in the long tail: A few-shot approach,"In the realm of digital music, using tags to efficiently organize and
retrieve music from extensive databases is crucial for music catalog owners.
Human tagging by experts is labor-intensive but mostly accurate, whereas
automatic tagging through supervised learning has approached satisfying
accuracy but is restricted to a predefined set of training tags. Few-shot
learning offers a viable solution to expand beyond this small set of predefined
tags by enabling models to learn from only a few human-provided examples to
understand tag meanings and subsequently apply these tags autonomously. We
propose to integrate few-shot learning methodology into multi-label music
auto-tagging by using features from pre-trained models as inputs to a
lightweight linear classifier, also known as a linear probe. We investigate
different popular pre-trained features, as well as different few-shot
parametrizations with varying numbers of classes and samples per class. Our
experiments demonstrate that a simple model with pre-trained features can
achieve performance close to state-of-the-art models while using significantly
less training data, such as 20 samples per tag. Additionally, our linear probe
performs competitively with leading models when trained on the entire training
dataset. The results show that this transfer learning-based few-shot approach
could effectively address the issue of automatically assigning long-tail tags
with only limited labeled data.",2024-09-12 03:33:19+00:00
Establish seedling quality classification standard for Chrysanthemum efficiently with help of deep clustering algorithm,"Establishing reasonable standards for edible chrysanthemum seedlings helps
promote seedling development, thereby improving plant quality. However, current
grading methods have the several issues. The limitation that only support a few
indicators causes information loss, and indicators selected to evaluate
seedling level have a narrow applicability. Meanwhile, some methods misuse
mathematical formulas. Therefore, we propose a simple, efficient, and generic
framework, SQCSEF, for establishing seedling quality classification standards
with flexible clustering modules, applicable to most plant species. In this
study, we introduce the state-of-the-art deep clustering algorithm CVCL, using
factor analysis to divide indicators into several perspectives as inputs for
the CVCL method, resulting in more reasonable clusters and ultimately a grading
standard $S_{cvcl}$ for edible chrysanthemum seedlings. Through conducting
extensive experiments, we validate the correctness and efficiency of the
proposed SQCSEF framework.",2024-09-12 03:09:11+00:00
GRE^2-MDCL: Graph Representation Embedding Enhanced via Multidimensional Contrastive Learning,"Graph representation learning has emerged as a powerful tool for preserving
graph topology when mapping nodes to vector representations, enabling various
downstream tasks such as node classification and community detection. However,
most current graph neural network models face the challenge of requiring
extensive labeled data, which limits their practical applicability in
real-world scenarios where labeled data is scarce. To address this challenge,
researchers have explored Graph Contrastive Learning (GCL), which leverages
enhanced graph data and contrastive learning techniques. While promising,
existing GCL methods often struggle with effectively capturing both local and
global graph structures, and balancing the trade-off between nodelevel and
graph-level representations. In this work, we propose Graph Representation
Embedding Enhanced via Multidimensional Contrastive Learning (GRE2-MDCL). Our
model introduces a novel triple network architecture with a multi-head
attention GNN as the core. GRE2-MDCL first globally and locally augments the
input graph using SVD and LAGNN techniques. It then constructs a
multidimensional contrastive loss, incorporating cross-network, cross-view, and
neighbor contrast, to optimize the model. Extensive experiments on benchmark
datasets Cora, Citeseer, and PubMed demonstrate that GRE2-MDCL achieves
state-of-the-art performance, with average accuracies of 82.5%, 72.5%, and
81.6% respectively. Visualizations further show tighter intra-cluster
aggregation and clearer inter-cluster boundaries, highlighting the
effectiveness of our framework in improving upon baseline GCL models.",2024-09-12 03:09:05+00:00
Advancing Depth Anything Model for Unsupervised Monocular Depth Estimation in Endoscopy,"Depth estimation is a cornerstone of 3D reconstruction and plays a vital role
in minimally invasive endoscopic surgeries. However, most current depth
estimation networks rely on traditional convolutional neural networks, which
are limited in their ability to capture global information. Foundation models
offer a promising avenue for enhancing depth estimation, but those currently
available are primarily trained on natural images, leading to suboptimal
performance when applied to endoscopic images. In this work, we introduce a
novel fine-tuning strategy for the Depth Anything Model and integrate it with
an intrinsic-based unsupervised monocular depth estimation framework. Our
approach includes a low-rank adaptation technique based on random vectors,
which improves the model's adaptability to different scales. Additionally, we
propose a residual block built on depthwise separable convolution to compensate
for the transformer's limited ability to capture high-frequency details, such
as edges and textures. Our experimental results on the SCARED dataset show that
our method achieves state-of-the-art performance while minimizing the number of
trainable parameters. Applying this method in minimally invasive endoscopic
surgery could significantly enhance both the precision and safety of these
procedures.",2024-09-12 03:04:43+00:00
FIReStereo: Forest InfraRed Stereo Dataset for UAS Depth Perception in Visually Degraded Environments,"Robust depth perception in visually-degraded environments is crucial for
autonomous aerial systems. Thermal imaging cameras, which capture infrared
radiation, are robust to visual degradation. However, due to lack of a
large-scale dataset, the use of thermal cameras for unmanned aerial system
(UAS) depth perception has remained largely unexplored. This paper presents a
stereo thermal depth perception dataset for autonomous aerial perception
applications. The dataset consists of stereo thermal images, LiDAR, IMU and
ground truth depth maps captured in urban and forest settings under diverse
conditions like day, night, rain, and smoke. We benchmark representative stereo
depth estimation algorithms, offering insights into their performance in
degraded conditions. Models trained on our dataset generalize well to unseen
smoky conditions, highlighting the robustness of stereo thermal imaging for
depth perception. We aim for this work to enhance robotic perception in
disaster scenarios, allowing for exploration and operations in previously
unreachable areas. The dataset and source code are available at
https://firestereo.github.io.",2024-09-12 02:51:21+00:00
CollaMamba: Efficient Collaborative Perception with Cross-Agent Spatial-Temporal State Space Model,"By sharing complementary perceptual information, multi-agent collaborative
perception fosters a deeper understanding of the environment. Recent studies on
collaborative perception mostly utilize CNNs or Transformers to learn feature
representation and fusion in the spatial dimension, which struggle to handle
long-range spatial-temporal features under limited computing and communication
resources. Holistically modeling the dependencies over extensive spatial areas
and extended temporal frames is crucial to enhancing feature quality. To this
end, we propose a resource efficient cross-agent spatial-temporal collaborative
state space model (SSM), named CollaMamba. Initially, we construct a
foundational backbone network based on spatial SSM. This backbone adeptly
captures positional causal dependencies from both single-agent and cross-agent
views, yielding compact and comprehensive intermediate features while
maintaining linear complexity. Furthermore, we devise a history-aware feature
boosting module based on temporal SSM, extracting contextual cues from extended
historical frames to refine vague features while preserving low overhead.
Extensive experiments across several datasets demonstrate that CollaMamba
outperforms state-of-the-art methods, achieving higher model accuracy while
reducing computational and communication overhead by up to 71.9% and 1/64,
respectively. This work pioneers the exploration of the Mamba's potential in
collaborative perception. The source code will be made available.",2024-09-12 02:50:04+00:00
Virtual Node Generation for Node Classification in Sparsely-Labeled Graphs,"In the broader machine learning literature, data-generation methods
demonstrate promising results by generating additional informative training
examples via augmenting sparse labels. Such methods are less studied in graphs
due to the intricate dependencies among nodes in complex topology structures.
This paper presents a novel node generation method that infuses a small set of
high-quality synthesized nodes into the graph as additional labeled nodes to
optimally expand the propagation of labeled information. By simply infusing
additional nodes, the framework is orthogonal to the graph learning and
downstream classification techniques, and thus is compatible with most popular
graph pre-training (self-supervised learning), semi-supervised learning, and
meta-learning methods. The contribution lies in designing the generated node
set by solving a novel optimization problem. The optimization places the
generated nodes in a manner that: (1) minimizes the classification loss to
guarantee training accuracy and (2) maximizes label propagation to
low-confidence nodes in the downstream task to ensure high-quality propagation.
Theoretically, we show that the above dual optimization maximizes the global
confidence of node classification. Our Experiments demonstrate statistically
significant performance improvements over 14 baselines on 10 publicly available
datasets.",2024-09-12 02:36:44+00:00
Dataset-Free Weight-Initialization on Restricted Boltzmann Machine,"In feed-forward neural networks, dataset-free weight-initialization method
such as LeCun, Xavier (or Glorot), and He initializations have been developed.
These methods randomly determine the initial values of weight parameters based
on specific distributions (e.g., Gaussian or uniform distributions) without
using training datasets. To the best of the authors' knowledge, such a
dataset-free weight-initialization method is yet to be developed for restricted
Boltzmann machines (RBMs), which are probabilistic neural networks consisting
of two layers, In this study, we derive a dataset-free weight-initialization
method for Bernoulli--Bernoulli RBMs based on a statistical mechanical
analysis. In the proposed weight-initialization method, the weight parameters
are drawn from a Gaussian distribution with zero mean. The standard deviation
of the Gaussian distribution is optimized based on our hypothesis which is that
a standard deviation providing a larger layer correlation (LC) between the two
layers improves the learning efficiency. The expression of the LC is derived
based on a statistical mechanical analysis. The optimal value of the standard
deviation corresponds to the maximum point of the LC. The proposed
weight-initialization method is identical to Xavier initialization in a
specific case (i.e., in the case the sizes of the two layers are the same, the
random variables of the layers are $\{-1,1\}$-binary, and all bias parameters
are zero).",2024-09-12 02:25:04+00:00
MedSegMamba: 3D CNN-Mamba Hybrid Architecture for Brain Segmentation,"Widely used traditional pipelines for subcortical brain segmentation are
often inefficient and slow, particularly when processing large datasets.
Furthermore, deep learning models face challenges due to the high resolution of
MRI images and the large number of anatomical classes involved. To address
these limitations, we developed a 3D patch-based hybrid CNN-Mamba model that
leverages Mamba's selective scan algorithm, thereby enhancing segmentation
accuracy and efficiency for 3D inputs. This retrospective study utilized 1784
T1-weighted MRI scans from a diverse, multi-site dataset of healthy
individuals. The dataset was divided into training, validation, and testing
sets with a 1076/345/363 split. The scans were obtained from 1.5T and 3T MRI
machines. Our model's performance was validated against several benchmarks,
including other CNN-Mamba, CNN-Transformer, and pure CNN networks, using
FreeSurfer-generated ground truths. We employed the Dice Similarity Coefficient
(DSC), Volume Similarity (VS), and Average Symmetric Surface Distance (ASSD) as
evaluation metrics. Statistical significance was determined using the Wilcoxon
signed-rank test with a threshold of P < 0.05. The proposed model achieved the
highest overall performance across all metrics (DSC 0.88383; VS 0.97076; ASSD
0.33604), significantly outperforming all non-Mamba-based models (P < 0.001).
While the model did not show significant improvement in DSC or VS compared to
another Mamba-based model (P-values of 0.114 and 0.425), it demonstrated a
significant enhancement in ASSD (P < 0.001) with approximately 20% fewer
parameters. In conclusion, our proposed hybrid CNN-Mamba architecture offers an
efficient and accurate approach for 3D subcortical brain segmentation,
demonstrating potential advantages over existing methods.",2024-09-12 02:19:19+00:00
Attack End-to-End Autonomous Driving through Module-Wise Noise,"With recent breakthroughs in deep neural networks, numerous tasks within
autonomous driving have exhibited remarkable performance. However, deep
learning models are susceptible to adversarial attacks, presenting significant
security risks to autonomous driving systems. Presently, end-to-end
architectures have emerged as the predominant solution for autonomous driving,
owing to their collaborative nature across different tasks. Yet, the
implications of adversarial attacks on such models remain relatively
unexplored. In this paper, we conduct comprehensive adversarial security
research on the modular end-to-end autonomous driving model for the first time.
We thoroughly consider the potential vulnerabilities in the model inference
process and design a universal attack scheme through module-wise noise
injection. We conduct large-scale experiments on the full-stack autonomous
driving model and demonstrate that our attack method outperforms previous
attack methods. We trust that our research will offer fresh insights into
ensuring the safety and reliability of autonomous driving systems.",2024-09-12 02:19:16+00:00
Super Monotonic Alignment Search,"Monotonic alignment search (MAS), introduced by Glow-TTS, is one of the most
popular algorithm in TTS to estimate unknown alignments between text and
speech. Since this algorithm needs to search for the most probable alignment
with dynamic programming by caching all paths, the time complexity of the
algorithm is $O(T \times S)$. The authors of Glow-TTS run this algorithm on
CPU, and while they mentioned it is difficult to parallelize, we found that MAS
can be parallelized in text-length dimension and CPU execution consumes an
inordinate amount of time for inter-device copy. Therefore, we implemented a
Triton kernel and PyTorch JIT script to accelerate MAS on GPU without
inter-device copy. As a result, Super-MAS Triton kernel is up to 72 times
faster in the extreme-length case. The code is available at
\url{https://github.com/supertone-inc/super-monotonic-align}.",2024-09-12 02:13:57+00:00
DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?,"Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have
demonstrated impressive language/vision reasoning abilities, igniting the
recent trend of building agents for targeted applications such as shopping
assistants or AI software engineers. Recently, many data science benchmarks
have been proposed to investigate their performance in the data science domain.
However, existing data science benchmarks still fall short when compared to
real-world data science applications due to their simplified settings. To
bridge this gap, we introduce DSBench, a comprehensive benchmark designed to
evaluate data science agents with realistic tasks. This benchmark includes 466
data analysis tasks and 74 data modeling tasks, sourced from Eloquence and
Kaggle competitions. DSBench offers a realistic setting by encompassing long
contexts, multimodal task backgrounds, reasoning with large data files and
multi-table structures, and performing end-to-end data modeling tasks. Our
evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle
with most tasks, with the best agent solving only 34.12% of data analysis tasks
and achieving a 34.74% Relative Performance Gap (RPG). These findings
underscore the need for further advancements in developing more practical,
intelligent, and autonomous data science agents.",2024-09-12 02:08:00+00:00
TMFNet: Two-Stream Multi-Channels Fusion Networks for Color Image Operation Chain Detection,"Image operation chain detection techniques have gained increasing attention
recently in the field of multimedia forensics. However, existing detection
methods suffer from the generalization problem. Moreover, the channel
correlation of color images that provides additional forensic evidence is often
ignored. To solve these issues, in this article, we propose a novel two-stream
multi-channels fusion networks for color image operation chain detection in
which the spatial artifact stream and the noise residual stream are explored in
a complementary manner. Specifically, we first propose a novel deep residual
architecture without pooling in the spatial artifact stream for learning the
global features representation of multi-channel correlation. Then, a set of
filters is designed to aggregate the correlation information of multi-channels
while capturing the low-level features in the noise residual stream.
Subsequently, the high-level features are extracted by the deep residual model.
Finally, features from the two streams are fed into a fusion module, to
effectively learn richer discriminative representations of the operation chain.
Extensive experiments show that the proposed method achieves state-of-the-art
generalization ability while maintaining robustness to JPEG compression. The
source code used in these experiments will be released at
https://github.com/LeiTan-98/TMFNet.",2024-09-12 02:04:26+00:00
Critically Damped Third-Order Langevin Dynamics,"While systems analysis has been studied for decades in the context of control
theory, it has only been recently used to improve the convergence of Denoising
Diffusion Probabilistic Models. This work describes a novel improvement to
Third- Order Langevin Dynamics (TOLD), a recent diffusion method that performs
better than its predecessors. This improvement, abbreviated TOLD++, is carried
out by critically damping the TOLD forward transition matrix similarly to
Dockhorn's Critically-Damped Langevin Dynamics (CLD). Specifically, it exploits
eigen-analysis of the forward transition matrix to derive the optimal set of
dynamics under the original TOLD scheme. TOLD++ is theoretically guaranteed to
converge faster than TOLD, and its faster convergence is verified on the Swiss
Roll toy dataset and CIFAR-10 dataset according to the FID metric.",2024-09-12 01:59:58+00:00
Learn from Balance: Rectifying Knowledge Transfer for Long-Tailed Scenarios,"Knowledge Distillation (KD) transfers knowledge from a large pre-trained
teacher network to a compact and efficient student network, making it suitable
for deployment on resource-limited media terminals. However, traditional KD
methods require balanced data to ensure robust training, which is often
unavailable in practical applications. In such scenarios, a few head categories
occupy a substantial proportion of examples. This imbalance biases the trained
teacher network towards the head categories, resulting in severe performance
degradation on the less represented tail categories for both the teacher and
student networks. In this paper, we propose a novel framework called Knowledge
Rectification Distillation (KRDistill) to address the imbalanced knowledge
inherited in the teacher network through the incorporation of the balanced
category priors. Furthermore, we rectify the biased predictions produced by the
teacher network, particularly focusing on the tail categories. Consequently,
the teacher network can provide balanced and accurate knowledge to train a
reliable student network. Intensive experiments conducted on various
long-tailed datasets demonstrate that our KRDistill can effectively train
reliable student networks in realistic scenarios of data imbalance.",2024-09-12 01:58:06+00:00
"Enhancing Q&A Text Retrieval with Ranking Models: Benchmarking, fine-tuning and deploying Rerankers for RAG","Ranking models play a crucial role in enhancing overall accuracy of text
retrieval systems. These multi-stage systems typically utilize either dense
embedding models or sparse lexical indices to retrieve relevant passages based
on a given query, followed by ranking models that refine the ordering of the
candidate passages by its relevance to the query.
  This paper benchmarks various publicly available ranking models and examines
their impact on ranking accuracy. We focus on text retrieval for
question-answering tasks, a common use case for Retrieval-Augmented Generation
systems. Our evaluation benchmarks include models some of which are
commercially viable for industrial applications.
  We introduce a state-of-the-art ranking model, NV-RerankQA-Mistral-4B-v3,
which achieves a significant accuracy increase of ~14% compared to pipelines
with other rerankers. We also provide an ablation study comparing the
fine-tuning of ranking models with different sizes, losses and self-attention
mechanisms.
  Finally, we discuss challenges of text retrieval pipelines with ranking
models in real-world industry applications, in particular the trade-offs among
model size, ranking accuracy and system requirements like indexing and serving
latency / throughput.",2024-09-12 01:51:06+00:00
Modeling Information Narrative Detection and Evolution on Telegram during the Russia-Ukraine War,"Following the Russian Federation's full-scale invasion of Ukraine in February
2022, a multitude of information narratives emerged within both pro-Russian and
pro-Ukrainian communities online. As the conflict progresses, so too do the
information narratives, constantly adapting and influencing local and global
community perceptions and attitudes. This dynamic nature of the evolving
information environment (IE) underscores a critical need to fully discern how
narratives evolve and affect online communities. Existing research, however,
often fails to capture information narrative evolution, overlooking both the
fluid nature of narratives and the internal mechanisms that drive their
evolution. Recognizing this, we introduce a novel approach designed to both
model narrative evolution and uncover the underlying mechanisms driving them.
In this work we perform a comparative discourse analysis across communities on
Telegram covering the initial three months following the invasion. First, we
uncover substantial disparities in narratives and perceptions between
pro-Russian and pro-Ukrainian communities. Then, we probe deeper into prevalent
narratives of each group, identifying key themes and examining the underlying
mechanisms fueling their evolution. Finally, we explore influences and factors
that may shape the development and spread of narratives.",2024-09-12 01:18:57+00:00
Open-Vocabulary Remote Sensing Image Semantic Segmentation,"Open-vocabulary image semantic segmentation (OVS) seeks to segment images
into semantic regions across an open set of categories. Existing OVS methods
commonly depend on foundational vision-language models and utilize similarity
computation to tackle OVS tasks. However, these approaches are predominantly
tailored to natural images and struggle with the unique characteristics of
remote sensing images, such as rapidly changing orientations and significant
scale variations. These challenges complicate OVS tasks in earth vision,
requiring specialized approaches. To tackle this dilemma, we propose the first
OVS framework specifically designed for remote sensing imagery, drawing
inspiration from the distinct remote sensing traits. Particularly, to address
the varying orientations, we introduce a rotation-aggregative similarity
computation module that generates orientation-adaptive similarity maps as
initial semantic maps. These maps are subsequently refined at both spatial and
categorical levels to produce more accurate semantic maps. Additionally, to
manage significant scale changes, we integrate multi-scale image features into
the upsampling process, resulting in the final scale-aware semantic masks. To
advance OVS in earth vision and encourage reproducible research, we establish
the first open-sourced OVS benchmark for remote sensing imagery, including four
public remote sensing datasets. Extensive experiments on this benchmark
demonstrate our proposed method achieves state-of-the-art performance. All
codes and datasets are available at https://github.com/caoql98/OVRS.",2024-09-12 01:16:25+00:00
Ratio Divergence Learning Using Target Energy in Restricted Boltzmann Machines: Beyond Kullback--Leibler Divergence Learning,"We propose ratio divergence (RD) learning for discrete energy-based models, a
method that utilizes both training data and a tractable target energy function.
We apply RD learning to restricted Boltzmann machines (RBMs), which are a
minimal model that satisfies the universal approximation theorem for discrete
distributions. RD learning combines the strength of both forward and reverse
Kullback-Leibler divergence (KLD) learning, effectively addressing the
""notorious"" issues of underfitting with the forward KLD and mode-collapse with
the reverse KLD. Since the summation of forward and reverse KLD seems to be
sufficient to combine the strength of both approaches, we include this learning
method as a direct baseline in numerical experiments to evaluate its
effectiveness. Numerical experiments demonstrate that RD learning significantly
outperforms other learning methods in terms of energy function fitting,
mode-covering, and learning stability across various discrete energy-based
models. Moreover, the performance gaps between RD learning and the other
learning methods become more pronounced as the dimensions of target models
increase.",2024-09-12 01:01:55+00:00
An Unsupervised Dialogue Topic Segmentation Model Based on Utterance Rewriting,"Dialogue topic segmentation plays a crucial role in various types of dialogue
modeling tasks. The state-of-the-art unsupervised DTS methods learn topic-aware
discourse representations from conversation data through adjacent discourse
matching and pseudo segmentation to further mine useful clues in unlabeled
conversational relations. However, in multi-round dialogs, discourses often
have co-references or omissions, leading to the fact that direct use of these
discourses for representation learning may negatively affect the semantic
similarity computation in the neighboring discourse matching task. In order to
fully utilize the useful cues in conversational relations, this study proposes
a novel unsupervised dialog topic segmentation method that combines the
Utterance Rewriting (UR) technique with an unsupervised learning algorithm to
efficiently utilize the useful cues in unlabeled dialogs by rewriting the
dialogs in order to recover the co-referents and omitted words. Compared with
existing unsupervised models, the proposed Discourse Rewriting Topic
Segmentation Model (UR-DTS) significantly improves the accuracy of topic
segmentation. The main finding is that the performance on DialSeg711 improves
by about 6% in terms of absolute error score and WD, achieving 11.42% in terms
of absolute error score and 12.97% in terms of WD. on Doc2Dial the absolute
error score and WD improves by about 3% and 2%, respectively, resulting in SOTA
reaching 35.17% in terms of absolute error score and 38.49% in terms of WD.
This shows that the model is very effective in capturing the nuances of
conversational topics, as well as the usefulness and challenges of utilizing
unlabeled conversations.",2024-09-12 00:27:31+00:00
Transformed Physics-Informed Neural Networks for The Convection-Diffusion Equation,"Singularly perturbed problems are known to have solutions with steep boundary
layers that are hard to resolve numerically. Traditional numerical methods,
such as Finite Difference Methods (FDMs), require a refined mesh to obtain
stable and accurate solutions. As Physics-Informed Neural Networks (PINNs) have
been shown to successfully approximate solutions to differential equations from
various fields, it is natural to examine their performance on singularly
perturbed problems. The convection-diffusion equation is a representative
example of such a class of problems, and we consider the use of PINNs to
produce numerical solutions of this equation. We study two ways to use PINNS:
as a method for correcting oscillatory discrete solutions obtained using FDMs,
and as a method for modifying reduced solutions of unperturbed problems. For
both methods, we also examine the use of input transformation to enhance
accuracy, and we explain the behavior of input transformations analytically,
with the help of neural tangent kernels.",2024-09-12 00:24:21+00:00
Passed the Turing Test: Living in Turing Futures,"The world has seen the emergence of machines based on pretrained models,
transformers, also known as generative artificial intelligences for their
ability to produce various types of content, including text, images, audio, and
synthetic data. Without resorting to preprogramming or special tricks, their
intelligence grows as they learn from experience, and to ordinary people, they
can appear human-like in conversation. This means that they can pass the Turing
test, and that we are now living in one of many possible Turing futures where
machines can pass for what they are not. However, the learning machines that
Turing imagined would pass his imitation tests were machines inspired by the
natural development of the low-energy human cortex. They would be raised like
human children and naturally learn the ability to deceive an observer. These
``child machines,'' Turing hoped, would be powerful enough to have an impact on
society and nature.",2024-09-11 22:56:30+00:00
STAND: Data-Efficient and Self-Aware Precondition Induction for Interactive Task Learning,"STAND is a data-efficient and computationally efficient machine learning
approach that produces better classification accuracy than popular approaches
like XGBoost on small-data tabular classification problems like learning rule
preconditions from interactive training. STAND accounts for a complete set of
good candidate generalizations instead of selecting a single generalization by
breaking ties randomly. STAND can use any greedy concept construction strategy,
like decision tree learning or sequential covering, and build a structure that
approximates a version space over disjunctive normal logical statements. Unlike
candidate elimination approaches to version-space learning, STAND does not
suffer from issues of version-space collapse from noisy data nor is it
restricted to learning strictly conjunctive concepts. More importantly, STAND
can produce a measure called instance certainty that can predict increases in
holdout set performance and has high utility as an active-learning heuristic.
Instance certainty enables STAND to be self-aware of its own learning: it knows
when it learns and what example will help it learn the most. We illustrate that
instance certainty has desirable properties that can help users select next
training problems, and estimate when training is complete in applications where
users interactively teach an AI a complex program.",2024-09-11 22:49:38+00:00
Gaussian Process Upper Confidence Bounds in Distributed Point Target Tracking over Wireless Sensor Networks,"Uncertainty quantification plays a key role in the development of autonomous
systems, decision-making, and tracking over wireless sensor networks (WSNs).
However, there is a need of providing uncertainty confidence bounds, especially
for distributed machine learning-based tracking, dealing with different volumes
of data collected by sensors. This paper aims to fill in this gap and proposes
a distributed Gaussian process (DGP) approach for point target tracking and
derives upper confidence bounds (UCBs) of the state estimates. A unique
contribution of this paper includes the derived theoretical guarantees on the
proposed approach and its maximum accuracy for tracking with and without
clutter measurements. Particularly, the developed approaches with uncertainty
bounds are generic and can provide trustworthy solutions with an increased
level of reliability. A novel hybrid Bayesian filtering method is proposed to
enhance the DGP approach by adopting a Poisson measurement likelihood model.
The proposed approaches are validated over a WSN case study, where sensors have
limited sensing ranges. Numerical results demonstrate the tracking accuracy and
robustness of the proposed approaches. The derived UCBs constitute a tool for
trustworthiness evaluation of DGP approaches. The simulation results reveal
that the proposed UCBs successfully encompass the true target states with 88%
and 42% higher probability in X and Y coordinates, respectively, when compared
to the confidence interval-based method.",2024-09-11 22:42:11+00:00
Foundation Models Boost Low-Level Perceptual Similarity Metrics,"For full-reference image quality assessment (FR-IQA) using deep-learning
approaches, the perceptual similarity score between a distorted image and a
reference image is typically computed as a distance measure between features
extracted from a pretrained CNN or more recently, a Transformer network. Often,
these intermediate features require further fine-tuning or processing with
additional neural network layers to align the final similarity scores with
human judgments. So far, most IQA models based on foundation models have
primarily relied on the final layer or the embedding for the quality score
estimation. In contrast, this work explores the potential of utilizing the
intermediate features of these foundation models, which have largely been
unexplored so far in the design of low-level perceptual similarity metrics. We
demonstrate that the intermediate features are comparatively more effective.
Moreover, without requiring any training, these metrics can outperform both
traditional and state-of-the-art learned metrics by utilizing distance measures
between the features.",2024-09-11 22:32:12+00:00
DiffTED: One-shot Audio-driven TED Talk Video Generation with Diffusion-based Co-speech Gestures,"Audio-driven talking video generation has advanced significantly, but
existing methods often depend on video-to-video translation techniques and
traditional generative networks like GANs and they typically generate taking
heads and co-speech gestures separately, leading to less coherent outputs.
Furthermore, the gestures produced by these methods often appear overly smooth
or subdued, lacking in diversity, and many gesture-centric approaches do not
integrate talking head generation. To address these limitations, we introduce
DiffTED, a new approach for one-shot audio-driven TED-style talking video
generation from a single image. Specifically, we leverage a diffusion model to
generate sequences of keypoints for a Thin-Plate Spline motion model, precisely
controlling the avatar's animation while ensuring temporally coherent and
diverse gestures. This innovative approach utilizes classifier-free guidance,
empowering the gestures to flow naturally with the audio input without relying
on pre-trained classifiers. Experiments demonstrate that DiffTED generates
temporally coherent talking videos with diverse co-speech gestures.",2024-09-11 22:31:55+00:00
Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review,"Recent advancements in predicting pedestrian crossing intentions for
Autonomous Vehicles using Computer Vision and Deep Neural Networks are
promising. However, the black-box nature of DNNs poses challenges in
understanding how the model works and how input features contribute to final
predictions. This lack of interpretability delimits the trust in model
performance and hinders informed decisions on feature selection,
representation, and model optimisation; thereby affecting the efficacy of
future research in the field. To address this, we introduce Context-aware
Permutation Feature Importance (CAPFI), a novel approach tailored for
pedestrian intention prediction. CAPFI enables more interpretability and
reliable assessments of feature importance by leveraging subdivided scenario
contexts, mitigating the randomness of feature values through targeted
shuffling. This aims to reduce variance and prevent biased estimations in
importance scores during permutations. We divide the Pedestrian Intention
Estimation (PIE) dataset into 16 comparable context sets, measure the baseline
performance of five distinct neural network architectures for intention
prediction in each context, and assess input feature importance using CAPFI. We
observed nuanced differences among models across various contextual
characteristics. The research reveals the critical role of pedestrian bounding
boxes and ego-vehicle speed in predicting pedestrian intentions, and potential
prediction biases due to the speed feature through cross-context permutation
evaluation. We propose an alternative feature representation by considering
proximity change rate for rendering dynamic pedestrian-vehicle locomotion,
thereby enhancing the contributions of input features to intention prediction.
These findings underscore the importance of contextual features and their
diversity to develop accurate and robust intent-predictive models.",2024-09-11 22:13:01+00:00
Deep Learning of Dynamic Systems using System Identification Toolbox(TM),"MATLAB(R) releases over the last 3 years have witnessed a continuing growth
in the dynamic modeling capabilities offered by the System Identification
Toolbox(TM). The emphasis has been on integrating deep learning architectures
and training techniques that facilitate the use of deep neural networks as
building blocks of nonlinear models. The toolbox offers neural state-space
models which can be extended with auto-encoding features that are particularly
suited for reduced-order modeling of large systems. The toolbox contains
several other enhancements that deepen its integration with the state-of-art
machine learning techniques, leverage auto-differentiation features for state
estimation, and enable a direct use of raw numeric matrices and timetables for
training models.",2024-09-11 21:54:17+00:00
Can We Count on LLMs? The Fixed-Effect Fallacy and Claims of GPT-4 Capabilities,"In this paper we explore evaluation of LLM capabilities. We present
measurements of GPT-4 performance on several deterministic tasks; each task
involves a basic calculation and takes as input parameter some element drawn
from a large well-defined population (e.g., count elements in a list, multiply
two k-digit numbers, etc). We examine several conditions per-task and perform
enough trials so that statistically significant differences can be detected.
This allows us to investigate the sensitivity of task-accuracy both to query
phrasing and input parameter population. We find that seemingly trivial
modifications in the task-prompt or input population can yield differences far
larger than can be explained by sampling effects. For example, performance on a
simple list-counting task varies with query-phrasing and list-length, but also
with list composition (i.e., the thing-to-be-counted) and object frequency
(e.g., success when an element accounts for $\approx$ 50\% of a list is
different from when it accounts for $\approx$ 70\% etc).
  We conclude that efforts to quantify LLM capabilities easily succumb to the
language-as-fixed-effect fallacy, where experimental observations are
improperly generalized beyond what the data supports. A consequence appears to
be that intuitions that have been formed based on interactions with humans form
a very unreliable guide as to which input modifications should ``make no
difference'' to LLM performance.",2024-09-11 21:48:33+00:00
Weather-Informed Probabilistic Forecasting and Scenario Generation in Power Systems,"The integration of renewable energy sources (RES) into power grids presents
significant challenges due to their intrinsic stochasticity and uncertainty,
necessitating the development of new techniques for reliable and efficient
forecasting. This paper proposes a method combining probabilistic forecasting
and Gaussian copula for day-ahead prediction and scenario generation of load,
wind, and solar power in high-dimensional contexts. By incorporating weather
covariates and restoring spatio-temporal correlations, the proposed method
enhances the reliability of probabilistic forecasts in RES. Extensive numerical
experiments compare the effectiveness of different time series models, with
performance evaluated using comprehensive metrics on a real-world and
high-dimensional dataset from Midcontinent Independent System Operator (MISO).
The results highlight the importance of weather information and demonstrate the
efficacy of the Gaussian copula in generating realistic scenarios, with the
proposed weather-informed Temporal Fusion Transformer (WI-TFT) model showing
superior performance.",2024-09-11 21:44:59+00:00
Learning Robust Observable to Address Noise in Quantum Machine Learning,"Quantum Machine Learning (QML) has emerged as a promising field that combines
the power of quantum computing with the principles of machine learning. One of
the significant challenges in QML is dealing with noise in quantum systems,
especially in the Noisy Intermediate-Scale Quantum (NISQ) era. Noise in quantum
systems can introduce errors in quantum computations and degrade the
performance of quantum algorithms. In this paper, we propose a framework for
learning observables that are robust against noisy channels in quantum systems.
We demonstrate that it is possible to learn observables that remain invariant
under the effects of noise and show that this can be achieved through a
machine-learning approach. We present a toy example using a Bell state under a
depolarization channel to illustrate the concept of robust observables. We then
describe a machine-learning framework for learning such observables across six
two-qubit quantum circuits and five noisy channels. Our results show that it is
possible to learn observables that are more robust to noise than conventional
observables. We discuss the implications of this finding for quantum machine
learning, including potential applications in enhancing the stability of QML
models in noisy environments. By developing techniques for learning robust
observables, we can improve the performance and reliability of quantum machine
learning models in the presence of noise, contributing to the advancement of
practical QML applications in the NISQ era.",2024-09-11 21:30:49+00:00
Dividable Configuration Performance Learning,"Machine/deep learning models have been widely adopted for predicting the
configuration performance of software systems. However, a crucial yet
unaddressed challenge is how to cater for the sparsity inherited from the
configuration landscape: the influence of configuration options (features) and
the distribution of data samples are highly sparse. In this paper, we propose a
model-agnostic and sparsity-robust framework for predicting configuration
performance, dubbed DaL, based on the new paradigm of dividable learning that
builds a model via ""divide-and-learn"". To handle sample sparsity, the samples
from the configuration landscape are divided into distant divisions, for each
of which we build a sparse local model, e.g., regularized Hierarchical
Interaction Neural Network, to deal with the feature sparsity. A newly given
configuration would then be assigned to the right model of division for the
final prediction. Further, DaL adaptively determines the optimal number of
divisions required for a system and sample size without any extra training or
profiling. Experiment results from 12 real-world systems and five sets of
training data reveal that, compared with the state-of-the-art approaches, DaL
performs no worse than the best counterpart on 44 out of 60 cases with up to
1.61x improvement on accuracy; requires fewer samples to reach the same/better
accuracy; and producing acceptable training overhead. In particular, the
mechanism that adapted the parameter d can reach the optimal value for 76.43%
of the individual runs. The result also confirms that the paradigm of dividable
learning is more suitable than other similar paradigms such as ensemble
learning for predicting configuration performance. Practically, DaL
considerably improves different global models when using them as the underlying
local models, which further strengthens its flexibility.",2024-09-11 21:23:23+00:00
Leveraging User-Generated Reviews for Recommender Systems with Dynamic Headers,"E-commerce platforms have a vast catalog of items to cater to their
customers' shopping interests. Most of these platforms assist their customers
in the shopping process by offering optimized recommendation carousels,
designed to help customers quickly locate their desired items. Many models have
been proposed in academic literature to generate and enhance the ranking and
recall set of items in these carousels. Conventionally, the accompanying
carousel title text (header) of these carousels remains static. In most
instances, a generic text such as ""Items similar to your current viewing"" is
utilized. Fixed variations such as the inclusion of specific attributes ""Other
items from a similar seller"" or ""Items from a similar brand"" in addition to
""frequently bought together"" or ""considered together"" are observed as well.
This work proposes a novel approach to customize the header generation process
of these carousels. Our work leverages user-generated reviews that lay focus on
specific attributes (aspects) of an item that were favorably perceived by users
during their interaction with the given item. We extract these aspects from
reviews and train a graph neural network-based model under the framework of a
conditional ranking task. We refer to our innovative methodology as Dynamic
Text Snippets (DTS) which generates multiple header texts for an anchor item
and its recall set. Our approach demonstrates the potential of utilizing
user-generated reviews and presents a unique paradigm for exploring
increasingly context-aware recommendation systems.",2024-09-11 21:18:21+00:00
Generalization Error Bound for Quantum Machine Learning in NISQ Era -- A Survey,"Despite the mounting anticipation for the quantum revolution, the success of
Quantum Machine Learning (QML) in the Noisy Intermediate-Scale Quantum (NISQ)
era hinges on a largely unexplored factor: the generalization error bound, a
cornerstone of robust and reliable machine learning models. Current QML
research, while exploring novel algorithms and applications extensively, is
predominantly situated in the context of noise-free, ideal quantum computers.
However, Quantum Circuit (QC) operations in NISQ-era devices are susceptible to
various noise sources and errors. In this article, we conduct a Systematic
Mapping Study (SMS) to explore the state-of-the-art generalization bound for
supervised QML in NISQ-era and analyze the latest practices in the field. Our
study systematically summarizes the existing computational platforms with
quantum hardware, datasets, optimization techniques, and the common properties
of the bounds found in the literature. We further present the performance
accuracy of various approaches in classical benchmark datasets like the MNIST
and IRIS datasets. The SMS also highlights the limitations and challenges in
QML in the NISQ era and discusses future research directions to advance the
field. Using a detailed Boolean operators query in five reliable indexers, we
collected 544 papers and filtered them to a small set of 37 relevant articles.
This filtration was done following the best practice of SMS with well-defined
research questions and inclusion and exclusion criteria.",2024-09-11 21:17:30+00:00
Object Depth and Size Estimation using Stereo-vision and Integration with SLAM,"Autonomous robots use simultaneous localization and mapping (SLAM) for
efficient and safe navigation in various environments. LiDAR sensors are
integral in these systems for object identification and localization. However,
LiDAR systems though effective in detecting solid objects (e.g., trash bin,
bottle, etc.), encounter limitations in identifying semitransparent or
non-tangible objects (e.g., fire, smoke, steam, etc.) due to poor reflecting
characteristics. Additionally, LiDAR also fails to detect features such as
navigation signs and often struggles to detect certain hazardous materials that
lack a distinct surface for effective laser reflection. In this paper, we
propose a highly accurate stereo-vision approach to complement LiDAR in
autonomous robots. The system employs advanced stereo vision-based object
detection to detect both tangible and non-tangible objects and then uses simple
machine learning to precisely estimate the depth and size of the object. The
depth and size information is then integrated into the SLAM process to enhance
the robot's navigation capabilities in complex environments. Our evaluation,
conducted on an autonomous robot equipped with LiDAR and stereo-vision systems
demonstrates high accuracy in the estimation of an object's depth and size. A
video illustration of the proposed scheme is available at:
\url{https://www.youtube.com/watch?v=nusI6tA9eSk}.",2024-09-11 21:12:48+00:00
Ensemble Methods for Sequence Classification with Hidden Markov Models,"We present a lightweight approach to sequence classification using Ensemble
Methods for Hidden Markov Models (HMMs). HMMs offer significant advantages in
scenarios with imbalanced or smaller datasets due to their simplicity,
interpretability, and efficiency. These models are particularly effective in
domains such as finance and biology, where traditional methods struggle with
high feature dimensionality and varied sequence lengths. Our ensemble-based
scoring method enables the comparison of sequences of any length and improves
performance on imbalanced datasets.
  This study focuses on the binary classification problem, particularly in
scenarios with data imbalance, where the negative class is the majority (e.g.,
normal data) and the positive class is the minority (e.g., anomalous data),
often with extreme distribution skews. We propose a novel training approach for
HMM Ensembles that generalizes to multi-class problems and supports
classification and anomaly detection. Our method fits class-specific groups of
diverse models using random data subsets, and compares likelihoods across
classes to produce composite scores, achieving high average precisions and
AUCs.
  In addition, we compare our approach with neural network-based methods such
as Convolutional Neural Networks (CNNs) and Long Short-Term Memory networks
(LSTMs), highlighting the efficiency and robustness of HMMs in data-scarce
environments. Motivated by real-world use cases, our method demonstrates robust
performance across various benchmarks, offering a flexible framework for
diverse applications.",2024-09-11 20:59:32+00:00
Understanding Foundation Models: Are We Back in 1924?,"This position paper explores the rapid development of Foundation Models (FMs)
in AI and their implications for intelligence and reasoning. It examines the
characteristics of FMs, including their training on vast datasets and use of
embedding spaces to capture semantic relationships. The paper discusses recent
advancements in FMs' reasoning abilities which we argue cannot be attributed to
increased model size but to novel training techniques which yield learning
phenomena like grokking. It also addresses the challenges in benchmarking FMs
and compares their structure to the human brain. We argue that while FMs show
promising developments in reasoning and knowledge representation, understanding
their inner workings remains a significant challenge, similar to ongoing
efforts in neuroscience to comprehend human brain function. Despite having some
similarities, fundamental differences between FMs and the structure of human
brain warn us against making direct comparisons or expecting neuroscience to
provide immediate insights into FM function.",2024-09-11 20:59:27+00:00
Token Turing Machines are Efficient Vision Models,"We propose Vision Token Turing Machines (ViTTM), an efficient, low-latency,
memory-augmented Vision Transformer (ViT). Our approach builds on Neural Turing
Machines and Token Turing Machines, which were applied to NLP and sequential
visual understanding tasks. ViTTMs are designed for non-sequential computer
vision tasks such as image classification and segmentation. Our model creates
two sets of tokens: process tokens and memory tokens; process tokens pass
through encoder blocks and read-write from memory tokens at each encoder block
in the network, allowing them to store and retrieve information from memory. By
ensuring that there are fewer process tokens than memory tokens, we are able to
reduce the inference time of the network while maintaining its accuracy. On
ImageNet-1K, the state-of-the-art ViT-B has median latency of 529.5ms and 81.0%
accuracy, while our ViTTM-B is 56% faster (234.1ms), with 2.4 times fewer
FLOPs, with an accuracy of 82.9%. On ADE20K semantic segmentation, ViT-B
achieves 45.65mIoU at 13.8 frame-per-second (FPS) whereas our ViTTM-B model
acheives a 45.17 mIoU with 26.8 FPS (+94%).",2024-09-11 20:50:41+00:00
When More Data Hurts: Optimizing Data Coverage While Mitigating Diversity Induced Underfitting in an Ultra-Fast Machine-Learned Potential,"Machine-learned interatomic potentials (MLIPs) are becoming an essential tool
in materials modeling. However, optimizing the generation of training data used
to parameterize the MLIPs remains a significant challenge. This is because
MLIPs can fail when encountering local enviroments too different from those
present in the training data. The difficulty of determining \textit{a priori}
the environments that will be encountered during molecular dynamics (MD)
simulation necessitates diverse, high-quality training data. This study
investigates how training data diversity affects the performance of MLIPs using
the Ultra-Fast Force Field (UF$^3$) to model amorphous silicon nitride. We
employ expert and autonomously generated data to create the training data and
fit four force-field variants to subsets of the data. Our findings reveal a
critical balance in training data diversity: insufficient diversity hinders
generalization, while excessive diversity can exceed the MLIP's learning
capacity, reducing simulation accuracy. Specifically, we found that the UF$^3$
variant trained on a subset of the training data, in which nitrogen-rich
structures were removed, offered vastly better prediction and simulation
accuracy than any other variant. By comparing these UF$^3$ variants, we
highlight the nuanced requirements for creating accurate MLIPs, emphasizing the
importance of application-specific training data to achieve optimal performance
in modeling complex material behaviors.",2024-09-11 20:45:44+00:00
A Cost-Aware Approach to Adversarial Robustness in Neural Networks,"Considering the growing prominence of production-level AI and the threat of
adversarial attacks that can evade a model at run-time, evaluating the
robustness of models to these evasion attacks is of critical importance.
Additionally, testing model changes likely means deploying the models to (e.g.
a car or a medical imaging device), or a drone to see how it affects
performance, making un-tested changes a public problem that reduces development
speed, increases cost of development, and makes it difficult (if not
impossible) to parse cause from effect. In this work, we used survival analysis
as a cloud-native, time-efficient and precise method for predicting model
performance in the presence of adversarial noise. For neural networks in
particular, the relationships between the learning rate, batch size, training
time, convergence time, and deployment cost are highly complex, so researchers
generally rely on benchmark datasets to assess the ability of a model to
generalize beyond the training data. To address this, we propose using
accelerated failure time models to measure the effect of hardware choice, batch
size, number of epochs, and test-set accuracy by using adversarial attacks to
induce failures on a reference model architecture before deploying the model to
the real world. We evaluate several GPU types and use the Tree Parzen Estimator
to maximize model robustness and minimize model run-time simultaneously. This
provides a way to evaluate the model and optimise it in a single step, while
simultaneously allowing us to model the effect of model parameters on training
time, prediction time, and accuracy. Using this technique, we demonstrate that
newer, more-powerful hardware does decrease the training time, but with a
monetary and power cost that far outpaces the marginal gains in accuracy.",2024-09-11 20:43:59+00:00
The Role of Deep Learning Regularizations on Actors in Offline RL,"Deep learning regularization techniques, such as \emph{dropout}, \emph{layer
normalization}, or \emph{weight decay}, are widely adopted in the construction
of modern artificial neural networks, often resulting in more robust training
processes and improved generalization capabilities. However, in the domain of
\emph{Reinforcement Learning} (RL), the application of these techniques has
been limited, usually applied to value function estimators
\citep{hiraoka2021dropout, smith2022walk}, and may result in detrimental
effects. This issue is even more pronounced in offline RL settings, which bear
greater similarity to supervised learning but have received less attention.
Recent work in continuous offline RL has demonstrated that while we can build
sufficiently powerful critic networks, the generalization of actor networks
remains a bottleneck. In this study, we empirically show that applying standard
regularization techniques to actor networks in offline RL actor-critic
algorithms yields improvements of 6\% on average across two algorithms and
three different continuous D4RL domains.",2024-09-11 20:35:29+00:00
Automated Discovery of Pairwise Interactions from Unstructured Data,"Pairwise interactions between perturbations to a system can provide evidence
for the causal dependencies of the underlying underlying mechanisms of a
system. When observations are low dimensional, hand crafted measurements,
detecting interactions amounts to simple statistical tests, but it is not
obvious how to detect interactions between perturbations affecting latent
variables. We derive two interaction tests that are based on pairwise
interventions, and show how these tests can be integrated into an active
learning pipeline to efficiently discover pairwise interactions between
perturbations. We illustrate the value of these tests in the context of
biology, where pairwise perturbation experiments are frequently used to reveal
interactions that are not observable from any single perturbation. Our tests
can be run on unstructured data, such as the pixels in an image, which enables
a more general notion of interaction than typical cell viability experiments,
and can be run on cheaper experimental assays. We validate on several synthetic
and real biological experiments that our tests are able to identify interacting
pairs effectively. We evaluate our approach on a real biological experiment
where we knocked out 50 pairs of genes and measured the effect with microscopy
images. We show that we are able to recover significantly more known biological
interactions than random search and standard active learning baselines.",2024-09-11 19:53:50+00:00
Deep Learning for predicting rate-induced tipping,"Nonlinear dynamical systems exposed to changing forcing can exhibit
catastrophic transitions between alternative and often markedly different
states. The phenomenon of critical slowing down (CSD) can be used to anticipate
such transitions if caused by a bifurcation and if the change in forcing is
slow compared to the internal time scale of the system. However, in many
real-world situations, these assumptions are not met and transitions can be
triggered because the forcing exceeds a critical rate. For example, given the
pace of anthropogenic climate change in comparison to the internal time scales
of key Earth system components, such as the polar ice sheets or the Atlantic
Meridional Overturning Circulation, such rate-induced tipping poses a severe
risk. Moreover, depending on the realisation of random perturbations, some
trajectories may transition across an unstable boundary, while others do not,
even under the same forcing. CSD-based indicators generally cannot distinguish
these cases of noise-induced tipping versus no tipping. This severely limits
our ability to assess the risks of tipping, and to predict individual
trajectories. To address this, we make a first attempt to develop a deep
learning framework to predict transition probabilities of dynamical systems
ahead of rate-induced transitions. Our method issues early warnings, as
demonstrated on three prototypical systems for rate-induced tipping, subjected
to time-varying equilibrium drift and noise perturbations. Exploiting
explainable artificial intelligence methods, our framework captures the
fingerprints necessary for early detection of rate-induced tipping, even in
cases of long lead times. Our findings demonstrate the predictability of
rate-induced and noise-induced tipping, advancing our ability to determine safe
operating spaces for a broader class of dynamical systems than possible so far.",2024-09-11 19:40:57+00:00
2D bidirectional gated recurrent unit convolutional Neural networks for end-to-end violence detection In videos,"Abnormal behavior detection, action recognition, fight and violence detection
in videos is an area that has attracted a lot of interest in recent years. In
this work, we propose an architecture that combines a Bidirectional Gated
Recurrent Unit (BiGRU) and a 2D Convolutional Neural Network (CNN) to detect
violence in video sequences. A CNN is used to extract spatial characteristics
from each frame, while the BiGRU extracts temporal and local motion
characteristics using CNN extracted features from multiple frames. The proposed
end-to-end deep learning network is tested in three public datasets with
varying scene complexities. The proposed network achieves accuracies up to 98%.
The obtained results are promising and show the performance of the proposed
end-to-end approach.",2024-09-11 19:36:12+00:00
Efficient Localized Adaptation of Neural Weather Forecasting: A Case Study in the MENA Region,"Accurate weather and climate modeling is critical for both scientific
advancement and safeguarding communities against environmental risks.
Traditional approaches rely heavily on Numerical Weather Prediction (NWP)
models, which simulate energy and matter flow across Earth's systems. However,
heavy computational requirements and low efficiency restrict the suitability of
NWP, leading to a pressing need for enhanced modeling techniques. Neural
network-based models have emerged as promising alternatives, leveraging
data-driven approaches to forecast atmospheric variables. In this work, we
focus on limited-area modeling and train our model specifically for localized
region-level downstream tasks. As a case study, we consider the MENA region due
to its unique climatic challenges, where accurate localized weather forecasting
is crucial for managing water resources, agriculture and mitigating the impacts
of extreme weather events. This targeted approach allows us to tailor the
model's capabilities to the unique conditions of the region of interest. Our
study aims to validate the effectiveness of integrating parameter-efficient
fine-tuning (PEFT) methodologies, specifically Low-Rank Adaptation (LoRA) and
its variants, to enhance forecast accuracy, as well as training speed,
computational resource utilization, and memory efficiency in weather and
climate modeling for specific regions.",2024-09-11 19:31:56+00:00
DS-ViT: Dual-Stream Vision Transformer for Cross-Task Distillation in Alzheimer's Early Diagnosis,"In the field of Alzheimer's disease diagnosis, segmentation and
classification tasks are inherently interconnected. Sharing knowledge between
models for these tasks can significantly improve training efficiency,
particularly when training data is scarce. However, traditional knowledge
distillation techniques often struggle to bridge the gap between segmentation
and classification due to the distinct nature of tasks and different model
architectures. To address this challenge, we propose a dual-stream pipeline
that facilitates cross-task and cross-architecture knowledge sharing. Our
approach introduces a dual-stream embedding module that unifies feature
representations from segmentation and classification models, enabling
dimensional integration of these features to guide the classification model. We
validated our method on multiple 3D datasets for Alzheimer's disease diagnosis,
demonstrating significant improvements in classification performance,
especially on small datasets. Furthermore, we extended our pipeline with a
residual temporal attention mechanism for early diagnosis, utilizing images
taken before the atrophy of patients' brain mass. This advancement shows
promise in enabling diagnosis approximately six months earlier in mild and
asymptomatic stages, offering critical time for intervention.",2024-09-11 19:31:01+00:00
Minimizing Embedding Distortion for Robust Out-of-Distribution Performance,"Foundational models, trained on vast and diverse datasets, have demonstrated
remarkable capabilities in generalizing across different domains and
distributions for various zero-shot tasks. Our work addresses the challenge of
retaining these powerful generalization capabilities when adapting foundational
models to specific downstream tasks through fine-tuning. To this end, we
introduce a novel approach we call ""similarity loss"", which can be incorporated
into the fine-tuning process of any task. By minimizing the distortion of
fine-tuned embeddings from the pre-trained embeddings, our method strikes a
balance between task-specific adaptation and preserving broad generalization
abilities. We evaluate our approach on two diverse tasks: image classification
on satellite imagery and face recognition, focusing on open-class and domain
shift scenarios to assess out-of-distribution (OOD) performance. We demonstrate
that this approach significantly improves OOD performance while maintaining
strong in-distribution (ID) performance.",2024-09-11 19:22:52+00:00
Violence detection in videos using deep recurrent and convolutional neural networks,"Violence and abnormal behavior detection research have known an increase of
interest in recent years, due mainly to a rise in crimes in large cities
worldwide. In this work, we propose a deep learning architecture for violence
detection which combines both recurrent neural networks (RNNs) and
2-dimensional convolutional neural networks (2D CNN). In addition to video
frames, we use optical flow computed using the captured sequences. CNN extracts
spatial characteristics in each frame, while RNN extracts temporal
characteristics. The use of optical flow allows to encode the movements in the
scenes. The proposed approaches reach the same level as the state-of-the-art
techniques and sometime surpass them. It was validated on 3 databases achieving
good results.",2024-09-11 19:21:51+00:00
A Novel Mathematical Framework for Objective Evaluation of Ideas using a Conversational AI (CAI) System,"The demand for innovation in product design necessitates a prolific ideation
phase. Conversational AI (CAI) systems that use Large Language Models (LLMs)
such as GPT (Generative Pre-trained Transformer) have been shown to be fruitful
in augmenting human creativity, providing numerous novel and diverse ideas.
Despite the success in ideation quantity, the qualitative assessment of these
ideas remains challenging and traditionally reliant on expert human evaluation.
This method suffers from limitations such as human judgment errors, bias, and
oversight. Addressing this gap, our study introduces a comprehensive
mathematical framework for automated analysis to objectively evaluate the
plethora of ideas generated by CAI systems and/or humans. This framework is
particularly advantageous for novice designers who lack experience in selecting
promising ideas. By converting the ideas into higher dimensional vectors and
quantitatively measuring the diversity between them using tools such as UMAP,
DBSCAN and PCA, the proposed method provides a reliable and objective way of
selecting the most promising ideas, thereby enhancing the efficiency of the
ideation phase.",2024-09-11 19:10:29+00:00
Mapping the Russian Internet Troll Network on Twitter using a Predictive Model,"Russian Internet Trolls use fake personas to spread disinformation through
multiple social media streams. Given the increased frequency of this threat
across social media platforms, understanding those operations is paramount in
combating their influence. Using Twitter content identified as part of the
Russian influence network, we created a predictive model to map the network
operations. We classify accounts type based on their authenticity function for
a sub-sample of accounts by introducing logical categories and training a
predictive model to identify similar behavior patterns across the network. Our
model attains 88% prediction accuracy for the test set. Validation is done by
comparing the similarities with the 3 million Russian troll tweets dataset. The
result indicates a 90.7% similarity between the two datasets. Furthermore, we
compare our model predictions on a Russian tweets dataset, and the results
state that there is 90.5% correspondence between the predictions and the actual
categories. The prediction and validation results suggest that our predictive
model can assist with mapping the actors in such networks.",2024-09-11 19:09:21+00:00
Self-Masking Networks for Unsupervised Adaptation,"With the advent of billion-parameter foundation models, efficient fine-tuning
has become increasingly important for the adaptation of models to downstream
tasks. However, especially in computer vision, it can be hard to achieve good
performance when access to quality labeled data is lacking. In this work, we
propose a method adapting pretrained generalist models in a self-supervised
manner by learning binary masks. These self-supervised masking networks (SMNs)
are up to 79x more efficient to store and significantly improve performance on
label-efficient downstream tasks. We validate the usefulness of learning binary
masks as a fine-tuning method on 8 datasets and 3 model architectures, and we
demonstrate the effectiveness of SMNs in 3 label-efficient settings.",2024-09-11 19:08:14+00:00
FaVoR: Features via Voxel Rendering for Camera Relocalization,"Camera relocalization methods range from dense image alignment to direct
camera pose regression from a query image. Among these, sparse feature matching
stands out as an efficient, versatile, and generally lightweight approach with
numerous applications. However, feature-based methods often struggle with
significant viewpoint and appearance changes, leading to matching failures and
inaccurate pose estimates. To overcome this limitation, we propose a novel
approach that leverages a globally sparse yet locally dense 3D representation
of 2D features. By tracking and triangulating landmarks over a sequence of
frames, we construct a sparse voxel map optimized to render image patch
descriptors observed during tracking. Given an initial pose estimate, we first
synthesize descriptors from the voxels using volumetric rendering and then
perform feature matching to estimate the camera pose. This methodology enables
the generation of descriptors for unseen views, enhancing robustness to view
changes. We extensively evaluate our method on the 7-Scenes and Cambridge
Landmarks datasets. Our results show that our method significantly outperforms
existing state-of-the-art feature representation techniques in indoor
environments, achieving up to a 39% improvement in median translation error.
Additionally, our approach yields comparable results to other methods for
outdoor scenarios while maintaining lower memory and computational costs.",2024-09-11 18:58:16+00:00
"A Survey of Inverse Constrained Reinforcement Learning: Definitions, Progress and Challenges","Inverse Constrained Reinforcement Learning (ICRL) is the task of inferring
the implicit constraints followed by expert agents from their demonstration
data. As an emerging research topic, ICRL has received considerable attention
in recent years. This article presents a categorical survey of the latest
advances in ICRL. It serves as a comprehensive reference for machine learning
researchers and practitioners, as well as starters seeking to comprehend the
definitions, advancements, and important challenges in ICRL. We begin by
formally defining the problem and outlining the algorithmic framework that
facilitates constraint inference across various scenarios. These include
deterministic or stochastic environments, environments with limited
demonstrations, and multiple agents. For each context, we illustrate the
critical challenges and introduce a series of fundamental methods to tackle
these issues. This survey encompasses discrete, virtual, and realistic
environments for evaluating ICRL agents. We also delve into the most pertinent
applications of ICRL, such as autonomous driving, robot control, and sports
analytics. To stimulate continuing research, we conclude the survey with a
discussion of key unresolved questions in ICRL that can effectively foster a
bridge between theoretical understanding and practical industrial applications.",2024-09-11 18:49:03+00:00
EchoDFKD: Data-Free Knowledge Distillation for Cardiac Ultrasound Segmentation using Synthetic Data,"The application of machine learning to medical ultrasound videos of the
heart, i.e., echocardiography, has recently gained traction with the
availability of large public datasets. Traditional supervised tasks, such as
ejection fraction regression, are now making way for approaches focusing more
on the latent structure of data distributions, as well as generative methods.
We propose a model trained exclusively by knowledge distillation, either on
real or synthetical data, involving retrieving masks suggested by a teacher
model. We achieve state-of-the-art (SOTA) values on the task of identifying
end-diastolic and end-systolic frames. By training the model only on synthetic
data, it reaches segmentation capabilities close to the performance when
trained on real data with a significantly reduced number of weights. A
comparison with the 5 main existing methods shows that our method outperforms
the others in most cases. We also present a new evaluation method that does not
require human annotation and instead relies on a large auxiliary model. We show
that this method produces scores consistent with those obtained from human
annotations. Relying on the integrated knowledge from a vast amount of records,
this method overcomes certain inherent limitations of human annotator labeling.
Code: https://github.com/GregoirePetit/EchoDFKD",2024-09-11 18:38:02+00:00
TabMixer: Noninvasive Estimation of the Mean Pulmonary Artery Pressure via Imaging and Tabular Data Mixing,"Right Heart Catheterization is a gold standard procedure for diagnosing
Pulmonary Hypertension by measuring mean Pulmonary Artery Pressure (mPAP). It
is invasive, costly, time-consuming and carries risks. In this paper, for the
first time, we explore the estimation of mPAP from videos of noninvasive
Cardiac Magnetic Resonance Imaging. To enhance the predictive capabilities of
Deep Learning models used for this task, we introduce an additional modality in
the form of demographic features and clinical measurements. Inspired by
all-Multilayer Perceptron architectures, we present TabMixer, a novel module
enabling the integration of imaging and tabular data through spatial, temporal
and channel mixing. Specifically, we present the first approach that utilizes
Multilayer Perceptrons to interchange tabular information with imaging features
in vision models. We test TabMixer for mPAP estimation and show that it
enhances the performance of Convolutional Neural Networks, 3D-MLP and Vision
Transformers while being competitive with previous modules for imaging and
tabular data. Our approach has the potential to improve clinical processes
involving both modalities, particularly in noninvasive mPAP estimation, thus,
significantly enhancing the quality of life for individuals affected by
Pulmonary Hypertension. We provide a source code for using TabMixer at
https://github.com/SanoScience/TabMixer.",2024-09-11 18:32:30+00:00
Unsupervised Point Cloud Registration with Self-Distillation,"Rigid point cloud registration is a fundamental problem and highly relevant
in robotics and autonomous driving. Nowadays deep learning methods can be
trained to match a pair of point clouds, given the transformation between them.
However, this training is often not scalable due to the high cost of collecting
ground truth poses. Therefore, we present a self-distillation approach to learn
point cloud registration in an unsupervised fashion. Here, each sample is
passed to a teacher network and an augmented view is passed to a student
network. The teacher includes a trainable feature extractor and a learning-free
robust solver such as RANSAC. The solver forces consistency among
correspondences and optimizes for the unsupervised inlier ratio, eliminating
the need for ground truth labels. Our approach simplifies the training
procedure by removing the need for initial hand-crafted features or consecutive
point cloud frames as seen in related methods. We show that our method not only
surpasses them on the RGB-D benchmark 3DMatch but also generalizes well to
automotive radar, where classical features adopted by others fail. The code is
available at https://github.com/boschresearch/direg .",2024-09-11 18:24:36+00:00
Machine Learning and Constraint Programming for Efficient Healthcare Scheduling,"Solving combinatorial optimization problems involve satisfying a set of hard
constraints while optimizing some objectives. In this context, exact or
approximate methods can be used. While exact methods guarantee the optimal
solution, they often come with an exponential running time as opposed to
approximate methods that trade the solutions quality for a better running time.
In this context, we tackle the Nurse Scheduling Problem (NSP). The NSP consist
in assigning nurses to daily shifts within a planning horizon such that
workload constraints are satisfied while hospitals costs and nurses preferences
are optimized. To solve the NSP, we propose implicit and explicit approaches.
In the implicit solving approach, we rely on Machine Learning methods using
historical data to learn and generate new solutions through the constraints and
objectives that may be embedded in the learned patterns. To quantify the
quality of using our implicit approach in capturing the embedded constraints
and objectives, we rely on the Frobenius Norm, a quality measure used to
compute the average error between the generated solutions and historical data.
To compensate for the uncertainty related to the implicit approach given that
the constraints and objectives may not be concretely visible in the produced
solutions, we propose an alternative explicit approach where we first model the
NSP using the Constraint Satisfaction Problem (CSP) framework. Then we develop
Stochastic Local Search methods and a new Branch and Bound algorithm enhanced
with constraint propagation techniques and variables/values ordering
heuristics. Since our implicit approach may not guarantee the feasibility or
optimality of the generated solution, we propose a data-driven approach to
passively learn the NSP as a constraint network. The learned constraint
network, formulated as a CSP, will then be solved using the methods we listed
earlier.",2024-09-11 18:09:25+00:00
ENACT: Entropy-based Clustering of Attention Input for Improving the Computational Performance of Object Detection Transformers,"Transformers demonstrate competitive performance in terms of precision on the
problem of vision-based object detection. However, they require considerable
computational resources due to the quadratic size of the attention weights. In
this work, we propose to cluster the transformer input on the basis of its
entropy. The reason for this is that the self-information of each pixel (whose
sum is the entropy), is likely to be similar among pixels corresponding to the
same objects. Clustering reduces the size of data given as input to the
transformer and therefore reduces training time and GPU memory usage, while at
the same time preserves meaningful information to be passed through the
remaining parts of the network. The proposed process is organized in a module
called ENACT, that can be plugged-in any transformer architecture that consists
of a multi-head self-attention computation in its encoder. We ran extensive
experiments using the COCO object detection dataset, and three detection
transformers. The obtained results demonstrate that in all tested cases, there
is consistent reduction in the required computational resources, while the
precision of the detection task is only slightly reduced. The code of the ENACT
module will become available at https://github.com/GSavathrakis/ENACT",2024-09-11 18:03:59+00:00
Using Neural Network Models to Estimate Stellar Ages from Lithium Equivalent Widths: An EAGLES Expansion,"We present an Artificial Neural Network (ANN) model of photospheric lithium
depletion in cool stars (3000 < Teff / K < 6500), producing estimates and
probability distributions of age from Li I 6708A equivalent width (LiEW) and
effective temperature data inputs. The model is trained on the same sample of
6200 stars from 52 open clusters, observed in the Gaia-ESO spectroscopic
survey, and used to calibrate the previously published analytical EAGLES model,
with ages 2 - 6000 Myr and -0.3 < [Fe/H] < 0.2. The additional flexibility of
the ANN provides some improvements, including better modelling of the ""lithium
dip"" at ages < 50 Myr and Teff ~ 3500K, and of the intrinsic dispersion in LiEW
at all ages. Poor age discrimination is still an issue at ages > 1 Gyr,
confirming that additional modelling flexibility is not sufficient to fully
represent the LiEW - age - Teff relationship, and suggesting the involvement of
further astrophysical parameters. Expansion to include such parameters -
rotation, accretion, and surface gravity - is discussed, and the use of an ANN
means these can be more easily included in future iterations, alongside more
flexible functional forms for the LiEW dispersion. Our methods and ANN model
are provided in an updated version 2.0 of the EAGLES software.",2024-09-11 18:00:03+00:00
Self-Evolving Depth-Supervised 3D Gaussian Splatting from Rendered Stereo Pairs,"3D Gaussian Splatting (GS) significantly struggles to accurately represent
the underlying 3D scene geometry, resulting in inaccuracies and floating
artifacts when rendering depth maps. In this paper, we address this limitation,
undertaking a comprehensive analysis of the integration of depth priors
throughout the optimization process of Gaussian primitives, and present a novel
strategy for this purpose. This latter dynamically exploits depth cues from a
readily available stereo network, processing virtual stereo pairs rendered by
the GS model itself during training and achieving consistent self-improvement
of the scene representation. Experimental results on three popular datasets,
breaking ground as the first to assess depth accuracy for these models,
validate our findings.",2024-09-11 17:59:58+00:00
DreamMesh: Jointly Manipulating and Texturing Triangle Meshes for Text-to-3D Generation,"Learning radiance fields (NeRF) with powerful 2D diffusion models has
garnered popularity for text-to-3D generation. Nevertheless, the implicit 3D
representations of NeRF lack explicit modeling of meshes and textures over
surfaces, and such surface-undefined way may suffer from the issues, e.g.,
noisy surfaces with ambiguous texture details or cross-view inconsistency. To
alleviate this, we present DreamMesh, a novel text-to-3D architecture that
pivots on well-defined surfaces (triangle meshes) to generate high-fidelity
explicit 3D model. Technically, DreamMesh capitalizes on a distinctive
coarse-to-fine scheme. In the coarse stage, the mesh is first deformed by
text-guided Jacobians and then DreamMesh textures the mesh with an interlaced
use of 2D diffusion models in a tuning free manner from multiple viewpoints. In
the fine stage, DreamMesh jointly manipulates the mesh and refines the texture
map, leading to high-quality triangle meshes with high-fidelity textured
materials. Extensive experiments demonstrate that DreamMesh significantly
outperforms state-of-the-art text-to-3D methods in faithfully generating 3D
content with richer textual details and enhanced geometry. Our project page is
available at https://dreammesh.github.io.",2024-09-11 17:59:02+00:00
"""My Grade is Wrong!"": A Contestable AI Framework for Interactive Feedback in Evaluating Student Essays","Interactive feedback, where feedback flows in both directions between teacher
and student, is more effective than traditional one-way feedback. However, it
is often too time-consuming for widespread use in educational practice. While
Large Language Models (LLMs) have potential for automating feedback, they
struggle with reasoning and interaction in an interactive setting. This paper
introduces CAELF, a Contestable AI Empowered LLM Framework for automating
interactive feedback. CAELF allows students to query, challenge, and clarify
their feedback by integrating a multi-agent system with computational
argumentation. Essays are first assessed by multiple Teaching-Assistant Agents
(TA Agents), and then a Teacher Agent aggregates the evaluations through formal
reasoning to generate feedback and grades. Students can further engage with the
feedback to refine their understanding. A case study on 500 critical thinking
essays with user studies demonstrates that CAELF significantly improves
interactive feedback, enhancing the reasoning and interaction capabilities of
LLMs. This approach offers a promising solution to overcoming the time and
resource barriers that have limited the adoption of interactive feedback in
educational settings.",2024-09-11 17:59:01+00:00
Hi3D: Pursuing High-Resolution Image-to-3D Generation with Video Diffusion Models,"Despite having tremendous progress in image-to-3D generation, existing
methods still struggle to produce multi-view consistent images with
high-resolution textures in detail, especially in the paradigm of 2D diffusion
that lacks 3D awareness. In this work, we present High-resolution Image-to-3D
model (Hi3D), a new video diffusion based paradigm that redefines a single
image to multi-view images as 3D-aware sequential image generation (i.e.,
orbital video generation). This methodology delves into the underlying temporal
consistency knowledge in video diffusion model that generalizes well to
geometry consistency across multiple views in 3D generation. Technically, Hi3D
first empowers the pre-trained video diffusion model with 3D-aware prior
(camera pose condition), yielding multi-view images with low-resolution texture
details. A 3D-aware video-to-video refiner is learnt to further scale up the
multi-view images with high-resolution texture details. Such high-resolution
multi-view images are further augmented with novel views through 3D Gaussian
Splatting, which are finally leveraged to obtain high-fidelity meshes via 3D
reconstruction. Extensive experiments on both novel view synthesis and single
view reconstruction demonstrate that our Hi3D manages to produce superior
multi-view consistency images with highly-detailed textures. Source code and
data are available at \url{https://github.com/yanghb22-fdu/Hi3D-Official}.",2024-09-11 17:58:57+00:00
FreeEnhance: Tuning-Free Image Enhancement via Content-Consistent Noising-and-Denoising Process,"The emergence of text-to-image generation models has led to the recognition
that image enhancement, performed as post-processing, would significantly
improve the visual quality of the generated images. Exploring diffusion models
to enhance the generated images nevertheless is not trivial and necessitates to
delicately enrich plentiful details while preserving the visual appearance of
key content in the original image. In this paper, we propose a novel framework,
namely FreeEnhance, for content-consistent image enhancement using the
off-the-shelf image diffusion models. Technically, FreeEnhance is a two-stage
process that firstly adds random noise to the input image and then capitalizes
on a pre-trained image diffusion model (i.e., Latent Diffusion Models) to
denoise and enhance the image details. In the noising stage, FreeEnhance is
devised to add lighter noise to the region with higher frequency to preserve
the high-frequent patterns (e.g., edge, corner) in the original image. In the
denoising stage, we present three target properties as constraints to
regularize the predicted noise, enhancing images with high acutance and high
visual quality. Extensive experiments conducted on the HPDv2 dataset
demonstrate that our FreeEnhance outperforms the state-of-the-art image
enhancement models in terms of quantitative metrics and human preference. More
remarkably, FreeEnhance also shows higher human preference compared to the
commercial image enhancement solution of Magnific AI.",2024-09-11 17:58:50+00:00
Still More Shades of Null: A Benchmark for Responsible Missing Value Imputation,"We present Shades-of-NULL, a benchmark for responsible missing value
imputation. Our benchmark includes state-of-the-art imputation techniques, and
embeds them into the machine learning development lifecycle. We model realistic
missingness scenarios that go beyond Rubin's classic Missing Completely at
Random (MCAR), Missing At Random (MAR) and Missing Not At Random (MNAR), to
include multi-mechanism missingness (when different missingness patterns
co-exist in the data) and missingness shift (when the missingness mechanism
changes between training and test). Another key novelty of our work is that we
evaluate imputers holistically, based on the predictive performance, fairness
and stability of the models that are trained and tested on the data they
produce.
  We use Shades-of-NULL to conduct a large-scale empirical study involving
20,952 experimental pipelines, and find that, while there is no single
best-performing imputation approach for all missingness types, interesting
performance patterns do emerge when comparing imputer performance in simpler
vs. more complex missingness scenarios. Further, while predictive performance,
fairness and stability can be seen as orthogonal, we identify trade-offs among
them that arise due to the combination of missingness scenario, the choice of
an imputer, and the architecture of the model trained on the data
post-imputation. We make Shades-of-NULL publicly available, and hope to enable
researchers to comprehensively and rigorously evaluate new missing value
imputation methods on a wide range of evaluation metrics, in plausible and
socially meaningful missingness scenarios.",2024-09-11 17:58:39+00:00
VMAS: Video-to-Music Generation via Semantic Alignment in Web Music Videos,"We present a framework for learning to generate background music from video
inputs. Unlike existing works that rely on symbolic musical annotations, which
are limited in quantity and diversity, our method leverages large-scale web
videos accompanied by background music. This enables our model to learn to
generate realistic and diverse music. To accomplish this goal, we develop a
generative video-music Transformer with a novel semantic video-music alignment
scheme. Our model uses a joint autoregressive and contrastive learning
objective, which encourages the generation of music aligned with high-level
video content. We also introduce a novel video-beat alignment scheme to match
the generated music beats with the low-level motions in the video. Lastly, to
capture fine-grained visual cues in a video needed for realistic background
music generation, we introduce a new temporal video encoder architecture,
allowing us to efficiently process videos consisting of many densely sampled
frames. We train our framework on our newly curated DISCO-MV dataset,
consisting of 2.2M video-music samples, which is orders of magnitude larger
than any prior datasets used for video music generation. Our method outperforms
existing approaches on the DISCO-MV and MusicCaps datasets according to various
music generation evaluation metrics, including human evaluation. Results are
available at https://genjib.github.io/project_page/VMAs/index.html",2024-09-11 17:56:48+00:00
Introducing Perturb-ability Score (PS) to Enhance Robustness Against Evasion Adversarial Attacks on ML-NIDS,"This paper proposes a novel Perturb-ability Score (PS) that can be used to
identify Network Intrusion Detection Systems (NIDS) features that can be easily
manipulated by attackers in the problem-space. We demonstrate that using PS to
select only non-perturb-able features for ML-based NIDS maintains detection
performance while enhancing robustness against adversarial attacks.",2024-09-11 17:52:37+00:00
StereoCrafter: Diffusion-based Generation of Long and High-fidelity Stereoscopic 3D from Monocular Videos,"This paper presents a novel framework for converting 2D videos to immersive
stereoscopic 3D, addressing the growing demand for 3D content in immersive
experience. Leveraging foundation models as priors, our approach overcomes the
limitations of traditional methods and boosts the performance to ensure the
high-fidelity generation required by the display devices. The proposed system
consists of two main steps: depth-based video splatting for warping and
extracting occlusion mask, and stereo video inpainting. We utilize pre-trained
stable video diffusion as the backbone and introduce a fine-tuning protocol for
the stereo video inpainting task. To handle input video with varying lengths
and resolutions, we explore auto-regressive strategies and tiled processing.
Finally, a sophisticated data processing pipeline has been developed to
reconstruct a large-scale and high-quality dataset to support our training. Our
framework demonstrates significant improvements in 2D-to-3D video conversion,
offering a practical solution for creating immersive content for 3D devices
like Apple Vision Pro and 3D displays. In summary, this work contributes to the
field by presenting an effective method for generating high-quality
stereoscopic videos from monocular input, potentially transforming how we
experience digital media.",2024-09-11 17:52:07+00:00
Adaptive Adapter Routing for Long-Tailed Class-Incremental Learning,"In our ever-evolving world, new data exhibits a long-tailed distribution,
such as e-commerce platform reviews. This necessitates continuous model
learning imbalanced data without forgetting, addressing the challenge of
long-tailed class-incremental learning (LTCIL). Existing methods often rely on
retraining linear classifiers with former data, which is impractical in
real-world settings. In this paper, we harness the potent representation
capabilities of pre-trained models and introduce AdaPtive Adapter RouTing
(APART) as an exemplar-free solution for LTCIL. To counteract forgetting, we
train inserted adapters with frozen pre-trained weights for deeper adaptation
and maintain a pool of adapters for selection during sequential model updates.
Additionally, we present an auxiliary adapter pool designed for effective
generalization, especially on minority classes. Adaptive instance routing
across these pools captures crucial correlations, facilitating a comprehensive
representation of all classes. Consequently, APART tackles the imbalance
problem as well as catastrophic forgetting in a unified framework. Extensive
benchmark experiments validate the effectiveness of APART. Code is available
at: https://github.com/vita-qzh/APART",2024-09-11 17:52:00+00:00
SUPER: Evaluating Agents on Setting Up and Executing Tasks from Research Repositories,"Given that Large Language Models (LLMs) have made significant progress in
writing code, can they now be used to autonomously reproduce results from
research repositories? Such a capability would be a boon to the research
community, helping researchers validate, understand, and extend prior work. To
advance towards this goal, we introduce SUPER, the first benchmark designed to
evaluate the capability of LLMs in setting up and executing tasks from research
repositories. SUPERaims to capture the realistic challenges faced by
researchers working with Machine Learning (ML) and Natural Language Processing
(NLP) research repositories. Our benchmark comprises three distinct problem
sets: 45 end-to-end problems with annotated expert solutions, 152 sub problems
derived from the expert set that focus on specific challenges (e.g.,
configuring a trainer), and 602 automatically generated problems for
larger-scale development. We introduce various evaluation measures to assess
both task success and progress, utilizing gold solutions when available or
approximations otherwise. We show that state-of-the-art approaches struggle to
solve these problems with the best model (GPT-4o) solving only 16.3% of the
end-to-end set, and 46.1% of the scenarios. This illustrates the challenge of
this task, and suggests that SUPER can serve as a valuable resource for the
community to make and measure progress.",2024-09-11 17:37:48+00:00
Asymptotics of Stochastic Gradient Descent with Dropout Regularization in Linear Models,"This paper proposes an asymptotic theory for online inference of the
stochastic gradient descent (SGD) iterates with dropout regularization in
linear regression. Specifically, we establish the geometric-moment contraction
(GMC) for constant step-size SGD dropout iterates to show the existence of a
unique stationary distribution of the dropout recursive function. By the GMC
property, we provide quenched central limit theorems (CLT) for the difference
between dropout and $\ell^2$-regularized iterates, regardless of
initialization. The CLT for the difference between the Ruppert-Polyak averaged
SGD (ASGD) with dropout and $\ell^2$-regularized iterates is also presented.
Based on these asymptotic normality results, we further introduce an online
estimator for the long-run covariance matrix of ASGD dropout to facilitate
inference in a recursive manner with efficiency in computational time and
memory. The numerical experiments demonstrate that for sufficiently large
samples, the proposed confidence intervals for ASGD with dropout nearly achieve
the nominal coverage probability.",2024-09-11 17:28:38+00:00
Synthetic continued pretraining,"Pretraining on large-scale, unstructured internet text has enabled language
models to acquire a significant amount of world knowledge. However, this
knowledge acquisition is data-inefficient -- to learn a given fact, models must
be trained on hundreds to thousands of diverse representations of it. This
poses a challenge when adapting a pretrained model to a small corpus of
domain-specific documents, where each fact may appear rarely or only once. We
propose to bridge this gap with synthetic continued pretraining: using the
small domain-specific corpus to synthesize a large corpus more amenable to
learning, and then performing continued pretraining on the synthesized corpus.
We instantiate this proposal with EntiGraph, a synthetic data augmentation
algorithm that extracts salient entities from the source documents and then
generates diverse text by drawing connections between the sampled entities.
Synthetic continued pretraining using EntiGraph enables a language model to
answer questions and follow generic instructions related to the source
documents without access to them. If instead, the source documents are
available at inference time, we show that the knowledge acquired through our
approach compounds with retrieval-augmented generation. To better understand
these results, we build a simple mathematical model of EntiGraph, and show how
synthetic data augmentation can ""rearrange"" knowledge to enable more
data-efficient learning.",2024-09-11 17:21:59+00:00
Deep Neural Network-Based Sign Language Recognition: A Comprehensive Approach Using Transfer Learning with Explainability,"To promote inclusion and ensuring effective communication for those who rely
on sign language as their main form of communication, sign language recognition
(SLR) is crucial. Sign language recognition (SLR) seamlessly incorporates with
diverse technology, enhancing accessibility for the deaf community by
facilitating their use of digital platforms, video calls, and communication
devices. To effectively solve this problem, we suggest a novel solution that
uses a deep neural network to fully automate sign language recognition. This
methodology integrates sophisticated preprocessing methodologies to optimise
the overall performance. The architectures resnet, inception, xception, and vgg
are utilised to selectively categorise images of sign language. We prepared a
DNN architecture and merged it with the pre-processing architectures. In the
post-processing phase, we utilised the SHAP deep explainer, which is based on
cooperative game theory, to quantify the influence of specific features on the
output of a machine learning model. Bhutanese-Sign-Language (BSL) dataset was
used for training and testing the suggested technique. While training on
Bhutanese-Sign-Language (BSL) dataset, overall ResNet50 with the DNN model
performed better accuracy which is 98.90%. Our model's ability to provide
informational clarity was assessed using the SHAP (SHapley Additive
exPlanations) method. In part to its considerable robustness and reliability,
the proposed methodological approach can be used to develop a fully automated
system for sign language recognition.",2024-09-11 17:17:44+00:00
Towards Fairer Health Recommendations: finding informative unbiased samples via Word Sense Disambiguation,"There have been growing concerns around high-stake applications that rely on
models trained with biased data, which consequently produce biased predictions,
often harming the most vulnerable. In particular, biased medical data could
cause health-related applications and recommender systems to create outputs
that jeopardize patient care and widen disparities in health outcomes. A recent
framework titled Fairness via AI posits that, instead of attempting to correct
model biases, researchers must focus on their root causes by using AI to debias
data. Inspired by this framework, we tackle bias detection in medical curricula
using NLP models, including LLMs, and evaluate them on a gold standard dataset
containing 4,105 excerpts annotated by medical experts for bias from a large
corpus. We build on previous work by coauthors which augments the set of
negative samples with non-annotated text containing social identifier terms.
However, some of these terms, especially those related to race and ethnicity,
can carry different meanings (e.g., ""white matter of spinal cord""). To address
this issue, we propose the use of Word Sense Disambiguation models to refine
dataset quality by removing irrelevant sentences. We then evaluate fine-tuned
variations of BERT models as well as GPT models with zero- and few-shot
prompting. We found LLMs, considered SOTA on many NLP tasks, unsuitable for
bias detection, while fine-tuned BERT models generally perform well across all
evaluated metrics.",2024-09-11 17:10:20+00:00
Controllable retinal image synthesis using conditional StyleGAN and latent space manipulation for improved diagnosis and grading of diabetic retinopathy,"Diabetic retinopathy (DR) is a consequence of diabetes mellitus characterized
by vascular damage within the retinal tissue. Timely detection is paramount to
mitigate the risk of vision loss. However, training robust grading models is
hindered by a shortage of annotated data, particularly for severe cases. This
paper proposes a framework for controllably generating high-fidelity and
diverse DR fundus images, thereby improving classifier performance in DR
grading and detection. We achieve comprehensive control over DR severity and
visual features (optic disc, vessel structure, lesion areas) within generated
images solely through a conditional StyleGAN, eliminating the need for feature
masks or auxiliary networks. Specifically, leveraging the SeFa algorithm to
identify meaningful semantics within the latent space, we manipulate the DR
images generated conditionally on grades, further enhancing the dataset
diversity. Additionally, we propose a novel, effective SeFa-based data
augmentation strategy, helping the classifier focus on discriminative regions
while ignoring redundant features. Using this approach, a ResNet50 model
trained for DR detection achieves 98.09% accuracy, 99.44% specificity, 99.45%
precision, and an F1-score of 98.09%. Moreover, incorporating synthetic images
generated by conditional StyleGAN into ResNet50 training for DR grading yields
83.33% accuracy, a quadratic kappa score of 87.64%, 95.67% specificity, and
72.24% precision. Extensive experiments conducted on the APTOS 2019 dataset
demonstrate the exceptional realism of the generated images and the superior
performance of our classifier compared to recent studies.",2024-09-11 17:08:28+00:00
Efficient One-Step Diffusion Refinement for Snapshot Compressive Imaging,"Coded Aperture Snapshot Spectral Imaging (CASSI) is a crucial technique for
capturing three-dimensional multispectral images (MSIs) through the complex
inverse task of reconstructing these images from coded two-dimensional
measurements. Current state-of-the-art methods, predominantly end-to-end, face
limitations in reconstructing high-frequency details and often rely on
constrained datasets like KAIST and CAVE, resulting in models with poor
generalizability. In response to these challenges, this paper introduces a
novel one-step Diffusion Probabilistic Model within a self-supervised
adaptation framework for Snapshot Compressive Imaging (SCI). Our approach
leverages a pretrained SCI reconstruction network to generate initial
predictions from two-dimensional measurements. Subsequently, a one-step
diffusion model produces high-frequency residuals to enhance these initial
predictions. Additionally, acknowledging the high costs associated with
collecting MSIs, we develop a self-supervised paradigm based on the Equivariant
Imaging (EI) framework. Experimental results validate the superiority of our
model compared to previous methods, showcasing its simplicity and adaptability
to various end-to-end or unfolding techniques.",2024-09-11 17:02:10+00:00
Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation,"Modern listwise recommendation systems need to consider both long-term user
perceptions and short-term interest shifts. Reinforcement learning can be
applied on recommendation to study such a problem but is also subject to large
search space, sparse user feedback and long interactive latency. Motivated by
recent progress in hierarchical reinforcement learning, we propose a novel
framework called mccHRL to provide different levels of temporal abstraction on
listwise recommendation. Within the hierarchical framework, the high-level
agent studies the evolution of user perception, while the low-level agent
produces the item selection policy by modeling the process as a sequential
decision-making problem. We argue that such framework has a well-defined
decomposition of the outra-session context and the intra-session context, which
are encoded by the high-level and low-level agents, respectively. To verify
this argument, we implement both a simulator-based environment and an
industrial dataset-based experiment. Results observe significant performance
improvement by our method, compared with several well-known baselines. Data and
codes have been made public.",2024-09-11 17:01:06+00:00
SoK: Security and Privacy Risks of Medical AI,"The integration of technology and healthcare has ushered in a new era where
software systems, powered by artificial intelligence and machine learning, have
become essential components of medical products and services. While these
advancements hold great promise for enhancing patient care and healthcare
delivery efficiency, they also expose sensitive medical data and system
integrity to potential cyberattacks. This paper explores the security and
privacy threats posed by AI/ML applications in healthcare. Through a thorough
examination of existing research across a range of medical domains, we have
identified significant gaps in understanding the adversarial attacks targeting
medical AI systems. By outlining specific adversarial threat models for medical
settings and identifying vulnerable application domains, we lay the groundwork
for future research that investigates the security and resilience of AI-driven
medical systems. Through our analysis of different threat models and
feasibility studies on adversarial attacks in different medical domains, we
provide compelling insights into the pressing need for cybersecurity research
in the rapidly evolving field of AI healthcare technology.",2024-09-11 16:59:58+00:00
NVRC: Neural Video Representation Compression,"Recent advances in implicit neural representation (INR)-based video coding
have demonstrated its potential to compete with both conventional and other
learning-based approaches. With INR methods, a neural network is trained to
overfit a video sequence, with its parameters compressed to obtain a compact
representation of the video content. However, although promising results have
been achieved, the best INR-based methods are still out-performed by the latest
standard codecs, such as VVC VTM, partially due to the simple model compression
techniques employed. In this paper, rather than focusing on representation
architectures as in many existing works, we propose a novel INR-based video
compression framework, Neural Video Representation Compression (NVRC),
targeting compression of the representation. Based on the novel entropy coding
and quantization models proposed, NVRC, for the first time, is able to optimize
an INR-based video codec in a fully end-to-end manner. To further minimize the
additional bitrate overhead introduced by the entropy models, we have also
proposed a new model compression framework for coding all the network,
quantization and entropy model parameters hierarchically. Our experiments show
that NVRC outperforms many conventional and learning-based benchmark codecs,
with a 24% average coding gain over VVC VTM (Random Access) on the UVG dataset,
measured in PSNR. As far as we are aware, this is the first time an INR-based
video codec achieving such performance. The implementation of NVRC will be
released at www.github.com.",2024-09-11 16:57:12+00:00
Manifold Learning via Foliations and Knowledge Transfer,"Understanding how real data is distributed in high dimensional spaces is the
key to many tasks in machine learning. We want to provide a natural geometric
structure on the space of data employing a deep ReLU neural network trained as
a classifier. Through the data information matrix (DIM), a variation of the
Fisher information matrix, the model will discern a singular foliation
structure on the space of data. We show that the singular points of such
foliation are contained in a measure zero set, and that a local regular
foliation exists almost everywhere. Experiments show that the data is
correlated with leaves of such foliation. Moreover we show the potential of our
approach for knowledge transfer by analyzing the spectrum of the DIM to measure
distances between datasets.",2024-09-11 16:53:53+00:00
Robust Robot Walker: Learning Agile Locomotion over Tiny Traps,"Quadruped robots must exhibit robust walking capabilities in practical
applications. In this work, we propose a novel approach that enables quadruped
robots to pass various small obstacles, or ""tiny traps"". Existing methods often
rely on exteroceptive sensors, which can be unreliable for detecting such tiny
traps. To overcome this limitation, our approach focuses solely on
proprioceptive inputs. We introduce a two-stage training framework
incorporating a contact encoder and a classification head to learn implicit
representations of different traps. Additionally, we design a set of tailored
reward functions to improve both the stability of training and the ease of
deployment for goal-tracking tasks. To benefit further research, we design a
new benchmark for tiny trap task. Extensive experiments in both simulation and
real-world settings demonstrate the effectiveness and robustness of our method.
Project Page: https://robust-robot-walker.github.io/",2024-09-11 16:50:29+00:00
CLNX: Bridging Code and Natural Language for C/C++ Vulnerability-Contributing Commits Identification,"Large Language Models (LLMs) have shown great promise in vulnerability
identification. As C/C++ comprises half of the Open-Source Software (OSS)
vulnerabilities over the past decade and updates in OSS mainly occur through
commits, enhancing LLMs' ability to identify C/C++ Vulnerability-Contributing
Commits (VCCs) is essential. However, current studies primarily focus on
further pre-training LLMs on massive code datasets, which is resource-intensive
and poses efficiency challenges. In this paper, we enhance the ability of
BERT-based LLMs to identify C/C++ VCCs in a lightweight manner. We propose
CodeLinguaNexus (CLNX) as a bridge facilitating communication between C/C++
programs and LLMs. Based on commits, CLNX efficiently converts the source code
into a more natural representation while preserving key details. Specifically,
CLNX first applies structure-level naturalization to decompose complex
programs, followed by token-level naturalization to interpret complex symbols.
We evaluate CLNX on public datasets of 25,872 C/C++ functions with their
commits. The results show that CLNX significantly enhances the performance of
LLMs on identifying C/C++ VCCs. Moreover, CLNX-equipped CodeBERT achieves new
state-of-the-art and identifies 38 OSS vulnerabilities in the real world.",2024-09-11 16:49:46+00:00
What to align in multimodal contrastive learning?,"Humans perceive the world through multisensory integration, blending the
information of different modalities to adapt their behavior. Contrastive
learning offers an appealing solution for multimodal self-supervised learning.
Indeed, by considering each modality as a different view of the same entity, it
learns to align features of different modalities in a shared representation
space. However, this approach is intrinsically limited as it only learns shared
or redundant information between modalities, while multimodal interactions can
arise in other ways. In this work, we introduce CoMM, a Contrastive MultiModal
learning strategy that enables the communication between modalities in a single
multimodal space. Instead of imposing cross- or intra- modality constraints, we
propose to align multimodal representations by maximizing the mutual
information between augmented versions of these multimodal features. Our
theoretical analysis shows that shared, synergistic and unique terms of
information naturally emerge from this formulation, allowing us to estimate
multimodal interactions beyond redundancy. We test CoMM both in a controlled
and in a series of real-world settings: in the former, we demonstrate that CoMM
effectively captures redundant, unique and synergistic information between
modalities. In the latter, CoMM learns complex multimodal interactions and
achieves state-of-the-art results on the six multimodal benchmarks.",2024-09-11 16:42:22+00:00
Convergence of continuous-time stochastic gradient descent with applications to linear deep neural networks,"We study a continuous-time approximation of the stochastic gradient descent
process for minimizing the expected loss in learning problems. The main results
establish general sufficient conditions for the convergence, extending the
results of Chatterjee (2022) established for (nonstochastic) gradient descent.
We show how the main result can be applied to the case of overparametrized
linear neural network training.",2024-09-11 16:40:24+00:00
Revisiting Static Feature-Based Android Malware Detection,"The increasing reliance on machine learning (ML) in computer security,
particularly for malware classification, has driven significant advancements.
However, the replicability and reproducibility of these results are often
overlooked, leading to challenges in verifying research findings. This paper
highlights critical pitfalls that undermine the validity of ML research in
Android malware detection, focusing on dataset and methodological issues. We
comprehensively analyze Android malware detection using two datasets and assess
offline and continual learning settings with six widely used ML models. Our
study reveals that when properly tuned, simpler baseline methods can often
outperform more complex models. To address reproducibility challenges, we
propose solutions for improving datasets and methodological practices, enabling
fairer model comparisons. Additionally, we open-source our code to facilitate
malware analysis, making it extensible for new models and datasets. Our paper
aims to support future research in Android malware detection and other security
domains, enhancing the reliability and reproducibility of published results.",2024-09-11 16:37:50+00:00
A Scalable Algorithm for Active Learning,"FIRAL is a recently proposed deterministic active learning algorithm for
multiclass classification using logistic regression. It was shown to outperform
the state-of-the-art in terms of accuracy and robustness and comes with
theoretical performance guarantees. However, its scalability suffers when
dealing with datasets featuring a large number of points $n$, dimensions $d$,
and classes $c$, due to its $\mathcal{O}(c^2d^2+nc^2d)$ storage and
$\mathcal{O}(c^3(nd^2 + bd^3 + bn))$ computational complexity where $b$ is the
number of points to select in active learning. To address these challenges, we
propose an approximate algorithm with storage requirements reduced to
$\mathcal{O}(n(d+c) + cd^2)$ and a computational complexity of
$\mathcal{O}(bncd^2)$. Additionally, we present a parallel implementation on
GPUs. We demonstrate the accuracy and scalability of our approach using MNIST,
CIFAR-10, Caltech101, and ImageNet. The accuracy tests reveal no deterioration
in accuracy compared to FIRAL. We report strong and weak scaling tests on up to
12 GPUs, for three million point synthetic dataset.",2024-09-11 16:34:01+00:00
D-CAPTCHA++: A Study of Resilience of Deepfake CAPTCHA under Transferable Imperceptible Adversarial Attack,"The advancements in generative AI have enabled the improvement of audio
synthesis models, including text-to-speech and voice conversion. This raises
concerns about its potential misuse in social manipulation and political
interference, as synthetic speech has become indistinguishable from natural
human speech. Several speech-generation programs are utilized for malicious
purposes, especially impersonating individuals through phone calls. Therefore,
detecting fake audio is crucial to maintain social security and safeguard the
integrity of information. Recent research has proposed a D-CAPTCHA system based
on the challenge-response protocol to differentiate fake phone calls from real
ones. In this work, we study the resilience of this system and introduce a more
robust version, D-CAPTCHA++, to defend against fake calls. Specifically, we
first expose the vulnerability of the D-CAPTCHA system under transferable
imperceptible adversarial attack. Secondly, we mitigate such vulnerability by
improving the robustness of the system by using adversarial training in
D-CAPTCHA deepfake detectors and task classifiers.",2024-09-11 16:25:02+00:00
A Contrastive Symmetric Forward-Forward Algorithm (SFFA) for Continual Learning Tasks,"The so-called Forward-Forward Algorithm (FFA) has recently gained momentum as
an alternative to the conventional back-propagation algorithm for neural
network learning, yielding competitive performance across various modeling
tasks. By replacing the backward pass of gradient back-propagation with two
contrastive forward passes, the FFA avoids several shortcomings undergone by
its predecessor (e.g., vanishing/exploding gradient) by enabling layer-wise
training heuristics. In classification tasks, this contrastive method has been
proven to effectively create a latent sparse representation of the input data,
ultimately favoring discriminability. However, FFA exhibits an inherent
asymmetric gradient behavior due to an imbalanced loss function between
positive and negative data, adversely impacting on the model's generalization
capabilities and leading to an accuracy degradation. To address this issue,
this work proposes the Symmetric Forward-Forward Algorithm (SFFA), a novel
modification of the original FFA which partitions each layer into positive and
negative neurons. This allows the local fitness function to be defined as the
ratio between the activation of positive neurons and the overall layer
activity, resulting in a symmetric loss landscape during the training phase. To
evaluate the enhanced convergence of our method, we conduct several experiments
using multiple image classification benchmarks, comparing the accuracy of
models trained with SFFA to those trained with its FFA counterpart. As a
byproduct of this reformulation, we explore the advantages of using a
layer-wise training algorithm for Continual Learning (CL) tasks. The
specialization of neurons and the sparsity of their activations induced by
layer-wise training algorithms enable efficient CL strategies that incorporate
new knowledge (classes) into the neural network, while preventing catastrophic
forgetting of previously...",2024-09-11 16:21:44+00:00
FIRAL: An Active Learning Algorithm for Multinomial Logistic Regression,"We investigate theory and algorithms for pool-based active learning for
multiclass classification using multinomial logistic regression. Using finite
sample analysis, we prove that the Fisher Information Ratio (FIR) lower and
upper bounds the excess risk. Based on our theoretical analysis, we propose an
active learning algorithm that employs regret minimization to minimize the FIR.
To verify our derived excess risk bounds, we conduct experiments on synthetic
datasets. Furthermore, we compare FIRAL with five other methods and found that
our scheme outperforms them: it consistently produces the smallest
classification error in the multiclass logistic regression setting, as
demonstrated through experiments on MNIST, CIFAR-10, and 50-class ImageNet.",2024-09-11 16:11:29+00:00
Awaking the Slides: A Tuning-free and Knowledge-regulated AI Tutoring System via Language Model Coordination,"The vast pre-existing slides serve as rich and important materials to carry
lecture knowledge. However, effectively leveraging lecture slides to serve
students is difficult due to the multi-modal nature of slide content and the
heterogeneous teaching actions. We study the problem of discovering effective
designs that convert a slide into an interactive lecture. We develop
Slide2Lecture, a tuning-free and knowledge-regulated intelligent tutoring
system that can (1) effectively convert an input lecture slide into a
structured teaching agenda consisting of a set of heterogeneous teaching
actions; (2) create and manage an interactive lecture that generates responsive
interactions catering to student learning demands while regulating the
interactions to follow teaching actions. Slide2Lecture contains a complete
pipeline for learners to obtain an interactive classroom experience to learn
the slide. For teachers and developers, Slide2Lecture enables customization to
cater to personalized demands. The evaluation rated by annotators and students
shows that Slide2Lecture is effective in outperforming the remaining
implementation. Slide2Lecture's online deployment has made more than 200K
interaction with students in the 3K lecture sessions. We open source
Slide2Lecture's implementation in
https://anonymous.4open.science/r/slide2lecture-4210/.",2024-09-11 16:03:09+00:00
Demo: SGCode: A Flexible Prompt-Optimizing System for Secure Generation of Code,"This paper introduces SGCode, a flexible prompt-optimizing system to generate
secure code with large language models (LLMs). SGCode integrates recent
prompt-optimization approaches with LLMs in a unified system accessible through
front-end and back-end APIs, enabling users to 1) generate secure code, which
is free of vulnerabilities, 2) review and share security analysis, and 3)
easily switch from one prompt optimization approach to another, while providing
insights on model and system performance. We populated SGCode on an AWS server
with PromSec, an approach that optimizes prompts by combining an LLM and
security tools with a lightweight generative adversarial graph neural network
to detect and fix security vulnerabilities in the generated code. Extensive
experiments show that SGCode is practical as a public tool to gain insights
into the trade-offs between model utility, secure code generation, and system
cost. SGCode has only a marginal cost compared with prompting LLMs. SGCode is
available at: http://3.131.141.63:8501/.",2024-09-11 15:56:15+00:00
Event-based Mosaicing Bundle Adjustment,"We tackle the problem of mosaicing bundle adjustment (i.e., simultaneous
refinement of camera orientations and scene map) for a purely rotating event
camera. We formulate the problem as a regularized non-linear least squares
optimization. The objective function is defined using the linearized event
generation model in the camera orientations and the panoramic gradient map of
the scene. We show that this BA optimization has an exploitable block-diagonal
sparsity structure, so that the problem can be solved efficiently. To the best
of our knowledge, this is the first work to leverage such sparsity to speed up
the optimization in the context of event-based cameras, without the need to
convert events into image-like representations. We evaluate our method, called
EMBA, on both synthetic and real-world datasets to show its effectiveness (50%
photometric error decrease), yielding results of unprecedented quality. In
addition, we demonstrate EMBA using high spatial resolution event cameras,
yielding delicate panoramas in the wild, even without an initial map. Project
page: https://github.com/tub-rip/emba",2024-09-11 15:53:01+00:00
Quantifying Knee Cartilage Shape and Lesion: From Image to Metrics,"Imaging features of knee articular cartilage have been shown to be potential
imaging biomarkers for knee osteoarthritis. Despite recent methodological
advancements in image analysis techniques like image segmentation,
registration, and domain-specific image computing algorithms, only a few works
focus on building fully automated pipelines for imaging feature extraction. In
this study, we developed a deep-learning-based medical image analysis
application for knee cartilage morphometrics, CartiMorph Toolbox (CMT). We
proposed a 2-stage joint template learning and registration network, CMT-reg.
We trained the model using the OAI-ZIB dataset and assessed its performance in
template-to-image registration. The CMT-reg demonstrated competitive results
compared to other state-of-the-art models. We integrated the proposed model
into an automated pipeline for the quantification of cartilage shape and lesion
(full-thickness cartilage loss, specifically). The toolbox provides a
comprehensive, user-friendly solution for medical image analysis and data
visualization. The software and models are available at
https://github.com/YongchengYAO/CMT-AMAI24paper .",2024-09-11 15:48:18+00:00
Training-Free Guidance for Discrete Diffusion Models for Molecular Generation,"Training-free guidance methods for continuous data have seen an explosion of
interest due to the fact that they enable foundation diffusion models to be
paired with interchangable guidance models. Currently, equivalent guidance
methods for discrete diffusion models are unknown. We present a framework for
applying training-free guidance to discrete data and demonstrate its utility on
molecular graph generation tasks using the discrete diffusion model
architecture of DiGress. We pair this model with guidance functions that return
the proportion of heavy atoms that are a specific atom type and the molecular
weight of the heavy atoms and demonstrate our method's ability to guide the
data generation.",2024-09-11 15:43:47+00:00
Securing Vision-Language Models with a Robust Encoder Against Jailbreak and Adversarial Attacks,"Large Vision-Language Models (LVLMs), trained on multimodal big datasets,
have significantly advanced AI by excelling in vision-language tasks. However,
these models remain vulnerable to adversarial attacks, particularly jailbreak
attacks, which bypass safety protocols and cause the model to generate
misleading or harmful responses. This vulnerability stems from both the
inherent susceptibilities of LLMs and the expanded attack surface introduced by
the visual modality. We propose Sim-CLIP+, a novel defense mechanism that
adversarially fine-tunes the CLIP vision encoder by leveraging a Siamese
architecture. This approach maximizes cosine similarity between perturbed and
clean samples, facilitating resilience against adversarial manipulations.
Sim-CLIP+ offers a plug-and-play solution, allowing seamless integration into
existing LVLM architectures as a robust vision encoder. Unlike previous
defenses, our method requires no structural modifications to the LVLM and
incurs minimal computational overhead. Sim-CLIP+ demonstrates effectiveness
against both gradient-based adversarial attacks and various jailbreak
techniques. We evaluate Sim-CLIP+ against three distinct jailbreak attack
strategies and perform clean evaluations using standard downstream datasets,
including COCO for image captioning and OKVQA for visual question answering.
Extensive experiments demonstrate that Sim-CLIP+ maintains high clean accuracy
while substantially improving robustness against both gradient-based
adversarial attacks and jailbreak techniques. Our code and robust vision
encoders are available at
https://github.com/speedlab-git/Robust-Encoder-against-Jailbreak-attack.git.",2024-09-11 15:39:42+00:00
Federated Impression for Learning with Distributed Heterogeneous Data,"Standard deep learning-based classification approaches may not always be
practical in real-world clinical applications, as they require a centralized
collection of all samples. Federated learning (FL) provides a paradigm that can
learn from distributed datasets across clients without requiring them to share
data, which can help mitigate privacy and data ownership issues. In FL,
sub-optimal convergence caused by data heterogeneity is common among data from
different health centers due to the variety in data collection protocols and
patient demographics across centers. Through experimentation in this study, we
show that data heterogeneity leads to the phenomenon of catastrophic forgetting
during local training. We propose FedImpres which alleviates catastrophic
forgetting by restoring synthetic data that represents the global information
as federated impression. To achieve this, we distill the global model resulting
from each communication round. Subsequently, we use the synthetic data
alongside the local data to enhance the generalization of local training.
Extensive experiments show that the proposed method achieves state-of-the-art
performance on both the BloodMNIST and Retina datasets, which contain label
imbalance and domain shift, with an improvement in classification accuracy of
up to 20%.",2024-09-11 15:37:52+00:00
The Role of Explainable AI in Revolutionizing Human Health Monitoring,"The complex nature of disease mechanisms and the variability of patient
symptoms present significant obstacles in developing effective diagnostic
tools. Although machine learning has made considerable advances in medical
diagnosis, its decision-making processes frequently lack transparency, which
can jeopardize patient outcomes. This underscores the critical need for
Explainable AI (XAI), which not only offers greater clarity but also has the
potential to significantly improve patient care. In this literature review, we
conduct a detailed analysis of analyzing XAI methods identified through
searches across various databases, focusing on chronic conditions such as
Parkinson's, stroke, depression, cancer, heart disease, and Alzheimer's
disease. The literature search revealed the application of 9 trending XAI
algorithms in the field of healthcare and highlighted the pros and cons of each
of them. Thus, the article is concluded with a critical appraisal of the
challenges and future research opportunities for XAI in human health
monitoring.",2024-09-11 15:31:40+00:00
Online Decision MetaMorphFormer: A Casual Transformer-Based Reinforcement Learning Framework of Universal Embodied Intelligence,"Interactive artificial intelligence in the motion control field is an
interesting topic, especially when universal knowledge is adaptive to multiple
tasks and universal environments. Despite there being increasing efforts in the
field of Reinforcement Learning (RL) with the aid of transformers, most of them
might be limited by the offline training pipeline, which prohibits exploration
and generalization abilities. To address this limitation, we propose the
framework of Online Decision MetaMorphFormer (ODM) which aims to achieve
self-awareness, environment recognition, and action planning through a unified
model architecture. Motivated by cognitive and behavioral psychology, an ODM
agent is able to learn from others, recognize the world, and practice itself
based on its own experience. ODM can also be applied to any arbitrary agent
with a multi-joint body, located in different environments, and trained with
different types of tasks using large-scale pre-trained datasets. Through the
use of pre-trained datasets, ODM can quickly warm up and learn the necessary
knowledge to perform the desired task, while the target environment continues
to reinforce the universal policy. Extensive online experiments as well as
few-shot and zero-shot environmental tests are used to verify ODM's performance
and generalization ability. The results of our study contribute to the study of
general artificial intelligence in embodied and cognitive fields. Code,
results, and video examples can be found on the website
\url{https://rlodm.github.io/odm/}.",2024-09-11 15:22:43+00:00
A Framework for Predicting the Impact of Game Balance Changes through Meta Discovery,"A metagame is a collection of knowledge that goes beyond the rules of a game.
In competitive, team-based games like Pok\'emon or League of Legends, it refers
to the set of current dominant characters and/or strategies within the player
base. Developer changes to the balance of the game can have drastic and
unforeseen consequences on these sets of meta characters. A framework for
predicting the impact of balance changes could aid developers in making more
informed balance decisions. In this paper we present such a Meta Discovery
framework, leveraging Reinforcement Learning for automated testing of balance
changes. Our results demonstrate the ability to predict the outcome of balance
changes in Pok\'emon Showdown, a collection of competitive Pok\'emon tiers,
with high accuracy.",2024-09-11 15:20:43+00:00
Benchmarking 2D Egocentric Hand Pose Datasets,"Hand pose estimation from egocentric video has broad implications across
various domains, including human-computer interaction, assistive technologies,
activity recognition, and robotics, making it a topic of significant research
interest. The efficacy of modern machine learning models depends on the quality
of data used for their training. Thus, this work is devoted to the analysis of
state-of-the-art egocentric datasets suitable for 2D hand pose estimation. We
propose a novel protocol for dataset evaluation, which encompasses not only the
analysis of stated dataset characteristics and assessment of data quality, but
also the identification of dataset shortcomings through the evaluation of
state-of-the-art hand pose estimation models. Our study reveals that despite
the availability of numerous egocentric databases intended for 2D hand pose
estimation, the majority are tailored for specific use cases. There is no ideal
benchmark dataset yet; however, H2O and GANerated Hands datasets emerge as the
most promising real and synthetic datasets, respectively.",2024-09-11 15:18:11+00:00
"Explanation, Debate, Align: A Weak-to-Strong Framework for Language Model Generalization","The rapid advancement of artificial intelligence systems has brought the
challenge of AI alignment to the forefront of research, particularly in complex
decision-making and task execution. As these systems surpass human-level
performance in sophisticated problems, ensuring their alignment with human
values, intentions, and ethical guidelines becomes crucial. Building on
previous work in explanation generation for human-agent alignment, we address
the more complex dynamics of multi-agent systems and human-AI teams. This paper
introduces a novel approach to model alignment through weak-to-strong
generalization in the context of language models. We present a framework where
a strong model facilitates the improvement of a weaker model, bridging the gap
between explanation generation and model alignment. Our method, formalized as a
facilitation function, allows for the transfer of capabilities from advanced
models to less capable ones without direct access to extensive training data.
Our results suggest that this facilitation-based approach not only enhances
model performance but also provides insights into the nature of model alignment
and the potential for scalable oversight of AI systems.",2024-09-11 15:16:25+00:00
Learning to Compress Contexts for Efficient Knowledge-based Visual Question Answering,"Multimodal Large Language Models (MLLMs) have demonstrated great zero-shot
performance on visual question answering (VQA). However, when it comes to
knowledge-based VQA (KB-VQA), MLLMs may lack human commonsense or specialized
domain knowledge to answer such questions and require obtaining necessary
information from external knowledge sources. Previous works like
Retrival-Augmented VQA-v2 (RAVQA-v2) focus on utilizing as much input
information, such as image-based textual descriptions and retrieved knowledge,
as possible to improve performance, but they all overlook the issue that with
the number of input tokens increasing, inference efficiency significantly
decreases, which contradicts the demands of practical applications. To address
this issue, we propose Retrieval-Augmented MLLM with Compressed Contexts
(RACC). RACC learns to compress and aggregate retrieved contexts, from which it
generates a compact modulation in the form of Key-Value (KV) cache. This
modulation is then used to adapt the downstream frozen MLLM, thereby achieving
effective and efficient inference. RACC achieves a state-of-the-art (SOTA)
performance of 62.9% on OK-VQA. Moreover, it significantly reduces inference
latency by 22.0%-59.7% compared to the prominent RAVQA-v2. Abundant experiments
show RACC's broad applicability. It is compatible with various off-the-shelf
MLLMs and can also handle different knowledge sources including textual and
multimodal documents.",2024-09-11 15:11:39+00:00
Current Symmetry Group Equivariant Convolution Frameworks for Representation Learning,"Euclidean deep learning is often inadequate for addressing real-world signals
where the representation space is irregular and curved with complex topologies.
Interpreting the geometric properties of such feature spaces has become
paramount in obtaining robust and compact feature representations that remain
unaffected by nontrivial geometric transformations, which vanilla CNNs cannot
effectively handle. Recognizing rotation, translation, permutation, or scale
symmetries can lead to equivariance properties in the learned representations.
This has led to notable advancements in computer vision and machine learning
tasks under the framework of geometric deep learning, as compared to their
invariant counterparts. In this report, we emphasize the importance of symmetry
group equivariant deep learning models and their realization of
convolution-like operations on graphs, 3D shapes, and non-Euclidean spaces by
leveraging group theory and symmetry. We categorize them as regular, steerable,
and PDE-based convolutions and thoroughly examine the inherent symmetries of
their input spaces and ensuing representations. We also outline the
mathematical link between group convolutions or message aggregation operations
and the concept of equivariance. The report also highlights various datasets,
their application scopes, limitations, and insightful observations on future
directions to serve as a valuable reference and stimulate further research in
this emerging discipline.",2024-09-11 15:07:18+00:00
ART: Artifact Removal Transformer for Reconstructing Noise-Free Multichannel Electroencephalographic Signals,"Artifact removal in electroencephalography (EEG) is a longstanding challenge
that significantly impacts neuroscientific analysis and brain-computer
interface (BCI) performance. Tackling this problem demands advanced algorithms,
extensive noisy-clean training data, and thorough evaluation strategies. This
study presents the Artifact Removal Transformer (ART), an innovative EEG
denoising model employing transformer architecture to adeptly capture the
transient millisecond-scale dynamics characteristic of EEG signals. Our
approach offers a holistic, end-to-end denoising solution for diverse artifact
types in multichannel EEG data. We enhanced the generation of noisy-clean EEG
data pairs using an independent component analysis, thus fortifying the
training scenarios critical for effective supervised learning. We performed
comprehensive validations using a wide range of open datasets from various BCI
applications, employing metrics like mean squared error and signal-to-noise
ratio, as well as sophisticated techniques such as source localization and EEG
component classification. Our evaluations confirm that ART surpasses other
deep-learning-based artifact removal methods, setting a new benchmark in EEG
signal processing. This advancement not only boosts the accuracy and
reliability of artifact removal but also promises to catalyze further
innovations in the field, facilitating the study of brain dynamics in
naturalistic environments.",2024-09-11 15:05:40+00:00
Statistically Valid Information Bottleneck via Multiple Hypothesis Testing,"The information bottleneck (IB) problem is a widely studied framework in
machine learning for extracting compressed features that are informative for
downstream tasks. However, current approaches to solving the IB problem rely on
a heuristic tuning of hyperparameters, offering no guarantees that the learned
features satisfy information-theoretic constraints. In this work, we introduce
a statistically valid solution to this problem, referred to as IB via multiple
hypothesis testing (IB-MHT), which ensures that the learned features meet the
IB constraints with high probability, regardless of the size of the available
dataset. The proposed methodology builds on Pareto testing and learn-then-test
(LTT), and it wraps around existing IB solvers to provide statistical
guarantees on the IB constraints. We demonstrate the performance of IB-MHT on
classical and deterministic IB formulations, validating the effectiveness of
IB-MHT in outperforming conventional methods in terms of statistical robustness
and reliability.",2024-09-11 15:04:32+00:00
Efficient and Unbiased Sampling of Boltzmann Distributions via Consistency Models,"Diffusion models have shown promising potential for advancing Boltzmann
Generators. However, two critical challenges persist: (1) inherent errors in
samples due to model imperfections, and (2) the requirement of hundreds of
functional evaluations (NFEs) to achieve high-quality samples. While existing
solutions like importance sampling and distillation address these issues
separately, they are often incompatible, as most distillation models lack the
necessary density information for importance sampling. This paper introduces a
novel sampling method that effectively combines Consistency Models (CMs) with
importance sampling. We evaluate our approach on both synthetic energy
functions and equivariant n-body particle systems. Our method produces unbiased
samples using only 6-25 NFEs while achieving a comparable Effective Sample Size
(ESS) to Denoising Diffusion Probabilistic Models (DDPMs) that require
approximately 100 NFEs.",2024-09-11 15:02:52+00:00
"Three-Dimensional, Multimodal Synchrotron Data for Machine Learning Applications","Machine learning techniques are being increasingly applied in medical and
physical sciences across a variety of imaging modalities; however, an important
issue when developing these tools is the availability of good quality training
data. Here we present a unique, multimodal synchrotron dataset of a bespoke
zinc-doped Zeolite 13X sample that can be used to develop advanced deep
learning and data fusion pipelines. Multi-resolution micro X-ray computed
tomography was performed on a zinc-doped Zeolite 13X fragment to characterise
its pores and features, before spatially resolved X-ray diffraction computed
tomography was carried out to characterise the homogeneous distribution of
sodium and zinc phases. Zinc absorption was controlled to create a simple,
spatially isolated, two-phase material. Both raw and processed data is
available as a series of Zenodo entries. Altogether we present a spatially
resolved, three-dimensional, multimodal, multi-resolution dataset that can be
used for the development of machine learning techniques. Such techniques
include development of super-resolution, multimodal data fusion, and 3D
reconstruction algorithm development.",2024-09-11 15:00:36+00:00
Module-wise Adaptive Adversarial Training for End-to-end Autonomous Driving,"Recent advances in deep learning have markedly improved autonomous driving
(AD) models, particularly end-to-end systems that integrate perception,
prediction, and planning stages, achieving state-of-the-art performance.
However, these models remain vulnerable to adversarial attacks, where
human-imperceptible perturbations can disrupt decision-making processes. While
adversarial training is an effective method for enhancing model robustness
against such attacks, no prior studies have focused on its application to
end-to-end AD models. In this paper, we take the first step in adversarial
training for end-to-end AD models and present a novel Module-wise Adaptive
Adversarial Training (MA2T). However, extending conventional adversarial
training to this context is highly non-trivial, as different stages within the
model have distinct objectives and are strongly interconnected. To address
these challenges, MA2T first introduces Module-wise Noise Injection, which
injects noise before the input of different modules, targeting training models
with the guidance of overall objectives rather than each independent module
loss. Additionally, we introduce Dynamic Weight Accumulation Adaptation, which
incorporates accumulated weight changes to adaptively learn and adjust the loss
weights of each module based on their contributions (accumulated reduction
rates) for better balance and robust training. To demonstrate the efficacy of
our defense, we conduct extensive experiments on the widely-used nuScenes
dataset across several end-to-end AD models under both white-box and black-box
attacks, where our method outperforms other baselines by large margins
(+5-10%). Moreover, we validate the robustness of our defense through
closed-loop evaluation in the CARLA simulation environment, showing improved
resilience even against natural corruption.",2024-09-11 15:00:18+00:00
MEDIC: Towards a Comprehensive Framework for Evaluating LLMs in Clinical Applications,"The rapid development of Large Language Models (LLMs) for healthcare
applications has spurred calls for holistic evaluation beyond frequently-cited
benchmarks like USMLE, to better reflect real-world performance. While
real-world assessments are valuable indicators of utility, they often lag
behind the pace of LLM evolution, likely rendering findings obsolete upon
deployment. This temporal disconnect necessitates a comprehensive upfront
evaluation that can guide model selection for specific clinical applications.
We introduce MEDIC, a framework assessing LLMs across five critical dimensions
of clinical competence: medical reasoning, ethics and bias, data and language
understanding, in-context learning, and clinical safety. MEDIC features a novel
cross-examination framework quantifying LLM performance across areas like
coverage and hallucination detection, without requiring reference outputs. We
apply MEDIC to evaluate LLMs on medical question-answering, safety,
summarization, note generation, and other tasks. Our results show performance
disparities across model sizes, baseline vs medically finetuned models, and
have implications on model selection for applications requiring specific model
strengths, such as low hallucination or lower cost of inference. MEDIC's
multifaceted evaluation reveals these performance trade-offs, bridging the gap
between theoretical capabilities and practical implementation in healthcare
settings, ensuring that the most promising models are identified and adapted
for diverse healthcare applications.",2024-09-11 14:44:51+00:00
Optimizing Neural Network Performance and Interpretability with Diophantine Equation Encoding,"This paper explores the integration of Diophantine equations into neural
network (NN) architectures to improve model interpretability, stability, and
efficiency. By encoding and decoding neural network parameters as integer
solutions to Diophantine equations, we introduce a novel approach that enhances
both the precision and robustness of deep learning models. Our method
integrates a custom loss function that enforces Diophantine constraints during
training, leading to better generalization, reduced error bounds, and enhanced
resilience against adversarial attacks. We demonstrate the efficacy of this
approach through several tasks, including image classification and natural
language processing, where improvements in accuracy, convergence, and
robustness are observed. This study offers a new perspective on combining
mathematical theory and machine learning to create more interpretable and
efficient models.",2024-09-11 14:38:40+00:00
Non-Invasive Glucose Prediction System Enhanced by Mixed Linear Models and Meta-Forests for Domain Generalization,"In this study, we present a non-invasive glucose prediction system that
integrates Near-Infrared (NIR) spectroscopy and millimeter-wave (mm-wave)
sensing. We employ a Mixed Linear Model (MixedLM) to analyze the association
between mm-wave frequency S_21 parameters and blood glucose levels within a
heterogeneous dataset. The MixedLM method considers inter-subject variability
and integrates multiple predictors, offering a more comprehensive analysis than
traditional correlation analysis. Additionally, we incorporate a Domain
Generalization (DG) model, Meta-forests, to effectively handle domain variance
in the dataset, enhancing the model's adaptability to individual differences.
Our results demonstrate promising accuracy in glucose prediction for unseen
subjects, with a mean absolute error (MAE) of 17.47 mg/dL, a root mean square
error (RMSE) of 31.83 mg/dL, and a mean absolute percentage error (MAPE) of
10.88%, highlighting its potential for clinical application. This study marks a
significant step towards developing accurate, personalized, and non-invasive
glucose monitoring systems, contributing to improved diabetes management.",2024-09-11 14:36:33+00:00
Data Augmentation via Latent Diffusion for Saliency Prediction,"Saliency prediction models are constrained by the limited diversity and
quantity of labeled data. Standard data augmentation techniques such as
rotating and cropping alter scene composition, affecting saliency. We propose a
novel data augmentation method for deep saliency prediction that edits natural
images while preserving the complexity and variability of real-world scenes.
Since saliency depends on high-level and low-level features, our approach
involves learning both by incorporating photometric and semantic attributes
such as color, contrast, brightness, and class. To that end, we introduce a
saliency-guided cross-attention mechanism that enables targeted edits on the
photometric properties, thereby enhancing saliency within specific image
regions. Experimental results show that our data augmentation method
consistently improves the performance of various saliency models. Moreover,
leveraging the augmentation features for saliency prediction yields superior
performance on publicly available saliency benchmarks. Our predictions align
closely with human visual attention patterns in the edited images, as validated
by a user study.",2024-09-11 14:36:24+00:00
BLS-GAN: A Deep Layer Separation Framework for Eliminating Bone Overlap in Conventional Radiographs,"Conventional radiography is the widely used imaging technology in diagnosing,
monitoring, and prognosticating musculoskeletal (MSK) diseases because of its
easy availability, versatility, and cost-effectiveness. In conventional
radiographs, bone overlaps are prevalent, and can impede the accurate
assessment of bone characteristics by radiologists or algorithms, posing
significant challenges to conventional and computer-aided diagnoses. This work
initiated the study of a challenging scenario - bone layer separation in
conventional radiographs, in which separate overlapped bone regions enable the
independent assessment of the bone characteristics of each bone layer and lay
the groundwork for MSK disease diagnosis and its automation. This work proposed
a Bone Layer Separation GAN (BLS-GAN) framework that can produce high-quality
bone layer images with reasonable bone characteristics and texture. This
framework introduced a reconstructor based on conventional radiography imaging
principles, which achieved efficient reconstruction and mitigates the recurrent
calculations and training instability issues caused by soft tissue in the
overlapped regions. Additionally, pre-training with synthetic images was
implemented to enhance the stability of both the training process and the
results. The generated images passed the visual Turing test, and improved
performance in downstream tasks. This work affirms the feasibility of
extracting bone layer images from conventional radiographs, which holds promise
for leveraging bone layer separation technology to facilitate more
comprehensive analytical research in MSK diagnosis, monitoring, and prognosis.
Code and dataset will be made available.",2024-09-11 14:34:17+00:00
PaveSAM Segment Anything for Pavement Distress,"Automated pavement monitoring using computer vision can analyze pavement
conditions more efficiently and accurately than manual methods. Accurate
segmentation is essential for quantifying the severity and extent of pavement
defects and consequently, the overall condition index used for prioritizing
rehabilitation and maintenance activities. Deep learning-based segmentation
models are however, often supervised and require pixel-level annotations, which
can be costly and time-consuming. While the recent evolution of zero-shot
segmentation models can generate pixel-wise labels for unseen classes without
any training data, they struggle with irregularities of cracks and textured
pavement backgrounds. This research proposes a zero-shot segmentation model,
PaveSAM, that can segment pavement distresses using bounding box prompts. By
retraining SAM's mask decoder with just 180 images, pavement distress
segmentation is revolutionized, enabling efficient distress segmentation using
bounding box prompts, a capability not found in current segmentation models.
This not only drastically reduces labeling efforts and costs but also showcases
our model's high performance with minimal input, establishing the pioneering
use of SAM in pavement distress segmentation. Furthermore, researchers can use
existing open-source pavement distress images annotated with bounding boxes to
create segmentation masks, which increases the availability and diversity of
segmentation pavement distress datasets.",2024-09-11 14:24:29+00:00
A Unified Contrastive Loss for Self-Training,"Self-training methods have proven to be effective in exploiting abundant
unlabeled data in semi-supervised learning, particularly when labeled data is
scarce. While many of these approaches rely on a cross-entropy loss function
(CE), recent advances have shown that the supervised contrastive loss function
(SupCon) can be more effective. Additionally, unsupervised contrastive learning
approaches have also been shown to capture high quality data representations in
the unsupervised setting. To benefit from these advantages in a semi-supervised
setting, we propose a general framework to enhance self-training methods, which
replaces all instances of CE losses with a unique contrastive loss. By using
class prototypes, which are a set of class-wise trainable parameters, we
recover the probability distributions of the CE setting and show a theoretical
equivalence with it. Our framework, when applied to popular self-training
methods, results in significant performance improvements across three different
datasets with a limited number of labeled data. Additionally, we demonstrate
further improvements in convergence speed, transfer ability, and hyperparameter
stability. The code is available at
\url{https://github.com/AurelienGauffre/semisupcon/}.",2024-09-11 14:22:41+00:00
Exploring User-level Gradient Inversion with a Diffusion Prior,"We explore user-level gradient inversion as a new attack surface in
distributed learning. We first investigate existing attacks on their ability to
make inferences about private information beyond training data reconstruction.
Motivated by the low reconstruction quality of existing methods, we propose a
novel gradient inversion attack that applies a denoising diffusion model as a
strong image prior in order to enhance recovery in the large batch setting.
Unlike traditional attacks, which aim to reconstruct individual samples and
suffer at large batch and image sizes, our approach instead aims to recover a
representative image that captures the sensitive shared semantic information
corresponding to the underlying user. Our experiments with face images
demonstrate the ability of our methods to recover realistic facial images along
with private user attributes.",2024-09-11 14:20:47+00:00
Using Generative Agents to Create Tip Sheets for Investigative Data Reporting,"This paper introduces a system using generative AI agents to create tip
sheets for investigative data reporting. Our system employs three specialized
agents--an analyst, a reporter, and an editor--to collaboratively generate and
refine tips from datasets. We validate this approach using real-world
investigative stories, demonstrating that our agent-based system generally
generates more newsworthy and accurate insights compared to a baseline model
without agents, although some variability was noted between different stories.
Our findings highlight the potential of generative AI to provide leads for
investigative data reporting.",2024-09-11 14:14:15+00:00
TLD-READY: Traffic Light Detection -- Relevance Estimation and Deployment Analysis,"Effective traffic light detection is a critical component of the perception
stack in autonomous vehicles. This work introduces a novel deep-learning
detection system while addressing the challenges of previous work. Utilizing a
comprehensive dataset amalgamation, including the Bosch Small Traffic Lights
Dataset, LISA, the DriveU Traffic Light Dataset, and a proprietary dataset from
Karlsruhe, we ensure a robust evaluation across varied scenarios. Furthermore,
we propose a relevance estimation system that innovatively uses directional
arrow markings on the road, eliminating the need for prior map creation. On the
DriveU dataset, this approach results in 96% accuracy in relevance estimation.
Finally, a real-world evaluation is performed to evaluate the deployment and
generalizing abilities of these models. For reproducibility and to facilitate
further research, we provide the model weights and code:
https://github.com/KASTEL-MobilityLab/traffic-light-detection.",2024-09-11 14:12:44+00:00
Tuning-Free Online Robust Principal Component Analysis through Implicit Regularization,"The performance of the standard Online Robust Principal Component Analysis
(OR-PCA) technique depends on the optimum tuning of the explicit regularizers
and this tuning is dataset sensitive. We aim to remove the dependency on these
tuning parameters by using implicit regularization. We propose to use the
implicit regularization effect of various modified gradient descents to make
OR-PCA tuning free. Our method incorporates three different versions of
modified gradient descent that separately but naturally encourage sparsity and
low-rank structures in the data. The proposed method performs comparable or
better than the tuned OR-PCA for both simulated and real-world datasets.
Tuning-free ORPCA makes it more scalable for large datasets since we do not
require dataset-dependent parameter tuning.",2024-09-11 13:49:06+00:00
RePlay: a Recommendation Framework for Experimentation and Production Use,"Using a single tool to build and compare recommender systems significantly
reduces the time to market for new models. In addition, the comparison results
when using such tools look more consistent. This is why many different tools
and libraries for researchers in the field of recommendations have recently
appeared. Unfortunately, most of these frameworks are aimed primarily at
researchers and require modification for use in production due to the inability
to work on large datasets or an inappropriate architecture. In this demo, we
present our open-source toolkit RePlay - a framework containing an end-to-end
pipeline for building recommender systems, which is ready for production use.
RePlay also allows you to use a suitable stack for the pipeline on each stage:
Pandas, Polars, or Spark. This allows the library to scale computations and
deploy to a cluster. Thus, RePlay allows data scientists to easily move from
research mode to production mode using the same interfaces.",2024-09-11 13:46:52+00:00
CCFExp: Facial Image Synthesis with Cycle Cross-Fusion Diffusion Model for Facial Paralysis Individuals,"Facial paralysis is a debilitating condition that affects the movement of
facial muscles, leading to a significant loss of facial expressions. Currently,
the diagnosis of facial paralysis remains a challenging task, often relying
heavily on the subjective judgment and experience of clinicians, which can
introduce variability and uncertainty in the assessment process. One promising
application in real-life situations is the automatic estimation of facial
paralysis. However, the scarcity of facial paralysis datasets limits the
development of robust machine learning models for automated diagnosis and
therapeutic interventions. To this end, this study aims to synthesize a
high-quality facial paralysis dataset to address this gap, enabling more
accurate and efficient algorithm training. Specifically, a novel Cycle
Cross-Fusion Expression Generative Model (CCFExp) based on the diffusion model
is proposed to combine different features of facial information and enhance the
visual details of facial appearance and texture in facial regions, thus
creating synthetic facial images that accurately represent various degrees and
types of facial paralysis. We have qualitatively and quantitatively evaluated
the proposed method on the commonly used public clinical datasets of facial
paralysis to demonstrate its effectiveness. Experimental results indicate that
the proposed method surpasses state-of-the-art methods, generating more
realistic facial images and maintaining identity consistency.",2024-09-11 13:46:35+00:00
Realistic and Efficient Face Swapping: A Unified Approach with Diffusion Models,"Despite promising progress in face swapping task, realistic swapped images
remain elusive, often marred by artifacts, particularly in scenarios involving
high pose variation, color differences, and occlusion. To address these issues,
we propose a novel approach that better harnesses diffusion models for
face-swapping by making following core contributions. (a) We propose to
re-frame the face-swapping task as a self-supervised, train-time inpainting
problem, enhancing the identity transfer while blending with the target image.
(b) We introduce a multi-step Denoising Diffusion Implicit Model (DDIM)
sampling during training, reinforcing identity and perceptual similarities. (c)
Third, we introduce CLIP feature disentanglement to extract pose, expression,
and lighting information from the target image, improving fidelity. (d)
Further, we introduce a mask shuffling technique during inpainting training,
which allows us to create a so-called universal model for swapping, with an
additional feature of head swapping. Ours can swap hair and even accessories,
beyond traditional face swapping. Unlike prior works reliant on multiple
off-the-shelf models, ours is a relatively unified approach and so it is
resilient to errors in other off-the-shelf models. Extensive experiments on
FFHQ and CelebA datasets validate the efficacy and robustness of our approach,
showcasing high-fidelity, realistic face-swapping with minimal inference time.
Our code is available at https://github.com/Sanoojan/REFace.",2024-09-11 13:43:53+00:00
Multi-Type Preference Learning: Empowering Preference-Based Reinforcement Learning with Equal Preferences,"Preference-Based reinforcement learning (PBRL) learns directly from the
preferences of human teachers regarding agent behaviors without needing
meticulously designed reward functions. However, existing PBRL methods often
learn primarily from explicit preferences, neglecting the possibility that
teachers may choose equal preferences. This neglect may hinder the
understanding of the agent regarding the task perspective of the teacher,
leading to the loss of important information. To address this issue, we
introduce the Equal Preference Learning Task, which optimizes the neural
network by promoting similar reward predictions when the behaviors of two
agents are labeled as equal preferences. Building on this task, we propose a
novel PBRL method, Multi-Type Preference Learning (MTPL), which allows
simultaneous learning from equal preferences while leveraging existing methods
for learning from explicit preferences. To validate our approach, we design
experiments applying MTPL to four existing state-of-the-art baselines across
ten locomotion and robotic manipulation tasks in the DeepMind Control Suite.
The experimental results indicate that simultaneous learning from both equal
and explicit preferences enables the PBRL method to more comprehensively
understand the feedback from teachers, thereby enhancing feedback efficiency.",2024-09-11 13:43:49+00:00
MiniDrive: More Efficient Vision-Language Models with Multi-Level 2D Features as Text Tokens for Autonomous Driving,"Vision-language models (VLMs) serve as general-purpose end-to-end models in
autonomous driving, performing subtasks such as prediction, planning, and
perception through question-and-answer interactions. However, most existing
methods rely on computationally expensive visual encoders and large language
models (LLMs), making them difficult to deploy in real-world scenarios and
real-time applications. Meanwhile, most existing VLMs lack the ability to
process multiple images, making it difficult to adapt to multi-camera
perception in autonomous driving. To address these issues, we propose a novel
framework called MiniDrive, which incorporates our proposed Feature Engineering
Mixture of Experts (FE-MoE) module and Dynamic Instruction Adapter
(DI-Adapter). The FE-MoE effectively maps 2D features into visual token
embeddings before being input into the language model. The DI-Adapter enables
the visual token embeddings to dynamically change with the instruction text
embeddings, resolving the issue of static visual token embeddings for the same
image in previous approaches. Compared to previous works, MiniDrive achieves
state-of-the-art performance in terms of parameter size, floating point
operations, and response efficiency, with the smallest version containing only
83M parameters.",2024-09-11 13:43:01+00:00
TopoMap++: A faster and more space efficient technique to compute projections with topological guarantees,"High-dimensional data, characterized by many features, can be difficult to
visualize effectively. Dimensionality reduction techniques, such as PCA, UMAP,
and t-SNE, address this challenge by projecting the data into a
lower-dimensional space while preserving important relationships. TopoMap is
another technique that excels at preserving the underlying structure of the
data, leading to interpretable visualizations. In particular, TopoMap maps the
high-dimensional data into a visual space, guaranteeing that the 0-dimensional
persistence diagram of the Rips filtration of the visual space matches the one
from the high-dimensional data. However, the original TopoMap algorithm can be
slow and its layout can be too sparse for large and complex datasets. In this
paper, we propose three improvements to TopoMap: 1) a more space-efficient
layout, 2) a significantly faster implementation, and 3) a novel TreeMap-based
representation that makes use of the topological hierarchy to aid the
exploration of the projections. These advancements make TopoMap, now referred
to as TopoMap++, a more powerful tool for visualizing high-dimensional data
which we demonstrate through different use case scenarios.",2024-09-11 13:26:32+00:00
"MRAC Track 1: 2nd Workshop on Multimodal, Generative and Responsible Affective Computing","With the rapid advancements in multimodal generative technology, Affective
Computing research has provoked discussion about the potential consequences of
AI systems equipped with emotional intelligence. Affective Computing involves
the design, evaluation, and implementation of Emotion AI and related
technologies aimed at improving people's lives. Designing a computational model
in affective computing requires vast amounts of multimodal data, including RGB
images, video, audio, text, and physiological signals. Moreover, Affective
Computing research is deeply engaged with ethical considerations at various
stages-from training emotionally intelligent models on large-scale human data
to deploying these models in specific applications. Fundamentally, the
development of any AI system must prioritize its impact on humans, aiming to
augment and enhance human abilities rather than replace them, while drawing
inspiration from human intelligence in a safe and responsible manner. The MRAC
2024 Track 1 workshop seeks to extend these principles from controlled,
small-scale lab environments to real-world, large-scale contexts, emphasizing
responsible development. The workshop also aims to highlight the potential
implications of generative technology, along with the ethical consequences of
its use, to researchers and industry professionals. To the best of our
knowledge, this is the first workshop series to comprehensively address the
full spectrum of multimodal, generative affective computing from a responsible
AI perspective, and this is the second iteration of this workshop. Webpage:
https://react-ws.github.io/2024/",2024-09-11 13:25:42+00:00
EMOdiffhead: Continuously Emotional Control in Talking Head Generation via Diffusion,"The task of audio-driven portrait animation involves generating a talking
head video using an identity image and an audio track of speech. While many
existing approaches focus on lip synchronization and video quality, few tackle
the challenge of generating emotion-driven talking head videos. The ability to
control and edit emotions is essential for producing expressive and realistic
animations. In response to this challenge, we propose EMOdiffhead, a novel
method for emotional talking head video generation that not only enables
fine-grained control of emotion categories and intensities but also enables
one-shot generation. Given the FLAME 3D model's linearity in expression
modeling, we utilize the DECA method to extract expression vectors, that are
combined with audio to guide a diffusion model in generating videos with
precise lip synchronization and rich emotional expressiveness. This approach
not only enables the learning of rich facial information from
emotion-irrelevant data but also facilitates the generation of emotional
videos. It effectively overcomes the limitations of emotional data, such as the
lack of diversity in facial and background information, and addresses the
absence of emotional details in emotion-irrelevant data. Extensive experiments
and user studies demonstrate that our approach achieves state-of-the-art
performance compared to other emotion portrait animation methods.",2024-09-11 13:23:22+00:00
"Alignment of Diffusion Models: Fundamentals, Challenges, and Future","Diffusion models have emerged as the leading paradigm in generative modeling,
excelling in various applications. Despite their success, these models often
misalign with human intentions, generating outputs that may not match text
prompts or possess desired properties. Inspired by the success of alignment in
tuning large language models, recent studies have investigated aligning
diffusion models with human expectations and preferences. This work mainly
reviews alignment of diffusion models, covering advancements in fundamentals of
alignment, alignment techniques of diffusion models, preference benchmarks, and
evaluation for diffusion models. Moreover, we discuss key perspectives on
current challenges and promising future directions on solving the remaining
challenges in alignment of diffusion models. To the best of our knowledge, our
work is the first comprehensive review paper for researchers and engineers to
comprehend, practice, and research alignment of diffusion models.",2024-09-11 13:21:32+00:00
Federated $\mathcal{X}$-armed Bandit with Flexible Personalisation,"This paper introduces a novel approach to personalised federated learning
within the $\mathcal{X}$-armed bandit framework, addressing the challenge of
optimising both local and global objectives in a highly heterogeneous
environment. Our method employs a surrogate objective function that combines
individual client preferences with aggregated global knowledge, allowing for a
flexible trade-off between personalisation and collective learning. We propose
a phase-based elimination algorithm that achieves sublinear regret with
logarithmic communication overhead, making it well-suited for federated
settings. Theoretical analysis and empirical evaluations demonstrate the
effectiveness of our approach compared to existing methods. Potential
applications of this work span various domains, including healthcare, smart
home devices, and e-commerce, where balancing personalisation with global
insights is crucial.",2024-09-11 13:19:41+00:00
Propaganda to Hate: A Multimodal Analysis of Arabic Memes with Multi-Agent LLMs,"In the past decade, social media platforms have been used for information
dissemination and consumption. While a major portion of the content is posted
to promote citizen journalism and public awareness, some content is posted to
mislead users. Among different content types such as text, images, and videos,
memes (text overlaid on images) are particularly prevalent and can serve as
powerful vehicles for propaganda, hate, and humor. In the current literature,
there have been efforts to individually detect such content in memes. However,
the study of their intersection is very limited. In this study, we explore the
intersection between propaganda and hate in memes using a multi-agent LLM-based
approach. We extend the propagandistic meme dataset with coarse and
fine-grained hate labels. Our finding suggests that there is an association
between propaganda and hate in memes. We provide detailed experimental results
that can serve as a baseline for future studies. We will make the experimental
resources publicly available to the community.",2024-09-11 13:04:34+00:00
Single-View 3D Reconstruction via SO(2)-Equivariant Gaussian Sculpting Networks,"This paper introduces SO(2)-Equivariant Gaussian Sculpting Networks (GSNs) as
an approach for SO(2)-Equivariant 3D object reconstruction from single-view
image observations.
  GSNs take a single observation as input to generate a Gaussian splat
representation describing the observed object's geometry and texture. By using
a shared feature extractor before decoding Gaussian colors, covariances,
positions, and opacities, GSNs achieve extremely high throughput (>150FPS).
Experiments demonstrate that GSNs can be trained efficiently using a multi-view
rendering loss and are competitive, in quality, with expensive diffusion-based
reconstruction algorithms. The GSN model is validated on multiple benchmark
experiments. Moreover, we demonstrate the potential for GSNs to be used within
a robotic manipulation pipeline for object-centric grasping.",2024-09-11 13:01:32+00:00
PiTe: Pixel-Temporal Alignment for Large Video-Language Model,"Fueled by the Large Language Models (LLMs) wave, Large Visual-Language Models
(LVLMs) have emerged as a pivotal advancement, bridging the gap between image
and text. However, video making it challenging for LVLMs to perform adequately
due to the complexity of the relationship between language and spatial-temporal
data structure. Recent Large Video-Language Models (LVidLMs) align feature of
static visual data like image into latent space of language feature, by general
multi-modal tasks to leverage abilities of LLMs sufficiently. In this paper, we
explore fine-grained alignment approach via object trajectory for different
modalities across both spatial and temporal dimensions simultaneously. Thus, we
propose a novel LVidLM by trajectory-guided Pixel-Temporal Alignment, dubbed
PiTe, that exhibits promising applicable model property. To achieve
fine-grained video-language alignment, we curate a multi-modal pre-training
dataset PiTe-143k, the dataset provision of moving trajectories in pixel level
for all individual objects, that appear and mention in the video and caption
both, by our automatic annotation pipeline. Meanwhile, PiTe demonstrates
astounding capabilities on myriad video-related multi-modal tasks through beat
the state-of-the-art methods by a large margin.",2024-09-11 12:53:07+00:00
Diff-VPS: Video Polyp Segmentation via a Multi-task Diffusion Network with Adversarial Temporal Reasoning,"Diffusion Probabilistic Models have recently attracted significant attention
in the community of computer vision due to their outstanding performance.
However, while a substantial amount of diffusion-based research has focused on
generative tasks, no work introduces diffusion models to advance the results of
polyp segmentation in videos, which is frequently challenged by polyps' high
camouflage and redundant temporal cues.In this paper, we present a novel
diffusion-based network for video polyp segmentation task, dubbed as Diff-VPS.
We incorporate multi-task supervision into diffusion models to promote the
discrimination of diffusion models on pixel-by-pixel segmentation. This
integrates the contextual high-level information achieved by the joint
classification and detection tasks. To explore the temporal dependency,
Temporal Reasoning Module (TRM) is devised via reasoning and reconstructing the
target frame from the previous frames. We further equip TRM with a generative
adversarial self-supervised strategy to produce more realistic frames and thus
capture better dynamic cues. Extensive experiments are conducted on SUN-SEG,
and the results indicate that our proposed Diff-VPS significantly achieves
state-of-the-art performance. Code is available at
https://github.com/lydia-yllu/Diff-VPS.",2024-09-11 12:51:41+00:00
3DGCQA: A Quality Assessment Database for 3D AI-Generated Contents,"Although 3D generated content (3DGC) offers advantages in reducing production
costs and accelerating design timelines, its quality often falls short when
compared to 3D professionally generated content. Common quality issues
frequently affect 3DGC, highlighting the importance of timely and effective
quality assessment. Such evaluations not only ensure a higher standard of 3DGCs
for end-users but also provide critical insights for advancing generative
technologies. To address existing gaps in this domain, this paper introduces a
novel 3DGC quality assessment dataset, 3DGCQA, built using 7 representative
Text-to-3D generation methods. During the dataset's construction, 50 fixed
prompts are utilized to generate contents across all methods, resulting in the
creation of 313 textured meshes that constitute the 3DGCQA dataset. The
visualization intuitively reveals the presence of 6 common distortion
categories in the generated 3DGCs. To further explore the quality of the 3DGCs,
subjective quality assessment is conducted by evaluators, whose ratings reveal
significant variation in quality across different generation methods.
Additionally, several objective quality assessment algorithms are tested on the
3DGCQA dataset. The results expose limitations in the performance of existing
algorithms and underscore the need for developing more specialized quality
assessment methods. To provide a valuable resource for future research and
development in 3D content generation and quality assessment, the dataset has
been open-sourced in https://github.com/zyj-2000/3DGCQA.",2024-09-11 12:47:40+00:00
Riemannian Federated Learning via Averaging Gradient Stream,"In recent years, federated learning has garnered significant attention as an
efficient and privacy-preserving distributed learning paradigm. In the
Euclidean setting, Federated Averaging (FedAvg) and its variants are a class of
efficient algorithms for expected (empirical) risk minimization. This paper
develops and analyzes a Riemannian Federated Averaging Gradient Stream
(RFedAGS) algorithm, which is a generalization of FedAvg, to problems defined
on a Riemannian manifold. Under standard assumptions, the convergence rate of
RFedAGS with fixed step sizes is proven to be sublinear for an approximate
stationary solution. If decaying step sizes are used, the global convergence is
established. Furthermore, assuming that the objective obeys the Riemannian
Polyak-{\L}ojasiewicz property, the optimal gaps generated by RFedAGS with
fixed step size are linearly decreasing up to a tiny upper bound, meanwhile, if
decaying step sizes are used, then the gaps sublinearly vanish.
  Numerical simulations conducted on synthetic and real-world data demonstrate
the performance of the proposed RFedAGS.",2024-09-11 12:28:42+00:00
Traceable LLM-based validation of statements in knowledge graphs,"This article presents a method for verifying RDF triples using LLMs, with an
emphasis on providing traceable arguments. Because the LLMs cannot currently
reliably identify the origin of the information used to construct the response
to the user query, our approach is to avoid using internal LLM factual
knowledge altogether. Instead, verified RDF statements are compared to chunks
of external documents retrieved through a web search or Wikipedia. To assess
the possible application of this workflow on biosciences content, we evaluated
1,719 positive statements from the BioRED dataset and the same number of newly
generated negative statements. The resulting precision is 88%, and recall is
44%. This indicates that the method requires human oversight. We demonstrate
the method on Wikidata, where a SPARQL query is used to automatically retrieve
statements needing verification. Overall, the results suggest that LLMs could
be used for large-scale verification of statements in KGs, a task previously
unfeasible due to human annotation costs.",2024-09-11 12:27:41+00:00
Watchlist Challenge: 3rd Open-set Face Detection and Identification,"In the current landscape of biometrics and surveillance, the ability to
accurately recognize faces in uncontrolled settings is paramount. The Watchlist
Challenge addresses this critical need by focusing on face detection and
open-set identification in real-world surveillance scenarios. This paper
presents a comprehensive evaluation of participating algorithms, using the
enhanced UnConstrained College Students (UCCS) dataset with new evaluation
protocols. In total, four participants submitted four face detection and nine
open-set face recognition systems. The evaluation demonstrates that while
detection capabilities are generally robust, closed-set identification
performance varies significantly, with models pre-trained on large-scale
datasets showing superior performance. However, open-set scenarios require
further improvement, especially at higher true positive identification rates,
i.e., lower thresholds.",2024-09-11 12:24:15+00:00
Behavioral Cloning Models Reality Check for Autonomous Driving,"How effective are recent advancements in autonomous vehicle perception
systems when applied to real-world autonomous vehicle control? While numerous
vision-based autonomous vehicle systems have been trained and evaluated in
simulated environments, there is a notable lack of real-world validation for
these systems. This paper addresses this gap by presenting the real-world
validation of state-of-the-art perception systems that utilize Behavior Cloning
(BC) for lateral control, processing raw image data to predict steering
commands. The dataset was collected using a scaled research vehicle and tested
on various track setups. Experimental results demonstrate that these methods
predict steering angles with low error margins in real-time, indicating
promising potential for real-world applications.",2024-09-11 12:19:38+00:00
Is merging worth it? Securely evaluating the information gain for causal dataset acquisition,"Merging datasets across institutions is a lengthy and costly procedure,
especially when it involves private information. Data hosts may therefore want
to prospectively gauge which datasets are most beneficial to merge with,
without revealing sensitive information. For causal estimation this is
particularly challenging as the value of a merge will depend not only on the
reduction in epistemic uncertainty but also the improvement in overlap. To
address this challenge, we introduce the first cryptographically secure
information-theoretic approach for quantifying the value of a merge in the
context of heterogeneous treatment effect estimation. We do this by evaluating
the Expected Information Gain (EIG) and utilising multi-party computation to
ensure it can be securely computed without revealing any raw data. As we
demonstrate, this can be used with differential privacy (DP) to ensure privacy
requirements whilst preserving more accurate computation than naive DP alone.
To the best of our knowledge, this work presents the first privacy-preserving
method for dataset acquisition tailored to causal estimation. We demonstrate
the effectiveness and reliability of our method on a range of simulated and
realistic benchmarks. The code is available anonymously.",2024-09-11 12:17:01+00:00
Enhancing CTC-Based Visual Speech Recognition,"This paper presents LiteVSR2, an enhanced version of our previously
introduced efficient approach to Visual Speech Recognition (VSR). Building upon
our knowledge distillation framework from a pre-trained Automatic Speech
Recognition (ASR) model, we introduce two key improvements: a stabilized video
preprocessing technique and feature normalization in the distillation process.
These improvements yield substantial performance gains on the LRS2 and LRS3
benchmarks, positioning LiteVSR2 as the current best CTC-based VSR model
without increasing the volume of training data or computational resources
utilized. Furthermore, we explore the scalability of our approach by examining
performance metrics across varying model complexities and training data
volumes. LiteVSR2 maintains the efficiency of its predecessor while
significantly enhancing accuracy, thereby demonstrating the potential for
resource-efficient advancements in VSR technology.",2024-09-11 12:02:42+00:00
Online Graph Filtering Over Expanding Graphs,"Graph filters are a staple tool for processing signals over graphs in a
multitude of downstream tasks. However, they are commonly designed for graphs
with a fixed number of nodes, despite real-world networks typically grow over
time. This topological evolution is often known up to a stochastic model, thus,
making conventional graph filters ill-equipped to withstand such topological
changes, their uncertainty, as well as the dynamic nature of the incoming data.
To tackle these issues, we propose an online graph filtering framework by
relying on online learning principles. We design filters for scenarios where
the topology is both known and unknown, including a learner adaptive to such
evolution. We conduct a regret analysis to highlight the role played by the
different components such as the online algorithm, the filter order, and the
growing graph model. Numerical experiments with synthetic and real data
corroborate the proposed approach for graph signal inference tasks and show a
competitive performance w.r.t. baselines and state-of-the-art alternatives.",2024-09-11 11:50:16+00:00
Heterogeneity-Aware Coordination for Federated Learning via Stitching Pre-trained blocks,"Federated learning (FL) coordinates multiple devices to collaboratively train
a shared model while preserving data privacy. However, large memory footprint
and high energy consumption during the training process excludes the low-end
devices from contributing to the global model with their own data, which
severely deteriorates the model performance in real-world scenarios. In this
paper, we propose FedStitch, a hierarchical coordination framework for
heterogeneous federated learning with pre-trained blocks. Unlike the
traditional approaches that train the global model from scratch, for a new
task, FedStitch composes the global model via stitching pre-trained blocks.
Specifically, each participating client selects the most suitable block based
on their local data from the candidate pool composed of blocks from pre-trained
models. The server then aggregates the optimal block for stitching. This
process iterates until a new stitched network is generated. Except for the new
training paradigm, FedStitch consists of the following three core components:
1) an RL-weighted aggregator, 2) a search space optimizer deployed on the
server side, and 3) a local energy optimizer deployed on each participating
client. The RL-weighted aggregator helps to select the right block in the
non-IID scenario, while the search space optimizer continuously reduces the
size of the candidate block pool during stitching. Meanwhile, the local energy
optimizer is designed to minimize energy consumption of each client while
guaranteeing the overall training progress. The results demonstrate that
compared to existing approaches, FedStitch improves the model accuracy up to
20.93%. At the same time, it achieves up to 8.12% speedup, reduces the memory
footprint up to 79.5%, and achieves 89.41% energy saving at most during the
learning procedure.",2024-09-11 11:47:50+00:00
ThermalGaussian: Thermal 3D Gaussian Splatting,"Thermography is especially valuable for the military and other users of
surveillance cameras. Some recent methods based on Neural Radiance Fields
(NeRF) are proposed to reconstruct the thermal scenes in 3D from a set of
thermal and RGB images. However, unlike NeRF, 3D Gaussian splatting (3DGS)
prevails due to its rapid training and real-time rendering. In this work, we
propose ThermalGaussian, the first thermal 3DGS approach capable of rendering
high-quality images in RGB and thermal modalities. We first calibrate the RGB
camera and the thermal camera to ensure that both modalities are accurately
aligned. Subsequently, we use the registered images to learn the multimodal 3D
Gaussians. To prevent the overfitting of any single modality, we introduce
several multimodal regularization constraints. We also develop smoothing
constraints tailored to the physical characteristics of the thermal modality.
Besides, we contribute a real-world dataset named RGBT-Scenes, captured by a
hand-hold thermal-infrared camera, facilitating future research on thermal
scene reconstruction. We conduct comprehensive experiments to show that
ThermalGaussian achieves photorealistic rendering of thermal images and
improves the rendering quality of RGB images. With the proposed multimodal
regularization constraints, we also reduced the model's storage cost by 90\%.
The code and dataset will be released.",2024-09-11 11:45:57+00:00
A Survey of Anomaly Detection in In-Vehicle Networks,"Modern vehicles are equipped with Electronic Control Units (ECU) that are
used for controlling important vehicle functions including safety-critical
operations. ECUs exchange information via in-vehicle communication buses, of
which the Controller Area Network (CAN bus) is by far the most widespread
representative. Problems that may occur in the vehicle's physical parts or
malicious attacks may cause anomalies in the CAN traffic, impairing the correct
vehicle operation. Therefore, the detection of such anomalies is vital for
vehicle safety. This paper reviews the research on anomaly detection for
in-vehicle networks, more specifically for the CAN bus. Our main focus is the
evaluation of methods used for CAN bus anomaly detection together with the
datasets used in such analysis. To provide the reader with a more comprehensive
understanding of the subject, we first give a brief review of related studies
on time series-based anomaly detection. Then, we conduct an extensive survey of
recent deep learning-based techniques as well as conventional techniques for
CAN bus anomaly detection. Our comprehensive analysis delves into anomaly
detection algorithms employed in in-vehicle networks, specifically focusing on
their learning paradigms, inherent strengths, and weaknesses, as well as their
efficacy when applied to CAN bus datasets. Lastly, we highlight challenges and
open research problems in CAN bus anomaly detection.",2024-09-11 11:45:18+00:00
"Cyber Deception: State of the art, Trends and Open challenges","The growing interest in cybersecurity has significantly increased articles
designing and implementing various Cyber Deception (CYDEC) mechanisms. This
trend reflects the urgent need for new strategies to address cyber threats
effectively. Since its emergence, CYDEC has established itself as an innovative
defense against attackers, thanks to its proactive and reactive capabilities,
finding applications in numerous real-life scenarios. Despite the considerable
work devoted to CYDEC, the literature still presents significant gaps. In
particular, there has not been (i) a comprehensive analysis of the main
components characterizing CYDEC, (ii) a generic classification covering all
types of solutions, nor (iii) a survey of the current state of the literature
in various contexts. This article aims to fill these gaps through a detailed
review of the main features that comprise CYDEC, developing a comprehensive
classification taxonomy. In addition, the different frameworks used to generate
CYDEC are reviewed, presenting a more comprehensive one. Existing solutions in
the literature using CYDEC, both without Artificial Intelligence (AI) and with
AI, are studied and compared. Finally, the most salient trends of the current
state of the art are discussed, offering a list of pending challenges for
future research.",2024-09-11 11:31:34+00:00
"How Mature is Requirements Engineering for AI-based Systems? A Systematic Mapping Study on Practices, Challenges, and Future Research Directions","Artificial intelligence (AI) permeates all fields of life, which resulted in
new challenges in requirements engineering for artificial intelligence (RE4AI),
e.g., the difficulty in specifying and validating requirements for AI or
considering new quality requirements due to emerging ethical implications. It
is currently unclear if existing RE methods are sufficient or if new ones are
needed to address these challenges. Therefore, our goal is to provide a
comprehensive overview of RE4AI to researchers and practitioners. What has been
achieved so far, i.e., what practices are available, and what research gaps and
challenges still need to be addressed? To achieve this, we conducted a
systematic mapping study combining query string search and extensive
snowballing. The extracted data was aggregated, and results were synthesized
using thematic analysis. Our selection process led to the inclusion of 126
primary studies. Existing RE4AI research focuses mainly on requirements
analysis and elicitation, with most practices applied in these areas.
Furthermore, we identified requirements specification, explainability, and the
gap between machine learning engineers and end-users as the most prevalent
challenges, along with a few others. Additionally, we proposed seven potential
research directions to address these challenges. Practitioners can use our
results to identify and select suitable RE methods for working on their
AI-based systems, while researchers can build on the identified gaps and
research directions to push the field forward.",2024-09-11 11:28:16+00:00
Applying Multi-Fidelity Bayesian Optimization in Chemistry: Open Challenges and Major Considerations,"Multi fidelity Bayesian optimization (MFBO) leverages experimental and or
computational data of varying quality and resource cost to optimize towards
desired maxima cost effectively. This approach is particularly attractive for
chemical discovery due to MFBO's ability to integrate diverse data sources.
Here, we investigate the application of MFBO to accelerate the identification
of promising molecules or materials. We specifically analyze the conditions
under which lower fidelity data can enhance performance compared to
single-fidelity problem formulations. We address two key challenges, selecting
the optimal acquisition function, understanding the impact of cost, and data
fidelity correlation. We then discuss how to assess the effectiveness of MFBO
for chemical discovery.",2024-09-11 11:22:17+00:00
A Perspective on AI-Guided Molecular Simulations in VR: Exploring Strategies for Imitation Learning in Hyperdimensional Molecular Systems,"Molecular dynamics simulations are a crucial computational tool for
researchers to understand and engineer molecular structure and function in
areas such as drug discovery, protein engineering, and material design. Despite
their utility, MD simulations are expensive, owing to the high dimensionality
of molecular systems. Interactive molecular dynamics in virtual reality
(iMD-VR) has recently been developed as a 'human-in-the-loop' strategy, which
leverages high-performance computing to accelerate the researcher's ability to
solve the hyperdimensional sampling problem. By providing an immersive 3D
environment that enables visualization and manipulation of real-time molecular
motion, iMD-VR enables researchers and students to efficiently and intuitively
explore and navigate these complex, high-dimensional systems. iMD-VR platforms
offer a unique opportunity to quickly generate rich datasets that capture human
experts' spatial insight regarding molecular structure and function. This paper
explores the possibility of employing user-generated iMD-VR datasets to train
AI agents via imitation learning (IL). IL is an important technique in robotics
that enables agents to mimic complex behaviors from expert demonstrations, thus
circumventing the need for explicit programming or intricate reward design. We
review the utilization of IL for manipulation tasks in robotics and discuss how
iMD-VR recordings could be used to train IL models for solving specific
molecular 'tasks'. We then investigate how such approaches could be applied to
the data captured from iMD-VR recordings. Finally, we outline the future
research directions and potential challenges of using AI agents to augment
human expertise to efficiently navigate conformational spaces, highlighting how
this approach could provide valuable insight across domains such as materials
science, protein engineering, and computer-aided drug design.",2024-09-11 11:21:02+00:00
FuXi-2.0: Advancing machine learning weather forecasting model for practical applications,"Machine learning (ML) models have become increasingly valuable in weather
forecasting, providing forecasts that not only lower computational costs but
often match or exceed the accuracy of traditional numerical weather prediction
(NWP) models. Despite their potential, ML models typically suffer from
limitations such as coarse temporal resolution, typically 6 hours, and a
limited set of meteorological variables, limiting their practical
applicability. To overcome these challenges, we introduce FuXi-2.0, an advanced
ML model that delivers 1-hourly global weather forecasts and includes a
comprehensive set of essential meteorological variables, thereby expanding its
utility across various sectors like wind and solar energy, aviation, and marine
shipping. Our study conducts comparative analyses between ML-based 1-hourly
forecasts and those from the high-resolution forecast (HRES) of the European
Centre for Medium-Range Weather Forecasts (ECMWF) for various practical
scenarios. The results demonstrate that FuXi-2.0 consistently outperforms ECMWF
HRES in forecasting key meteorological variables relevant to these sectors. In
particular, FuXi-2.0 shows superior performance in wind power forecasting
compared to ECMWF HRES, further validating its efficacy as a reliable tool for
scenarios demanding precise weather forecasts. Additionally, FuXi-2.0 also
integrates both atmospheric and oceanic components, representing a significant
step forward in the development of coupled atmospheric-ocean models. Further
comparative analyses reveal that FuXi-2.0 provides more accurate forecasts of
tropical cyclone intensity than its predecessor, FuXi-1.0, suggesting that
there are benefits of an atmosphere-ocean coupled model over atmosphere-only
models.",2024-09-11 11:21:00+00:00
Enhancing Angular Resolution via Directionality Encoding and Geometric Constraints in Brain Diffusion Tensor Imaging,"Diffusion-weighted imaging (DWI) is a type of Magnetic Resonance Imaging
(MRI) technique sensitised to the diffusivity of water molecules, offering the
capability to inspect tissue microstructures and is the only in-vivo method to
reconstruct white matter fiber tracts non-invasively. The DWI signal can be
analysed with the diffusion tensor imaging (DTI) model to estimate the
directionality of water diffusion within voxels. Several scalar metrics,
including axial diffusivity (AD), mean diffusivity (MD), radial diffusivity
(RD), and fractional anisotropy (FA), can be further derived from DTI to
quantitatively summarise the microstructural integrity of brain tissue. These
scalar metrics have played an important role in understanding the organisation
and health of brain tissue at a microscopic level in clinical studies. However,
reliable DTI metrics rely on DWI acquisitions with high gradient directions,
which often go beyond the commonly used clinical protocols. To enhance the
utility of clinically acquired DWI and save scanning time for robust DTI
analysis, this work proposes DirGeo-DTI, a deep learning-based method to
estimate reliable DTI metrics even from a set of DWIs acquired with the minimum
theoretical number (6) of gradient directions. DirGeo-DTI leverages directional
encoding and geometric constraints to facilitate the training process. Two
public DWI datasets were used for evaluation, demonstrating the effectiveness
of the proposed method. Extensive experimental results show that the proposed
method achieves the best performance compared to existing DTI enhancement
methods and potentially reveals further clinical insights with routine clinical
DWI scans.",2024-09-11 11:12:26+00:00
Phy124: Fast Physics-Driven 4D Content Generation from a Single Image,"4D content generation focuses on creating dynamic 3D objects that change over
time. Existing methods primarily rely on pre-trained video diffusion models,
utilizing sampling processes or reference videos. However, these approaches
face significant challenges. Firstly, the generated 4D content often fails to
adhere to real-world physics since video diffusion models do not incorporate
physical priors. Secondly, the extensive sampling process and the large number
of parameters in diffusion models result in exceedingly time-consuming
generation processes. To address these issues, we introduce Phy124, a novel,
fast, and physics-driven method for controllable 4D content generation from a
single image. Phy124 integrates physical simulation directly into the 4D
generation process, ensuring that the resulting 4D content adheres to natural
physical laws. Phy124 also eliminates the use of diffusion models during the 4D
dynamics generation phase, significantly speeding up the process. Phy124 allows
for the control of 4D dynamics, including movement speed and direction, by
manipulating external forces. Extensive experiments demonstrate that Phy124
generates high-fidelity 4D content with significantly reduced inference times,
achieving stateof-the-art performance. The code and generated 4D content are
available at the provided link: https://anonymous.4open.science/r/BBF2/.",2024-09-11 10:41:46+00:00
Coupling Machine Learning Local Predictions with a Computational Fluid Dynamics Solver to Accelerate Transient Buoyant Plume Simulations,"Data-driven methods demonstrate considerable potential for accelerating the
inherently expensive computational fluid dynamics (CFD) solvers. Nevertheless,
pure machine-learning surrogate models face challenges in ensuring physical
consistency and scaling up to address real-world problems. This study presents
a versatile and scalable hybrid methodology, combining CFD and machine
learning, to accelerate long-term incompressible fluid flow simulations without
compromising accuracy. A neural network was trained offline using simulated
data of various two-dimensional transient buoyant plume flows. The objective
was to leverage local features to predict the temporal changes in the pressure
field in comparable scenarios. Due to cell-level predictions, the methodology
was successfully applied to diverse geometries without additional training.
Pressure estimates were employed as initial values to accelerate the
pressure-velocity coupling procedure. The results demonstrated an average
improvement of 94% in the initial guess for solving the Poisson equation. The
first pressure corrector acceleration reached a mean factor of 3, depending on
the iterative solver employed. Our work reveals that machine learning estimates
at the cell level can enhance the efficiency of CFD iterative linear solvers
while maintaining accuracy. Although the scalability of the methodology to more
complex cases has yet to be demonstrated, this study underscores the
prospective value of domain-specific hybrid solvers for CFD.",2024-09-11 10:38:30+00:00
Swin-LiteMedSAM: A Lightweight Box-Based Segment Anything Model for Large-Scale Medical Image Datasets,"Medical imaging is essential for the diagnosis and treatment of diseases,
with medical image segmentation as a subtask receiving high attention. However,
automatic medical image segmentation models are typically task-specific and
struggle to handle multiple scenarios, such as different imaging modalities and
regions of interest. With the introduction of the Segment Anything Model (SAM),
training a universal model for various clinical scenarios has become feasible.
Recently, several Medical SAM (MedSAM) methods have been proposed, but these
models often rely on heavy image encoders to achieve high performance, which
may not be practical for real-world applications due to their high
computational demands and slow inference speed. To address this issue, a
lightweight version of the MedSAM (LiteMedSAM) can provide a viable solution,
achieving high performance while requiring fewer resources and less time. In
this work, we introduce Swin-LiteMedSAM, a new variant of LiteMedSAM. This
model integrates the tiny Swin Transformer as the image encoder, incorporates
multiple types of prompts, including box-based points and scribble generated
from a given bounding box, and establishes skip connections between the image
encoder and the mask decoder. In the \textit{Segment Anything in Medical Images
on Laptop} challenge (CVPR 2024), our approach strikes a good balance between
segmentation performance and speed, demonstrating significantly improved
overall results across multiple modalities compared to the LiteMedSAM baseline
provided by the challenge organizers. Our proposed model achieved a DSC score
of \textbf{0.8678} and an NSD score of \textbf{0.8844} on the validation set.
On the final test set, it attained a DSC score of \textbf{0.8193} and an NSD
score of \textbf{0.8461}, securing fourth place in the challenge.",2024-09-11 10:35:42+00:00
AC-IND: Sparse CT reconstruction based on attenuation coefficient estimation and implicit neural distribution,"Computed tomography (CT) reconstruction plays a crucial role in industrial
nondestructive testing and medical diagnosis. Sparse view CT reconstruction
aims to reconstruct high-quality CT images while only using a small number of
projections, which helps to improve the detection speed of industrial assembly
lines and is also meaningful for reducing radiation in medical scenarios.
Sparse CT reconstruction methods based on implicit neural representations
(INRs) have recently shown promising performance, but still produce artifacts
because of the difficulty of obtaining useful prior information. In this work,
we incorporate a powerful prior: the total number of material categories of
objects. To utilize the prior, we design AC-IND, a self-supervised method based
on Attenuation Coefficient Estimation and Implicit Neural Distribution.
Specifically, our method first transforms the traditional INR from scalar
mapping to probability distribution mapping. Then we design a compact
attenuation coefficient estimator initialized with values from a rough
reconstruction and fast segmentation. Finally, our algorithm finishes the CT
reconstruction by jointly optimizing the estimator and the generated
distribution. Through experiments, we find that our method not only outperforms
the comparative methods in sparse CT reconstruction but also can automatically
generate semantic segmentation maps.",2024-09-11 10:34:41+00:00
Linear Time Complexity Conformers with SummaryMixing for Streaming Speech Recognition,"Automatic speech recognition (ASR) with an encoder equipped with
self-attention, whether streaming or non-streaming, takes quadratic time in the
length of the speech utterance. This slows down training and decoding, increase
their cost, and limit the deployment of the ASR in constrained devices.
SummaryMixing is a promising linear-time complexity alternative to
self-attention for non-streaming speech recognition that, for the first time,
preserves or outperforms the accuracy of self-attention models. Unfortunately,
the original definition of SummaryMixing is not suited to streaming speech
recognition. Hence, this work extends SummaryMixing to a Conformer Transducer
that works in both a streaming and an offline mode. It shows that this new
linear-time complexity speech encoder outperforms self-attention in both
scenarios while requiring less compute and memory during training and decoding.",2024-09-11 10:24:43+00:00
Mamba Policy: Towards Efficient 3D Diffusion Policy with Hybrid Selective State Models,"Diffusion models have been widely employed in the field of 3D manipulation
due to their efficient capability to learn distributions, allowing for precise
prediction of action trajectories. However, diffusion models typically rely on
large parameter UNet backbones as policy networks, which can be challenging to
deploy on resource-constrained devices. Recently, the Mamba model has emerged
as a promising solution for efficient modeling, offering low computational
complexity and strong performance in sequence modeling. In this work, we
propose the Mamba Policy, a lighter but stronger policy that reduces the
parameter count by over 80% compared to the original policy network while
achieving superior performance. Specifically, we introduce the XMamba Block,
which effectively integrates input information with conditional features and
leverages a combination of Mamba and Attention mechanisms for deep feature
extraction. Extensive experiments demonstrate that the Mamba Policy excels on
the Adroit, Dexart, and MetaWorld datasets, requiring significantly fewer
computational resources. Additionally, we highlight the Mamba Policy's enhanced
robustness in long-horizon scenarios compared to baseline methods and explore
the performance of various Mamba variants within the Mamba Policy framework.
Our project page is in https://andycao1125.github.io/mamba_policy/.",2024-09-11 10:21:21+00:00
Recurrent Aggregators in Neural Algorithmic Reasoning,"Neural algorithmic reasoning (NAR) is an emerging field that seeks to design
neural networks that mimic classical algorithmic computations. Today, graph
neural networks (GNNs) are widely used in neural algorithmic reasoners due to
their message passing framework and permutation equivariance. In this extended
abstract, we challenge this design choice, and replace the equivariant
aggregation function with a recurrent neural network. While seemingly
counter-intuitive, this approach has appropriate grounding when nodes have a
natural ordering -- and this is the case frequently in established reasoning
benchmarks like CLRS-30. Indeed, our recurrent NAR (RNAR) model performs very
strongly on such tasks, while handling many others gracefully. A notable
achievement of RNAR is its decisive state-of-the-art result on the Heapsort and
Quickselect tasks, both deemed as a significant challenge for contemporary
neural algorithmic reasoners -- especially the latter, where RNAR achieves a
mean micro-F1 score of 87%.",2024-09-11 09:59:56+00:00
Zero-Shot Text-to-Speech as Golden Speech Generator: A Systematic Framework and its Applicability in Automatic Pronunciation Assessment,"Second language (L2) learners can improve their pronunciation by imitating
golden speech, especially when the speech that aligns with their respective
speech characteristics. This study explores the hypothesis that
learner-specific golden speech generated with zero-shot text-to-speech (ZS-TTS)
techniques can be harnessed as an effective metric for measuring the
pronunciation proficiency of L2 learners. Building on this exploration, the
contributions of this study are at least two-fold: 1) design and development of
a systematic framework for assessing the ability of a synthesis model to
generate golden speech, and 2) in-depth investigations of the effectiveness of
using golden speech in automatic pronunciation assessment (APA). Comprehensive
experiments conducted on the L2-ARCTIC and Speechocean762 benchmark datasets
suggest that our proposed modeling can yield significant performance
improvements with respect to various assessment metrics in relation to some
prior arts. To our knowledge, this study is the first to explore the role of
golden speech in both ZS-TTS and APA, offering a promising regime for
computer-assisted pronunciation training (CAPT).",2024-09-11 09:55:57+00:00
Combined Optimization of Dynamics and Assimilation with End-to-End Learning on Sparse Observations,"Fitting nonlinear dynamical models to sparse and noisy observations is
fundamentally challenging. Identifying dynamics requires data assimilation (DA)
to estimate system states, but DA requires an accurate dynamical model. To
break this deadlock we present CODA, an end-to-end optimization scheme for
jointly learning dynamics and DA directly from sparse and noisy observations. A
neural network is trained to carry out data accurate, efficient and
parallel-in-time DA, while free parameters of the dynamical system are
simultaneously optimized. We carry out end-to-end learning directly on
observation data, introducing a novel learning objective that combines unrolled
auto-regressive dynamics with the data- and self-consistency terms of
weak-constraint 4Dvar DA. By taking into account interactions between new and
existing simulation components over multiple time steps, CODA can recover
initial conditions, fit unknown dynamical parameters and learn neural
network-based PDE terms to match both available observations and
self-consistency constraints. In addition to facilitating end-to-end learning
of dynamics and providing fast, amortized, non-sequential DA, CODA provides
greater robustness to model misspecification than classical DA approaches.",2024-09-11 09:36:15+00:00
Leveraging Unstructured Text Data for Federated Instruction Tuning of Large Language Models,"Federated instruction tuning enables multiple clients to collaboratively
fine-tune a shared large language model (LLM) that can follow humans'
instructions without directly sharing raw data. However, existing literature
impractically requires that all the clients readily hold instruction-tuning
data (i.e., structured instruction-response pairs), which necessitates massive
human annotations since clients' data is usually unstructured text instead.
Addressing this, we propose a novel and flexible framework FedIT-U2S, which can
automatically transform unstructured corpus into structured data for federated
instruction tuning. FedIT-U2S consists two key steps: (1) few-shot
instruction-tuning data generation, where each unstructured data piece together
with several examples is combined to prompt an LLM in generating an
instruction-response pair. To further enhance the flexibility, a
retrieval-based example selection technique is proposed, where the examples are
automatically selected based on the relatedness between the client's data piece
and example pool, bypassing the need of determining examples in advance. (2) A
typical federated instruction tuning process based on the generated data.
Overall, FedIT-U2S can be applied to diverse scenarios as long as the client
holds valuable text corpus, broadening the application scope of federated
instruction tuning. We conduct a series of experiments on three domains
(medicine, knowledge, and math), showing that our proposed FedIT-U2S can
consistently and significantly brings improvement over the base LLM.",2024-09-11 09:31:44+00:00
Unsupervised Novelty Detection Methods Benchmarking with Wavelet Decomposition,"Novelty detection is a critical task in various engineering fields. Numerous
approaches to novelty detection rely on supervised or semi-supervised learning,
which requires labelled datasets for training. However, acquiring labelled
data, when feasible, can be expensive and time-consuming. For these reasons,
unsupervised learning is a powerful alternative that allows performing novelty
detection without needing labelled samples. In this study, numerous
unsupervised machine learning algorithms for novelty detection are compared,
highlighting their strengths and weaknesses in the context of vibration
sensing. The proposed framework uses a continuous metric, unlike most
traditional methods that merely flag anomalous samples without quantifying the
degree of anomaly. Moreover, a new dataset is gathered from an actuator
vibrating at specific frequencies to benchmark the algorithms and evaluate the
framework. Novel conditions are introduced by altering the input wave signal.
Our findings offer valuable insights into the adaptability and robustness of
unsupervised learning techniques for real-world novelty detection applications.",2024-09-11 09:31:28+00:00
LLM-based feature generation from text for interpretable machine learning,"Existing text representations such as embeddings and bag-of-words are not
suitable for rule learning due to their high dimensionality and absent or
questionable feature-level interpretability. This article explores whether
large language models (LLMs) could address this by extracting a small number of
interpretable features from text. We demonstrate this process on two datasets
(CORD-19 and M17+) containing several thousand scientific articles from
multiple disciplines and a target being a proxy for research impact. An
evaluation based on testing for the statistically significant correlation with
research impact has shown that LLama 2-generated features are semantically
meaningful. We consequently used these generated features in text
classification to predict the binary target variable representing the citation
rate for the CORD-19 dataset and the ordinal 5-class target representing an
expert-awarded grade in the M17+ dataset. Machine-learning models trained on
the LLM-generated features provided similar predictive performance to the
state-of-the-art embedding model SciBERT for scientific text. The LLM used only
62 features compared to 768 features in SciBERT embeddings, and these features
were directly interpretable, corresponding to notions such as article
methodological rigor, novelty, or grammatical correctness. As the final step,
we extract a small number of well-interpretable action rules. Consistently
competitive results obtained with the same LLM feature set across both
thematically diverse datasets show that this approach generalizes across
domains.",2024-09-11 09:29:28+00:00
Reranking Laws for Language Generation: A Communication-Theoretic Perspective,"To ensure large language models (LLMs) are used safely, one must reduce their
propensity to hallucinate or to generate unacceptable answers. A simple and
often used strategy is to first let the LLM generate multiple hypotheses and
then employ a reranker to choose the best one. In this paper, we draw a
parallel between this strategy and the use of redundancy to decrease the error
rate in noisy communication channels. We conceptualize the generator as a
sender transmitting multiple descriptions of a message through parallel noisy
channels. The receiver decodes the message by ranking the (potentially
corrupted) descriptions and selecting the one found to be most reliable. We
provide conditions under which this protocol is asymptotically error-free
(i.e., yields an acceptable answer almost surely) even in scenarios where the
reranker is imperfect (governed by Mallows or Zipf-Mandelbrot models) and the
channel distributions are statistically dependent. We use our framework to
obtain reranking laws which we validate empirically on two real-world tasks
using LLMs: text-to-code generation with DeepSeek-Coder 7B and machine
translation of medical data with TowerInstruct 13B.",2024-09-11 09:27:50+00:00
MVLLaVA: An Intelligent Agent for Unified and Flexible Novel View Synthesis,"This paper introduces MVLLaVA, an intelligent agent designed for novel view
synthesis tasks. MVLLaVA integrates multiple multi-view diffusion models with a
large multimodal model, LLaVA, enabling it to handle a wide range of tasks
efficiently. MVLLaVA represents a versatile and unified platform that adapts to
diverse input types, including a single image, a descriptive caption, or a
specific change in viewing azimuth, guided by language instructions for
viewpoint generation. We carefully craft task-specific instruction templates,
which are subsequently used to fine-tune LLaVA. As a result, MVLLaVA acquires
the capability to generate novel view images based on user instructions,
demonstrating its flexibility across diverse tasks. Experiments are conducted
to validate the effectiveness of MVLLaVA, demonstrating its robust performance
and versatility in tackling diverse novel view synthesis challenges.",2024-09-11 09:25:37+00:00
Deep Learning Techniques for Hand Vein Biometrics: A Comprehensive Review,"Biometric authentication has garnered significant attention as a secure and
efficient method of identity verification. Among the various modalities, hand
vein biometrics, including finger vein, palm vein, and dorsal hand vein
recognition, offer unique advantages due to their high accuracy, low
susceptibility to forgery, and non-intrusiveness. The vein patterns within the
hand are highly complex and distinct for each individual, making them an ideal
biometric identifier. Additionally, hand vein recognition is contactless,
enhancing user convenience and hygiene compared to other modalities such as
fingerprint or iris recognition. Furthermore, the veins are internally located,
rendering them less susceptible to damage or alteration, thus enhancing the
security and reliability of the biometric system. The combination of these
factors makes hand vein biometrics a highly effective and secure method for
identity verification. This review paper delves into the latest advancements in
deep learning techniques applied to finger vein, palm vein, and dorsal hand
vein recognition. It encompasses all essential fundamentals of hand vein
biometrics, summarizes publicly available datasets, and discusses
state-of-the-art metrics used for evaluating the three modes. Moreover, it
provides a comprehensive overview of suggested approaches for finger, palm,
dorsal, and multimodal vein techniques, offering insights into the best
performance achieved, data augmentation techniques, and effective transfer
learning methods, along with associated pretrained deep learning models.
Additionally, the review addresses research challenges faced and outlines
future directions and perspectives, encouraging researchers to enhance existing
methods and propose innovative techniques.",2024-09-11 09:25:05+00:00
DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training,"Efficient communication can enhance the overall performance of collaborative
multi-agent reinforcement learning. A common approach is to share observations
through full communication, leading to significant communication overhead.
Existing work attempts to perceive the global state by conducting teammate
model based on local information. However, they ignore that the uncertainty
generated by prediction may lead to difficult training. To address this
problem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC)
protocol, which use an upper bound training to obtain the ideal policy. By
utilizing the demand parsing module, agent can interpret the gain of sending
local message on teammate, and generate customized messages via compute the
correlation between demands and local observation using cross-attention
mechanism. Moreover, our method can adapt to the communication resources of
agents and accelerate the training progress by appropriating the ideal policy
which is trained with joint observation. Experimental results reveal that DCMAC
significantly outperforms the baseline algorithms in both unconstrained and
communication constrained scenarios.",2024-09-11 09:23:27+00:00
Cross-Refine: Improving Natural Language Explanation Generation by Learning in Tandem,"Natural language explanations (NLEs) are vital for elucidating the reasoning
behind large language model (LLM) decisions. Many techniques have been
developed to generate NLEs using LLMs. However, like humans, LLMs might not
always produce optimal NLEs on first attempt. Inspired by human learning
processes, we introduce Cross-Refine, which employs role modeling by deploying
two LLMs as generator and critic, respectively. The generator outputs a first
NLE and then refines this initial explanation using feedback and suggestions
provided by the critic. Cross-Refine does not require any supervised training
data or additional training. We validate Cross-Refine across three NLP tasks
using three state-of-the-art open-source LLMs through automatic and human
evaluation. We select Self-Refine (Madaan et al., 2023) as the baseline, which
only utilizes self-feedback to refine the explanations. Our findings from
automatic evaluation and a user study indicate that Cross-Refine outperforms
Self-Refine. Meanwhile, Cross-Refine can perform effectively with less powerful
LLMs, whereas Self-Refine only yields strong results with ChatGPT.
Additionally, we conduct an ablation study to assess the importance of feedback
and suggestions. Both of them play an important role in refining explanations.
We further evaluate Cross-Refine on a bilingual dataset in English and German.",2024-09-11 09:21:20+00:00
Credibility-Limited Revision for Epistemic Spaces,"We consider credibility-limited revision in the framework of belief change
for epistemic spaces, permitting inconsistent belief sets and inconsistent
beliefs. In this unrestricted setting, the class of credibility-limited
revision operators does not include any AGM revision operators. We extend the
class of credibility-limited revision operators in a way that all AGM revision
operators are included while keeping the original spirit of credibility-limited
revision. Extended credibility-limited revision operators are defined
axiomatically. A semantic characterization of extended credibility-limited
revision operators that employ total preorders on possible worlds is presented.",2024-09-11 09:15:43+00:00
"Attention Down-Sampling Transformer, Relative Ranking and Self-Consistency for Blind Image Quality Assessment","The no-reference image quality assessment is a challenging domain that
addresses estimating image quality without the original reference. We introduce
an improved mechanism to extract local and non-local information from images
via different transformer encoders and CNNs. The utilization of Transformer
encoders aims to mitigate locality bias and generate a non-local representation
by sequentially processing CNN features, which inherently capture local visual
structures. Establishing a stronger connection between subjective and objective
assessments is achieved through sorting within batches of images based on
relative distance information. A self-consistency approach to self-supervision
is presented, explicitly addressing the degradation of no-reference image
quality assessment (NR-IQA) models under equivariant transformations. Our
approach ensures model robustness by maintaining consistency between an image
and its horizontally flipped equivalent. Through empirical evaluation of five
popular image quality assessment datasets, the proposed model outperforms
alternative algorithms in the context of no-reference image quality assessment
datasets, especially on smaller datasets. Codes are available at
\href{https://github.com/mas94/ADTRS}{https://github.com/mas94/ADTRS}",2024-09-11 09:08:43+00:00
A Continual and Incremental Learning Approach for TinyML On-device Training Using Dataset Distillation and Model Size Adaption,"A new algorithm for incremental learning in the context of Tiny Machine
learning (TinyML) is presented, which is optimized for low-performance and
energy efficient embedded devices. TinyML is an emerging field that deploys
machine learning models on resource-constrained devices such as
microcontrollers, enabling intelligent applications like voice recognition,
anomaly detection, predictive maintenance, and sensor data processing in
environments where traditional machine learning models are not feasible. The
algorithm solve the challenge of catastrophic forgetting through the use of
knowledge distillation to create a small, distilled dataset. The novelty of the
method is that the size of the model can be adjusted dynamically, so that the
complexity of the model can be adapted to the requirements of the task. This
offers a solution for incremental learning in resource-constrained
environments, where both model size and computational efficiency are critical
factors. Results show that the proposed algorithm offers a promising approach
for TinyML incremental learning on embedded devices. The algorithm was tested
on five datasets including: CIFAR10, MNIST, CORE50, HAR, Speech Commands. The
findings indicated that, despite using only 43% of Floating Point Operations
(FLOPs) compared to a larger fixed model, the algorithm experienced a
negligible accuracy loss of just 1%. In addition, the presented method is
memory efficient. While state-of-the-art incremental learning is usually very
memory intensive, the method requires only 1% of the original data set.",2024-09-11 09:02:33+00:00
"Advancing On-Device Neural Network Training with TinyPropv2: Dynamic, Sparse, and Efficient Backpropagation","This study introduces TinyPropv2, an innovative algorithm optimized for
on-device learning in deep neural networks, specifically designed for low-power
microcontroller units. TinyPropv2 refines sparse backpropagation by dynamically
adjusting the level of sparsity, including the ability to selectively skip
training steps. This feature significantly lowers computational effort without
substantially compromising accuracy. Our comprehensive evaluation across
diverse datasets CIFAR 10, CIFAR100, Flower, Food, Speech Command, MNIST, HAR,
and DCASE2020 reveals that TinyPropv2 achieves near-parity with full training
methods, with an average accuracy drop of only around 1 percent in most cases.
For instance, against full training, TinyPropv2's accuracy drop is minimal, for
example, only 0.82 percent on CIFAR 10 and 1.07 percent on CIFAR100. In terms
of computational effort, TinyPropv2 shows a marked reduction, requiring as
little as 10 percent of the computational effort needed for full training in
some scenarios, and consistently outperforms other sparse training
methodologies. These findings underscore TinyPropv2's capacity to efficiently
manage computational resources while maintaining high accuracy, positioning it
as an advantageous solution for advanced embedded device applications in the
IoT ecosystem.",2024-09-11 08:56:13+00:00
Fast Medical Shape Reconstruction via Meta-learned Implicit Neural Representations,"Efficient and fast reconstruction of anatomical structures plays a crucial
role in clinical practice. Minimizing retrieval and processing times not only
potentially enhances swift response and decision-making in critical scenarios
but also supports interactive surgical planning and navigation. Recent methods
attempt to solve the medical shape reconstruction problem by utilizing implicit
neural functions. However, their performance suffers in terms of generalization
and computation time, a critical metric for real-time applications. To address
these challenges, we propose to leverage meta-learning to improve the network
parameters initialization, reducing inference time by an order of magnitude
while maintaining high accuracy. We evaluate our approach on three public
datasets covering different anatomical shapes and modalities, namely CT and
MRI. Our experimental results show that our model can handle various input
configurations, such as sparse slices with different orientations and spacings.
Additionally, we demonstrate that our method exhibits strong transferable
capabilities in generalizing to shape domains unobserved at training time.",2024-09-11 08:44:10+00:00
Redundancy-Aware Camera Selection for Indoor Scene Neural Rendering,"Novel view synthesis of indoor scenes can be achieved by capturing a
monocular video sequence of the environment. However, redundant information
caused by artificial movements in the input video data reduces the efficiency
of scene modeling. In this work, we tackle this challenge from the perspective
of camera selection. We begin by constructing a similarity matrix that
incorporates both the spatial diversity of the cameras and the semantic
variation of the images. Based on this matrix, we use the Intra-List Diversity
(ILD) metric to assess camera redundancy, formulating the camera selection task
as an optimization problem. Then we apply a diversity-based sampling algorithm
to optimize the camera selection. We also develop a new dataset, IndoorTraj,
which includes long and complex camera movements captured by humans in virtual
indoor environments, closely mimicking real-world scenarios. Experimental
results demonstrate that our strategy outperforms other approaches under time
and memory constraints. Remarkably, our method achieves performance comparable
to models trained on the full dataset, while using only an average of 15% of
the frames and 75% of the allotted time.",2024-09-11 08:36:49+00:00
Deep intra-operative illumination calibration of hyperspectral cameras,"Hyperspectral imaging (HSI) is emerging as a promising novel imaging modality
with various potential surgical applications. Currently available cameras,
however, suffer from poor integration into the clinical workflow because they
require the lights to be switched off, or the camera to be manually
recalibrated as soon as lighting conditions change. Given this critical
bottleneck, the contribution of this paper is threefold: (1) We demonstrate
that dynamically changing lighting conditions in the operating room
dramatically affect the performance of HSI applications, namely physiological
parameter estimation, and surgical scene segmentation. (2) We propose a novel
learning-based approach to automatically recalibrating hyperspectral images
during surgery and show that it is sufficiently accurate to replace the tedious
process of white reference-based recalibration. (3) Based on a total of 742 HSI
cubes from a phantom, porcine models, and rats we show that our recalibration
method not only outperforms previously proposed methods, but also generalizes
across species, lighting conditions, and image processing tasks. Due to its
simple workflow integration as well as high accuracy, speed, and generalization
capabilities, our method could evolve as a central component in clinical
surgical HSI.",2024-09-11 08:30:03+00:00
CWT-Net: Super-resolution of Histopathology Images Using a Cross-scale Wavelet-based Transformer,"Super-resolution (SR) aims to enhance the quality of low-resolution images
and has been widely applied in medical imaging. We found that the design
principles of most existing methods are influenced by SR tasks based on
real-world images and do not take into account the significance of the
multi-level structure in pathological images, even if they can achieve
respectable objective metric evaluations. In this work, we delve into two
super-resolution working paradigms and propose a novel network called CWT-Net,
which leverages cross-scale image wavelet transform and Transformer
architecture. Our network consists of two branches: one dedicated to learning
super-resolution and the other to high-frequency wavelet features. To generate
high-resolution histopathology images, the Transformer module shares and fuses
features from both branches at various stages. Notably, we have designed a
specialized wavelet reconstruction module to effectively enhance the wavelet
domain features and enable the network to operate in different modes, allowing
for the introduction of additional relevant information from cross-scale
images. Our experimental results demonstrate that our model significantly
outperforms state-of-the-art methods in both performance and visualization
evaluations and can substantially boost the accuracy of image diagnostic
networks.",2024-09-11 08:26:28+00:00
TrialSynth: Generation of Synthetic Sequential Clinical Trial Data,"Analyzing data from past clinical trials is part of the ongoing effort to
optimize the design, implementation, and execution of new clinical trials and
more efficiently bring life-saving interventions to market. While there have
been recent advances in the generation of static context synthetic clinical
trial data, due to both limited patient availability and constraints imposed by
patient privacy needs, the generation of fine-grained synthetic time-sequential
clinical trial data has been challenging. Given that patient trajectories over
an entire clinical trial are of high importance for optimizing trial design and
efforts to prevent harmful adverse events, there is a significant need for the
generation of high-fidelity time-sequence clinical trial data. Here we
introduce TrialSynth, a Variational Autoencoder (VAE) designed to address the
specific challenges of generating synthetic time-sequence clinical trial data.
Distinct from related clinical data VAE methods, the core of our method
leverages Hawkes Processes (HP), which are particularly well-suited for
modeling event-type and time gap prediction needed to capture the structure of
sequential clinical trial data. Our experiments demonstrate that TrialSynth
surpasses the performance of other comparable methods that can generate
sequential clinical trial data, in terms of both fidelity and in enabling the
generation of highly accurate event sequences across multiple real-world
sequential event datasets with small patient source populations when using
minimal external information. Notably, our empirical findings highlight that
TrialSynth not only outperforms existing clinical sequence-generating methods
but also produces data with superior utility while empirically preserving
patient privacy.",2024-09-11 08:20:30+00:00
Ontology-Free General-Domain Knowledge Graph-to-Text Generation Dataset Synthesis using Large Language Model,"Knowledge Graph-to-Text (G2T) generation involves verbalizing structured
knowledge graphs into natural language text. Recent advancements in Pretrained
Language Models (PLMs) have improved G2T performance, but their effectiveness
depends on datasets with precise graph-text alignment. However, the scarcity of
high-quality, general-domain G2T generation datasets restricts progress in the
general-domain G2T generation research. To address this issue, we introduce
Wikipedia Ontology-Free Graph-text dataset (WikiOFGraph), a new large-scale G2T
dataset generated using a novel method that leverages Large Language Model
(LLM) and Data-QuestEval. Our new dataset, which contains 5.85M general-domain
graph-text pairs, offers high graph-text consistency without relying on
external ontologies. Experimental results demonstrate that PLM fine-tuned on
WikiOFGraph outperforms those trained on other datasets across various
evaluation metrics. Our method proves to be a scalable and effective solution
for generating high-quality G2T data, significantly advancing the field of G2T
generation.",2024-09-11 08:16:20+00:00
Understanding Knowledge Drift in LLMs through Misinformation,"Large Language Models (LLMs) have revolutionized numerous applications,
making them an integral part of our digital ecosystem. However, their
reliability becomes critical, especially when these models are exposed to
misinformation. We primarily analyze the susceptibility of state-of-the-art
LLMs to factual inaccuracies when they encounter false information in a QnA
scenario, an issue that can lead to a phenomenon we refer to as *knowledge
drift*, which significantly undermines the trustworthiness of these models. We
evaluate the factuality and the uncertainty of the models' responses relying on
Entropy, Perplexity, and Token Probability metrics. Our experiments reveal that
an LLM's uncertainty can increase up to 56.6% when the question is answered
incorrectly due to the exposure to false information. At the same time,
repeated exposure to the same false information can decrease the models
uncertainty again (-52.8% w.r.t. the answers on the untainted prompts),
potentially manipulating the underlying model's beliefs and introducing a drift
from its original knowledge. These findings provide insights into LLMs'
robustness and vulnerability to adversarial inputs, paving the way for
developing more reliable LLM applications across various domains. The code is
available at https://github.com/afastowski/knowledge_drift.",2024-09-11 08:11:16+00:00
Multimodal Emotion Recognition with Vision-language Prompting and Modality Dropout,"In this paper, we present our solution for the Second Multimodal Emotion
Recognition Challenge Track 1(MER2024-SEMI). To enhance the accuracy and
generalization performance of emotion recognition, we propose several methods
for Multimodal Emotion Recognition. Firstly, we introduce EmoVCLIP, a model
fine-tuned based on CLIP using vision-language prompt learning, designed for
video-based emotion recognition tasks. By leveraging prompt learning on CLIP,
EmoVCLIP improves the performance of pre-trained CLIP on emotional videos.
Additionally, to address the issue of modality dependence in multimodal fusion,
we employ modality dropout for robust information fusion. Furthermore, to aid
Baichuan in better extracting emotional information, we suggest using GPT-4 as
the prompt for Baichuan. Lastly, we utilize a self-training strategy to
leverage unlabeled videos. In this process, we use unlabeled videos with
high-confidence pseudo-labels generated by our model and incorporate them into
the training set. Experimental results demonstrate that our model ranks 1st in
the MER2024-SEMI track, achieving an accuracy of 90.15% on the test set.",2024-09-11 08:06:47+00:00
Edge Modeling Activation Free Fourier Network for Spacecraft Image Denoising,"Spacecraft image denoising is a crucial basic technology closely related to
aerospace research. However, the existing deep learning-based image denoising
methods lack deep consideration of the characteristics of spacecraft image. To
address the aforementioned shortcomings, we analyses spacecraft noise image and
identifies two main characteristics. One is that there are a large number of
low-light images in the obtained spacecraft noise image dataset. Another is
there are a lot of repetitive periodic features in spacecraft image. According
to the above mentioned characteristics, we propose a Edge modeling Activation
Free Fourier Network (EAFFN), which is an efficient spacecraft image denoising
method including Edge Modeling Block (EMB) and Activation Free Fourier Block
(AFFB). We present EMB to effectively model edge and extract structural
information and better identify the spacecraft components from dark regions in
spacecraft noise image. We present AFFB and utilize an improved fast fourier
block to extract repetitive periodic features and long-range information in
noisy spacecraft image. In addition, Simple Gate is designed in our AFFB to
reduce the computational complexity. Extensive experimental results demonstrate
our EAFFN performs competitively to the state-of-the-art on spacecraft noise
image datasets.",2024-09-11 07:35:02+00:00
Legal Fact Prediction: Task Definition and Dataset Construction,"Legal facts refer to the facts that can be proven by acknowledged evidence in
a trial. They form the basis for the determination of court judgments. This
paper introduces a novel NLP task: legal fact prediction, which aims to predict
the legal fact based on a list of evidence. The predicted facts can instruct
the parties and their lawyers involved in a trial to strengthen their
submissions and optimize their strategies during the trial. Moreover, since
real legal facts are difficult to obtain before the final judgment, the
predicted facts also serve as an important basis for legal judgment prediction.
We construct a benchmark dataset consisting of evidence lists and ground-truth
legal facts for real civil loan cases, LFPLoan. Our experiments on this dataset
show that this task is non-trivial and requires further considerable research
efforts.",2024-09-11 07:01:08+00:00
Native vs Non-Native Language Prompting: A Comparative Analysis,"Large language models (LLMs) have shown remarkable abilities in different
fields, including standard Natural Language Processing (NLP) tasks. To elicit
knowledge from LLMs, prompts play a key role, consisting of natural language
instructions. Most open and closed source LLMs are trained on available labeled
and unlabeled resources--digital content such as text, images, audio, and
videos. Hence, these models have better knowledge for high-resourced languages
but struggle with low-resourced languages. Since prompts play a crucial role in
understanding their capabilities, the language used for prompts remains an
important research question. Although there has been significant research in
this area, it is still limited, and less has been explored for medium to
low-resourced languages. In this study, we investigate different prompting
strategies (native vs. non-native) on 11 different NLP tasks associated with 12
different Arabic datasets (9.7K data points). In total, we conducted 197
experiments involving 3 LLMs, 12 datasets, and 3 prompting strategies. Our
findings suggest that, on average, the non-native prompt performs the best,
followed by mixed and native prompts.",2024-09-11 06:59:37+00:00
Pushing the Limits of Vision-Language Models in Remote Sensing without Human Annotations,"The prominence of generalized foundation models in vision-language
integration has witnessed a surge, given their multifarious applications.
Within the natural domain, the procurement of vision-language datasets to
construct these foundation models is facilitated by their abundant availability
and the ease of web crawling. Conversely, in the remote sensing domain,
although vision-language datasets exist, their volume is suboptimal for
constructing robust foundation models. This study introduces an approach to
curate vision-language datasets by employing an image decoding machine learning
model, negating the need for human-annotated labels. Utilizing this
methodology, we amassed approximately 9.6 million vision-language paired
datasets in VHR imagery. The resultant model outperformed counterparts that did
not leverage publicly available vision-language datasets, particularly in
downstream tasks such as zero-shot classification, semantic localization, and
image-text retrieval. Moreover, in tasks exclusively employing vision encoders,
such as linear probing and k-NN classification, our model demonstrated superior
efficacy compared to those relying on domain-specific vision-language datasets.",2024-09-11 06:36:08+00:00
Beyond IID: Optimizing Instruction Learning from the Perspective of Instruction Interaction and Dependency,"With the availability of various instruction datasets, a pivotal challenge is
how to effectively select and integrate these instructions to fine-tune large
language models (LLMs). Previous research mainly focuses on selecting
individual high-quality instructions. However, these works overlooked the joint
interactions and dependencies between different categories of instructions,
leading to suboptimal selection strategies. Moreover, the nature of these
interaction patterns remains largely unexplored, let alone optimize the
instruction set with regard to them. To fill these gaps, in this paper, we: (1)
systemically investigate interaction and dependency patterns between different
categories of instructions, (2) manage to optimize the instruction set
concerning the interaction patterns using a linear programming-based method,
and optimize the learning schema of SFT using an instruction dependency
taxonomy guided curriculum learning. Experimental results across different LLMs
demonstrate improved performance over strong baselines on widely adopted
benchmarks.",2024-09-11 06:27:50+00:00
SoftShadow: Leveraging Penumbra-Aware Soft Masks for Shadow Removal,"Recent advancements in deep learning have yielded promising results for the
image shadow removal task. However, most existing methods rely on binary
pre-generated shadow masks. The binary nature of such masks could potentially
lead to artifacts near the boundary between shadow and non-shadow areas. In
view of this, inspired by the physical model of shadow formation, we introduce
novel soft shadow masks specifically designed for shadow removal. To achieve
such soft masks, we propose a \textit{SoftShadow} framework by leveraging the
prior knowledge of pretrained SAM and integrating physical constraints.
Specifically, we jointly tune the SAM and the subsequent shadow removal network
using penumbra formation constraint loss and shadow removal loss. This
framework enables accurate predictions of penumbra (partially shaded regions)
and umbra (fully shaded regions) areas while simultaneously facilitating
end-to-end shadow removal. Through extensive experiments on popular datasets,
we found that our SoftShadow framework, which generates soft masks, can better
restore boundary artifacts, achieve state-of-the-art performance, and
demonstrate superior generalizability.",2024-09-11 06:12:26+00:00
Retinex-RAWMamba: Bridging Demosaicing and Denoising for Low-Light RAW Image Enhancement,"Low-light image enhancement, particularly in cross-domain tasks such as
mapping from the raw domain to the sRGB domain, remains a significant
challenge. Many deep learning-based methods have been developed to address this
issue and have shown promising results in recent years. However, single-stage
methods, which attempt to unify the complex mapping across both domains,
leading to limited denoising performance. In contrast, two-stage approaches
typically decompose a raw image with color filter arrays (CFA) into a
four-channel RGGB format before feeding it into a neural network. However, this
strategy overlooks the critical role of demosaicing within the Image Signal
Processing (ISP) pipeline, leading to color distortions under varying lighting
conditions, especially in low-light scenarios. To address these issues, we
design a novel Mamba scanning mechanism, called RAWMamba, to effectively handle
raw images with different CFAs. Furthermore, we present a Retinex Decomposition
Module (RDM) grounded in Retinex prior, which decouples illumination from
reflectance to facilitate more effective denoising and automatic non-linear
exposure correction. By bridging demosaicing and denoising, better raw image
enhancement is achieved. Experimental evaluations conducted on public datasets
SID and MCR demonstrate that our proposed RAWMamba achieves state-of-the-art
performance on cross-domain mapping.",2024-09-11 06:12:03+00:00
E-commerce Webpage Recommendation Scheme Base on Semantic Mining and Neural Networks,"In e-commerce websites, web mining web page recommendation technology has
been widely used. However, recommendation solutions often cannot meet the
actual application needs of online shopping users. To address this problem,
this paper proposes an e-commerce web page recommendation solution that
combines semantic web mining and BP neural networks. First, the web logs of
user searches are processed, and 5 features are extracted: content priority,
time consumption priority, online shopping users' explicit/implicit feedback on
the website, recommendation semantics and input deviation amount. Then, these
features are used as input features of the BP neural network to classify and
identify the priority of the final output web page. Finally, the web pages are
sorted according to priority and recommended to users. This project uses book
sales webpages as samples for experiments. The results show that this solution
can quickly and accurately identify the webpages required by users.",2024-09-11 06:03:02+00:00
From optimal score matching to optimal sampling,"The recent, impressive advances in algorithmic generation of high-fidelity
image, audio, and video are largely due to great successes in score-based
diffusion models. A key implementing step is score matching, that is, the
estimation of the score function of the forward diffusion process from training
data. As shown in earlier literature, the total variation distance between the
law of a sample generated from the trained diffusion model and the ground truth
distribution can be controlled by the score matching risk.
  Despite the widespread use of score-based diffusion models, basic theoretical
questions concerning exact optimal statistical rates for score estimation and
its application to density estimation remain open. We establish the sharp
minimax rate of score estimation for smooth, compactly supported densities.
Formally, given \(n\) i.i.d. samples from an unknown \(\alpha\)-H\""{o}lder
density \(f\) supported on \([-1, 1]\), we prove the minimax rate of estimating
the score function of the diffused distribution \(f * \mathcal{N}(0, t)\) with
respect to the score matching loss is \(\frac{1}{nt^2} \wedge
\frac{1}{nt^{3/2}} \wedge (t^{\alpha-1} + n^{-2(\alpha-1)/(2\alpha+1)})\) for
all \(\alpha > 0\) and \(t \ge 0\). As a consequence, it is shown the law
\(\hat{f}\) of a sample generated from the diffusion model achieves the sharp
minimax rate \(\bE(\dTV(\hat{f}, f)^2) \lesssim n^{-2\alpha/(2\alpha+1)}\) for
all \(\alpha > 0\) without any extraneous logarithmic terms which are prevalent
in the literature, and without the need for early stopping which has been
required for all existing procedures to the best of our knowledge.",2024-09-11 06:02:47+00:00
Dynamic Error-Bounded Hierarchical Matrices in Neural Network Compression,"This paper presents an innovative framework that integrates hierarchical
matrix (H-matrix) compression techniques into the structure and training of
Physics-Informed Neural Networks (PINNs). By leveraging the low-rank properties
of matrix sub-blocks, the proposed dynamic, error-bounded H-matrix compression
method significantly reduces computational complexity and storage requirements
without compromising accuracy. This approach is rigorously compared to
traditional compression techniques, such as Singular Value Decomposition (SVD),
pruning, and quantization, demonstrating superior performance, particularly in
maintaining the Neural Tangent Kernel (NTK) properties critical for the
stability and convergence of neural networks. The findings reveal that H-matrix
compression not only enhances training efficiency but also ensures the
scalability and robustness of PINNs for complex, large-scale applications in
physics-based modeling. This work offers a substantial contribution to the
optimization of deep learning models, paving the way for more efficient and
practical implementations of PINNs in real-world scenarios.",2024-09-11 05:55:51+00:00
CPSample: Classifier Protected Sampling for Guarding Training Data During Diffusion,"Diffusion models have a tendency to exactly replicate their training data,
especially when trained on small datasets. Most prior work has sought to
mitigate this problem by imposing differential privacy constraints or masking
parts of the training data, resulting in a notable substantial decrease in
image quality. We present CPSample, a method that modifies the sampling process
to prevent training data replication while preserving image quality. CPSample
utilizes a classifier that is trained to overfit on random binary labels
attached to the training data. CPSample then uses classifier guidance to steer
the generation process away from the set of points that can be classified with
high certainty, a set that includes the training data. CPSample achieves FID
scores of 4.97 and 2.97 on CIFAR-10 and CelebA-64, respectively, without
producing exact replicates of the training data. Unlike prior methods intended
to guard the training images, CPSample only requires training a classifier
rather than retraining a diffusion model, which is computationally cheaper.
Moreover, our technique provides diffusion models with greater robustness
against membership inference attacks, wherein an adversary attempts to discern
which images were in the model's training dataset. We show that CPSample
behaves like a built-in rejection sampler, and we demonstrate its capabilities
to prevent mode collapse in Stable Diffusion.",2024-09-11 05:42:01+00:00
SCLNet: A Scale-Robust Complementary Learning Network for Object Detection in UAV Images,"Most recent UAV (Unmanned Aerial Vehicle) detectors focus primarily on
general challenge such as uneven distribution and occlusion. However, the
neglect of scale challenges, which encompass scale variation and small objects,
continues to hinder object detection in UAV images. Although existing works
propose solutions, they are implicitly modeled and have redundant steps, so
detection performance remains limited. And one specific work addressing the
above scale challenges can help improve the performance of UAV image detectors.
Compared to natural scenes, scale challenges in UAV images happen with problems
of limited perception in comprehensive scales and poor robustness to small
objects. We found that complementary learning is beneficial for the detection
model to address the scale challenges. Therefore, the paper introduces it to
form our scale-robust complementary learning network (SCLNet) in conjunction
with the object detection model. The SCLNet consists of two implementations and
a cooperation method. In detail, one implementation is based on our proposed
scale-complementary decoder and scale-complementary loss function to explicitly
extract complementary information as complement, named comprehensive-scale
complementary learning (CSCL). Another implementation is based on our proposed
contrastive complement network and contrastive complement loss function to
explicitly guide the learning of small objects with the rich texture detail
information of the large objects, named inter-scale contrastive complementary
learning (ICCL). In addition, an end-to-end cooperation (ECoop) between two
implementations and with the detection model is proposed to exploit each
potential.",2024-09-11 05:39:25+00:00
Insight Any Instance: Promptable Instance Segmentation for Remote Sensing Images,"Instance segmentation of remote sensing images (RSIs) is an essential task
for a wide range of applications such as land planning and intelligent
transport. Instance segmentation of RSIs is constantly plagued by the
unbalanced ratio of foreground and background and limited instance size. And
most of the instance segmentation models are based on deep feature learning and
contain operations such as multiple downsampling, which is harmful to instance
segmentation of RSIs, and thus the performance is still limited. Inspired by
the recent superior performance of prompt learning in visual tasks, we propose
a new prompt paradigm to address the above issues. Based on the existing
instance segmentation model, firstly, a local prompt module is designed to mine
local prompt information from original local tokens for specific instances;
secondly, a global-to-local prompt module is designed to model the contextual
information from the global tokens to the local tokens where the instances are
located for specific instances. Finally, a proposal's area loss function is
designed to add a decoupling dimension for proposals on the scale to better
exploit the potential of the above two prompt modules. It is worth mentioning
that our proposed approach can extend the instance segmentation model to a
promptable instance segmentation model, i.e., to segment the instances with the
specific boxes prompt. The time consumption for each promptable instance
segmentation process is only 40 ms. The paper evaluates the effectiveness of
our proposed approach based on several existing models in four instance
segmentation datasets of RSIs, and thorough experiments prove that our proposed
approach is effective for addressing the above issues and is a competitive
model for instance segmentation of RSIs.",2024-09-11 05:31:50+00:00
EVENet: Evidence-based Ensemble Learning for Uncertainty-aware Brain Parcellation Using Diffusion MRI,"In this study, we developed an Evidence-based Ensemble Neural Network, namely
EVENet, for anatomical brain parcellation using diffusion MRI. The key
innovation of EVENet is the design of an evidential deep learning framework to
quantify predictive uncertainty at each voxel during a single inference. Using
EVENet, we obtained accurate parcellation and uncertainty estimates across
different datasets from healthy and clinical populations and with different
imaging acquisitions. The overall network includes five parallel subnetworks,
where each is dedicated to learning the FreeSurfer parcellation for a certain
diffusion MRI parameter. An evidence-based ensemble methodology is then
proposed to fuse the individual outputs. We perform experimental evaluations on
large-scale datasets from multiple imaging sources, including high-quality
diffusion MRI data from healthy adults and clinically diffusion MRI data from
participants with various brain diseases (schizophrenia, bipolar disorder,
attention-deficit/hyperactivity disorder, Parkinson's disease, cerebral small
vessel disease, and neurosurgical patients with brain tumors). Compared to
several state-of-the-art methods, our experimental results demonstrate highly
improved parcellation accuracy across the multiple testing datasets despite the
differences in dMRI acquisition protocols and health conditions. Furthermore,
thanks to the uncertainty estimation, our EVENet approach demonstrates a good
ability to detect abnormal brain regions in patients with lesions, enhancing
the interpretability and reliability of the segmentation results.",2024-09-11 05:26:23+00:00
Improving Anomalous Sound Detection via Low-Rank Adaptation Fine-Tuning of Pre-Trained Audio Models,"Anomalous Sound Detection (ASD) has gained significant interest through the
application of various Artificial Intelligence (AI) technologies in industrial
settings. Though possessing great potential, ASD systems can hardly be readily
deployed in real production sites due to the generalization problem, which is
primarily caused by the difficulty of data collection and the complexity of
environmental factors. This paper introduces a robust ASD model that leverages
audio pre-trained models. Specifically, we fine-tune these models using machine
operation data, employing SpecAug as a data augmentation strategy.
Additionally, we investigate the impact of utilizing Low-Rank Adaptation (LoRA)
tuning instead of full fine-tuning to address the problem of limited data for
fine-tuning. Our experiments on the DCASE2023 Task 2 dataset establish a new
benchmark of 77.75% on the evaluation set, with a significant improvement of
6.48% compared with previous state-of-the-art (SOTA) models, including top-tier
traditional convolutional networks and speech pre-trained models, which
demonstrates the effectiveness of audio pre-trained models with LoRA tuning.
Ablation studies are also conducted to showcase the efficacy of the proposed
scheme.",2024-09-11 05:19:38+00:00
A Practical Theory of Generalization in Selectivity Learning,"Query-driven machine learning models have emerged as a promising estimation
technique for query selectivities. Yet, surprisingly little is known about the
efficacy of these techniques from a theoretical perspective, as there exist
substantial gaps between practical solutions and state-of-the-art (SOTA) theory
based on the Probably Approximately Correct (PAC) learning framework. In this
paper, we aim to bridge the gaps between theory and practice. First, we
demonstrate that selectivity predictors induced by signed measures are
learnable, which relaxes the reliance on probability measures in SOTA theory.
More importantly, beyond the PAC learning framework (which only allows us to
characterize how the model behaves when both training and test workloads are
drawn from the same distribution), we establish, under mild assumptions, that
selectivity predictors from this class exhibit favorable out-of-distribution
(OOD) generalization error bounds.
  These theoretical advances provide us with a better understanding of both the
in-distribution and OOD generalization capabilities of query-driven selectivity
learning, and facilitate the design of two general strategies to improve OOD
generalization for existing query-driven selectivity models. We empirically
verify that our techniques help query-driven selectivity models generalize
significantly better to OOD queries both in terms of prediction accuracy and
query latency performance, while maintaining their superior in-distribution
generalization performance.",2024-09-11 05:10:32+00:00
Towards Predicting Temporal Changes in a Patient's Chest X-ray Images based on Electronic Health Records,"Chest X-ray imaging (CXR) is an important diagnostic tool used in hospitals
to assess patient conditions and monitor changes over time. Generative models,
specifically diffusion-based models, have shown promise in generating realistic
synthetic X-rays. However, these models mainly focus on conditional generation
using single-time-point data, i.e., typically CXRs taken at a specific time
with their corresponding reports, limiting their clinical utility, particularly
for capturing temporal changes. To address this limitation, we propose a novel
framework, EHRXDiff, which predicts future CXR images by integrating previous
CXRs with subsequent medical events, e.g., prescriptions, lab measures, etc.
Our framework dynamically tracks and predicts disease progression based on a
latent diffusion model, conditioned on the previous CXR image and a history of
medical events. We comprehensively evaluate the performance of our framework
across three key aspects, including clinical consistency, demographic
consistency, and visual realism. We demonstrate that our framework generates
high-quality, realistic future images that capture potential temporal changes,
suggesting its potential for further development as a clinical simulation tool.
This could offer valuable insights for patient monitoring and treatment
planning in the medical field.",2024-09-11 04:49:44+00:00
Performance Assessment of Feature Detection Methods for 2-D FS Sonar Imagery,"Underwater robot perception is crucial in scientific subsea exploration and
commercial operations. The key challenges include non-uniform lighting and poor
visibility in turbid environments. High-frequency forward-look sonar cameras
address these issues, by providing high-resolution imagery at maximum range of
tens of meters, despite complexities posed by high degree of speckle noise, and
lack of color and texture. In particular, robust feature detection is an
essential initial step for automated object recognition, localization,
navigation, and 3-D mapping. Various local feature detectors developed for RGB
images are not well-suited for sonar data. To assess their performances, we
evaluate a number of feature detectors using real sonar images from five
different sonar devices. Performance metrics such as detection accuracy, false
positives, and robustness to variations in target characteristics and sonar
devices are applied to analyze the experimental results. The study would
provide a deeper insight into the bottlenecks of feature detection for sonar
data, and developing more effective methods",2024-09-11 04:35:07+00:00
ODYSSEE: Oyster Detection Yielded by Sensor Systems on Edge Electronics,"Oysters are a vital keystone species in coastal ecosystems, providing
significant economic, environmental, and cultural benefits. As the importance
of oysters grows, so does the relevance of autonomous systems for their
detection and monitoring. However, current monitoring strategies often rely on
destructive methods. While manual identification of oysters from video footage
is non-destructive, it is time-consuming, requires expert input, and is further
complicated by the challenges of the underwater environment.
  To address these challenges, we propose a novel pipeline using stable
diffusion to augment a collected real dataset with realistic synthetic data.
This method enhances the dataset used to train a YOLOv10-based vision model.
The model is then deployed and tested on an edge platform in underwater
robotics, achieving a state-of-the-art 0.657 mAP@50 for oyster detection on the
Aqua2 platform.",2024-09-11 04:31:09+00:00
AdvLogo: Adversarial Patch Attack against Object Detectors based on Diffusion Models,"With the rapid development of deep learning, object detectors have
demonstrated impressive performance; however, vulnerabilities still exist in
certain scenarios. Current research exploring the vulnerabilities using
adversarial patches often struggles to balance the trade-off between attack
effectiveness and visual quality. To address this problem, we propose a novel
framework of patch attack from semantic perspective, which we refer to as
AdvLogo. Based on the hypothesis that every semantic space contains an
adversarial subspace where images can cause detectors to fail in recognizing
objects, we leverage the semantic understanding of the diffusion denoising
process and drive the process to adversarial subareas by perturbing the latent
and unconditional embeddings at the last timestep. To mitigate the distribution
shift that exposes a negative impact on image quality, we apply perturbation to
the latent in frequency domain with the Fourier Transform. Experimental results
demonstrate that AdvLogo achieves strong attack performance while maintaining
high visual quality.",2024-09-11 04:30:45+00:00
Learning Personalized Scoping for Graph Neural Networks under Heterophily,"Heterophilous graphs, where dissimilar nodes tend to connect, pose a
challenge for graph neural networks (GNNs) as their superior performance
typically comes from aggregating homophilous information. Increasing the GNN
depth can expand the scope (i.e., receptive field), potentially finding
homophily from the higher-order neighborhoods. However, uniformly expanding the
scope results in subpar performance since real-world graphs often exhibit
homophily disparity between nodes. An ideal way is personalized scopes,
allowing nodes to have varying scope sizes. Existing methods typically add
node-adaptive weights for each hop. Although expressive, they inevitably suffer
from severe overfitting. To address this issue, we formalize personalized
scoping as a separate scope classification problem that overcomes GNN
overfitting in node classification. Specifically, we predict the optimal GNN
depth for each node. Our theoretical and empirical analysis suggests that
accurately predicting the depth can significantly enhance generalization. We
further propose Adaptive Scope (AS), a lightweight MLP-based approach that only
participates in GNN inference. AS encodes structural patterns and predicts the
depth to select the best model for each node's prediction. Experimental results
show that AS is highly flexible with various GNN architectures across a wide
range of datasets while significantly improving accuracy.",2024-09-11 04:13:39+00:00
What is the Right Notion of Distance between Predict-then-Optimize Tasks?,"Comparing datasets is a fundamental task in machine learning, essential for
various learning paradigms; from evaluating train and test datasets for model
generalization to using dataset similarity for detecting data drift. While
traditional notions of dataset distances offer principled measures of
similarity, their utility has largely been assessed through prediction error
minimization. However, in Predict-then-Optimize (PtO) frameworks, where
predictions serve as inputs for downstream optimization tasks, model
performance is measured through decision regret minimization rather than
prediction error minimization. In this work, we (i) show that traditional
dataset distances, which rely solely on feature and label dimensions, lack
informativeness in the PtO context, and (ii) propose a new dataset distance
that incorporates the impacts of downstream decisions. Our results show that
this decision-aware dataset distance effectively captures adaptation success in
PtO contexts, providing a PtO adaptation bound in terms of dataset distance.
Empirically, we show that our proposed distance measure accurately predicts
transferability across three different PtO tasks from the literature.",2024-09-11 04:13:17+00:00
RICAU-Net: Residual-block Inspired Coordinate Attention U-Net for Segmentation of Small and Sparse Calcium Lesions in Cardiac CT,"The Agatston score, which is the sum of the calcification in the four main
coronary arteries, has been widely used in the diagnosis of coronary artery
disease (CAD). However, many studies have emphasized the importance of the
vessel-specific Agatston score, as calcification in a specific vessel is
significantly correlated with the occurrence of coronary heart disease (CHD).
In this paper, we propose the Residual-block Inspired Coordinate Attention
U-Net (RICAU-Net), which incorporates coordinate attention in two distinct
manners and a customized combo loss function for lesion-specific coronary
artery calcium (CAC) segmentation. This approach aims to tackle the high
class-imbalance issue associated with small and sparse lesions, particularly
for CAC in the left main coronary artery (LM) which is generally small and the
scarcest in the dataset due to its anatomical structure. The proposed method
was compared with six different methods using Dice score, precision, and
recall. Our approach achieved the highest per-lesion Dice scores for all four
lesions, especially for CAC in LM compared to other methods. The ablation
studies demonstrated the significance of positional information from the
coordinate attention and the customized loss function in segmenting small and
sparse lesions with a high class-imbalance problem.",2024-09-11 03:54:40+00:00
1M-Deepfakes Detection Challenge,"The detection and localization of deepfake content, particularly when small
fake segments are seamlessly mixed with real videos, remains a significant
challenge in the field of digital media security. Based on the recently
released AV-Deepfake1M dataset, which contains more than 1 million manipulated
videos across more than 2,000 subjects, we introduce the 1M-Deepfakes Detection
Challenge. This challenge is designed to engage the research community in
developing advanced methods for detecting and localizing deepfake manipulations
within the large-scale high-realistic audio-visual dataset. The participants
can access the AV-Deepfake1M dataset and are required to submit their inference
results for evaluation across the metrics for detection or localization tasks.
The methodologies developed through the challenge will contribute to the
development of next-generation deepfake detection and localization systems.
Evaluation scripts, baseline models, and accompanying code will be available on
https://github.com/ControlNet/AV-Deepfake1M.",2024-09-11 03:43:53+00:00
Enhancing Cross-domain Pre-Trained Decision Transformers with Adaptive Attention,"Recently, the pre-training of decision transformers (DT) using a different
domain, such as natural language text, has generated significant attention in
offline reinforcement learning (Offline RL). Although this cross-domain
pre-training approach achieves superior performance compared to training from
scratch in environments required short-term planning ability, the mechanisms by
which pre-training benefits the fine-tuning phase remain unclear. Furthermore,
we point out that the cross-domain pre-training approach hinders the extraction
of distant information in environments like PointMaze that require long-term
planning ability, leading to performance that is much worse than training DT
from scratch. This work first analyzes these issues and found that Markov
Matrix, a component that exists in pre-trained attention heads, is the key to
explain the significant performance disparity of pre-trained models in
different planning abilities. Inspired by our analysis, we propose a general
method GPT-DTMA, which equips a pre-trained DT with Mixture of Attention (MoA),
to enable adaptive learning and accommodating diverse attention requirements
during fine-tuning. Extensive experiments demonstrate that the effectiveness of
GPT-DTMA: it achieves superior performance in short-term environments compared
to baselines, and in long-term environments, it mitigates the negative impact
caused by Markov Matrix, achieving results comparable to those of DT trained
from scratch.",2024-09-11 03:18:34+00:00
PanAdapter: Two-Stage Fine-Tuning with Spatial-Spectral Priors Injecting for Pansharpening,"Pansharpening is a challenging image fusion task that involves restoring
images using two different modalities: low-resolution multispectral images
(LRMS) and high-resolution panchromatic (PAN). Many end-to-end specialized
models based on deep learning (DL) have been proposed, yet the scale and
performance of these models are limited by the size of dataset. Given the
superior parameter scales and feature representations of pre-trained models,
they exhibit outstanding performance when transferred to downstream tasks with
small datasets. Therefore, we propose an efficient fine-tuning method, namely
PanAdapter, which utilizes additional advanced semantic information from
pre-trained models to alleviate the issue of small-scale datasets in
pansharpening tasks. Specifically, targeting the large domain discrepancy
between image restoration and pansharpening tasks, the PanAdapter adopts a
two-stage training strategy for progressively adapting to the downstream task.
In the first stage, we fine-tune the pre-trained CNN model and extract
task-specific priors at two scales by proposed Local Prior Extraction (LPE)
module. In the second stage, we feed the extracted two-scale priors into two
branches of cascaded adapters respectively. At each adapter, we design two
parameter-efficient modules for allowing the two branches to interact and be
injected into the frozen pre-trained VisionTransformer (ViT) blocks. We
demonstrate that by only training the proposed LPE modules and adapters with a
small number of parameters, our approach can benefit from pre-trained image
restoration models and achieve state-of-the-art performance in several
benchmark pansharpening datasets. The code will be available soon.",2024-09-11 03:13:08+00:00
Large Language Models and the Extended Church-Turing Thesis,"The Extended Church-Turing Thesis (ECTT) posits that all effective
information processing, including unbounded and non-uniform interactive
computations, can be described in terms of interactive Turing machines with
advice. Does this assertion also apply to the abilities of contemporary large
language models (LLMs)? From a broader perspective, this question calls for an
investigation of the computational power of LLMs by the classical means of
computability and computational complexity theory, especially the theory of
automata. Along these lines, we establish a number of fundamental results.
Firstly, we argue that any fixed (non-adaptive) LLM is computationally
equivalent to a, possibly very large, deterministic finite-state transducer.
This characterizes the base level of LLMs. We extend this to a key result
concerning the simulation of space-bounded Turing machines by LLMs. Secondly,
we show that lineages of evolving LLMs are computationally equivalent to
interactive Turing machines with advice. The latter finding confirms the
validity of the ECTT for lineages of LLMs. From a computability viewpoint, it
also suggests that lineages of LLMs possess super-Turing computational power.
Consequently, in our computational model knowledge generation is in general a
non-algorithmic process realized by lineages of LLMs. Finally, we discuss the
merits of our findings in the broader context of several related disciplines
and philosophies.",2024-09-11 03:09:55+00:00
Brain-Inspired Stepwise Patch Merging for Vision Transformers,"The hierarchical architecture has become a mainstream design paradigm for
Vision Transformers (ViTs), with Patch Merging serving as the pivotal component
that transforms a columnar architecture into a hierarchical one. Drawing
inspiration from the brain's ability to integrate global and local information
for comprehensive visual understanding, we propose a novel technique called
Stepwise Patch Merging (SPM), which enhances the subsequent attention
mechanism's ability to 'see' better. SPM comprises two critical modules:
Multi-Scale Aggregation (MSA) and Guided Local Enhancement (GLE). The MSA
module integrates multi-scale features to enrich feature representation, while
the GLE module focuses on refining local detail extraction, thus achieving an
optimal balance between long-range dependency modeling and local feature
enhancement. Extensive experiments conducted on benchmark datasets, including
ImageNet-1K, COCO, and ADE20K, demonstrate that SPM significantly improves the
performance of various models, particularly in dense prediction tasks such as
object detection and semantic segmentation. These results underscore the
efficacy of SPM in enhancing model accuracy and robustness across a wide range
of computer vision tasks.",2024-09-11 03:04:46+00:00
Toward Model-Agnostic Detection of New Physics Using Data-Driven Signal Regions,"In the search for new particles in high-energy physics, it is crucial to
select the Signal Region (SR) in such a way that it is enriched with signal
events if they are present. While most existing search methods set the region
relying on prior domain knowledge, it may be unavailable for a completely novel
particle that falls outside the current scope of understanding. We address this
issue by proposing a method built upon a model-agnostic but often realistic
assumption about the localized topology of the signal events, in which they are
concentrated in a certain area of the feature space. Considering the signal
component as a localized high-frequency feature, our approach employs the
notion of a low-pass filter. We define the SR as an area which is most affected
when the observed events are smeared with additive random noise. We overcome
challenges in density estimation in the high-dimensional feature space by
learning the density ratio of events that potentially include a signal to the
complementary observation of events that closely resemble the target events but
are free of any signals. By applying our method to simulated $\mathrm{HH}
\rightarrow 4b$ events, we demonstrate that the method can efficiently identify
a data-driven SR in a high-dimensional feature space in which a high portion of
signal events concentrate.",2024-09-11 02:49:53+00:00
Policy Filtration in RLHF to Fine-Tune LLM for Code Generation,"Reinforcement learning from human feedback (RLHF) is one of the key
techniques that helps large language models (LLMs) to follow instructions and
provide helpful and harmless responses. While direct policy optimization
methods exist, state-of-the-art LLMs adopt RL-based methods (usually PPO) in
RLHF to train the policy to generate good responses guided by a reward model
learned from preference data. The main challenge of these methods is the
inaccuracy of the intermediate reward model, especially in code generation
tasks that require long and complex reasoning to score a response. We find that
the reliability of the reward model varies across responses assigned with
different rewards. This motivates us to filter the samples whose rewards may be
unreliable to improve signal-to-noise ratio during policy learning, resulting
in Policy Filtration for Proximal Policy Optimization (PF-PPO). To choose a
proper policy filtration strategy for a given reward model, the coefficient of
determination ($R^2$) between rewards and actual scores on filtered samples
serves as a good metrics and helps us find several promising strategies. We
provide extensive experiments to validate the effectiveness of PF-PPO in code
generation tasks, and find that some variants of PF-PPO are highly effective
and achieve new state-of-the-art performance across 7-billion-parameter models
on HumanEval, MBPP, and a new and more challenging LeetCode Contest benchmark.",2024-09-11 02:40:38+00:00
Bridging Domain Gap of Point Cloud Representations via Self-Supervised Geometric Augmentation,"Recent progress of semantic point clouds analysis is largely driven by
synthetic data (e.g., the ModelNet and the ShapeNet), which are typically
complete, well-aligned and noisy free. Therefore, representations of those
ideal synthetic point clouds have limited variations in the geometric
perspective and can gain good performance on a number of 3D vision tasks such
as point cloud classification. In the context of unsupervised domain adaptation
(UDA), representation learning designed for synthetic point clouds can hardly
capture domain invariant geometric patterns from incomplete and noisy point
clouds. To address such a problem, we introduce a novel scheme for induced
geometric invariance of point cloud representations across domains, via
regularizing representation learning with two self-supervised geometric
augmentation tasks. On one hand, a novel pretext task of predicting translation
distances of augmented samples is proposed to alleviate centroid shift of point
clouds due to occlusion and noises. On the other hand, we pioneer an
integration of the relational self-supervised learning on
geometrically-augmented point clouds in a cascade manner, utilizing the
intrinsic relationship of augmented variants and other samples as extra
constraints of cross-domain geometric features. Experiments on the PointDA-10
dataset demonstrate the effectiveness of the proposed method, achieving the
state-of-the-art performance.",2024-09-11 02:39:19+00:00
Privacy-Preserving Federated Learning with Consistency via Knowledge Distillation Using Conditional Generator,"Federated Learning (FL) is gaining popularity as a distributed learning
framework that only shares model parameters or gradient updates and keeps
private data locally. However, FL is at risk of privacy leakage caused by
privacy inference attacks. And most existing privacy-preserving mechanisms in
FL conflict with achieving high performance and efficiency. Therefore, we
propose FedMD-CG, a novel FL method with highly competitive performance and
high-level privacy preservation, which decouples each client's local model into
a feature extractor and a classifier, and utilizes a conditional generator
instead of the feature extractor to perform server-side model aggregation. To
ensure the consistency of local generators and classifiers, FedMD-CG leverages
knowledge distillation to train local models and generators at both the latent
feature level and the logit level. Also, we construct additional classification
losses and design new diversity losses to enhance client-side training.
FedMD-CG is robust to data heterogeneity and does not require training extra
discriminators (like cGAN). We conduct extensive experiments on various image
classification tasks to validate the superiority of FedMD-CG.",2024-09-11 02:36:36+00:00
Neural Algorithmic Reasoning with Multiple Correct Solutions,"Neural Algorithmic Reasoning (NAR) aims to optimize classical algorithms.
However, canonical implementations of NAR train neural networks to return only
a single solution, even when there are multiple correct solutions to a problem,
such as single-source shortest paths. For some applications, it is desirable to
recover more than one correct solution. To that end, we give the first method
for NAR with multiple solutions. We demonstrate our method on two classical
algorithms: Bellman-Ford (BF) and Depth-First Search (DFS), favouring deeper
insight into two algorithms over a broader survey of algorithms. This method
involves generating appropriate training data as well as sampling and
validating solutions from model output. Each step of our method, which can
serve as a framework for neural algorithmic reasoning beyond the tasks
presented in this paper, might be of independent interest to the field and our
results represent the first attempt at this task in the NAR literature.",2024-09-11 02:29:53+00:00
You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling,"Developing a consistent and reliable AI game master for text-based games is a
challenging task due to the limitations of large language models (LLMs) and the
complexity of the game master's role. This paper presents a novel approach to
enhance AI game masters by leveraging function calling in the context of the
table-top role-playing game ""Jim Henson's Labyrinth: The Adventure Game."" Our
methodology involves integrating game-specific controls through functions,
which we show improves the narrative quality and state update consistency of
the AI game master. The experimental results, based on human evaluations and
unit tests, demonstrate the effectiveness of our approach in enhancing gameplay
experience and maintaining coherence with the game state. This work contributes
to the advancement of game AI and interactive storytelling, offering insights
into the design of more engaging and consistent AI-driven game masters.",2024-09-11 02:03:51+00:00
FSMDet: Vision-guided feature diffusion for fully sparse 3D detector,"Fully sparse 3D detection has attracted an increasing interest in the recent
years. However, the sparsity of the features in these frameworks challenges the
generation of proposals because of the limited diffusion process. In addition,
the quest for efficiency has led to only few work on vision-assisted fully
sparse models. In this paper, we propose FSMDet (Fully Sparse Multi-modal
Detection), which use visual information to guide the LiDAR feature diffusion
process while still maintaining the efficiency of the pipeline. Specifically,
most of fully sparse works focus on complex customized center fusion
diffusion/regression operators. However, we observed that if the adequate
object completion is performed, even the simplest interpolation operator leads
to satisfactory results. Inspired by this observation, we split the
vision-guided diffusion process into two modules: a Shape Recover Layer
(SRLayer) and a Self Diffusion Layer (SDLayer). The former uses RGB information
to recover the shape of the visible part of an object, and the latter uses a
visual prior to further spread the features to the center region. Experiments
demonstrate that our approach successfully improves the performance of previous
fully sparse models that use LiDAR only and reaches SOTA performance in
multimodal models. At the same time, thanks to the sparse architecture, our
method can be up to 5 times more efficient than previous SOTA methods in the
inference process.",2024-09-11 01:55:45+00:00
Automated Body Composition Analysis Using DAFS Express on 2D MRI Slices at L3 Vertebral Level,"Body composition analysis is vital in assessing health conditions such as
obesity, sarcopenia, and metabolic syndromes. MRI provides detailed images of
skeletal muscle (SKM), visceral adipose tissue (VAT), and subcutaneous adipose
tissue (SAT), but their manual segmentation is labor-intensive and limits
clinical applicability. This study validates an automated tool for MRI-based 2D
body composition analysis- (Data Analysis Facilitation Suite (DAFS) Express),
comparing its automated measurements with expert manual segmentations using UK
Biobank data. A cohort of 399 participants from the UK Biobank dataset was
selected, yielding 423 single L3 slices for analysis. DAFS Express performed
automated segmentations of SKM, VAT, and SAT, which were then manually
corrected by expert raters for validation. Evaluation metrics included Jaccard
coefficients, Dice scores, Intraclass Correlation Coefficients (ICCs), and
Bland-Altman Plots to assess segmentation agreement and reliability. High
agreements were observed between automated and manual segmentations with mean
Jaccard scores: SKM 99.03%, VAT 95.25%, and SAT 99.57%; and mean Dice scores:
SKM 99.51%, VAT 97.41%, and SAT 99.78%. Cross-sectional area comparisons showed
consistent measurements with automated methods closely matching manual
measurements for SKM and SAT, and slightly higher values for VAT (SKM: Auto
132.51 cm^2, Manual 132.36 cm^2; VAT: Auto 137.07 cm^2, Manual 134.46 cm^2;
SAT: Auto 203.39 cm^2, Manual 202.85 cm^2). ICCs confirmed strong reliability
(SKM: 0.998, VAT: 0.994, SAT: 0.994). Bland-Altman plots revealed minimal
biases, and boxplots illustrated distribution similarities across SKM, VAT, and
SAT areas. On average DAFS Express took 18 seconds per DICOM. This underscores
its potential to streamline image analysis processes in research and clinical
settings, enhancing diagnostic accuracy and efficiency.",2024-09-11 01:46:56+00:00
FreeRide: Harvesting Bubbles in Pipeline Parallelism,"The occurrence of bubbles in pipeline parallelism is an inherent limitation
that can account for more than 40% of the large language model (LLM) training
time and is one of the main reasons for the underutilization of GPU resources
in LLM training. Harvesting these bubbles for GPU side tasks can increase
resource utilization and reduce training costs but comes with challenges.
First, because bubbles are discontinuous with various shapes, programming side
tasks becomes difficult while requiring excessive engineering effort. Second, a
side task can compete with pipeline training for GPU resources and incur
significant overhead. To address these challenges, we propose FreeRide, a
system designed to harvest bubbles in pipeline parallelism for side tasks.
FreeRide provides programmers with interfaces to implement side tasks easily,
manages bubbles and side tasks during pipeline training, and controls access to
GPU resources by side tasks to reduce overhead. We demonstrate that FreeRide
achieves 7.8% average cost savings with a negligible overhead of about 1% in
training LLMs while serving model training, graph analytics, and image
processing side tasks.",2024-09-11 01:46:49+00:00
"k-MLE, k-Bregman, k-VARs: Theory, Convergence, Computation","We develop hard clustering based on likelihood rather than distance and prove
convergence. We also provide simulations and real data examples.",2024-09-11 01:37:02+00:00
Intrapartum Ultrasound Image Segmentation of Pubic Symphysis and Fetal Head Using Dual Student-Teacher Framework with CNN-ViT Collaborative Learning,"The segmentation of the pubic symphysis and fetal head (PSFH) constitutes a
pivotal step in monitoring labor progression and identifying potential delivery
complications. Despite the advances in deep learning, the lack of annotated
medical images hinders the training of segmentation. Traditional
semi-supervised learning approaches primarily utilize a unified network model
based on Convolutional Neural Networks (CNNs) and apply consistency
regularization to mitigate the reliance on extensive annotated data. However,
these methods often fall short in capturing the discriminative features of
unlabeled data and in delineating the long-range dependencies inherent in the
ambiguous boundaries of PSFH within ultrasound images. To address these
limitations, we introduce a novel framework, the Dual-Student and Teacher
Combining CNN and Transformer (DSTCT), which synergistically integrates the
capabilities of CNNs and Transformers. Our framework comprises a Vision
Transformer (ViT) as the teacher and two student mod ls one ViT and one CNN.
This dual-student setup enables mutual supervision through the generation of
both hard and soft pseudo-labels, with the consistency in their predictions
being refined by minimizing the classifier determinacy discrepancy. The teacher
model further reinforces learning within this architecture through the
imposition of consistency regularization constraints. To augment the
generalization abilities of our approach, we employ a blend of data and model
perturbation techniques. Comprehensive evaluations on the benchmark dataset of
the PSFH Segmentation Grand Challenge at MICCAI 2023 demonstrate our DSTCT
framework outperformed ten contemporary semi-supervised segmentation methods.
Code available at https://github.com/jjm1589/DSTCT.",2024-09-11 00:57:31+00:00
Representation Tuning,"Activation engineering is becoming increasingly popular as a means of online
control of large language models (LLMs). In this work, I extend the idea of
active steering with vectors that represent a behavioral direction of interest
to tuning those vectors directly into the model, obviating the need for online
control. First, I identify activation vectors related to honesty in an
open-source LLM (Llama- 2-13b-chat). Next, I demonstrate that model output can
be made more or less honest by adding positive or negative multiples of these
vectors to residual stream activations during generation. Then, I show that a
similar effect can be achieved by fine-tuning the vectors directly into the
model, by use of a dual loss function based on the cosine similarity of
residual stream activations to the vectors combined with a standard token-based
loss (""representation tuning""). Finally, I compare the generations in response
to honesty-probing prompts from the resulting models to those from models
fine-tuned with a token-based loss alone, and to those from the untuned model
subjected to online steering. Overall, fine-tuning the vectors into the models
using the cosine similarity plus token loss showed a stronger effect than
online steering, and generalized better than using the standard loss,
suggesting the potential utility of this approach as a safety measure. Code and
data are available at https://github.com/cma1114/representation_tuning; tuned
models are available at https://huggingface.co/collections/cackerman/
representation-tuning-66da1e5ab41cd1b824687d9f.",2024-09-11 00:56:02+00:00
Rethinking Directional Parameterization in Neural Implicit Surface Reconstruction,"Multi-view 3D surface reconstruction using neural implicit representations
has made notable progress by modeling the geometry and view-dependent radiance
fields within a unified framework. However, their effectiveness in
reconstructing objects with specular or complex surfaces is typically biased by
the directional parameterization used in their view-dependent radiance network.
{\it Viewing direction} and {\it reflection direction} are the two most
commonly used directional parameterizations but have their own limitations.
Typically, utilizing the viewing direction usually struggles to correctly
decouple the geometry and appearance of objects with highly specular surfaces,
while using the reflection direction tends to yield overly smooth
reconstructions for concave or complex structures. In this paper, we analyze
their failed cases in detail and propose a novel hybrid directional
parameterization to address their limitations in a unified form. Extensive
experiments demonstrate the proposed hybrid directional parameterization
consistently delivered satisfactory results in reconstructing objects with a
wide variety of materials, geometry and appearance, whereas using other
directional parameterizations faces challenges in reconstructing certain
objects. Moreover, the proposed hybrid directional parameterization is nearly
parameter-free and can be effortlessly applied in any existing neural surface
reconstruction method.",2024-09-11 00:44:31+00:00
AdaPPA: Adaptive Position Pre-Fill Jailbreak Attack Approach Targeting LLMs,"Jailbreak vulnerabilities in Large Language Models (LLMs) refer to methods
that extract malicious content from the model by carefully crafting prompts or
suffixes, which has garnered significant attention from the research community.
However, traditional attack methods, which primarily focus on the semantic
level, are easily detected by the model. These methods overlook the difference
in the model's alignment protection capabilities at different output stages. To
address this issue, we propose an adaptive position pre-fill jailbreak attack
approach for executing jailbreak attacks on LLMs. Our method leverages the
model's instruction-following capabilities to first output pre-filled safe
content, then exploits its narrative-shifting abilities to generate harmful
content. Extensive black-box experiments demonstrate our method can improve the
attack success rate by 47% on the widely recognized secure model (Llama2)
compared to existing approaches. Our code can be found at:
https://github.com/Yummy416/AdaPPA.",2024-09-11 00:00:58+00:00
Interactive Counterfactual Exploration of Algorithmic Harms in Recommender Systems,"Recommender systems have become integral to digital experiences, shaping user
interactions and preferences across various platforms. Despite their widespread
use, these systems often suffer from algorithmic biases that can lead to unfair
and unsatisfactory user experiences. This study introduces an interactive tool
designed to help users comprehend and explore the impacts of algorithmic harms
in recommender systems. By leveraging visualizations, counterfactual
explanations, and interactive modules, the tool allows users to investigate how
biases such as miscalibration, stereotypes, and filter bubbles affect their
recommendations. Informed by in-depth user interviews, this tool benefits both
general users and researchers by increasing transparency and offering
personalized impact assessments, ultimately fostering a better understanding of
algorithmic biases and contributing to more equitable recommendation outcomes.
This work provides valuable insights for future research and practical
applications in mitigating bias and enhancing fairness in machine learning
algorithms.",2024-09-10 23:58:27+00:00
"A Bayesian framework for active object recognition, pose estimation and shape transfer learning through touch","As humans can explore and understand the world through the sense of touch,
tactile sensing is also an important aspect of robotic perception. In
unstructured environments, robots can encounter both known and novel objects,
this calls for a method to address both known and novel objects. In this study,
we combine a particle filter (PF) and Gaussian process implicit surface (GPIS)
in a unified Bayesian framework. The framework can differentiate between known
and novel objects, perform object recognition, estimate pose for known objects,
and reconstruct shapes for unknown objects, in an active learning fashion. By
grounding the selection of the GPIS prior with the
maximum-likelihood-estimation (MLE) shape from the PF, the knowledge about
known objects' shapes can be transferred to learn novel shapes. An exploration
procedure with global shape estimation is proposed to guide active data
acquisition and conclude the exploration when sufficient information is
obtained. The performance of the proposed Bayesian framework is evaluated
through simulations on known and novel objects, initialized with random poses.
The results show that the proposed exploration procedure, utilizing global
shape estimation, achieves faster exploration than a local exploration
procedure based on rapidly explore random tree (RRT). Overall, our results
indicate that the proposed framework is effective and efficient in object
recognition, pose estimation and shape reconstruction. Moreover, we show that a
learned shape can be included as a new prior and used effectively for future
object recognition and pose estimation.",2024-09-10 23:35:30+00:00
Applied Federated Model Personalisation in the Industrial Domain: A Comparative Study,"The time-consuming nature of training and deploying complicated Machine and
Deep Learning (DL) models for a variety of applications continues to pose
significant challenges in the field of Machine Learning (ML). These challenges
are particularly pronounced in the federated domain, where optimizing models
for individual nodes poses significant difficulty. Many methods have been
developed to tackle this problem, aiming to reduce training expenses and time
while maintaining efficient optimisation. Three suggested strategies to tackle
this challenge include Active Learning, Knowledge Distillation, and Local
Memorization. These methods enable the adoption of smaller models that require
fewer computational resources and allow for model personalization with local
insights, thereby improving the effectiveness of current models. The present
study delves into the fundamental principles of these three approaches and
proposes an advanced Federated Learning System that utilises different
Personalisation methods towards improving the accuracy of AI models and
enhancing user experience in real-time NG-IoT applications, investigating the
efficacy of these techniques in the local and federated domain. The results of
the original and optimised models are then compared in both local and federated
contexts using a comparison analysis. The post-analysis shows encouraging
outcomes when it comes to optimising and personalising the models with the
suggested techniques.",2024-09-10 23:00:19+00:00
Semi-Supervised Reward Modeling via Iterative Self-Training,"Reward models (RM) capture the values and preferences of humans and play a
central role in Reinforcement Learning with Human Feedback (RLHF) to align
pretrained large language models (LLMs). Traditionally, training these models
relies on extensive human-annotated preference data, which poses significant
challenges in terms of scalability and cost. To overcome these limitations, we
propose Semi-Supervised Reward Modeling (SSRM), an approach that enhances RM
training using unlabeled data. Given an unlabeled dataset, SSRM involves three
key iterative steps: pseudo-labeling unlabeled examples, selecting
high-confidence examples through a confidence threshold, and supervised
finetuning on the refined dataset. Across extensive experiments on various
model configurations, we demonstrate that SSRM significantly improves reward
models without incurring additional labeling costs. Notably, SSRM can achieve
performance comparable to models trained entirely on labeled data of equivalent
volumes. Overall, SSRM substantially reduces the dependency on large volumes of
human-annotated data, thereby decreasing the overall cost and time involved in
training effective reward models.",2024-09-10 22:57:58+00:00
"Mazed and Confused: A Dataset of Cybersickness, Working Memory, Mental Load, Physical Load, and Attention During a Real Walking Task in VR","Virtual Reality (VR) is quickly establishing itself in various industries,
including training, education, medicine, and entertainment, in which users are
frequently required to carry out multiple complex cognitive and physical
activities. However, the relationship between cognitive activities, physical
activities, and familiar feelings of cybersickness is not well understood and
thus can be unpredictable for developers. Researchers have previously provided
labeled datasets for predicting cybersickness while users are stationary, but
there have been few labeled datasets on cybersickness while users are
physically walking. Thus, from 39 participants, we collected head orientation,
head position, eye tracking, images, physiological readings from external
sensors, and the self-reported cybersickness severity, physical load, and
mental load in VR. Throughout the data collection, participants navigated mazes
via real walking and performed tasks challenging their attention and working
memory. To demonstrate the dataset's utility, we conducted a case study of
training classifiers in which we achieved 95% accuracy for cybersickness
severity classification. The noteworthy performance of the straightforward
classifiers makes this dataset ideal for future researchers to develop
cybersickness detection and reduction models. To better understand the features
that helped with classification, we performed SHAP(SHapley Additive
exPlanations) analysis, highlighting the importance of eye tracking and
physiological measures for cybersickness prediction while walking. This open
dataset can allow future researchers to study the connection between
cybersickness and cognitive loads and develop prediction models. This dataset
will empower future VR developers to design efficient and effective Virtual
Environments by improving cognitive load management and minimizing
cybersickness.",2024-09-10 22:41:14+00:00
Formative Study for AI-assisted Data Visualization,"This formative study investigates the impact of data quality on AI-assisted
data visualizations, focusing on how uncleaned datasets influence the outcomes
of these tools. By generating visualizations from datasets with inherent
quality issues, the research aims to identify and categorize the specific
visualization problems that arise. The study further explores potential methods
and tools to address these visualization challenges efficiently and
effectively. Although tool development has not yet been undertaken, the
findings emphasize enhancing AI visualization tools to handle flawed data
better. This research underscores the critical need for more robust,
user-friendly solutions that facilitate quicker and easier correction of data
and visualization errors, thereby improving the overall reliability and
usability of AI-assisted data visualization processes.",2024-09-10 22:20:28+00:00
Learning Deep Kernels for Non-Parametric Independence Testing,"The Hilbert-Schmidt Independence Criterion (HSIC) is a powerful tool for
nonparametric detection of dependence between random variables. It crucially
depends, however, on the selection of reasonable kernels; commonly-used choices
like the Gaussian kernel, or the kernel that yields the distance covariance,
are sufficient only for amply sized samples from data distributions with
relatively simple forms of dependence. We propose a scheme for selecting the
kernels used in an HSIC-based independence test, based on maximizing an
estimate of the asymptotic test power. We prove that maximizing this estimate
indeed approximately maximizes the true power of the test, and demonstrate that
our learned kernels can identify forms of structured dependence between random
variables in various experiments.",2024-09-10 22:18:07+00:00
Enhanced Pix2Pix GAN for Visual Defect Removal in UAV-Captured Images,"This paper presents a neural network that effectively removes visual defects
from UAV-captured images. It features an enhanced Pix2Pix GAN, specifically
engineered to address visual defects in UAV imagery. The method incorporates
advanced modifications to the Pix2Pix architecture, targeting prevalent issues
such as mode collapse. The suggested method facilitates significant
improvements in the quality of defected UAV images, yielding cleaner and more
precise visual results. The effectiveness of the proposed approach is
demonstrated through evaluation on a custom dataset of aerial photographs,
highlighting its capability to refine and restore UAV imagery effectively.",2024-09-10 22:16:41+00:00
Ordinal Learning: Longitudinal Attention Alignment Model for Predicting Time to Future Breast Cancer Events from Mammograms,"Precision breast cancer (BC) risk assessment is crucial for developing
individualized screening and prevention. Despite the promising potential of
recent mammogram (MG) based deep learning models in predicting BC risk, they
mostly overlook the 'time-to-future-event' ordering among patients and exhibit
limited explorations into how they track history changes in breast tissue,
thereby limiting their clinical application. In this work, we propose a novel
method, named OA-BreaCR, to precisely model the ordinal relationship of the
time to and between BC events while incorporating longitudinal breast tissue
changes in a more explainable manner. We validate our method on public EMBED
and inhouse datasets, comparing with existing BC risk prediction and time
prediction methods. Our ordinal learning method OA-BreaCR outperforms existing
methods in both BC risk and time-to-future-event prediction tasks.
Additionally, ordinal heatmap visualizations show the model's attention over
time. Our findings underscore the importance of interpretable and precise risk
assessment for enhancing BC screening and prevention efforts. The code will be
accessible to the public.",2024-09-10 22:03:26+00:00
A Dataset for Evaluating LLM-based Evaluation Functions for Research Question Extraction Task,"The progress in text summarization techniques has been remarkable. However
the task of accurately extracting and summarizing necessary information from
highly specialized documents such as research papers has not been sufficiently
investigated. We are focusing on the task of extracting research questions (RQ)
from research papers and construct a new dataset consisting of machine learning
papers, RQ extracted from these papers by GPT-4, and human evaluations of the
extracted RQ from multiple perspectives. Using this dataset, we systematically
compared recently proposed LLM-based evaluation functions for summarizations,
and found that none of the functions showed sufficiently high correlations with
human evaluations. We expect our dataset provides a foundation for further
research on developing better evaluation functions tailored to the RQ
extraction task, and contribute to enhance the performance of the task. The
dataset is available at https://github.com/auto-res/PaperRQ-HumanAnno-Dataset.",2024-09-10 21:54:46+00:00
Joint trajectory and network inference via reference fitting,"Network inference, the task of reconstructing interactions in a complex
system from experimental observables, is a central yet extremely challenging
problem in systems biology. While much progress has been made in the last two
decades, network inference remains an open problem. For systems observed at
steady state, limited insights are available since temporal information is
unavailable and thus causal information is lost. Two common avenues for gaining
causal insights into system behaviour are to leverage temporal dynamics in the
form of trajectories, and to apply interventions such as knock-out
perturbations. We propose an approach for leveraging both dynamical and
perturbational single cell data to jointly learn cellular trajectories and
power network inference. Our approach is motivated by min-entropy estimation
for stochastic dynamics and can infer directed and signed networks from
time-stamped single cell snapshots.",2024-09-10 21:49:57+00:00
The Competition Complexity of Prophet Inequalities with Correlations,"We initiate the study of the prophet inequality problem through the resource
augmentation framework in scenarios when the values of the rewards are
correlated. Our goal is to determine the number of additional rewards an online
algorithm requires to approximate the maximum value of the original instance.
While the independent reward case is well understood, we extend this research
to account for correlations among rewards. Our results demonstrate that, unlike
in the independent case, the required number of additional rewards for
approximation depends on the number of original rewards, and that
block-threshold algorithms, which are optimal in the independent case, may
require an infinite number of additional rewards when correlations are present.
We develop asymptotically optimal algorithms for the following three scenarios:
(1) where rewards arrive in blocks corresponding to the different copies of the
original instance; (2) where rewards across all copies are arbitrarily
shuffled; and (3) where rewards arrive in blocks corresponding to the different
copies of the original instance, and values within each block are pairwise
independent rather than fully correlated.",2024-09-10 21:11:37+00:00
Towards Understanding Human Emotional Fluctuations with Sparse Check-In Data,"Data sparsity is a key challenge limiting the power of AI tools across
various domains. The problem is especially pronounced in domains that require
active user input rather than measurements derived from automated sensors. It
is a critical barrier to harnessing the full potential of AI in domains
requiring active user engagement, such as self-reported mood check-ins, where
capturing a continuous picture of emotional states is essential. In this
context, sparse data can hinder efforts to capture the nuances of individual
emotional experiences such as causes, triggers, and contributing factors.
Existing methods for addressing data scarcity often rely on heuristics or large
established datasets, favoring deep learning models that lack adaptability to
new domains. This paper proposes a novel probabilistic framework that
integrates user-centric feedback-based learning, allowing for personalized
predictions despite limited data. Achieving 60% accuracy in predicting user
states among 64 options (chance of 1/64), this framework effectively mitigates
data sparsity. It is versatile across various applications, bridging the gap
between theoretical AI research and practical deployment.",2024-09-10 21:00:33+00:00
NSP: A Neuro-Symbolic Natural Language Navigational Planner,"Path planners that can interpret free-form natural language instructions hold
promise to automate a wide range of robotics applications. These planners
simplify user interactions and enable intuitive control over complex
semi-autonomous systems. While existing symbolic approaches offer guarantees on
the correctness and efficiency, they struggle to parse free-form natural
language inputs. Conversely, neural approaches based on pre-trained Large
Language Models (LLMs) can manage natural language inputs but lack performance
guarantees. In this paper, we propose a neuro-symbolic framework for path
planning from natural language inputs called NSP. The framework leverages the
neural reasoning abilities of LLMs to i) craft symbolic representations of the
environment and ii) a symbolic path planning algorithm. Next, a solution to the
path planning problem is obtained by executing the algorithm on the environment
representation. The framework uses a feedback loop from the symbolic execution
environment to the neural generation process to self-correct syntax errors and
satisfy execution time constraints. We evaluate our neuro-symbolic approach
using a benchmark suite with 1500 path-planning problems. The experimental
evaluation shows that our neuro-symbolic approach produces 90.1% valid paths
that are on average 19-77% shorter than state-of-the-art neural approaches.",2024-09-10 20:49:05+00:00
AssistTaxi: A Comprehensive Dataset for Taxiway Analysis and Autonomous Operations,"The availability of high-quality datasets play a crucial role in advancing
research and development especially, for safety critical and autonomous
systems. In this paper, we present AssistTaxi, a comprehensive novel dataset
which is a collection of images for runway and taxiway analysis. The dataset
comprises of more than 300,000 frames of diverse and carefully collected data,
gathered from Melbourne (MLB) and Grant-Valkaria (X59) general aviation
airports. The importance of AssistTaxi lies in its potential to advance
autonomous operations, enabling researchers and developers to train and
evaluate algorithms for efficient and safe taxiing. Researchers can utilize
AssistTaxi to benchmark their algorithms, assess performance, and explore novel
approaches for runway and taxiway analysis. Addition-ally, the dataset serves
as a valuable resource for validating and enhancing existing algorithms,
facilitating innovation in autonomous operations for aviation. We also propose
an initial approach to label the dataset using a contour based detection and
line extraction technique.",2024-09-10 20:40:54+00:00
ExIQA: Explainable Image Quality Assessment Using Distortion Attributes,"Blind Image Quality Assessment (BIQA) aims to develop methods that estimate
the quality scores of images in the absence of a reference image. In this
paper, we approach BIQA from a distortion identification perspective, where our
primary goal is to predict distortion types and strengths using Vision-Language
Models (VLMs), such as CLIP, due to their extensive knowledge and
generalizability. Based on these predicted distortions, we then estimate the
quality score of the image. To achieve this, we propose an explainable approach
for distortion identification based on attribute learning. Instead of prompting
VLMs with the names of distortions, we prompt them with the attributes or
effects of distortions and aggregate this information to infer the distortion
strength. Additionally, we consider multiple distortions per image, making our
method more scalable. To support this, we generate a dataset consisting of
100,000 images for efficient training. Finally, attribute probabilities are
retrieved and fed into a regressor to predict the image quality score. The
results show that our approach, besides its explainability and transparency,
achieves state-of-the-art (SOTA) performance across multiple datasets in both
PLCC and SRCC metrics. Moreover, the zero-shot results demonstrate the
generalizability of the proposed approach.",2024-09-10 20:28:14+00:00
LIME-M: Less Is More for Evaluation of MLLMs,"With the remarkable success achieved by Multimodal Large Language Models
(MLLMs), numerous benchmarks have been designed to assess MLLMs' ability to
guide their development in image perception tasks (e.g., image captioning and
visual question answering). However, the existence of numerous benchmarks
results in a substantial computational burden when evaluating model performance
across all of them. Moreover, these benchmarks contain many overly simple
problems or challenging samples, which do not effectively differentiate the
capabilities among various MLLMs. To address these challenges, we propose a
pipeline to process the existing benchmarks, which consists of two modules: (1)
Semi-Automated Screening Process and (2) Eliminating Answer Leakage. The
Semi-Automated Screening Process filters out samples that cannot distinguish
the model's capabilities by synthesizing various MLLMs and manually evaluating
them. The Eliminate Answer Leakage module filters samples whose answers can be
inferred without images. Finally, we curate the LIME-M: Less Is More for
Evaluation of Multimodal LLMs, a lightweight Multimodal benchmark that can more
effectively evaluate the performance of different models. Our experiments
demonstrate that: LIME-M can better distinguish the performance of different
MLLMs with fewer samples (24% of the original) and reduced time (23% of the
original); LIME-M eliminates answer leakage, focusing mainly on the information
within images; The current automatic metric (i.e., CIDEr) is insufficient for
evaluating MLLMs' capabilities in captioning. Moreover, removing the caption
task score when calculating the overall score provides a more accurate
reflection of model performance differences. All our codes and data are
released at https://github.com/kangreen0210/LIME-M.",2024-09-10 20:19:14+00:00
Shadow Removal Refinement via Material-Consistent Shadow Edges,"Shadow boundaries can be confused with material boundaries as both exhibit
sharp changes in luminance or contrast within a scene. However, shadows do not
modify the intrinsic color or texture of surfaces. Therefore, on both sides of
shadow edges traversing regions with the same material, the original color and
textures should be the same if the shadow is removed properly. These
shadow/shadow-free pairs are very useful but hard-to-collect supervision
signals. The crucial contribution of this paper is to learn how to identify
those shadow edges that traverse material-consistent regions and how to use
them as self-supervision for shadow removal refinement during test time. To
achieve this, we fine-tune SAM, an image segmentation foundation model, to
produce a shadow-invariant segmentation and then extract material-consistent
shadow edges by comparing the SAM segmentation with the shadow mask. Utilizing
these shadow edges, we introduce color and texture-consistency losses to
enhance the shadow removal process. We demonstrate the effectiveness of our
method in improving shadow removal results on more challenging, in-the-wild
images, outperforming the state-of-the-art shadow removal methods.
Additionally, we propose a new metric and an annotated dataset for evaluating
the performance of shadow removal methods without the need for paired
shadow/shadow-free data.",2024-09-10 20:16:28+00:00
"Stratospheric aerosol source inversion: Noise, variability, and uncertainty quantification","Stratospheric aerosols play an important role in the earth system and can
affect the climate on timescales of months to years. However, estimating the
characteristics of partially observed aerosol injections, such as those from
volcanic eruptions, is fraught with uncertainties. This article presents a
framework for stratospheric aerosol source inversion which accounts for
background aerosol noise and earth system internal variability via a Bayesian
approximation error approach. We leverage specially designed earth system model
simulations using the Energy Exascale Earth System Model (E3SM). A
comprehensive framework for data generation, data processing, dimension
reduction, operator learning, and Bayesian inversion is presented where each
component of the framework is designed to address particular challenges in
stratospheric modeling on the global scale. We present numerical results using
synthesized observational data to rigorously assess the ability of our approach
to estimate aerosol sources and associate uncertainty with those estimates.",2024-09-10 20:12:36+00:00
Face Mask Removal with Region-attentive Face Inpainting,"During the COVID-19 pandemic, face masks have become ubiquitous in our lives.
Face masks can cause some face recognition models to fail since they cover
significant portion of a face. In addition, removing face masks from captured
images or videos can be desirable, e.g., for better social interaction and for
image/video editing and enhancement purposes. Hence, we propose a generative
face inpainting method to effectively recover/reconstruct the masked part of a
face. Face inpainting is more challenging compared to traditional inpainting,
since it requires high fidelity while maintaining the identity at the same
time. Our proposed method includes a Multi-scale Channel-Spatial Attention
Module (M-CSAM) to mitigate the spatial information loss and learn the inter-
and intra-channel correlation. In addition, we introduce an approach enforcing
the supervised signal to focus on masked regions instead of the whole image. We
also synthesize our own Masked-Faces dataset from the CelebA dataset by
incorporating five different types of face masks, including surgical mask,
regular mask and scarves, which also cover the neck area. The experimental
results show that our proposed method outperforms different baselines in terms
of structural similarity index measure, peak signal-to-noise ratio and l1 loss,
while also providing better outputs qualitatively. The code will be made
publicly available. Code is available at GitHub.",2024-09-10 20:10:11+00:00
Few-Shot Learning: Expanding ID Cards Presentation Attack Detection to Unknown ID Countries,"This paper proposes a Few-shot Learning (FSL) approach for detecting
Presentation Attacks on ID Cards deployed in a remote verification system and
its extension to new countries. Our research analyses the performance of
Prototypical Networks across documents from Spain and Chile as a baseline and
measures the extension of generalisation capabilities of new ID Card countries
such as Argentina and Costa Rica. Specifically targeting the challenge of
screen display presentation attacks. By leveraging convolutional architectures
and meta-learning principles embodied in Prototypical Networks, we have crafted
a model that demonstrates high efficacy with Few-shot examples. This research
reveals that competitive performance can be achieved with as Few-shots as five
unique identities and with under 100 images per new country added. This opens a
new insight for novel generalised Presentation Attack Detection on ID cards to
unknown attacks.",2024-09-10 20:05:00+00:00
Explainable Metrics for the Assessment of Neurodegenerative Diseases through Handwriting Analysis,"Motor changes are early signs of neurodegenerative diseases (NDs) such as
Parkinson's disease (PD) and Alzheimer's disease (AD), but are often difficult
to detect, especially in the early stages. In this work, we examine the
behavior of a wide array of explainable metrics extracted from the handwriting
signals of 113 subjects performing multiple tasks on a digital tablet. The aim
is to measure their effectiveness in characterizing and assessing multiple NDs,
including AD and PD. To this end, task-agnostic and task-specific metrics are
extracted from 14 distinct tasks. Subsequently, through statistical analysis
and a series of classification experiments, we investigate which metrics
provide greater discriminative power between NDs and healthy controls and among
different NDs. Preliminary results indicate that the various tasks at hand can
all be effectively leveraged to distinguish between the considered set of NDs,
specifically by measuring the stability, the speed of writing, the time spent
not writing, and the pressure variations between groups from our handcrafted
explainable metrics, which shows p-values lower than 0.0001 for multiple tasks.
Using various classification algorithms on the computed metrics, we obtain up
to 87% accuracy to discriminate AD and healthy controls (CTL), and up to 69%
for PD vs CTL.",2024-09-10 20:04:27+00:00
Atom dimension adaptation for infinite set dictionary learning,"Recent work on dictionary learning with set-atoms has shown benefits in
anomaly detection. Instead of viewing an atom as a single vector, these methods
allow building sparse representations with atoms taken from a set around a
central vector; the set can be a cone or may have a probability distribution
associated to it. We propose a method for adaptively adjusting the size of
set-atoms in Gaussian and cone dictionary learning. The purpose of the
algorithm is to match the atom sizes with their contribution in representing
the signals. The proposed algorithm not only decreases the representation
error, but also improves anomaly detection, for a class of anomalies called
`dependency'. We obtain better detection performance than state-of-the-art
methods.",2024-09-10 19:18:03+00:00
Noisy Early Stopping for Noisy Labels,"Training neural network classifiers on datasets contaminated with noisy
labels significantly increases the risk of overfitting. Thus, effectively
implementing Early Stopping in noisy label environments is crucial. Under ideal
circumstances, Early Stopping utilises a validation set uncorrupted by label
noise to effectively monitor generalisation during training. However, obtaining
a noise-free validation dataset can be costly and challenging to obtain. This
study establishes that, in many typical learning environments, a noise-free
validation set is not necessary for effective Early Stopping. Instead,
near-optimal results can be achieved by monitoring accuracy on a noisy dataset
- drawn from the same distribution as the noisy training set. Referred to as
`Noisy Early Stopping' (NES), this method simplifies and reduces the cost of
implementing Early Stopping. We provide theoretical insights into the
conditions under which this method is effective and empirically demonstrate its
robust performance across standard benchmarks using common loss functions.",2024-09-10 19:15:03+00:00
Cross-Modal Self-Supervised Learning with Effective Contrastive Units for LiDAR Point Clouds,"3D perception in LiDAR point clouds is crucial for a self-driving vehicle to
properly act in 3D environment. However, manually labeling point clouds is hard
and costly. There has been a growing interest in self-supervised pre-training
of 3D perception models. Following the success of contrastive learning in
images, current methods mostly conduct contrastive pre-training on point clouds
only. Yet an autonomous driving vehicle is typically supplied with multiple
sensors including cameras and LiDAR. In this context, we systematically study
single modality, cross-modality, and multi-modality for contrastive learning of
point clouds, and show that cross-modality wins over other alternatives. In
addition, considering the huge difference between the training sources in 2D
images and 3D point clouds, it remains unclear how to design more effective
contrastive units for LiDAR. We therefore propose the instance-aware and
similarity-balanced contrastive units that are tailored for self-driving point
clouds. Extensive experiments reveal that our approach achieves remarkable
performance gains over various point cloud models across the downstream
perception tasks of LiDAR based 3D object detection and 3D semantic
segmentation on the four popular benchmarks including Waymo Open Dataset,
nuScenes, SemanticKITTI and ONCE.",2024-09-10 19:11:45+00:00
Sam2Rad: A Segmentation Model for Medical Images with Learnable Prompts,"Foundation models like the segment anything model require high-quality manual
prompts for medical image segmentation, which is time-consuming and requires
expertise. SAM and its variants often fail to segment structures in ultrasound
(US) images due to domain shift.
  We propose Sam2Rad, a prompt learning approach to adapt SAM and its variants
for US bone segmentation without human prompts. It introduces a prompt
predictor network (PPN) with a cross-attention module to predict prompt
embeddings from image encoder features. PPN outputs bounding box and mask
prompts, and 256-dimensional embeddings for regions of interest. The framework
allows optional manual prompting and can be trained end-to-end using
parameter-efficient fine-tuning (PEFT).
  Sam2Rad was tested on 3 musculoskeletal US datasets: wrist (3822 images),
rotator cuff (1605 images), and hip (4849 images). It improved performance
across all datasets without manual prompts, increasing Dice scores by 2-7% for
hip/wrist and up to 33% for shoulder data. Sam2Rad can be trained with as few
as 10 labeled images and is compatible with any SAM architecture for automatic
segmentation.",2024-09-10 19:04:44+00:00
Bifurcation Identification for Ultrasound-driven Robotic Cannulation,"In trauma and critical care settings, rapid and precise intravascular access
is key to patients' survival. Our research aims at ensuring this access, even
when skilled medical personnel are not readily available. Vessel bifurcations
are anatomical landmarks that can guide the safe placement of catheters or
needles during medical procedures. Although ultrasound is advantageous in
navigating anatomical landmarks in emergency scenarios due to its portability
and safety, to our knowledge no existing algorithm can autonomously extract
vessel bifurcations using ultrasound images. This is primarily due to the
limited availability of ground truth data, in particular, data from live
subjects, needed for training and validating reliable models. Researchers often
resort to using data from anatomical phantoms or simulations. We introduce
BIFURC, Bifurcation Identification for Ultrasound-driven Robot Cannulation, a
novel algorithm that identifies vessel bifurcations and provides optimal needle
insertion sites for an autonomous robotic cannulation system. BIFURC integrates
expert knowledge with deep learning techniques to efficiently detect vessel
bifurcations within the femoral region and can be trained on a limited amount
of in-vivo data. We evaluated our algorithm using a medical phantom as well as
real-world experiments involving live pigs. In all cases, BIFURC consistently
identified bifurcation points and needle insertion locations in alignment with
those identified by expert clinicians.",2024-09-10 18:53:52+00:00
Object Modeling from Underwater Forward-Scan Sonar Imagery with Sea-Surface Multipath,"We propose an optimization technique for 3-D underwater object modeling from
2-D forward-scan sonar images at known poses. A key contribution, for objects
imaged in the proximity of the sea surface, is to resolve the multipath
artifacts due to the air-water interface. Here, the object image formed by the
direct target backscatter is almost always corrupted by the ghost and sometimes
by the mirror components (generated by the multipath propagation). Assuming a
planar air-water interface, we model, localize, and discard the corrupted
object region within each view, thus avoiding the distortion of recovered 3-D
shape. Additionally, complementary visual cues from the boundary of the mirror
component, distinct at suitable sonar poses, are employed to enhance the 3-D
modeling accuracy.
  The optimization is implemented as iterative shape adjustment by displacing
the vertices of triangular patches in the 3-D surface mesh model, in order to
minimize the discrepancy between the data and synthesized views of the 3-D
object model. To this end, we first determine 2-D motion fields that align the
object regions in the data and synthesized views, then calculate the 3-D motion
of triangular patch centers, and finally the model vertices. The 3-D model is
initialized with the solution of an earlier space carving method applied to the
same data. The same parameters are applied in various experiments with 2 real
data sets, mixed real-synthetic data set, and computer-generated data guided by
general findings from a real experiment, to explore the impact of non-flat
air-water interface. The results confirm the generation of a refined 3-D model
in about half-dozen iterations.",2024-09-10 18:46:25+00:00
DetailCLIP: Detail-Oriented CLIP for Fine-Grained Tasks,"In this paper, we introduce DetailCLIP: A Detail-Oriented CLIP to address the
limitations of contrastive learning-based vision-language models, particularly
CLIP, in handling detail-oriented and fine-grained tasks like segmentation.
While CLIP and its variants excel in the global alignment of image and text
representations, they often struggle to capture the fine-grained details
necessary for precise segmentation. To overcome these challenges, we propose a
novel framework that employs patch-level comparison of self-distillation and
pixel-level reconstruction losses, enhanced with an attention-based token
removal mechanism. This approach selectively retains semantically relevant
tokens, enabling the model to focus on the image's critical regions aligned
with the specific functions of our model, including textual information
processing, patch comparison, and image reconstruction, ensuring that the model
learns high-level semantics and detailed visual features. Our experiments
demonstrate that DetailCLIP surpasses existing CLIP-based and traditional
self-supervised learning (SSL) models in segmentation accuracy and exhibits
superior generalization across diverse datasets. DetailCLIP represents a
significant advancement in vision-language modeling, offering a robust solution
for tasks that demand high-level semantic understanding and detailed feature
extraction. https://github.com/KishoreP1/DetailCLIP.",2024-09-10 18:27:36+00:00
Personalized Federated Learning Techniques: Empirical Analysis,"Personalized Federated Learning (pFL) holds immense promise for tailoring
machine learning models to individual users while preserving data privacy.
However, achieving optimal performance in pFL often requires a careful
balancing act between memory overhead costs and model accuracy. This paper
delves into the trade-offs inherent in pFL, offering valuable insights for
selecting the right algorithms for diverse real-world scenarios. We empirically
evaluate ten prominent pFL techniques across various datasets and data splits,
uncovering significant differences in their performance. Our study reveals
interesting insights into how pFL methods that utilize personalized (local)
aggregation exhibit the fastest convergence due to their efficiency in
communication and computation. Conversely, fine-tuning methods face limitations
in handling data heterogeneity and potential adversarial attacks while
multi-objective learning methods achieve higher accuracy at the cost of
additional training and resource consumption. Our study emphasizes the critical
role of communication efficiency in scaling pFL, demonstrating how it can
significantly affect resource usage in real-world deployments.",2024-09-10 18:16:28+00:00
How Molecules Impact Cells: Unlocking Contrastive PhenoMolecular Retrieval,"Predicting molecular impact on cellular function is a core challenge in
therapeutic design. Phenomic experiments, designed to capture cellular
morphology, utilize microscopy based techniques and demonstrate a high
throughput solution for uncovering molecular impact on the cell. In this work,
we learn a joint latent space between molecular structures and microscopy
phenomic experiments, aligning paired samples with contrastive learning.
Specifically, we study the problem ofContrastive PhenoMolecular Retrieval,
which consists of zero-shot molecular structure identification conditioned on
phenomic experiments. We assess challenges in multi-modal learning of phenomics
and molecular modalities such as experimental batch effect, inactive molecule
perturbations, and encoding perturbation concentration. We demonstrate improved
multi-modal learner retrieval through (1) a uni-modal pre-trained phenomics
model, (2) a novel inter sample similarity aware loss, and (3) models
conditioned on a representation of molecular concentration. Following this
recipe, we propose MolPhenix, a molecular phenomics model. MolPhenix leverages
a pre-trained phenomics model to demonstrate significant performance gains
across perturbation concentrations, molecular scaffolds, and activity
thresholds. In particular, we demonstrate an 8.1x improvement in zero shot
molecular retrieval of active molecules over the previous state-of-the-art,
reaching 77.33% in top-1% accuracy. These results open the door for machine
learning to be applied in virtual phenomics screening, which can significantly
benefit drug discovery applications.",2024-09-10 18:16:27+00:00
Adaptive Meta-Domain Transfer Learning (AMDTL): A Novel Approach for Knowledge Transfer in AI,"This paper presents Adaptive Meta-Domain Transfer Learning (AMDTL), a novel
methodology that combines principles of meta-learning with domain-specific
adaptations to enhance the transferability of artificial intelligence models
across diverse and unknown domains. AMDTL aims to address the main challenges
of transfer learning, such as domain misalignment, negative transfer, and
catastrophic forgetting, through a hybrid framework that emphasizes both
generalization and contextual specialization. The framework integrates a
meta-learner trained on a diverse distribution of tasks, adversarial training
techniques for aligning domain feature distributions, and dynamic feature
regulation mechanisms based on contextual domain embeddings. Experimental
results on benchmark datasets demonstrate that AMDTL outperforms existing
transfer learning methodologies in terms of accuracy, adaptation efficiency,
and robustness. This research provides a solid theoretical and practical
foundation for the application of AMDTL in various fields, opening new
perspectives for the development of more adaptable and inclusive AI systems.",2024-09-10 18:11:48+00:00
Adversarial Attacks to Multi-Modal Models,"Multi-modal models have gained significant attention due to their powerful
capabilities. These models effectively align embeddings across diverse data
modalities, showcasing superior performance in downstream tasks compared to
their unimodal counterparts. Recent study showed that the attacker can
manipulate an image or audio file by altering it in such a way that its
embedding matches that of an attacker-chosen targeted input, thereby deceiving
downstream models. However, this method often underperforms due to inherent
disparities in data from different modalities. In this paper, we introduce
CrossFire, an innovative approach to attack multi-modal models. CrossFire
begins by transforming the targeted input chosen by the attacker into a format
that matches the modality of the original image or audio file. We then
formulate our attack as an optimization problem, aiming to minimize the angular
deviation between the embeddings of the transformed input and the modified
image or audio file. Solving this problem determines the perturbations to be
added to the original media. Our extensive experiments on six real-world
benchmark datasets reveal that CrossFire can significantly manipulate
downstream tasks, surpassing existing attacks. Additionally, we evaluate six
defensive strategies against CrossFire, finding that current defenses are
insufficient to counteract our CrossFire.",2024-09-10 18:02:51+00:00
Human Motion Synthesis_ A Diffusion Approach for Motion Stitching and In-Betweening,"Human motion generation is an important area of research in many fields. In
this work, we tackle the problem of motion stitching and in-betweening. Current
methods either require manual efforts, or are incapable of handling longer
sequences. To address these challenges, we propose a diffusion model with a
transformer-based denoiser to generate realistic human motion. Our method
demonstrated strong performance in generating in-betweening sequences,
transforming a variable number of input poses into smooth and realistic motion
sequences consisting of 75 frames at 15 fps, resulting in a total duration of 5
seconds. We present the performance evaluation of our method using quantitative
metrics such as Frechet Inception Distance (FID), Diversity, and Multimodality,
along with visual assessments of the generated outputs.",2024-09-10 18:02:32+00:00
GeoCalib: Learning Single-image Calibration with Geometric Optimization,"From a single image, visual cues can help deduce intrinsic and extrinsic
camera parameters like the focal length and the gravity direction. This
single-image calibration can benefit various downstream applications like image
editing and 3D mapping. Current approaches to this problem are based on either
classical geometry with lines and vanishing points or on deep neural networks
trained end-to-end. The learned approaches are more robust but struggle to
generalize to new environments and are less accurate than their classical
counterparts. We hypothesize that they lack the constraints that 3D geometry
provides. In this work, we introduce GeoCalib, a deep neural network that
leverages universal rules of 3D geometry through an optimization process.
GeoCalib is trained end-to-end to estimate camera parameters and learns to find
useful visual cues from the data. Experiments on various benchmarks show that
GeoCalib is more robust and more accurate than existing classical and learned
approaches. Its internal optimization estimates uncertainties, which help flag
failure cases and benefit downstream applications like visual localization. The
code and trained models are publicly available at
https://github.com/cvg/GeoCalib.",2024-09-10 17:59:55+00:00
LEIA: Latent View-invariant Embeddings for Implicit 3D Articulation,"Neural Radiance Fields (NeRFs) have revolutionized the reconstruction of
static scenes and objects in 3D, offering unprecedented quality. However,
extending NeRFs to model dynamic objects or object articulations remains a
challenging problem. Previous works have tackled this issue by focusing on
part-level reconstruction and motion estimation for objects, but they often
rely on heuristics regarding the number of moving parts or object categories,
which can limit their practical use. In this work, we introduce LEIA, a novel
approach for representing dynamic 3D objects. Our method involves observing the
object at distinct time steps or ""states"" and conditioning a hypernetwork on
the current state, using this to parameterize our NeRF. This approach allows us
to learn a view-invariant latent representation for each state. We further
demonstrate that by interpolating between these states, we can generate novel
articulation configurations in 3D space that were previously unseen. Our
experimental results highlight the effectiveness of our method in articulating
objects in a manner that is independent of the viewing angle and joint
configuration. Notably, our approach outperforms previous methods that rely on
motion information for articulation registration.",2024-09-10 17:59:53+00:00
Hint-AD: Holistically Aligned Interpretability in End-to-End Autonomous Driving,"End-to-end architectures in autonomous driving (AD) face a significant
challenge in interpretability, impeding human-AI trust. Human-friendly natural
language has been explored for tasks such as driving explanation and 3D
captioning. However, previous works primarily focused on the paradigm of
declarative interpretability, where the natural language interpretations are
not grounded in the intermediate outputs of AD systems, making the
interpretations only declarative. In contrast, aligned interpretability
establishes a connection between language and the intermediate outputs of AD
systems. Here we introduce Hint-AD, an integrated AD-language system that
generates language aligned with the holistic perception-prediction-planning
outputs of the AD model. By incorporating the intermediate outputs and a
holistic token mixer sub-network for effective feature adaptation, Hint-AD
achieves desirable accuracy, achieving state-of-the-art results in driving
language tasks including driving explanation, 3D dense captioning, and command
prediction. To facilitate further study on driving explanation task on
nuScenes, we also introduce a human-labeled dataset, Nu-X. Codes, dataset, and
models will be publicly available.",2024-09-10 17:59:40+00:00
"A study on Deep Convolutional Neural Networks, Transfer Learning and Ensemble Model for Breast Cancer Detection","In deep learning, transfer learning and ensemble models have shown promise in
improving computer-aided disease diagnosis. However, applying the transfer
learning and ensemble model is still relatively limited. Moreover, the ensemble
model's development is ad-hoc, overlooks redundant layers, and suffers from
imbalanced datasets and inadequate augmentation. Lastly, significant Deep
Convolutional Neural Networks (D-CNNs) have been introduced to detect and
classify breast cancer. Still, very few comparative studies were conducted to
investigate the accuracy and efficiency of existing CNN architectures.
Realising the gaps, this study compares the performance of D-CNN, which
includes the original CNN, transfer learning, and an ensemble model, in
detecting breast cancer. The comparison study of this paper consists of
comparison using six CNN-based deep learning architectures (SE-ResNet152,
MobileNetV2, VGG19, ResNet18, InceptionV3, and DenseNet-121), a transfer
learning, and an ensemble model on breast cancer detection. Among the
comparison of these models, the ensemble model provides the highest detection
and classification accuracy of 99.94% for breast cancer detection and
classification. However, this study also provides a negative result in the case
of transfer learning, as the transfer learning did not increase the accuracy of
the original SE-ResNet152, MobileNetV2, VGG19, ResNet18, InceptionV3, and
DenseNet-121 model. The high accuracy in detecting and categorising breast
cancer detection using CNN suggests that the CNN model is promising in breast
cancer disease detection. This research is significant in biomedical
engineering, computer-aided disease diagnosis, and ML-based disease detection.",2024-09-10 17:58:21+00:00
gsplat: An Open-Source Library for Gaussian Splatting,"gsplat is an open-source library designed for training and developing
Gaussian Splatting methods. It features a front-end with Python bindings
compatible with the PyTorch library and a back-end with highly optimized CUDA
kernels. gsplat offers numerous features that enhance the optimization of
Gaussian Splatting models, which include optimization improvements for speed,
memory, and convergence times. Experimental results demonstrate that gsplat
achieves up to 10% less training time and 4x less memory than the original
implementation. Utilized in several research projects, gsplat is actively
maintained on GitHub. Source code is available at
https://github.com/nerfstudio-project/gsplat under Apache License 2.0. We
welcome contributions from the open-source community.",2024-09-10 17:57:38+00:00
DANCE: Deep Learning-Assisted Analysis of Protein Sequences Using Chaos Enhanced Kaleidoscopic Images,"Cancer is a complex disease characterized by uncontrolled cell growth. T cell
receptors (TCRs), crucial proteins in the immune system, play a key role in
recognizing antigens, including those associated with cancer. Recent
advancements in sequencing technologies have facilitated comprehensive
profiling of TCR repertoires, uncovering TCRs with potent anti-cancer activity
and enabling TCR-based immunotherapies. However, analyzing these intricate
biomolecules necessitates efficient representations that capture their
structural and functional information. T-cell protein sequences pose unique
challenges due to their relatively smaller lengths compared to other
biomolecules. An image-based representation approach becomes a preferred choice
for efficient embeddings, allowing for the preservation of essential details
and enabling comprehensive analysis of T-cell protein sequences. In this paper,
we propose to generate images from the protein sequences using the idea of
Chaos Game Representation (CGR) using the Kaleidoscopic images approach. This
Deep Learning Assisted Analysis of Protein Sequences Using Chaos Enhanced
Kaleidoscopic Images (called DANCE) provides a unique way to visualize protein
sequences by recursively applying chaos game rules around a central seed point.
we perform the classification of the T cell receptors (TCRs) protein sequences
in terms of their respective target cancer cells, as TCRs are known for their
immune response against cancer disease. The TCR sequences are converted into
images using the DANCE method. We employ deep-learning vision models to perform
the classification to obtain insights into the relationship between the visual
patterns observed in the generated kaleidoscopic images and the underlying
protein properties. By combining CGR-based image generation with deep learning
classification, this study opens novel possibilities in the protein analysis
domain.",2024-09-10 17:55:59+00:00
Modeling Image Tone Dichotomy with the Power Function,"The primary purpose of this paper is to present the concept of dichotomy in
image illumination modeling based on the power function. In particular, we
review several mathematical properties of the power function to identify the
limitations and propose a new mathematical model capable of abstracting
illumination dichotomy. The simplicity of the equation opens new avenues for
classical and modern image analysis and processing. The article provides
practical and illustrative image examples to explain how the new model manages
dichotomy in image perception. The article shows dichotomy image space as a
viable way to extract rich information from images despite poor contrast linked
to tone, lightness, and color perception. Moreover, a comparison with
state-of-the-art methods in image enhancement provides evidence of the method's
value.",2024-09-10 17:55:09+00:00
HybridFC: A Hybrid Fact-Checking Approach for Knowledge Graphs,"We consider fact-checking approaches that aim to predict the veracity of
assertions in knowledge graphs. Five main categories of fact-checking
approaches for knowledge graphs have been proposed in the recent literature, of
which each is subject to partially overlapping limitations. In particular,
current text-based approaches are limited by manual feature engineering.
Path-based and rule-based approaches are limited by their exclusive use of
knowledge graphs as background knowledge, and embedding-based approaches suffer
from low accuracy scores on current fact-checking tasks. We propose a hybrid
approach -- dubbed HybridFC -- that exploits the diversity of existing
categories of fact-checking approaches within an ensemble learning setting to
achieve a significantly better prediction performance. In particular, our
approach outperforms the state of the art by 0.14 to 0.27 in terms of Area
Under the Receiver Operating Characteristic curve on the FactBench dataset. Our
code is open-source and can be found at https://github.com/dice-group/HybridFC.",2024-09-10 17:55:00+00:00
Geometric-Averaged Preference Optimization for Soft Preference Labels,"Many algorithms for aligning LLMs with human preferences assume that human
preferences are binary and deterministic. However, it is reasonable to think
that they can vary with different individuals, and thus should be
distributional to reflect the fine-grained relationship between the responses.
In this work, we introduce the distributional soft preference labels and
improve Direct Preference Optimization (DPO) with a weighted geometric average
of the LLM output likelihood in the loss function. In doing so, the scale of
learning loss is adjusted based on the soft labels, and the loss with equally
preferred responses would be close to zero. This simple modification can be
easily applied to any DPO family and helps the models escape from the
over-optimization and objective mismatch prior works suffer from. In our
experiments, we simulate the soft preference labels with AI feedback from LLMs
and demonstrate that geometric averaging consistently improves performance on
standard benchmarks for alignment research. In particular, we observe more
preferable responses than binary labels and significant improvements with data
where modestly-confident labels are in the majority.",2024-09-10 17:54:28+00:00
Benchmarking Sub-Genre Classification For Mainstage Dance Music,"Music classification, with a wide range of applications, is one of the most
prominent tasks in music information retrieval. To address the absence of
comprehensive datasets and high-performing methods in the classification of
mainstage dance music, this work introduces a novel benchmark comprising a new
dataset and a baseline. Our dataset extends the number of sub-genres to cover
most recent mainstage live sets by top DJs worldwide in music festivals. A
continuous soft labeling approach is employed to account for tracks that span
multiple sub-genres, preserving the inherent sophistication. For the baseline,
we developed deep learning models that outperform current state-of-the-art
multimodel language models, which struggle to identify house music sub-genres,
emphasizing the need for specialized models trained on fine-grained datasets.
Our benchmark is applicable to serve for application scenarios such as music
recommendation, DJ set curation, and interactive multimedia, where we also
provide video demos. Our code is on
\url{https://anonymous.4open.science/r/Mainstage-EDM-Benchmark/}.",2024-09-10 17:54:00+00:00
A comprehensive study on Blood Cancer detection and classification using Convolutional Neural Network,"Over the years in object detection several efficient Convolutional Neural
Networks (CNN) networks, such as DenseNet201, InceptionV3, ResNet152v2,
SEresNet152, VGG19, Xception gained significant attention due to their
performance. Moreover, CNN paradigms have expanded to transfer learning and
ensemble models from original CNN architectures. Research studies suggest that
transfer learning and ensemble models are capable of increasing the accuracy of
deep learning (DL) models. However, very few studies have conducted
comprehensive experiments utilizing these techniques in detecting and
localizing blood malignancies. Realizing the gap, this study conducted three
experiments; in the first experiment -- six original CNNs were used, in the
second experiment -- transfer learning and, in the third experiment a novel
ensemble model DIX (DenseNet201, InceptionV3, and Xception) was developed to
detect and classify blood cancer. The statistical result suggests that DIX
outperformed the original and transfer learning performance, providing an
accuracy of 99.12%. However, this study also provides a negative result in the
case of transfer learning, as the transfer learning did not increase the
accuracy of the original CNNs. Like many other cancers, blood cancer diseases
require timely identification for effective treatment plans and increased
survival possibilities. The high accuracy in detecting and categorization blood
cancer detection using CNN suggests that the CNN model is promising in blood
cancer disease detection. This research is significant in the fields of
biomedical engineering, computer-aided disease diagnosis, and ML-based disease
detection.",2024-09-10 17:53:47+00:00
A study on deep feature extraction to detect and classify Acute Lymphoblastic Leukemia (ALL),"Acute lymphoblastic leukaemia (ALL) is a blood malignancy that mainly affects
adults and children. This study looks into the use of deep learning,
specifically Convolutional Neural Networks (CNNs), for the detection and
classification of ALL. Conventional techniques for ALL diagnosis, such bone
marrow biopsy, are costly and prone to mistakes made by hand. By utilising
automated technologies, the research seeks to improve diagnostic accuracy. The
research uses a variety of pre-trained CNN models, such as InceptionV3,
ResNet101, VGG19, DenseNet121, MobileNetV2, and DenseNet121, to extract
characteristics from pictures of blood smears. ANOVA, Recursive Feature
Elimination (RFE), Random Forest, Lasso, and Principal Component Analysis (PCA)
are a few of the selection approaches used to find the most relevant features
after feature extraction. Following that, machine learning methods like Na\""ive
Bayes, Random Forest, Support Vector Machine (SVM), and K-Nearest Neighbours
(KNN) are used to classify these features. With an 87% accuracy rate, the
ResNet101 model produced the best results, closely followed by DenseNet121 and
VGG19. According to the study, CNN-based models have the potential to decrease
the need for medical specialists by increasing the speed and accuracy of ALL
diagnosis. To improve model performance, the study also recommends expanding
and diversifying datasets and investigating more sophisticated designs such as
transformers. This study highlights how well automated deep learning systems do
medical diagnosis.",2024-09-10 17:53:29+00:00
GigaGS: Scaling up Planar-Based 3D Gaussians for Large Scene Surface Reconstruction,"3D Gaussian Splatting (3DGS) has shown promising performance in novel view
synthesis. Previous methods adapt it to obtaining surfaces of either individual
3D objects or within limited scenes. In this paper, we make the first attempt
to tackle the challenging task of large-scale scene surface reconstruction.
This task is particularly difficult due to the high GPU memory consumption,
different levels of details for geometric representation, and noticeable
inconsistencies in appearance. To this end, we propose GigaGS, the first work
for high-quality surface reconstruction for large-scale scenes using 3DGS.
GigaGS first applies a partitioning strategy based on the mutual visibility of
spatial regions, which effectively grouping cameras for parallel processing. To
enhance the quality of the surface, we also propose novel multi-view
photometric and geometric consistency constraints based on Level-of-Detail
representation. In doing so, our method can reconstruct detailed surface
structures. Comprehensive experiments are conducted on various datasets. The
consistent improvement demonstrates the superiority of GigaGS.",2024-09-10 17:51:39+00:00
Generative Hierarchical Materials Search,"Generative models trained at scale can now produce text, video, and more
recently, scientific data such as crystal structures. In applications of
generative approaches to materials science, and in particular to crystal
structures, the guidance from the domain expert in the form of high-level
instructions can be essential for an automated system to output candidate
crystals that are viable for downstream research. In this work, we formulate
end-to-end language-to-structure generation as a multi-objective optimization
problem, and propose Generative Hierarchical Materials Search (GenMS) for
controllable generation of crystal structures. GenMS consists of (1) a language
model that takes high-level natural language as input and generates
intermediate textual information about a crystal (e.g., chemical formulae), and
(2) a diffusion model that takes intermediate information as input and
generates low-level continuous value crystal structures. GenMS additionally
uses a graph neural network to predict properties (e.g., formation energy) from
the generated crystal structures. During inference, GenMS leverages all three
components to conduct a forward tree search over the space of possible
structures. Experiments show that GenMS outperforms other alternatives of
directly using language models to generate structures both in satisfying user
request and in generating low-energy structures. We confirm that GenMS is able
to generate common crystal structures such as double perovskites, or spinels,
solely from natural language input, and hence can form the foundation for more
complex structure generation in near future.",2024-09-10 17:51:28+00:00
Alignist: CAD-Informed Orientation Distribution Estimation by Fusing Shape and Correspondences,"Object pose distribution estimation is crucial in robotics for better path
planning and handling of symmetric objects. Recent distribution estimation
approaches employ contrastive learning-based approaches by maximizing the
likelihood of a single pose estimate in the absence of a CAD model. We propose
a pose distribution estimation method leveraging symmetry respecting
correspondence distributions and shape information obtained using a CAD model.
Contrastive learning-based approaches require an exhaustive amount of training
images from different viewpoints to learn the distribution properly, which is
not possible in realistic scenarios. Instead, we propose a pipeline that can
leverage correspondence distributions and shape information from the CAD model,
which are later used to learn pose distributions. Besides, having access to
pose distribution based on correspondences before learning pose distributions
conditioned on images, can help formulate the loss between distributions. The
prior knowledge of distribution also helps the network to focus on getting
sharper modes instead. With the CAD prior, our approach converges much faster
and learns distribution better by focusing on learning sharper distribution
near all the valid modes, unlike contrastive approaches, which focus on a
single mode at a time. We achieve benchmark results on SYMSOL-I and T-Less
datasets.",2024-09-10 17:51:03+00:00
Constructing an Interpretable Deep Denoiser by Unrolling Graph Laplacian Regularizer,"An image denoiser can be used for a wide range of restoration problems via
the Plug-and-Play (PnP) architecture. In this paper, we propose a general
framework to build an interpretable graph-based deep denoiser (GDD) by
unrolling a solution to a maximum a posteriori (MAP) problem equipped with a
graph Laplacian regularizer (GLR) as signal prior. Leveraging a recent theorem
showing that any (pseudo-)linear denoiser $\boldsymbol \Psi$, under mild
conditions, can be mapped to a solution of a MAP denoising problem regularized
using GLR, we first initialize a graph Laplacian matrix $\mathbf L$ via
truncated Taylor Series Expansion (TSE) of $\boldsymbol \Psi^{-1}$. Then, we
compute the MAP linear system solution by unrolling iterations of the conjugate
gradient (CG) algorithm into a sequence of neural layers as a feed-forward
network -- one that is amenable to parameter tuning. The resulting GDD network
is ""graph-interpretable"", low in parameter count, and easy to initialize thanks
to $\mathbf L$ derived from a known well-performing denoiser $\boldsymbol
\Psi$. Experimental results show that GDD achieves competitive image denoising
performance compared to competitors, but employing far fewer parameters, and is
more robust to covariate shift.",2024-09-10 17:42:14+00:00
Liability and Insurance for Catastrophic Losses: the Nuclear Power Precedent and Lessons for AI,"As AI systems become more autonomous and capable, experts warn of them
potentially causing catastrophic losses. Drawing on the successful precedent
set by the nuclear power industry, this paper argues that developers of
frontier AI models should be assigned limited, strict, and exclusive third
party liability for harms resulting from Critical AI Occurrences (CAIOs) -
events that cause or easily could have caused catastrophic losses. Mandatory
insurance for CAIO liability is recommended to overcome developers'
judgment-proofness, mitigate winner's curse dynamics, and leverage insurers'
quasi-regulatory abilities. Based on theoretical arguments and observations
from the analogous nuclear power context, insurers are expected to engage in a
mix of causal risk-modeling, monitoring, lobbying for stricter regulation, and
providing loss prevention guidance in the context of insuring against
heavy-tail risks from AI. While not a substitute for regulation, clear
liability assignment and mandatory insurance can help efficiently allocate
resources to risk-modeling and safe design, facilitating future regulatory
efforts.",2024-09-10 17:41:31+00:00
Insuring Uninsurable Risks from AI: The State as Insurer of Last Resort,"Many experts believe that AI systems will sooner or later pose uninsurable
risks, including existential risks. This creates an extreme judgment-proof
problem: few if any parties can be held accountable ex post in the event of
such a catastrophe. This paper proposes a novel solution: a
government-provided, mandatory indemnification program for AI developers. The
program uses risk-priced indemnity fees to induce socially optimal levels of
care. Risk-estimates are determined by surveying experts, including indemnified
developers. The Bayesian Truth Serum mechanism is employed to incent honest and
effortful responses. Compared to alternatives, this approach arguably better
leverages all private information, and provides a clearer signal to indemnified
developers regarding what risks they must mitigate to lower their fees. It's
recommended that collected fees be used to help fund the safety research
developers need, employing a fund matching mechanism (Quadratic Financing) to
induce an optimal supply of this public good. Under Quadratic Financing, safety
research projects would compete for private contributions from developers,
signaling how much each is to be supplemented with public funds.",2024-09-10 17:41:24+00:00
A Semantic Segmentation Approach on Sweet Orange Leaf Diseases Detection Utilizing YOLO,"This research introduces an advanced method for diagnosing diseases in sweet
orange leaves by utilising advanced artificial intelligence models like YOLOv8
. Due to their significance as a vital agricultural product, sweet oranges
encounter significant threats from a variety of diseases that harmfully affect
both their yield and quality. Conventional methods for disease detection
primarily depend on manual inspection which is ineffective and frequently leads
to errors, resulting in delayed treatment and increased financial losses. In
response to this challenge, the research utilized YOLOv8 , harnessing their
proficiencies in detecting objects and analyzing images. YOLOv8 is recognized
for its rapid and precise performance, while VIT is acknowledged for its
detailed feature extraction abilities. Impressively, during both the training
and validation stages, YOLOv8 exhibited a perfect accuracy of 80.4%, while VIT
achieved an accuracy of 99.12%, showcasing their potential to transform disease
detection in agriculture. The study comprehensively examined the practical
challenges related to the implementation of AI technologies in agriculture,
encompassing the computational demands and user accessibility, and offering
viable solutions for broader usage. Moreover, it underscores the environmental
considerations, particularly the potential for reduced pesticide usage, thereby
promoting sustainable farming and environmental conservation. These findings
provide encouraging insights into the application of AI in agriculture,
suggesting a transition towards more effective, sustainable, and
technologically advanced farming methods. This research not only highlights the
efficacy of YOLOv8 within a specific agricultural domain but also lays the
foundation for further studies that encompass a broader application in crop
management and sustainable agricultural practices.",2024-09-10 17:40:46+00:00
DA-MoE: Towards Dynamic Expert Allocation for Mixture-of-Experts Models,"Transformer-based Mixture-of-Experts (MoE) models have been driving several
recent technological advancements in Natural Language Processing (NLP). These
MoE models adopt a router mechanism to determine which experts to activate for
routing input tokens. However, existing router mechanisms allocate a fixed
number of experts to each token, which neglects the varying importance of
different input tokens. In this study, we propose a novel dynamic router
mechanism that Dynamically Allocates a variable number of experts for
Mixture-of-Experts (DA-MoE) models based on an effective token importance
measure. First, we show that the Transformer attention mechanism provides a
natural and effective way of calculating token importance. Second, we propose a
dynamic router mechanism that effectively decides the optimal number of experts
(K) and allocates the top-K experts for each input token. Third, comprehensive
experiments on several benchmark datasets demonstrate that our DA-MoE approach
consistently outperforms the state-of-the-art Transformer based MoE model on
the popular GLUE benchmark.",2024-09-10 17:36:15+00:00
LLaMA-Omni: Seamless Speech Interaction with Large Language Models,"Models like GPT-4o enable real-time interaction with large language models
(LLMs) through speech, significantly enhancing user experience compared to
traditional text-based interaction. However, there is still a lack of
exploration on how to build speech interaction models based on open-source
LLMs. To address this, we propose LLaMA-Omni, a novel model architecture
designed for low-latency and high-quality speech interaction with LLMs.
LLaMA-Omni integrates a pretrained speech encoder, a speech adaptor, an LLM,
and a streaming speech decoder. It eliminates the need for speech
transcription, and can simultaneously generate text and speech responses
directly from speech instructions with extremely low latency. We build our
model based on the latest Llama-3.1-8B-Instruct model. To align the model with
speech interaction scenarios, we construct a dataset named InstructS2S-200K,
which includes 200K speech instructions and corresponding speech responses.
Experimental results show that compared to previous speech-language models,
LLaMA-Omni provides better responses in both content and style, with a response
latency as low as 226ms. Additionally, training LLaMA-Omni takes less than 3
days on just 4 GPUs, paving the way for the efficient development of
speech-language models in the future.",2024-09-10 17:34:34+00:00
Data Collection-free Masked Video Modeling,"Pre-training video transformers generally requires a large amount of data,
presenting significant challenges in terms of data collection costs and
concerns related to privacy, licensing, and inherent biases. Synthesizing data
is one of the promising ways to solve these issues, yet pre-training solely on
synthetic data has its own challenges. In this paper, we introduce an effective
self-supervised learning framework for videos that leverages readily available
and less costly static images. Specifically, we define the Pseudo Motion
Generator (PMG) module that recursively applies image transformations to
generate pseudo-motion videos from images. These pseudo-motion videos are then
leveraged in masked video modeling. Our approach is applicable to synthetic
images as well, thus entirely freeing video pre-training from data collection
costs and other concerns in real data. Through experiments in action
recognition tasks, we demonstrate that this framework allows effective learning
of spatio-temporal features through pseudo-motion videos, significantly
improving over existing methods which also use static images and partially
outperforming those using both real and synthetic videos. These results uncover
fragments of what video transformers learn through masked video modeling.",2024-09-10 17:34:07+00:00
World-Grounded Human Motion Recovery via Gravity-View Coordinates,"We present a novel method for recovering world-grounded human motion from
monocular video. The main challenge lies in the ambiguity of defining the world
coordinate system, which varies between sequences. Previous approaches attempt
to alleviate this issue by predicting relative motion in an autoregressive
manner, but are prone to accumulating errors. Instead, we propose estimating
human poses in a novel Gravity-View (GV) coordinate system, which is defined by
the world gravity and the camera view direction. The proposed GV system is
naturally gravity-aligned and uniquely defined for each video frame, largely
reducing the ambiguity of learning image-pose mapping. The estimated poses can
be transformed back to the world coordinate system using camera rotations,
forming a global motion sequence. Additionally, the per-frame estimation avoids
error accumulation in the autoregressive methods. Experiments on in-the-wild
benchmarks demonstrate that our method recovers more realistic motion in both
the camera space and world-grounded settings, outperforming state-of-the-art
methods in both accuracy and speed. The code is available at
https://zju3dv.github.io/gvhmr/.",2024-09-10 17:25:47+00:00
Sortformer: Seamless Integration of Speaker Diarization and ASR by Bridging Timestamps and Tokens,"We propose Sortformer, a novel neural model for speaker diarization, trained
with unconventional objectives compared to existing end-to-end diarization
models. The permutation problem in speaker diarization has long been regarded
as a critical challenge. Most prior end-to-end diarization systems employ
permutation invariant loss (PIL), which optimizes for the permutation that
yields the lowest error. In contrast, we introduce Sort Loss, which enables a
diarization model to autonomously resolve permutation, with or without PIL. We
demonstrate that combining Sort Loss and PIL achieves performance competitive
with state-of-the-art end-to-end diarization models trained exclusively with
PIL. Crucially, we present a streamlined multispeaker ASR architecture that
leverages Sortformer as a speaker supervision model, embedding speaker label
estimation within the ASR encoder state using a sinusoidal kernel function.
This approach resolves the speaker permutation problem through sorted
objectives, effectively bridging speaker-label timestamps and speaker tokens.
In our experiments, we show that the proposed multispeaker ASR architecture,
enhanced with speaker supervision, improves performance via adapter techniques.
Code and trained models will be made publicly available via the NVIDIA NeMo
framework",2024-09-10 17:20:11+00:00
KANtrol: A Physics-Informed Kolmogorov-Arnold Network Framework for Solving Multi-Dimensional and Fractional Optimal Control Problems,"In this paper, we introduce the KANtrol framework, which utilizes
Kolmogorov-Arnold Networks (KANs) to solve optimal control problems involving
continuous time variables. We explain how Gaussian quadrature can be employed
to approximate the integral parts within the problem, particularly for
integro-differential state equations. We also demonstrate how automatic
differentiation is utilized to compute exact derivatives for integer-order
dynamics, while for fractional derivatives of non-integer order, we employ
matrix-vector product discretization within the KAN framework. We tackle
multi-dimensional problems, including the optimal control of a 2D heat partial
differential equation. The results of our simulations, which cover both forward
and parameter identification problems, show that the KANtrol framework
outperforms classical MLPs in terms of accuracy and efficiency.",2024-09-10 17:12:37+00:00
Image Vectorization with Depth: convexified shape layers with depth ordering,"Image vectorization is a process to convert a raster image into a scalable
vector graphic format. Objective is to effectively remove the pixelization
effect while representing boundaries of image by scaleable parameterized
curves. We propose new image vectorization with depth which considers depth
ordering among shapes and use curvature-based inpainting for convexifying
shapes in vectorization process.From a given color quantized raster image, we
first define each connected component of the same color as a shape layer, and
construct depth ordering among them using a newly proposed depth ordering
energy. Global depth ordering among all shapes is described by a directed
graph, and we propose an energy to remove cycle within the graph. After
constructing depth ordering of shapes, we convexify occluded regions by Euler's
elastica curvature-based variational inpainting, and leverage on the stability
of Modica-Mortola double-well potential energy to inpaint large regions. This
is following human vision perception that boundaries of shapes extend smoothly,
and we assume shapes are likely to be convex. Finally, we fit B\'{e}zier curves
to the boundaries and save vectorization as a SVG file which allows
superposition of curvature-based inpainted shapes following the depth ordering.
This is a new way to vectorize images, by decomposing an image into scalable
shape layers with computed depth ordering. This approach makes editing shapes
and images more natural and intuitive. We also consider grouping shape layers
for semantic vectorization. We present various numerical results and
comparisons against recent layer-based vectorization methods to validate the
proposed model.",2024-09-10 17:06:54+00:00
EyeCLIP: A visual-language foundation model for multi-modal ophthalmic image analysis,"Early detection of eye diseases like glaucoma, macular degeneration, and
diabetic retinopathy is crucial for preventing vision loss. While artificial
intelligence (AI) foundation models hold significant promise for addressing
these challenges, existing ophthalmic foundation models primarily focus on a
single modality, whereas diagnosing eye diseases requires multiple modalities.
A critical yet often overlooked aspect is harnessing the multi-view information
across various modalities for the same patient. Additionally, due to the
long-tail nature of ophthalmic diseases, standard fully supervised or
unsupervised learning approaches often struggle. Therefore, it is essential to
integrate clinical text to capture a broader spectrum of diseases. We propose
EyeCLIP, a visual-language foundation model developed using over 2.77 million
multi-modal ophthalmology images with partial text data. To fully leverage the
large multi-modal unlabeled and labeled data, we introduced a pretraining
strategy that combines self-supervised reconstructions, multi-modal image
contrastive learning, and image-text contrastive learning to learn a shared
representation of multiple modalities. Through evaluation using 14 benchmark
datasets, EyeCLIP can be transferred to a wide range of downstream tasks
involving ocular and systemic diseases, achieving state-of-the-art performance
in disease classification, visual question answering, and cross-modal
retrieval. EyeCLIP represents a significant advancement over previous methods,
especially showcasing few-shot, even zero-shot capabilities in real-world
long-tail scenarios.",2024-09-10 17:00:19+00:00
MoWE-Audio: Multitask AudioLLMs with Mixture of Weak Encoders,"The rapid advancements in large language models (LLMs) have significantly
enhanced natural language processing capabilities, facilitating the development
of AudioLLMs that process and understand speech and audio inputs alongside
text. Existing AudioLLMs typically combine a pre-trained audio encoder with a
pre-trained LLM, which are subsequently finetuned on specific audio tasks.
However, the pre-trained audio encoder has constrained capacity to capture
features for new tasks and datasets. To address this, we propose to incorporate
mixtures of `weak' encoders (MoWE) into the AudioLLM framework. MoWE
supplements a base encoder with a pool of relatively light weight encoders,
selectively activated based on the audio input to enhance feature extraction
without significantly increasing model size. Our empirical results demonstrate
that MoWE effectively improves multi-task performance, broadening the
applicability of AudioLLMs to more diverse audio tasks.",2024-09-10 16:46:18+00:00
SaRA: High-Efficient Diffusion Model Fine-tuning with Progressive Sparse Low-Rank Adaptation,"In recent years, the development of diffusion models has led to significant
progress in image and video generation tasks, with pre-trained models like the
Stable Diffusion series playing a crucial role. Inspired by model pruning which
lightens large pre-trained models by removing unimportant parameters, we
propose a novel model fine-tuning method to make full use of these ineffective
parameters and enable the pre-trained model with new task-specified
capabilities. In this work, we first investigate the importance of parameters
in pre-trained diffusion models, and discover that the smallest 10% to 20% of
parameters by absolute values do not contribute to the generation process.
Based on this observation, we propose a method termed SaRA that re-utilizes
these temporarily ineffective parameters, equating to optimizing a sparse
weight matrix to learn the task-specific knowledge. To mitigate overfitting, we
propose a nuclear-norm-based low-rank sparse training scheme for efficient
fine-tuning. Furthermore, we design a new progressive parameter adjustment
strategy to make full use of the re-trained/finetuned parameters. Finally, we
propose a novel unstructural backpropagation strategy, which significantly
reduces memory costs during fine-tuning. Our method enhances the generative
capabilities of pre-trained models in downstream applications and outperforms
traditional fine-tuning methods like LoRA in maintaining model's generalization
ability. We validate our approach through fine-tuning experiments on SD models,
demonstrating significant improvements. SaRA also offers a practical advantage
that requires only a single line of code modification for efficient
implementation and is seamlessly compatible with existing methods.",2024-09-10 16:44:47+00:00
Beyond designer's knowledge: Generating materials design hypotheses via large language models,"Materials design often relies on human-generated hypotheses, a process
inherently limited by cognitive constraints such as knowledge gaps and limited
ability to integrate and extract knowledge implications, particularly when
multidisciplinary expertise is required. This work demonstrates that large
language models (LLMs), coupled with prompt engineering, can effectively
generate non-trivial materials hypotheses by integrating scientific principles
from diverse sources without explicit design guidance by human experts. These
include design ideas for high-entropy alloys with superior cryogenic properties
and halide solid electrolytes with enhanced ionic conductivity and formability.
These design ideas have been experimentally validated in high-impact
publications in 2023 not available in the LLM training data, demonstrating the
LLM's ability to generate highly valuable and realizable innovative ideas not
established in the literature. Our approach primarily leverages materials
system charts encoding processing-structure-property relationships, enabling
more effective data integration by condensing key information from numerous
papers, and evaluation and categorization of numerous hypotheses for human
cognition, both through the LLM. This LLM-driven approach opens the door to new
avenues of artificial intelligence-driven materials discovery by accelerating
design, democratizing innovation, and expanding capabilities beyond the
designer's direct knowledge.",2024-09-10 16:28:50+00:00
Towards Localizing Structural Elements: Merging Geometrical Detection with Semantic Verification in RGB-D Data,"RGB-D cameras supply rich and dense visual and spatial information for
various robotics tasks such as scene understanding, map reconstruction, and
localization. Integrating depth and visual information can aid robots in
localization and element mapping, advancing applications like 3D scene graph
generation and Visual Simultaneous Localization and Mapping (VSLAM). While
point cloud data containing such information is primarily used for enhanced
scene understanding, exploiting their potential to capture and represent rich
semantic information has yet to be adequately targeted. This paper presents a
real-time pipeline for localizing building components, including wall and
ground surfaces, by integrating geometric calculations for pure 3D plane
detection followed by validating their semantic category using point cloud data
from RGB-D cameras. It has a parallel multi-thread architecture to precisely
estimate poses and equations of all the planes detected in the environment,
filters the ones forming the map structure using a panoptic segmentation
validation, and keeps only the validated building components. Incorporating the
proposed method into a VSLAM framework confirmed that constraining the map with
the detected environment-driven semantic elements can improve scene
understanding and map reconstruction accuracy. It can also ensure
(re-)association of these detected components into a unified 3D scene graph,
bridging the gap between geometric accuracy and semantic understanding.
Additionally, the pipeline allows for the detection of potential higher-level
structural entities, such as rooms, by identifying the relationships between
building components based on their layout.",2024-09-10 16:28:09+00:00
A Practice of Post-Training on Llama-3 70B with Optimal Selection of Additional Language Mixture Ratio,"Large Language Models (LLM) often needs to be Continual Pre-Trained (CPT) to
obtain the unfamiliar language skill or adapt into new domains. The huge
training cost of CPT often asks for cautious choice of key hyper-parameters
such as the mixture ratio of extra language or domain corpus. However, there is
no systematic study which bridge the gap between the optimal mixture ratio and
the actual model performance, and the gap between experimental scaling law and
the actual deployment in the full model size. In this paper, we perform CPT on
Llama-3 8B and 70B to enhance its Chinese ability. We study the optimal
correlation between the Additional Language Mixture Ratio (ALMR) and the
Learning Rate (LR) on the 8B size which directly indicate the optimal
experimental set up. By thorough choice of hyper-parameter, and subsequent
fine-tuning, the model capability is improved not only on the Chinese-related
benchmark, but also some specific domains including math, coding and emotional
intelligence. We deploy the final 70B version of LLM on an real-life chat
system which obtain satisfying performance.",2024-09-10 16:26:43+00:00
MVGaussian: High-Fidelity text-to-3D Content Generation with Multi-View Guidance and Surface Densification,"The field of text-to-3D content generation has made significant progress in
generating realistic 3D objects, with existing methodologies like Score
Distillation Sampling (SDS) offering promising guidance. However, these methods
often encounter the ""Janus"" problem-multi-face ambiguities due to imprecise
guidance. Additionally, while recent advancements in 3D gaussian splitting have
shown its efficacy in representing 3D volumes, optimization of this
representation remains largely unexplored. This paper introduces a unified
framework for text-to-3D content generation that addresses these critical gaps.
Our approach utilizes multi-view guidance to iteratively form the structure of
the 3D model, progressively enhancing detail and accuracy. We also introduce a
novel densification algorithm that aligns gaussians close to the surface,
optimizing the structural integrity and fidelity of the generated models.
Extensive experiments validate our approach, demonstrating that it produces
high-quality visual outputs with minimal time cost. Notably, our method
achieves high-quality results within half an hour of training, offering a
substantial efficiency gain over most existing methods, which require hours of
training time to achieve comparable results.",2024-09-10 16:16:34+00:00
Hierarchical Multi-Label Classification with Missing Information for Benthic Habitat Imagery,"In this work, we apply state-of-the-art self-supervised learning techniques
on a large dataset of seafloor imagery, \textit{BenthicNet}, and study their
performance for a complex hierarchical multi-label (HML) classification
downstream task. In particular, we demonstrate the capacity to conduct HML
training in scenarios where there exist multiple levels of missing annotation
information, an important scenario for handling heterogeneous real-world data
collected by multiple research groups with differing data collection protocols.
We find that, when using smaller one-hot image label datasets typical of local
or regional scale benthic science projects, models pre-trained with
self-supervision on a larger collection of in-domain benthic data outperform
models pre-trained on ImageNet. In the HML setting, we find the model can
attain a deeper and more precise classification if it is pre-trained with
self-supervision on in-domain data. We hope this work can establish a benchmark
for future models in the field of automated underwater image annotation tasks
and can guide work in other domains with hierarchical annotations of mixed
resolution.",2024-09-10 16:15:01+00:00
When to Extract ReID Features: A Selective Approach for Improved Multiple Object Tracking,"Extracting and matching Re-Identification (ReID) features is used by many
state-of-the-art (SOTA) Multiple Object Tracking (MOT) methods, particularly
effective against frequent and long-term occlusions. While end-to-end object
detection and tracking have been the main focus of recent research, they have
yet to outperform traditional methods in benchmarks like MOT17 and MOT20. Thus,
from an application standpoint, methods with separate detection and embedding
remain the best option for accuracy, modularity, and ease of implementation,
though they are impractical for edge devices due to the overhead involved. In
this paper, we investigate a selective approach to minimize the overhead of
feature extraction while preserving accuracy, modularity, and ease of
implementation. This approach can be integrated into various SOTA methods. We
demonstrate its effectiveness by applying it to StrongSORT and Deep OC-SORT.
Experiments on MOT17, MOT20, and DanceTrack datasets show that our mechanism
retains the advantages of feature extraction during occlusions while
significantly reducing runtime. Additionally, it improves accuracy by
preventing confusion in the feature-matching stage, particularly in cases of
deformation and appearance similarity, which are common in DanceTrack.
https://github.com/emirhanbayar/Fast-StrongSORT,
https://github.com/emirhanbayar/Fast-Deep-OC-SORT",2024-09-10 16:14:46+00:00
One-Shot Imitation under Mismatched Execution,"Human demonstrations as prompts are a powerful way to program robots to do
long-horizon manipulation tasks. However, directly translating such
demonstrations into robot-executable actions poses significant challenges due
to execution mismatches, such as different movement styles and physical
capabilities. Existing methods either rely on robot-demonstrator paired data,
which is infeasible to scale, or overly rely on frame-level visual
similarities, which fail to hold. To address these challenges, we propose
RHyME, a novel framework that automatically establishes task execution
correspondences between the robot and the demonstrator by using optimal
transport costs. Given long-horizon robot demonstrations, RHyME synthesizes
semantically equivalent human demonstrations by retrieving and composing
similar short-horizon human clips, facilitating effective policy training
without the need for paired data. We show that RHyME outperforms a range of
baselines across various cross-embodiment datasets on all degrees of
mismatches. Through detailed analysis, we uncover insights for learning and
leveraging cross-embodiment visual representations.",2024-09-10 16:11:57+00:00
DemoStart: Demonstration-led auto-curriculum applied to sim-to-real with multi-fingered robots,"We present DemoStart, a novel auto-curriculum reinforcement learning method
capable of learning complex manipulation behaviors on an arm equipped with a
three-fingered robotic hand, from only a sparse reward and a handful of
demonstrations in simulation. Learning from simulation drastically reduces the
development cycle of behavior generation, and domain randomization techniques
are leveraged to achieve successful zero-shot sim-to-real transfer. Transferred
policies are learned directly from raw pixels from multiple cameras and robot
proprioception. Our approach outperforms policies learned from demonstrations
on the real robot and requires 100 times fewer demonstrations, collected in
simulation. More details and videos in https://sites.google.com/view/demostart.",2024-09-10 16:05:25+00:00
Scaling Law Hypothesis for Multimodal Model,"We propose a scaling law hypothesis for multimodal models processing text,
audio, images, and video within a shared token and embedding space. Our
framework predicts model performance based on modality-specific compression and
tokenization efficiency, extending established scaling laws from text-based
decoder models to mixed-modality systems. We explore whether leveraging more
training data in multiple modalities can reduce the size of the multimodal
model, enabling efficient deployment on resource-constrained devices.",2024-09-10 16:05:02+00:00
Label-free Monitoring of Self-Supervised Learning Progress,"Self-supervised learning (SSL) is an effective method for exploiting
unlabelled data to learn a high-level embedding space that can be used for
various downstream tasks. However, existing methods to monitor the quality of
the encoder -- either during training for one model or to compare several
trained models -- still rely on access to annotated data. When SSL
methodologies are applied to new data domains, a sufficiently large labelled
dataset may not always be available. In this study, we propose several
evaluation metrics which can be applied on the embeddings of unlabelled data
and investigate their viability by comparing them to linear probe accuracy (a
common metric which utilizes an annotated dataset). In particular, we apply
$k$-means clustering and measure the clustering quality with the silhouette
score and clustering agreement. We also measure the entropy of the embedding
distribution. We find that while the clusters did correspond better to the
ground truth annotations as training of the network progressed, label-free
clustering metrics correlated with the linear probe accuracy only when training
with SSL methods SimCLR and MoCo-v2, but not with SimSiam. Additionally,
although entropy did not always have strong correlations with LP accuracy, this
appears to be due to instability arising from early training, with the metric
stabilizing and becoming more reliable at later stages of learning.
Furthermore, while entropy generally decreases as learning progresses, this
trend reverses for SimSiam. More research is required to establish the cause
for this unexpected behaviour. Lastly, we find that while clustering based
approaches are likely only viable for same-architecture comparisons, entropy
may be architecture-independent.",2024-09-10 16:04:10+00:00
Improving the Precision of CNNs for Magnetic Resonance Spectral Modeling,"Magnetic resonance spectroscopic imaging is a widely available imaging
modality that can non-invasively provide a metabolic profile of the tissue of
interest, yet is challenging to integrate clinically. One major reason is the
expensive, expert data processing and analysis that is required. Using machine
learning to predict MRS-related quantities offers avenues around this problem,
but deep learning models bring their own challenges, especially model trust.
Current research trends focus primarily on mean error metrics, but
comprehensive precision metrics are also needed, e.g. standard deviations,
confidence intervals, etc.. This work highlights why more comprehensive error
characterization is important and how to improve the precision of CNNs for
spectral modeling, a quantitative task. The results highlight advantages and
trade-offs of these techniques that should be considered when addressing such
regression tasks with CNNs. Detailed insights into the underlying mechanisms of
each technique, and how they interact with other techniques, are discussed in
depth.",2024-09-10 16:02:12+00:00
Simulation-based Scenario Generation for Robust Hybrid AI for Autonomy,"Application of Unmanned Aerial Vehicles (UAVs) in search and rescue,
emergency management, and law enforcement has gained traction with the advent
of low-cost platforms and sensor payloads. The emergence of hybrid neural and
symbolic AI approaches for complex reasoning is expected to further push the
boundaries of these applications with decreasing levels of human intervention.
However, current UAV simulation environments lack semantic context suited to
this hybrid approach. To address this gap, HAMERITT (Hybrid Ai Mission
Environment for RapId Training and Testing) provides a simulation-based
autonomy software framework that supports the training, testing and assurance
of neuro-symbolic algorithms for autonomous maneuver and perception reasoning.
HAMERITT includes scenario generation capabilities that offer mission-relevant
contextual symbolic information in addition to raw sensor data. Scenarios
include symbolic descriptions for entities of interest and their relations to
scene elements, as well as spatial-temporal constraints in the form of
time-bounded areas of interest with prior probabilities and restricted zones
within those areas. HAMERITT also features support for training distinct
algorithm threads for maneuver vs. perception within an end-to-end mission run.
Future work includes improving scenario realism and scaling symbolic context
generation through automated workflow.",2024-09-10 16:00:26+00:00
An Ontology-based Approach Towards Traceable Behavior Specifications in Automated Driving,"Vehicles in public traffic that are equipped with Automated Driving Systems
are subject to a number of expectations: Among other aspects, their behavior
should be safe, conforming to the rules of the road and provide mobility to
their users. This poses challenges for the developers of such systems:
Developers are responsible for specifying this behavior, for example, in terms
of requirements at system design time. As we will discuss in the article, this
specification always involves the need for assumptions and trade-offs. As a
result, insufficiencies in such a behavior specification can occur that can
potentially lead to unsafe system behavior. In order to support the
identification of specification insufficiencies, requirements and respective
assumptions need to be made explicit. In this article, we propose the Semantic
Norm Behavior Analysis as an ontology-based approach to specify the behavior
for an Automated Driving System equipped vehicle. We use ontologies to formally
represent specified behavior for a targeted operational environment, and to
establish traceability between specified behavior and the addressed stakeholder
needs. Furthermore, we illustrate the application of the Semantic Norm Behavior
Analysis in two example scenarios and evaluate our results.",2024-09-10 16:00:22+00:00
Interactive 3D Segmentation for Primary Gross Tumor Volume in Oropharyngeal Cancer,"The main treatment modality for oropharyngeal cancer (OPC) is radiotherapy,
where accurate segmentation of the primary gross tumor volume (GTVp) is
essential. However, accurate GTVp segmentation is challenging due to
significant interobserver variability and the time-consuming nature of manual
annotation, while fully automated methods can occasionally fail. An interactive
deep learning (DL) model offers the advantage of automatic high-performance
segmentation with the flexibility for user correction when necessary. In this
study, we examine interactive DL for GTVp segmentation in OPC. We implement
state-of-the-art algorithms and propose a novel two-stage Interactive Click
Refinement (2S-ICR) framework. Using the 2021 HEad and neCK TumOR (HECKTOR)
dataset for development and an external dataset from The University of Texas MD
Anderson Cancer Center for evaluation, the 2S-ICR framework achieves a Dice
similarity coefficient of 0.713 $\pm$ 0.152 without user interaction and 0.824
$\pm$ 0.099 after five interactions, outperforming existing methods in both
cases.",2024-09-10 15:58:21+00:00
A Practical Gated Recurrent Transformer Network Incorporating Multiple Fusions for Video Denoising,"State-of-the-art (SOTA) video denoising methods employ multi-frame
simultaneous denoising mechanisms, resulting in significant delays (e.g., 16
frames), making them impractical for real-time cameras. To overcome this
limitation, we propose a multi-fusion gated recurrent Transformer network
(GRTN) that achieves SOTA denoising performance with only a single-frame delay.
Specifically, the spatial denoising module extracts features from the current
frame, while the reset gate selects relevant information from the previous
frame and fuses it with current frame features via the temporal denoising
module. The update gate then further blends this result with the previous frame
features, and the reconstruction module integrates it with the current frame.
To robustly compute attention for noisy features, we propose a residual
simplified Swin Transformer with Euclidean distance (RSSTE) in the spatial and
temporal denoising modules. Comparative objective and subjective results show
that our GRTN achieves denoising performance comparable to SOTA multi-frame
delay networks, with only a single-frame delay.",2024-09-10 15:55:53+00:00
Alleviating Hallucinations in Large Language Models with Scepticism Modeling,"Hallucinations is a major challenge for large language models (LLMs),
prevents adoption in diverse fields. Uncertainty estimation could be used for
alleviating the damages of hallucinations. The skeptical emotion of human could
be useful for enhancing the ability of self estimation. Inspirited by this
observation, we proposed a new approach called Skepticism Modeling (SM). This
approach is formalized by combining the information of token and logits for
self estimation. We construct the doubt emotion aware data, perform continual
pre-training, and then fine-tune the LLMs, improve their ability of self
estimation. Experimental results demonstrate this new approach effectively
enhances a model's ability to estimate their uncertainty, and validate its
generalization ability of other tasks by out-of-domain experiments.",2024-09-10 15:51:15+00:00
Advancing Causal Inference: A Nonparametric Approach to ATE and CATE Estimation with Continuous Treatments,"This paper introduces a generalized ps-BART model for the estimation of
Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE)
in continuous treatments, addressing limitations of the Bayesian Causal Forest
(BCF) model. The ps-BART model's nonparametric nature allows for flexibility in
capturing nonlinear relationships between treatment and outcome variables.
Across three distinct sets of Data Generating Processes (DGPs), the ps-BART
model consistently outperforms the BCF model, particularly in highly nonlinear
settings. The ps-BART model's robustness in uncertainty estimation and accuracy
in both point-wise and probabilistic estimation demonstrate its utility for
real-world applications. This research fills a crucial gap in causal inference
literature, providing a tool better suited for nonlinear treatment-outcome
relationships and opening avenues for further exploration in the domain of
continuous treatment effect estimation.",2024-09-10 15:34:48+00:00
Lightweight Multiscale Feature Fusion Super-Resolution Network Based on Two-branch Convolution and Transformer,"The single image super-resolution(SISR) algorithms under deep learning
currently have two main models, one based on convolutional neural networks and
the other based on Transformer. The former uses the stacking of convolutional
layers with different convolutional kernel sizes to design the model, which
enables the model to better extract the local features of the image; the latter
uses the self-attention mechanism to design the model, which allows the model
to establish long-distance dependencies between image pixel points through the
self-attention mechanism and then better extract the global features of the
image. However, both of the above methods face their problems. Based on this,
this paper proposes a new lightweight multi-scale feature fusion network model
based on two-way complementary convolutional and Transformer, which integrates
the respective features of Transformer and convolutional neural networks
through a two-branch network architecture, to realize the mutual fusion of
global and local information. Meanwhile, considering the partial loss of
information caused by the low-pixel images trained by the deep neural network,
this paper designs a modular connection method of multi-stage feature
supplementation to fuse the feature maps extracted from the shallow stage of
the model with those extracted from the deep stage of the model, to minimize
the loss of the information in the feature images that is beneficial to the
image restoration as much as possible, to facilitate the obtaining of a
higher-quality restored image. The practical results finally show that the
model proposed in this paper is optimal in image recovery performance when
compared with other lightweight models with the same amount of parameters.",2024-09-10 15:31:37+00:00
Seg-HGNN: Unsupervised and Light-Weight Image Segmentation with Hyperbolic Graph Neural Networks,"Image analysis in the euclidean space through linear hyperspaces is well
studied. However, in the quest for more effective image representations, we
turn to hyperbolic manifolds. They provide a compelling alternative to capture
complex hierarchical relationships in images with remarkably small
dimensionality. To demonstrate hyperbolic embeddings' competence, we introduce
a light-weight hyperbolic graph neural network for image segmentation,
encompassing patch-level features in a very small embedding size. Our solution,
Seg-HGNN, surpasses the current best unsupervised method by 2.5\%, 4\% on
VOC-07, VOC-12 for localization, and by 0.8\%, 1.3\% on CUB-200, ECSSD for
segmentation, respectively. With less than 7.5k trainable parameters, Seg-HGNN
delivers effective and fast ($\approx 2$ images/second) results on very
standard GPUs like the GTX1650. This empirical evaluation presents compelling
evidence of the efficacy and potential of hyperbolic representations for vision
tasks.",2024-09-10 15:30:20+00:00
Developing the Temporal Graph Convolutional Neural Network Model to Predict Hip Replacement using Electronic Health Records,"Background: Hip replacement procedures improve patient lives by relieving
pain and restoring mobility. Predicting hip replacement in advance could reduce
pain by enabling timely interventions, prioritising individuals for surgery or
rehabilitation, and utilising physiotherapy to potentially delay the need for
joint replacement. This study predicts hip replacement a year in advance to
enhance quality of life and health service efficiency. Methods: Adapting
previous work using Temporal Graph Convolutional Neural Network (TG-CNN)
models, we construct temporal graphs from primary care medical event codes,
sourced from ResearchOne EHRs of 40-75-year-old patients, to predict hip
replacement risk. We match hip replacement cases to controls by age, sex, and
Index of Multiple Deprivation. The model, trained on 9,187 cases and 9,187
controls, predicts hip replacement one year in advance. We validate the model
on two unseen datasets, recalibrating for class imbalance. Additionally, we
conduct an ablation study and compare against four baseline models. Results:
Our best model predicts hip replacement risk one year in advance with an AUROC
of 0.724 (95% CI: 0.715-0.733) and an AUPRC of 0.185 (95% CI: 0.160-0.209),
achieving a calibration slope of 1.107 (95% CI: 1.074-1.139) after
recalibration. Conclusions: The TG-CNN model effectively predicts hip
replacement risk by identifying patterns in patient trajectories, potentially
improving understanding and management of hip-related conditions.",2024-09-10 15:26:58+00:00
Transtreaming: Adaptive Delay-aware Transformer for Real-time Streaming Perception,"Real-time object detection is critical for the decision-making process for
many real-world applications, such as collision avoidance and path planning in
autonomous driving. This work presents an innovative real-time streaming
perception method, Transtreaming, which addresses the challenge of real-time
object detection with dynamic computational delay. The core innovation of
Transtreaming lies in its adaptive delay-aware transformer, which can
concurrently predict multiple future frames and select the output that best
matches the real-world present time, compensating for any system-induced
computation delays. The proposed model outperforms the existing
state-of-the-art methods, even in single-frame detection scenarios, by
leveraging a transformer-based methodology. It demonstrates robust performance
across a range of devices, from powerful V100 to modest 2080Ti, achieving the
highest level of perceptual accuracy on all platforms. Unlike most
state-of-the-art methods that struggle to complete computation within a single
frame on less powerful devices, Transtreaming meets the stringent real-time
processing requirements on all kinds of devices. The experimental results
emphasize the system's adaptability and its potential to significantly improve
the safety and reliability for many real-world systems, such as autonomous
driving.",2024-09-10 15:26:38+00:00
Semi-Supervised 3D Object Detection with Chanel Augmentation using Transformation Equivariance,"Accurate 3D object detection is crucial for autonomous vehicles and robots to
navigate and interact with the environment safely and effectively. Meanwhile,
the performance of 3D detector relies on the data size and annotation which is
expensive. Consequently, the demand of training with limited labeled data is
growing. We explore a novel teacher-student framework employing channel
augmentation for 3D semi-supervised object detection. The teacher-student SSL
typically adopts a weak augmentation and strong augmentation to teacher and
student, respectively. In this work, we apply multiple channel augmentations to
both networks using the transformation equivariance detector (TED). The TED
allows us to explore different combinations of augmentation on point clouds and
efficiently aggregates multi-channel transformation equivariance features. In
principle, by adopting fixed channel augmentations for the teacher network, the
student can train stably on reliable pseudo-labels. Adopting strong channel
augmentations can enrich the diversity of data, fostering robustness to
transformations and enhancing generalization performance of the student
network. We use SOTA hierarchical supervision as a baseline and adapt its
dual-threshold to TED, which is called channel IoU consistency. We evaluate our
method with KITTI dataset, and achieved a significant performance leap,
surpassing SOTA 3D semi-supervised object detection models.",2024-09-10 15:22:05+00:00
Quantifying and Enabling the Interpretability of CLIP-like Models,"CLIP is one of the most popular foundational models and is heavily used for
many vision-language tasks. However, little is known about the inner workings
of CLIP. To bridge this gap we propose a study to quantify the interpretability
in CLIP like models. We conduct this study on six different CLIP models from
OpenAI and OpenCLIP which vary by size, type of pre-training data and patch
size. Our approach begins with using the TEXTSPAN algorithm and in-context
learning to break down individual attention heads into specific properties. We
then evaluate how easily these heads can be interpreted using new metrics which
measure property consistency within heads and property disentanglement across
heads. Our findings reveal that larger CLIP models are generally more
interpretable than their smaller counterparts. To further assist users in
understanding the inner workings of CLIP models, we introduce CLIP-InterpreT, a
tool designed for interpretability analysis. CLIP-InterpreT offers five types
of analyses: property-based nearest neighbor search, per-head topic
segmentation, contrastive segmentation, per-head nearest neighbors of an image,
and per-head nearest neighbors of text.",2024-09-10 15:19:40+00:00
Indirect Dynamic Negotiation in the Nash Demand Game,"The paper addresses a problem of sequential bilateral bargaining with
incomplete information. We proposed a decision model that helps agents to
successfully bargain by performing indirect negotiation and learning the
opponent's model. Methodologically the paper casts heuristically-motivated
bargaining of a self-interested independent player into a framework of Bayesian
learning and Markov decision processes. The special form of the reward
implicitly motivates the players to negotiate indirectly, via closed-loop
interaction. We illustrate the approach by applying our model to the Nash
demand game, which is an abstract model of bargaining. The results indicate
that the established negotiation: i) leads to coordinating players' actions;
ii) results in maximising success rate of the game and iii) brings more
individual profit to the players.",2024-09-10 14:58:00+00:00
ChatGPT's Potential in Cryptography Misuse Detection: A Comparative Analysis with Static Analysis Tools,"The correct adoption of cryptography APIs is challenging for mainstream
developers, often resulting in widespread API misuse. Meanwhile, cryptography
misuse detectors have demonstrated inconsistent performance and remain largely
inaccessible to most developers. We investigated the extent to which ChatGPT
can detect cryptography misuses and compared its performance with that of the
state-of-the-art static analysis tools. Our investigation, mainly based on the
CryptoAPI-Bench benchmark, demonstrated that ChatGPT is effective in
identifying cryptography API misuses, and with the use of prompt engineering,
it can even outperform leading static cryptography misuse detectors.",2024-09-10 14:50:12+00:00
Gaussian Differentially Private Human Faces Under a Face Radial Curve Representation,"In this paper we consider the problem of releasing a Gaussian Differentially
Private (GDP) 3D human face. The human face is a complex structure with many
features and inherently tied to one's identity. Protecting this data, in a
formally private way, is important yet challenging given the dimensionality of
the problem. We extend approximate DP techniques for functional data to the GDP
framework. We further propose a novel representation, face radial curves, of a
3D face as a set of functions and then utilize our proposed GDP functional data
mechanism. To preserve the shape of the face while injecting noise we rely on
tools from shape analysis for our novel representation of the face. We show
that our method preserves the shape of the average face and injects less noise
than traditional methods for the same privacy budget. Our mechanism consists of
two primary components, the first is generally applicable to function value
summaries (as are commonly found in nonparametric statistics or functional data
analysis) while the second is general to disk-like surfaces and hence more
applicable than just to human faces.",2024-09-10 14:47:31+00:00
A Primer on Variational Inference for Physics-Informed Deep Generative Modelling,"Variational inference (VI) is a computationally efficient and scalable
methodology for approximate Bayesian inference. It strikes a balance between
accuracy of uncertainty quantification and practical tractability. It excels at
generative modelling and inversion tasks due to its built-in Bayesian
regularisation and flexibility, essential qualities for physics related
problems. Deriving the central learning objective for VI must often be tailored
to new learning tasks where the nature of the problems dictates the conditional
dependence between variables of interest, such as arising in physics problems.
In this paper, we provide an accessible and thorough technical introduction to
VI for forward and inverse problems, guiding the reader through standard
derivations of the VI framework and how it can best be realized through deep
learning. We then review and unify recent literature exemplifying the creative
flexibility allowed by VI. This paper is designed for a general scientific
audience looking to solve physics-based problems with an emphasis on
uncertainty quantification.",2024-09-10 14:43:03+00:00
Learn2Aggregate: Supervised Generation of Chvátal-Gomory Cuts Using Graph Neural Networks,"We present $\textit{Learn2Aggregate}$, a machine learning (ML) framework for
optimizing the generation of Chv\'atal-Gomory (CG) cuts in mixed integer linear
programming (MILP). The framework trains a graph neural network to classify
useful constraints for aggregation in CG cut generation. The ML-driven CG
separator selectively focuses on a small set of impactful constraints,
improving runtimes without compromising the strength of the generated cuts. Key
to our approach is the formulation of a constraint classification task which
favours sparse aggregation of constraints, consistent with empirical findings.
This, in conjunction with a careful constraint labeling scheme and a hybrid of
deep learning and feature engineering, results in enhanced CG cut generation
across five diverse MILP benchmarks. On the largest test sets, our method
closes roughly $\textit{twice}$ as much of the integrality gap as the standard
CG method while running 40$% faster. This performance improvement is due to our
method eliminating 75% of the constraints prior to aggregation.",2024-09-10 14:41:46+00:00
Deep Neural Networks: Multi-Classification and Universal Approximation,"We demonstrate that a ReLU deep neural network with a width of $2$ and a
depth of $2N+4M-1$ layers can achieve finite sample memorization for any
dataset comprising $N$ elements in $\mathbb{R}^d$, where $d\ge1,$ and $M$
classes, thereby ensuring accurate classification.
  By modeling the neural network as a time-discrete nonlinear dynamical system,
we interpret the memorization property as a problem of simultaneous or ensemble
controllability. This problem is addressed by constructing the network
parameters inductively and explicitly, bypassing the need for training or
solving any optimization problem.
  Additionally, we establish that such a network can achieve universal
approximation in $L^p(\Omega;\mathbb{R}_+)$, where $\Omega$ is a bounded subset
of $\mathbb{R}^d$ and $p\in[1,\infty)$, using a ReLU deep neural network with a
width of $d+1$. We also provide depth estimates for approximating $W^{1,p}$
functions and width estimates for approximating $L^p(\Omega;\mathbb{R}^m)$ for
$m\geq1$. Our proofs are constructive, offering explicit values for the biases
and weights involved.",2024-09-10 14:31:21+00:00
Modelling Global Trade with Optimal Transport,"Global trade is shaped by a complex mix of factors beyond supply and demand,
including tangible variables like transport costs and tariffs, as well as less
quantifiable influences such as political and economic relations.
Traditionally, economists model trade using gravity models, which rely on
explicit covariates but often struggle to capture these subtler drivers of
trade. In this work, we employ optimal transport and a deep neural network to
learn a time-dependent cost function from data, without imposing a specific
functional form. This approach consistently outperforms traditional gravity
models in accuracy while providing natural uncertainty quantification. Applying
our framework to global food and agricultural trade, we show that the global
South suffered disproportionately from the war in Ukraine's impact on wheat
markets. We also analyze the effects of free-trade agreements and trade
disputes with China, as well as Brexit's impact on British trade with Europe,
uncovering hidden patterns that trade volumes alone cannot reveal.",2024-09-10 14:31:03+00:00
Dynamic Decoupling of Placid Terminal Attractor-based Gradient Descent Algorithm,"Gradient descent (GD) and stochastic gradient descent (SGD) have been widely
used in a large number of application domains. Therefore, understanding the
dynamics of GD and improving its convergence speed is still of great
importance. This paper carefully analyzes the dynamics of GD based on the
terminal attractor at different stages of its gradient flow. On the basis of
the terminal sliding mode theory and the terminal attractor theory, four
adaptive learning rates are designed. Their performances are investigated in
light of a detailed theoretical investigation, and the running times of the
learning procedures are evaluated and compared. The total times of their
learning processes are also studied in detail. To evaluate their effectiveness,
various simulation results are investigated on a function approximation problem
and an image classification problem.",2024-09-10 14:15:56+00:00
"PoseEmbroider: Towards a 3D, Visual, Semantic-aware Human Pose Representation","Aligning multiple modalities in a latent space, such as images and texts, has
shown to produce powerful semantic visual representations, fueling tasks like
image captioning, text-to-image generation, or image grounding. In the context
of human-centric vision, albeit CLIP-like representations encode most standard
human poses relatively well (such as standing or sitting), they lack sufficient
acuteness to discern detailed or uncommon ones. Actually, while 3D human poses
have been often associated with images (e.g. to perform pose estimation or
pose-conditioned image generation), or more recently with text (e.g. for
text-to-pose generation), they have seldom been paired with both. In this work,
we combine 3D poses, person's pictures and textual pose descriptions to produce
an enhanced 3D-, visual- and semantic-aware human pose representation. We
introduce a new transformer-based model, trained in a retrieval fashion, which
can take as input any combination of the aforementioned modalities. When
composing modalities, it outperforms a standard multi-modal alignment retrieval
model, making it possible to sort out partial information (e.g. image with the
lower body occluded). We showcase the potential of such an embroidered pose
representation for (1) SMPL regression from image with optional text cue; and
(2) on the task of fine-grained instruction generation, which consists in
generating a text that describes how to move from one 3D pose to another (as a
fitness coach). Unlike prior works, our model can take any kind of input (image
and/or pose) without retraining.",2024-09-10 14:09:39+00:00
Functionally Constrained Algorithm Solves Convex Simple Bilevel Problems,"This paper studies simple bilevel problems, where a convex upper-level
function is minimized over the optimal solutions of a convex lower-level
problem. We first show the fundamental difficulty of simple bilevel problems,
that the approximate optimal value of such problems is not obtainable by
first-order zero-respecting algorithms. Then we follow recent works to pursue
the weak approximate solutions. For this goal, we propose novel near-optimal
methods for smooth and nonsmooth problems by reformulating them into
functionally constrained problems.",2024-09-10 14:05:12+00:00
A tutorial on automatic differentiation with complex numbers,"Automatic differentiation is everywhere, but there exists only minimal
documentation of how it works in complex arithmetic beyond stating ""derivatives
in $\mathbb{C}^d$"" $\cong$ ""derivatives in $\mathbb{R}^{2d}$"" and, at best,
shallow references to Wirtinger calculus. Unfortunately, the equivalence
$\mathbb{C}^d \cong \mathbb{R}^{2d}$ becomes insufficient as soon as we need to
derive custom gradient rules, e.g., to avoid differentiating ""through""
expensive linear algebra functions or differential equation simulators. To
combat such a lack of documentation, this article surveys forward- and
reverse-mode automatic differentiation with complex numbers, covering topics
such as Wirtinger derivatives, a modified chain rule, and different gradient
conventions while explicitly avoiding holomorphicity and the Cauchy--Riemann
equations (which would be far too restrictive). To be precise, we will derive,
explain, and implement a complex version of Jacobian-vector and vector-Jacobian
products almost entirely with linear algebra without relying on complex
analysis or differential geometry. This tutorial is a call to action, for users
and developers alike, to take complex values seriously when implementing custom
gradient propagation rules -- the manuscript explains how.",2024-09-10 14:04:58+00:00
MENSA: A Multi-Event Network for Survival Analysis under Informative Censoring,"Given an instance, a multi-event survival model predicts the time until that
instance experiences each of several different events. These events are not
mutually exclusive and there are often statistical dependencies between them.
There are relatively few multi-event survival results, most focusing on
producing a simple risk score, rather than the time-to-event itself. To
overcome these issues, we introduce MENSA, a novel, deep learning approach for
multi-event survival analysis that can jointly learn representations of the
input covariates and the dependence structure between events. As a practical
motivation for multi-event survival analysis, we consider the problem of
predicting the time until a patient with amyotrophic lateral sclerosis (ALS)
loses various physical functions, i.e., the ability to speak, swallow, write,
or walk. When estimating when a patient is no longer able to swallow, our
approach achieves an L1-Margin loss of 278.8 days, compared to 355.2 days when
modeling each event separately. In addition, we also evaluate our approach in
single-event and competing risk scenarios by modeling the censoring and event
distributions as equal contributing factors in the optimization process, and
show that our approach performs well across multiple benchmark datasets. The
source code is available at: https://github.com/thecml/mensa",2024-09-10 14:02:34+00:00
The Weak Form Is Stronger Than You Think,"The weak form is a ubiquitous, well-studied, and widely-utilized mathematical
tool in modern computational and applied mathematics. In this work we provide a
survey of both the history and recent developments for several fields in which
the weak form can play a critical role. In particular, we highlight several
recent advances in weak form versions of equation learning, parameter
estimation, and coarse graining, which offer surprising noise robustness,
accuracy, and computational efficiency.
  We note that this manuscript is a companion piece to our October 2024 SIAM
News article of the same name. Here we provide more detailed explanations of
mathematical developments as well as a more complete list of references.
Lastly, we note that the software with which to reproduce the results in this
manuscript is also available on our group's GitHub website
https://github.com/MathBioCU .",2024-09-10 13:59:17+00:00
Deep Learning for Koopman Operator Estimation in Idealized Atmospheric Dynamics,"Deep learning is revolutionizing weather forecasting, with new data-driven
models achieving accuracy on par with operational physical models for
medium-term predictions. However, these models often lack interpretability,
making their underlying dynamics difficult to understand and explain. This
paper proposes methodologies to estimate the Koopman operator, providing a
linear representation of complex nonlinear dynamics to enhance the transparency
of data-driven models. Despite its potential, applying the Koopman operator to
large-scale problems, such as atmospheric modeling, remains challenging. This
study aims to identify the limitations of existing methods, refine these models
to overcome various bottlenecks, and introduce novel convolutional neural
network architectures that capture simplified dynamics.",2024-09-10 13:56:54+00:00
In Flight Boresight Rectification for Lightweight Airborne Pushbroom Imaging Spectrometry,"Hyperspectral cameras have recently been miniaturized for operation on
lightweight airborne platforms such as UAV or small aircraft. Unlike frame
cameras (RGB or Multispectral), many hyperspectral sensors use a linear array
or 'push-broom' scanning design. This design presents significant challenges
for image rectification and the calibration of the intrinsic and extrinsic
camera parameters. Typically, methods employed to address such tasks rely on a
precise GPS/INS estimate of the airborne platform trajectory and a detailed
terrain model. However, inaccuracies in the trajectory or surface model
information can introduce systematic errors and complicate geometric modeling
which ultimately degrade the quality of the rectification. To overcome these
challenges, we propose a method for tie point extraction and camera calibration
for 'push-broom' hyperspectral sensors using only the raw spectral imagery and
raw, possibly low quality, GPS/INS trajectory. We demonstrate that our approach
allows for the automatic calibration of airborne systems with hyperspectral
cameras, outperforms other state-of-the-art automatic rectification methods and
reaches an accuracy on par with manual calibration methods.",2024-09-10 13:55:47+00:00
Questioning Internal Knowledge Structure of Large Language Models Through the Lens of the Olympic Games,"Large language models (LLMs) have become a dominant approach in natural
language processing, yet their internal knowledge structures remain largely
unexplored. In this paper, we analyze the internal knowledge structures of LLMs
using historical medal tallies from the Olympic Games. We task the models with
providing the medal counts for each team and identifying which teams achieved
specific rankings. Our results reveal that while state-of-the-art LLMs perform
remarkably well in reporting medal counts for individual teams, they struggle
significantly with questions about specific rankings. This suggests that the
internal knowledge structures of LLMs are fundamentally different from those of
humans, who can easily infer rankings from known medal counts. To support
further research, we publicly release our code, dataset, and model outputs.",2024-09-10 13:54:04+00:00
Limit Order Book Simulation and Trade Evaluation with $K$-Nearest-Neighbor Resampling,"In this paper, we show how $K$-nearest neighbor ($K$-NN) resampling, an
off-policy evaluation method proposed in \cite{giegrich2023k}, can be applied
to simulate limit order book (LOB) markets and how it can be used to evaluate
and calibrate trading strategies. Using historical LOB data, we demonstrate
that our simulation method is capable of recreating realistic LOB dynamics and
that synthetic trading within the simulation leads to a market impact in line
with the corresponding literature. Compared to other statistical LOB simulation
methods, our algorithm has theoretical convergence guarantees under general
conditions, does not require optimization, is easy to implement and
computationally efficient. Furthermore, we show that in a benchmark comparison
our method outperforms a deep learning-based algorithm for several key
statistics. In the context of a LOB with pro-rata type matching, we demonstrate
how our algorithm can calibrate the size of limit orders for a liquidation
strategy. Finally, we describe how $K$-NN resampling can be modified for
choices of higher dimensional state spaces.",2024-09-10 13:50:53+00:00
"Sine, Transient, Noise Neural Modeling of Piano Notes","This paper introduces a novel method for emulating piano sounds. We propose
to exploit the sine, transient, and noise decomposition to design a
differentiable spectral modeling synthesizer replicating piano notes. Three
sub-modules learn these components from piano recordings and generate the
corresponding harmonic, transient, and noise signals. Splitting the emulation
into three independently trainable models reduces the modeling tasks'
complexity. The quasi-harmonic content is produced using a differentiable
sinusoidal model guided by physics-derived formulas, whose parameters are
automatically estimated from audio recordings. The noise sub-module uses a
learnable time-varying filter, and the transients are generated using a deep
convolutional network. From singular notes, we emulate the coupling between
different keys in trichords with a convolutional-based network. Results show
the model matches the partial distribution of the target while predicting the
energy in the higher part of the spectrum presents more challenges. The energy
distribution in the spectra of the transient and noise components is accurate
overall. While the model is more computationally and memory efficient,
perceptual tests reveal limitations in accurately modeling the attack phase of
notes. Despite this, it generally achieves perceptual accuracy in emulating
single notes and trichords.",2024-09-10 13:48:18+00:00
Aligning Machine and Human Visual Representations across Abstraction Levels,"Deep neural networks have achieved success across a wide range of
applications, including as models of human behavior in vision tasks. However,
neural network training and human learning differ in fundamental ways, and
neural networks often fail to generalize as robustly as humans do, raising
questions regarding the similarity of their underlying representations. What is
missing for modern learning systems to exhibit more human-like behavior? We
highlight a key misalignment between vision models and humans: whereas human
conceptual knowledge is hierarchically organized from fine- to coarse-scale
distinctions, model representations do not accurately capture all these levels
of abstraction. To address this misalignment, we first train a teacher model to
imitate human judgments, then transfer human-like structure from its
representations into pretrained state-of-the-art vision foundation models.
These human-aligned models more accurately approximate human behavior and
uncertainty across a wide range of similarity tasks, including a new dataset of
human judgments spanning multiple levels of semantic abstractions. They also
perform better on a diverse set of machine learning tasks, increasing
generalization and out-of-distribution robustness. Thus, infusing neural
networks with additional human knowledge yields a best-of-both-worlds
representation that is both more consistent with human cognition and more
practically useful, thus paving the way toward more robust, interpretable, and
human-like artificial intelligence systems.",2024-09-10 13:41:08+00:00
Neural Laplacian Operator for 3D Point Clouds,"The discrete Laplacian operator holds a crucial role in 3D geometry
processing, yet it is still challenging to define it on point clouds. Previous
works mainly focused on constructing a local triangulation around each point to
approximate the underlying manifold for defining the Laplacian operator, which
may not be robust or accurate. In contrast, we simply use the K-nearest
neighbors (KNN) graph constructed from the input point cloud and learn the
Laplacian operator on the KNN graph with graph neural networks (GNNs). However,
the ground-truth Laplacian operator is defined on a manifold mesh with a
different connectivity from the KNN graph and thus cannot be directly used for
training. To train the GNN, we propose a novel training scheme by imitating the
behavior of the ground-truth Laplacian operator on a set of probe functions so
that the learned Laplacian operator behaves similarly to the ground-truth
Laplacian operator. We train our network on a subset of ShapeNet and evaluate
it across a variety of point clouds. Compared with previous methods, our method
reduces the error by an order of magnitude and excels in handling sparse point
clouds with thin structures or sharp features. Our method also demonstrates a
strong generalization ability to unseen shapes. With our learned Laplacian
operator, we further apply a series of Laplacian-based geometry processing
algorithms directly to point clouds and achieve accurate results, enabling many
exciting possibilities for geometry processing on point clouds. The code and
trained models are available at https://github.com/IntelligentGeometry/NeLo.",2024-09-10 13:40:34+00:00
Can Agents Spontaneously Form a Society? Introducing a Novel Architecture for Generative Multi-Agents to Elicit Social Emergence,"Generative agents have demonstrated impressive capabilities in specific
tasks, but most of these frameworks focus on independent tasks and lack
attention to social interactions. We introduce a generative agent architecture
called ITCMA-S, which includes a basic framework for individual agents and a
framework called LTRHA that supports social interactions among multi-agents.
This architecture enables agents to identify and filter out behaviors that are
detrimental to social interactions, guiding them to choose more favorable
actions. We designed a sandbox environment to simulate the natural evolution of
social relationships among multiple identity-less agents for experimental
evaluation. The results showed that ITCMA-S performed well on multiple
evaluation indicators, demonstrating its ability to actively explore the
environment, recognize new agents, and acquire new information through
continuous actions and dialogue. Observations show that as agents establish
connections with each other, they spontaneously form cliques with internal
hierarchies around a selected leader and organize collective activities.",2024-09-10 13:39:29+00:00
Learning local and semi-local density functionals from exact exchange-correlation potentials and energies,"Finding accurate exchange-correlation (XC) functionals remains the defining
challenge in density functional theory (DFT). Despite 40 years of active
development, the desired chemical accuracy is still elusive with existing
functionals. We present a data-driven pathway to learn the XC functionals by
utilizing the exact density, XC energy, and XC potential. While the exact
densities are obtained from accurate configuration interaction (CI), the exact
XC energies and XC potentials are obtained via inverse DFT calculations on the
CI densities. We demonstrate how simple neural network (NN) based local density
approximation (LDA) and generalized gradient approximation (GGA), trained on
just five atoms and two molecules, provide remarkable improvement in total
energies, densities, atomization energies, and barrier heights for hundreds of
molecules outside the training set. Particularly, the NN-based GGA functional
attains similar accuracy as the higher rung SCAN meta-GGA, highlighting the
promise of using the XC potential in modeling XC functionals. We expect this
approach to pave the way for systematic learning of increasingly accurate and
sophisticated XC functionals.",2024-09-10 13:26:37+00:00
Mitigating Hallucination in Visual-Language Models via Re-Balancing Contrastive Decoding,"Although Visual-Language Models (VLMs) have shown impressive capabilities in
tasks like visual question answering and image captioning, they still struggle
with hallucinations. Analysis of attention distribution in these models shows
that VLMs tend to processing textual tokens rather than visual tokens. This
imbalance of attention distribution causes VLMs to favor textual knowledge in
the case of multimodal knowledge conflicts, resulting in differences from the
image information. In this paper, we propose Re-Balancing Contrastive Decoding
(RBD) method, which employs textual and visual branches to recalibrate
attention distribution in VLMs. Specifically, the textual branch injects image
noise to stimulate the model's dependency on text, thereby reducing textual
bias. Concurrently, the visual branch focuses on the selection of significant
tokens, refining the attention mechanism to highlight the primary subject. This
dual-branch strategy enables the RBD method to diminish textual bias while
enhancing visual information. Experimental results demonstrate that our method,
RBD, outperforms the existing methods by the CHAIR and POPE metrics, mitigate
hallucinations without reducing the model's general capabilities.",2024-09-10 13:13:14+00:00
"Superior Computer Chess with Model Predictive Control, Reinforcement Learning, and Rollout","In this paper we apply model predictive control (MPC), rollout, and
reinforcement learning (RL) methodologies to computer chess. We introduce a new
architecture for move selection, within which available chess engines are used
as components. One engine is used to provide position evaluations in an
approximation in value space MPC/RL scheme, while a second engine is used as
nominal opponent, to emulate or approximate the moves of the true opponent
player.
  We show that our architecture improves substantially the performance of the
position evaluation engine. In other words our architecture provides an
additional layer of intelligence, on top of the intelligence of the engines on
which it is based. This is true for any engine, regardless of its strength: top
engines such as Stockfish and Komodo Dragon (of varying strengths), as well as
weaker engines.
  Structurally, our basic architecture selects moves by a one-move lookahead
search, with an intermediate move generated by a nominal opponent engine, and
followed by a position evaluation by another chess engine. Simpler schemes that
forego the use of the nominal opponent, also perform better than the position
evaluator, but not quite by as much. More complex schemes, involving multistep
lookahead, may also be used and generally tend to perform better as the length
of the lookahead increases.
  Theoretically, our methodology relies on generic cost improvement properties
and the superlinear convergence framework of Newton's method, which
fundamentally underlies approximation in value space, and related MPC/RL and
rollout/policy iteration schemes. A critical requirement of this framework is
that the first lookahead step should be executed exactly. This fact has guided
our architectural choices, and is apparently an important factor in improving
the performance of even the best available chess engines.",2024-09-10 13:05:45+00:00
Multi-scale Cycle Tracking in Dynamic Planar Graphs,"This paper presents a nested tracking framework for analyzing cycles in 2D
force networks within granular materials. These materials are composed of
interacting particles, whose interactions are described by a force network.
Understanding the cycles within these networks at various scales and their
evolution under external loads is crucial, as they significantly contribute to
the mechanical and kinematic properties of the system. Our approach involves
computing a cycle hierarchy by partitioning the 2D domain into segments bounded
by cycles in the force network. We can adapt concepts from nested tracking
graphs originally developed for merge trees by leveraging the duality between
this partitioning and the cycles. We demonstrate the effectiveness of our
method on two force networks derived from experiments with photoelastic disks.",2024-09-10 13:05:31+00:00
Weakly-supervised Camera Localization by Ground-to-satellite Image Registration,"The ground-to-satellite image matching/retrieval was initially proposed for
city-scale ground camera localization. This work addresses the problem of
improving camera pose accuracy by ground-to-satellite image matching after a
coarse location and orientation have been obtained, either from the city-scale
retrieval or from consumer-level GPS and compass sensors. Existing
learning-based methods for solving this task require accurate GPS labels of
ground images for network training. However, obtaining such accurate GPS labels
is difficult, often requiring an expensive {\color{black}Real Time Kinematics
(RTK)} setup and suffering from signal occlusion, multi-path signal
disruptions, \etc. To alleviate this issue, this paper proposes a weakly
supervised learning strategy for ground-to-satellite image registration when
only noisy pose labels for ground images are available for network training. It
derives positive and negative satellite images for each ground image and
leverages contrastive learning to learn feature representations for ground and
satellite images useful for translation estimation. We also propose a
self-supervision strategy for cross-view image relative rotation estimation,
which trains the network by creating pseudo query and reference image pairs.
Experimental results show that our weakly supervised learning strategy achieves
the best performance on cross-area evaluation compared to recent
state-of-the-art methods that are reliant on accurate pose labels for
supervision.",2024-09-10 12:57:16+00:00
An Effective Context-Balanced Adaptation Approach for Long-Tailed Speech Recognition,"End-to-end (E2E) automatic speech recognition (ASR) models have become
standard practice for various commercial applications. However, in real-world
scenarios, the long-tailed nature of word distribution often leads E2E ASR
models to perform well on common words but fall short in recognizing uncommon
ones. Recently, the notion of a contextual adapter (CA) was proposed to infuse
external knowledge represented by a context word list into E2E ASR models.
Although CA can improve recognition performance on rare words, two crucial data
imbalance problems remain. First, when using low-frequency words as context
words during training, since these words rarely occur in the utterance, CA
becomes prone to overfit on attending to the <no-context> token due to
higher-frequency words not being present in the context list. Second, the
long-tailed distribution within the context list itself still causes the model
to perform poorly on low-frequency context words. In light of this, we explore
in-depth the impact of altering the context list to have words with different
frequency distributions on model performance, and meanwhile extend CA with a
simple yet effective context-balanced learning objective. A series of
experiments conducted on the AISHELL-1 benchmark dataset suggests that using
all vocabulary words from the training corpus as the context list and pairing
them with our balanced objective yields the best performance, demonstrating a
significant reduction in character error rate (CER) by up to 1.21% and a more
pronounced 9.44% reduction in the error rate of zero-shot words.",2024-09-10 12:52:36+00:00
A Machine Learning Based Approach for Statistical Analysis of Detonation Cells from Soot Foils,"This study presents a novel algorithm based on machine learning (ML) for the
precise segmentation and measurement of detonation cells from soot foil images,
addressing the limitations of manual and primitive edge detection methods
prevalent in the field. Using advances in cellular biology segmentation models,
the proposed algorithm is designed to accurately extract cellular patterns
without a training procedure or dataset, which is a significant challenge in
detonation research. The algorithm's performance was validated using a series
of test cases that mimic experimental and numerical detonation studies. The
results demonstrated consistent accuracy, with errors remaining within 10%,
even in complex cases. The algorithm effectively captured key cell metrics such
as cell area and span, revealing trends across different soot foil samples with
uniform to highly irregular cellular structures. Although the model proved
robust, challenges remain in segmenting and analyzing highly complex or
irregular cellular patterns. This work highlights the broad applicability and
potential of the algorithm to advance the understanding of detonation wave
dynamics.",2024-09-10 12:50:46+00:00
Continual Domain Incremental Learning for Privacy-aware Digital Pathology,"In recent years, there has been remarkable progress in the field of digital
pathology, driven by the ability to model complex tissue patterns using
advanced deep-learning algorithms. However, the robustness of these models is
often severely compromised in the presence of data shifts (e.g., different
stains, organs, centers, etc.). Alternatively, continual learning (CL)
techniques aim to reduce the forgetting of past data when learning new data
with distributional shift conditions. Specifically, rehearsal-based CL
techniques, which store some past data in a buffer and then replay it with new
data, have proven effective in medical image analysis tasks. However, privacy
concerns arise as these approaches store past data, prompting the development
of our novel Generative Latent Replay-based CL (GLRCL) approach. GLRCL captures
the previous distribution through Gaussian Mixture Models instead of storing
past samples, which are then utilized to generate features and perform latent
replay with new data. We systematically evaluate our proposed framework under
different shift conditions in histopathology data, including stain and organ
shift. Our approach significantly outperforms popular buffer-free CL approaches
and performs similarly to rehearsal-based CL approaches that require large
buffers causing serious privacy violations.",2024-09-10 12:21:54+00:00
Ransomware Detection Using Machine Learning in the Linux Kernel,"Linux-based cloud environments have become lucrative targets for ransomware
attacks, employing various encryption schemes at unprecedented speeds.
Addressing the urgency for real-time ransomware protection, we propose
leveraging the extended Berkeley Packet Filter (eBPF) to collect system call
information regarding active processes and infer about the data directly at the
kernel level. In this study, we implement two Machine Learning (ML) models in
eBPF - a decision tree and a multilayer perceptron. Benchmarking latency and
accuracy against their user space counterparts, our findings underscore the
efficacy of this approach.",2024-09-10 12:17:23+00:00
Multimodal Large Language Model Driven Scenario Testing for Autonomous Vehicles,"The generation of corner cases has become increasingly crucial for
efficiently testing autonomous vehicles prior to road deployment. However,
existing methods struggle to accommodate diverse testing requirements and often
lack the ability to generalize to unseen situations, thereby reducing the
convenience and usability of the generated scenarios. A method that facilitates
easily controllable scenario generation for efficient autonomous vehicles (AV)
testing with realistic and challenging situations is greatly needed. To address
this, we proposed OmniTester: a multimodal Large Language Model (LLM) based
framework that fully leverages the extensive world knowledge and reasoning
capabilities of LLMs. OmniTester is designed to generate realistic and diverse
scenarios within a simulation environment, offering a robust solution for
testing and evaluating AVs. In addition to prompt engineering, we employ tools
from Simulation of Urban Mobility to simplify the complexity of codes generated
by LLMs. Furthermore, we incorporate Retrieval-Augmented Generation and a
self-improvement mechanism to enhance the LLM's understanding of scenarios,
thereby increasing its ability to produce more realistic scenes. In the
experiments, we demonstrated the controllability and realism of our approaches
in generating three types of challenging and complex scenarios. Additionally,
we showcased its effectiveness in reconstructing new scenarios described in
crash report, driven by the generalization capability of LLMs.",2024-09-10 12:12:09+00:00
HexaCoder: Secure Code Generation via Oracle-Guided Synthetic Training Data,"Large language models (LLMs) have shown great potential for automatic code
generation and form the basis for various tools such as GitHub Copilot.
However, recent studies highlight that many LLM-generated code contains serious
security vulnerabilities. While previous work tries to address this by training
models that generate secure code, these attempts remain constrained by limited
access to training data and labor-intensive data preparation.
  In this paper, we introduce HexaCoder, a novel approach to enhance the
ability of LLMs to generate secure codes by automatically synthesizing secure
codes, which reduces the effort of finding suitable training data. HexaCoder
comprises two key components: an oracle-guided data synthesis pipeline and a
two-step process for secure code generation. The data synthesis pipeline
generates pairs of vulnerable and fixed codes for specific Common Weakness
Enumeration (CWE) types by utilizing a state-of-the-art LLM for repairing
vulnerable code. A security oracle identifies vulnerabilities, and a
state-of-the-art LLM repairs them by extending and/or editing the codes,
creating data pairs for fine-tuning using the Low-Rank Adaptation (LoRA)
method. Each example of our fine-tuning dataset includes the necessary
security-related libraries and code that form the basis of our novel two-step
generation approach. This allows the model to integrate security-relevant
libraries before generating the main code, significantly reducing the number of
generated vulnerable codes by up to 85% compared to the baseline methods. We
perform extensive evaluations on three different benchmarks for four LLMs,
demonstrating that HexaCoder not only improves the security of the generated
code but also maintains a high level of functional correctness.",2024-09-10 12:01:43+00:00
Learning Generative Interactive Environments By Trained Agent Exploration,"World models are increasingly pivotal in interpreting and simulating the
rules and actions of complex environments. Genie, a recent model, excels at
learning from visually diverse environments but relies on costly
human-collected data. We observe that their alternative method of using random
agents is too limited to explore the environment. We propose to improve the
model by employing reinforcement learning based agents for data generation.
This approach produces diverse datasets that enhance the model's ability to
adapt and perform well across various scenarios and realistic actions within
the environment. In this paper, we first release the model GenieRedux - an
implementation based on Genie. Additionally, we introduce GenieRedux-G, a
variant that uses the agent's readily available actions to factor out action
prediction uncertainty during validation. Our evaluation, including a
replication of the Coinrun case study, shows that GenieRedux-G achieves
superior visual fidelity and controllability using the trained agent
exploration. The proposed approach is reproducable, scalable and adaptable to
new types of environments. Our codebase is available at
https://github.com/insait-institute/GenieRedux .",2024-09-10 12:00:40+00:00
Knowledge Distillation via Query Selection for Detection Transformer,"Transformers have revolutionized the object detection landscape by
introducing DETRs, acclaimed for their simplicity and efficacy. Despite their
advantages, the substantial size of these models poses significant challenges
for practical deployment, particularly in resource-constrained environments.
This paper addresses the challenge of compressing DETR by leveraging knowledge
distillation, a technique that holds promise for maintaining model performance
while reducing size. A critical aspect of DETRs' performance is their reliance
on queries to interpret object representations accurately. Traditional
distillation methods often focus exclusively on positive queries, identified
through bipartite matching, neglecting the rich information present in
hard-negative queries. Our visual analysis indicates that hard-negative
queries, focusing on foreground elements, are crucial for enhancing
distillation outcomes. To this end, we introduce a novel Group Query Selection
strategy, which diverges from traditional query selection in DETR distillation
by segmenting queries based on their Generalized Intersection over Union (GIoU)
with ground truth objects, thereby uncovering valuable hard-negative queries
for distillation. Furthermore, we present the Knowledge Distillation via Query
Selection for DETR (QSKD) framework, which incorporates Attention-Guided
Feature Distillation (AGFD) and Local Alignment Prediction Distillation (LAPD).
These components optimize the distillation process by focusing on the most
informative aspects of the teacher model's intermediate features and output.
Our comprehensive experimental evaluation of the MS-COCO dataset demonstrates
the effectiveness of our approach, significantly improving average precision
(AP) across various DETR architectures without incurring substantial
computational costs. Specifically, the AP of Conditional DETR ResNet-18
increased from 35.8 to 39.9.",2024-09-10 11:49:28+00:00
Prompt2Fashion: An automatically generated fashion dataset,"Despite the rapid evolution and increasing efficacy of language and vision
generative models, there remains a lack of comprehensive datasets that bridge
the gap between personalized fashion needs and AI-driven design, limiting the
potential for truly inclusive and customized fashion solutions. In this work,
we leverage generative models to automatically construct a fashion image
dataset tailored to various occasions, styles, and body types as instructed by
users. We use different Large Language Models (LLMs) and prompting strategies
to offer personalized outfits of high aesthetic quality, detail, and relevance
to both expert and non-expert users' requirements, as demonstrated by
qualitative analysis. Up until now the evaluation of the generated outfits has
been conducted by non-expert human subjects. Despite the provided fine-grained
insights on the quality and relevance of generation, we extend the discussion
on the importance of expert knowledge for the evaluation of artistic
AI-generated datasets such as this one. Our dataset is publicly available on
GitHub at https://github.com/georgiarg/Prompt2Fashion.",2024-09-10 11:48:05+00:00
Extending Explainable Ensemble Trees (E2Tree) to regression contexts,"Ensemble methods such as random forests have transformed the landscape of
supervised learning, offering highly accurate prediction through the
aggregation of multiple weak learners. However, despite their effectiveness,
these methods often lack transparency, impeding users' comprehension of how RF
models arrive at their predictions. Explainable ensemble trees (E2Tree) is a
novel methodology for explaining random forests, that provides a graphical
representation of the relationship between response variables and predictors. A
striking characteristic of E2Tree is that it not only accounts for the effects
of predictor variables on the response but also accounts for associations
between the predictor variables through the computation and use of
dissimilarity measures. The E2Tree methodology was initially proposed for use
in classification tasks. In this paper, we extend the methodology to encompass
regression contexts. To demonstrate the explanatory power of the proposed
algorithm, we illustrate its use on real-world datasets.",2024-09-10 11:42:55+00:00
A Short Information-Theoretic Analysis of Linear Auto-Regressive Learning,"In this note, we give a short information-theoretic proof of the consistency
of the Gaussian maximum likelihood estimator in linear auto-regressive models.
Our proof yields nearly optimal non-asymptotic rates for parameter recovery and
works without any invocation of stability in the case of finite hypothesis
classes.",2024-09-10 11:42:22+00:00
EasyST: A Simple Framework for Spatio-Temporal Prediction,"Spatio-temporal prediction is a crucial research area in data-driven urban
computing, with implications for transportation, public safety, and
environmental monitoring. However, scalability and generalization challenges
remain significant obstacles. Advanced models often rely on Graph Neural
Networks to encode spatial and temporal correlations, but struggle with the
increased complexity of large-scale datasets. The recursive GNN-based message
passing schemes used in these models hinder their training and deployment in
real-life urban sensing scenarios. Moreover, long-spanning large-scale
spatio-temporal data introduce distribution shifts, necessitating improved
generalization performance. To address these challenges, we propose a simple
framework for spatio-temporal prediction - EasyST paradigm. It learns
lightweight and robust Multi-Layer Perceptrons (MLPs) by effectively distilling
knowledge from complex spatio-temporal GNNs. We ensure robust knowledge
distillation by integrating the spatio-temporal information bottleneck with
teacher-bounded regression loss, filtering out task-irrelevant noise and
avoiding erroneous guidance. We further enhance the generalization ability of
the student model by incorporating spatial and temporal prompts to provide
downstream task contexts. Evaluation on three spatio-temporal datasets for
urban computing tasks demonstrates that EasyST surpasses state-of-the-art
approaches in terms of efficiency and accuracy. The implementation code is
available at: https://github.com/HKUDS/EasyST.",2024-09-10 11:40:01+00:00
Fine-tuning and Prompt Engineering with Cognitive Knowledge Graphs for Scholarly Knowledge Organization,"The increasing amount of published scholarly articles, exceeding 2.5 million
yearly, raises the challenge for researchers in following scientific progress.
Integrating the contributions from scholarly articles into a novel type of
cognitive knowledge graph (CKG) will be a crucial element for accessing and
organizing scholarly knowledge, surpassing the insights provided by titles and
abstracts. This research focuses on effectively conveying structured scholarly
knowledge by utilizing large language models (LLMs) to categorize scholarly
articles and describe their contributions in a structured and comparable
manner. While previous studies explored language models within specific
research domains, the extensive domain-independent knowledge captured by LLMs
offers a substantial opportunity for generating structured contribution
descriptions as CKGs. Additionally, LLMs offer customizable pathways through
prompt engineering or fine-tuning, thus facilitating to leveraging of smaller
LLMs known for their efficiency, cost-effectiveness, and environmental
considerations. Our methodology involves harnessing LLM knowledge, and
complementing it with domain expert-verified scholarly data sourced from a CKG.
This strategic fusion significantly enhances LLM performance, especially in
tasks like scholarly article categorization and predicate recommendation. Our
method involves fine-tuning LLMs with CKG knowledge and additionally injecting
knowledge from a CKG with a novel prompting technique significantly increasing
the accuracy of scholarly knowledge extraction. We integrated our approach in
the Open Research Knowledge Graph (ORKG), thus enabling precise access to
organized scholarly knowledge, crucially benefiting domain-independent
scholarly knowledge exchange and dissemination among policymakers, industrial
practitioners, and the general public.",2024-09-10 11:31:02+00:00
"Spectral Map for Slow Collective Variables, Markovian Dynamics, and Transition State Ensembles","Understanding the behavior of complex molecular systems is a fundamental
problem in physical chemistry. To describe the long-time dynamics of such
systems, which is responsible for their most informative characteristics, we
can identify a few slow collective variables (CVs) while treating the remaining
fast variables as thermal noise. This enables us to simplify the dynamics and
treat it as diffusion in a free-energy landscape spanned by slow CVs,
effectively rendering the dynamics Markovian. Our recent statistical learning
technique, spectral map [Rydzewski, J. Phys. Chem. Lett. 2023, 14, 22,
5216-5220], explores this strategy to learn slow CVs by maximizing a spectral
gap of a transition matrix. In this work, we introduce several advancements
into our framework, using a high-dimensional reversible folding process of a
protein as an example. We implement an algorithm for coarse-graining Markov
transition matrices to partition the reduced space of slow CVs kinetically and
use it to define a transition state ensemble. We show that slow CVs learned by
spectral map closely approach the Markovian limit for an overdamped diffusion.
We demonstrate that coordinate-dependent diffusion coefficients only slightly
affect the constructed free-energy landscapes. Finally, we present how spectral
map can be used to quantify the importance of features and compare slow CVs
with structural descriptors commonly used in protein folding. Overall, we
demonstrate that a single slow CV learned by spectral map can be used as a
physical reaction coordinate to capture essential characteristics of protein
folding.",2024-09-10 11:20:36+00:00
GeMuCo: Generalized Multisensory Correlational Model for Body Schema Learning,"Humans can autonomously learn the relationship between sensation and motion
in their own bodies, estimate and control their own body states, and move while
continuously adapting to the current environment. On the other hand, current
robots control their bodies by learning the network structure described by
humans from their experiences, making certain assumptions on the relationship
between sensors and actuators. In addition, the network model does not adapt to
changes in the robot's body, the tools that are grasped, or the environment,
and there is no unified theory, not only for control but also for state
estimation, anomaly detection, simulation, and so on. In this study, we propose
a Generalized Multisensory Correlational Model (GeMuCo), in which the robot
itself acquires a body schema describing the correlation between sensors and
actuators from its own experience, including model structures such as network
input/output. The robot adapts to the current environment by updating this body
schema model online, estimates and controls its body state, and even performs
anomaly detection and simulation. We demonstrate the effectiveness of this
method by applying it to tool-use considering changes in grasping state for an
axis-driven robot, to joint-muscle mapping learning for a musculoskeletal
robot, and to full-body tool manipulation for a low-rigidity plastic-made
humanoid.",2024-09-10 11:19:13+00:00
A Likelihood Ratio-Based Approach to Segmenting Unknown Objects,"Addressing the Out-of-Distribution (OoD) segmentation task is a prerequisite
for perception systems operating in an open-world environment. Large
foundational models are frequently used in downstream tasks, however, their
potential for OoD remains mostly unexplored. We seek to leverage a large
foundational model to achieve robust representation. Outlier supervision is a
widely used strategy for improving OoD detection of the existing segmentation
networks. However, current approaches for outlier supervision involve
retraining parts of the original network, which is typically disruptive to the
model's learned feature representation. Furthermore, retraining becomes
infeasible in the case of large foundational models. Our goal is to retrain for
outlier segmentation without compromising the strong representation space of
the foundational model. To this end, we propose an adaptive, lightweight
unknown estimation module (UEM) for outlier supervision that significantly
enhances the OoD segmentation performance without affecting the learned feature
representation of the original network. UEM learns a distribution for outliers
and a generic distribution for known classes. Using the learned distributions,
we propose a likelihood-ratio-based outlier scoring function that fuses the
confidence of UEM with that of the pixel-wise segmentation inlier network to
detect unknown objects. We also propose an objective to optimize this score
directly. Our approach achieves a new state-of-the-art across multiple
datasets, outperforming the previous best method by 5.74% average precision
points while having a lower false-positive rate. Importantly, strong inlier
performance remains unaffected.",2024-09-10 11:10:32+00:00
Unrevealed Threats: A Comprehensive Study of the Adversarial Robustness of Underwater Image Enhancement Models,"Learning-based methods for underwater image enhancement (UWIE) have undergone
extensive exploration. However, learning-based models are usually vulnerable to
adversarial examples so as the UWIE models. To the best of our knowledge, there
is no comprehensive study on the adversarial robustness of UWIE models, which
indicates that UWIE models are potentially under the threat of adversarial
attacks. In this paper, we propose a general adversarial attack protocol. We
make a first attempt to conduct adversarial attacks on five well-designed UWIE
models on three common underwater image benchmark datasets. Considering the
scattering and absorption of light in the underwater environment, there exists
a strong correlation between color correction and underwater image enhancement.
On the basis of that, we also design two effective UWIE-oriented adversarial
attack methods Pixel Attack and Color Shift Attack targeting different color
spaces. The results show that five models exhibit varying degrees of
vulnerability to adversarial attacks and well-designed small perturbations on
degraded images are capable of preventing UWIE models from generating enhanced
results. Further, we conduct adversarial training on these models and
successfully mitigated the effectiveness of adversarial attacks. In summary, we
reveal the adversarial vulnerability of UWIE models and propose a new
evaluation dimension of UWIE models.",2024-09-10 11:02:35+00:00
Exploring the Integration of Large Language Models in Industrial Test Maintenance Processes,"Much of the cost and effort required during the software testing process is
invested in performing test maintenance - the addition, removal, or
modification of test cases to keep the test suite in sync with the
system-under-test or to otherwise improve its quality. Tool support could
reduce the cost - and improve the quality - of test maintenance by automating
aspects of the process or by providing guidance and support to developers.
  In this study, we explore the capabilities and applications of large language
models (LLMs) - complex machine learning models adapted to textual analysis -
to support test maintenance. We conducted a case study at Ericsson AB where we
explored the triggers that indicate the need for test maintenance, the actions
that LLMs can take, and the considerations that must be made when deploying
LLMs in an industrial setting. We also proposed and demonstrated
implementations of two multi-agent architectures that can predict which test
cases require maintenance following a change to the source code. Collectively,
these contributions advance our theoretical and practical understanding of how
LLMs can be deployed to benefit industrial test maintenance processes.",2024-09-10 10:55:48+00:00
Length Desensitization in Directed Preference Optimization,"Direct Preference Optimization (DPO) is widely utilized in the Reinforcement
Learning from Human Feedback (RLHF) phase to align Large Language Models (LLMs)
with human preferences, thereby enhancing both their harmlessness and efficacy.
However, it has been observed that DPO tends to over-optimize for verbosity,
which can detrimentally affect both performance and user experience. In this
paper, we conduct an in-depth theoretical analysis of DPO's optimization
objective and reveal a strong correlation between its implicit reward and data
length. This correlation misguides the optimization direction, resulting in
length sensitivity during the DPO training and leading to verbosity. To address
this issue, we propose a length-desensitization improvement method for DPO,
termed LD-DPO. The proposed method aims to desensitize DPO to data length by
decoupling explicit length preference, which is relatively insignificant, from
the other implicit preferences, thereby enabling more effective learning of the
intrinsic preferences. We utilized two settings (Base and Instruct) of
Llama2-13B, Llama3-8B, and Qwen2-7B for experimental validation on various
benchmarks including MT-Bench and AlpacaEval 2. The experimental results
indicate that LD-DPO consistently outperforms DPO and other baseline methods,
achieving more concise responses with a 10-40\% reduction in length compared to
DPO. We conducted in-depth experimental analyses to demonstrate that LD-DPO can
indeed achieve length desensitization and align the model more closely with
human-real preferences.",2024-09-10 10:49:38+00:00
Sources of Uncertainty in 3D Scene Reconstruction,"The process of 3D scene reconstruction can be affected by numerous
uncertainty sources in real-world scenes. While Neural Radiance Fields (NeRFs)
and 3D Gaussian Splatting (GS) achieve high-fidelity rendering, they lack
built-in mechanisms to directly address or quantify uncertainties arising from
the presence of noise, occlusions, confounding outliers, and imprecise camera
pose inputs. In this paper, we introduce a taxonomy that categorizes different
sources of uncertainty inherent in these methods. Moreover, we extend NeRF- and
GS-based methods with uncertainty estimation techniques, including learning
uncertainty outputs and ensembles, and perform an empirical study to assess
their ability to capture the sensitivity of the reconstruction. Our study
highlights the need for addressing various uncertainty aspects when designing
NeRF/GS-based methods for uncertainty-aware 3D reconstruction.",2024-09-10 10:43:53+00:00
Symmetry Breaking in Neural Network Optimization: Insights from Input Dimension Expansion,"Understanding the mechanisms behind neural network optimization is crucial
for improving network design and performance. While various optimization
techniques have been developed, a comprehensive understanding of the underlying
principles that govern these techniques remains elusive. Specifically, the role
of symmetry breaking, a fundamental concept in physics, has not been fully
explored in neural network optimization. This gap in knowledge limits our
ability to design networks that are both efficient and effective. Here, we
propose the symmetry breaking hypothesis to elucidate the significance of
symmetry breaking in enhancing neural network optimization. We demonstrate that
a simple input expansion can significantly improve network performance across
various tasks, and we show that this improvement can be attributed to the
underlying symmetry breaking mechanism. We further develop a metric to quantify
the degree of symmetry breaking in neural networks, providing a practical
approach to evaluate and guide network design. Our findings confirm that
symmetry breaking is a fundamental principle that underpins various
optimization techniques, including dropout, batch normalization, and
equivariance. By quantifying the degree of symmetry breaking, our work offers a
practical technique for performance enhancement and a metric to guide network
design without the need for complete datasets and extensive training processes.",2024-09-10 10:36:40+00:00
AMNS: Attention-Weighted Selective Mask and Noise Label Suppression for Text-to-Image Person Retrieval,"Text-to-image person retrieval aims to retrieve images of person given
textual descriptions, and most methods implicitly assume that the training
image-text pairs are correctly aligned, but in practice, under-correlated and
false-correlated problems arise for image-text pairs due to poor image quality
and mislabeling. Meanwhile, the random masking augmentation strategy may
incorrectly discard semantic content resulting in the problem of generating
noisy pairings between image lexical elements and text descriptions. To solve
these two problems, we propose a new noise label suppression method and
alleviate the problem generated by random mask through an attention-weighted
selective mask strategy. In the proposed noise label suppression method, the
effect of noise labels is suppressed by preventing the model from being
overconfident by considering the inverse KL scatter loss, which is combined
with the weight adjustment focus loss to further improve the model's
recognition ability on difficult samples. On the other hand, Attention-Weighted
Selective Mask processes the raw image through the EMA version of the image
encoder, retaining some of the tokens with strong semantic associations with
the corresponding text descriptions in order to extract better features.
Numerous experiments validate the effectiveness of our approach in terms of
dealing with noisy problems. The code will be available soon at
https://github.com/RunQing715/AMNS.git.",2024-09-10 10:08:01+00:00
A Cross-Font Image Retrieval Network for Recognizing Undeciphered Oracle Bone Inscriptions,"Oracle Bone Inscription (OBI) is the earliest mature writing system known in
China to date, which represents a crucial stage in the development of
hieroglyphs. Nevertheless, the substantial quantity of undeciphered OBI
characters continues to pose a persistent challenge for scholars, while
conventional methods of ancient script research are both time-consuming and
labor-intensive. In this paper, we propose a cross-font image retrieval network
(CFIRN) to decipher OBI characters by establishing associations between OBI
characters and other script forms, simulating the interpretive behavior of
paleography scholars. Concretely, our network employs a siamese framework to
extract deep features from character images of various fonts, fully exploring
structure clues with different resolution by designed multiscale feature
integration (MFI) module and multiscale refinement classifier (MRC). Extensive
experiments on three challenging cross-font image retrieval datasets
demonstrate that, given undeciphered OBI characters, our CFIRN can effectively
achieve accurate matches with characters from other gallery fonts.",2024-09-10 10:04:58+00:00
Distilling Generative-Discriminative Representations for Very Low-Resolution Face Recognition,"Very low-resolution face recognition is challenging due to the serious loss
of informative facial details in resolution degradation. In this paper, we
propose a generative-discriminative representation distillation approach that
combines generative representation with cross-resolution aligned knowledge
distillation. This approach facilitates very low-resolution face recognition by
jointly distilling generative and discriminative models via two distillation
modules. Firstly, the generative representation distillation takes the encoder
of a diffusion model pretrained for face super-resolution as the generative
teacher to supervise the learning of the student backbone via feature
regression, and then freezes the student backbone. After that, the
discriminative representation distillation further considers a pretrained face
recognizer as the discriminative teacher to supervise the learning of the
student head via cross-resolution relational contrastive distillation. In this
way, the general backbone representation can be transformed into discriminative
head representation, leading to a robust and discriminative student model for
very low-resolution face recognition. Our approach improves the recovery of the
missing details in very low-resolution faces and achieves better knowledge
transfer. Extensive experiments on face datasets demonstrate that our approach
enhances the recognition accuracy of very low-resolution faces, showcasing its
effectiveness and adaptability.",2024-09-10 09:53:06+00:00
Texture-AD: An Anomaly Detection Dataset and Benchmark for Real Algorithm Development,"Anomaly detection is a crucial process in industrial manufacturing and has
made significant advancements recently. However, there is a large variance
between the data used in the development and the data collected by the
production environment. Therefore, we present the Texture-AD benchmark based on
representative texture-based anomaly detection to evaluate the effectiveness of
unsupervised anomaly detection algorithms in real-world applications. This
dataset includes images of 15 different cloth, 14 semiconductor wafers and 10
metal plates acquired under different optical schemes. In addition, it includes
more than 10 different types of defects produced during real manufacturing
processes, such as scratches, wrinkles, color variations and point defects,
which are often more difficult to detect than existing datasets. All anomalous
areas are provided with pixel-level annotations to facilitate comprehensive
evaluation using anomaly detection models. Specifically, to adapt to diverse
products in automated pipelines, we present a new evaluation method and results
of baseline algorithms. The experimental results show that Texture-AD is a
difficult challenge for state-of-the-art algorithms. To our knowledge,
Texture-AD is the first dataset to be devoted to evaluating industrial defect
detection algorithms in the real world. The dataset is available at
https://XXX.",2024-09-10 09:44:38+00:00
One Policy to Run Them All: an End-to-end Learning Approach to Multi-Embodiment Locomotion,"Deep Reinforcement Learning techniques are achieving state-of-the-art results
in robust legged locomotion. While there exists a wide variety of legged
platforms such as quadruped, humanoids, and hexapods, the field is still
missing a single learning framework that can control all these different
embodiments easily and effectively and possibly transfer, zero or few-shot, to
unseen robot embodiments. We introduce URMA, the Unified Robot Morphology
Architecture, to close this gap. Our framework brings the end-to-end Multi-Task
Reinforcement Learning approach to the realm of legged robots, enabling the
learned policy to control any type of robot morphology. The key idea of our
method is to allow the network to learn an abstract locomotion controller that
can be seamlessly shared between embodiments thanks to our morphology-agnostic
encoders and decoders. This flexible architecture can be seen as a potential
first step in building a foundation model for legged robot locomotion. Our
experiments show that URMA can learn a locomotion policy on multiple
embodiments that can be easily transferred to unseen robot platforms in
simulation and the real world.",2024-09-10 09:44:15+00:00
What happens to diffusion model likelihood when your model is conditional?,"Diffusion Models (DMs) iteratively denoise random samples to produce
high-quality data. The iterative sampling process is derived from Stochastic
Differential Equations (SDEs), allowing a speed-quality trade-off chosen at
inference. Another advantage of sampling with differential equations is exact
likelihood computation. These likelihoods have been used to rank unconditional
DMs and for out-of-domain classification. Despite the many existing and
possible uses of DM likelihoods, the distinct properties captured are unknown,
especially in conditional contexts such as Text-To-Image (TTI) or
Text-To-Speech synthesis (TTS). Surprisingly, we find that TTS DM likelihoods
are agnostic to the text input. TTI likelihood is more expressive but cannot
discern confounding prompts. Our results show that applying DMs to conditional
tasks reveals inconsistencies and strengthens claims that the properties of DM
likelihood are unknown. This impact sheds light on the previously unknown
nature of DM likelihoods. Although conditional DMs maximise likelihood, the
likelihood in question is not as sensitive to the conditioning input as one
expects. This investigation provides a new point-of-view on diffusion
likelihoods.",2024-09-10 09:42:58+00:00
Connecting Concept Convexity and Human-Machine Alignment in Deep Neural Networks,"Understanding how neural networks align with human cognitive processes is a
crucial step toward developing more interpretable and reliable AI systems.
Motivated by theories of human cognition, this study examines the relationship
between \emph{convexity} in neural network representations and
\emph{human-machine alignment} based on behavioral data. We identify a
correlation between these two dimensions in pretrained and fine-tuned vision
transformer models. Our findings suggest that the convex regions formed in
latent spaces of neural networks to some extent align with human-defined
categories and reflect the similarity relations humans use in cognitive tasks.
While optimizing for alignment generally enhances convexity, increasing
convexity through fine-tuning yields inconsistent effects on alignment, which
suggests a complex relationship between the two. This study presents a first
step toward understanding the relationship between the convexity of latent
representations and human-machine alignment.",2024-09-10 09:32:16+00:00
Distributed Cooperative AI for Large-Scale Eigenvalue Computations Using Neural Networks,"This paper presents a novel method for eigenvalue computation using a
distributed cooperative neural network framework. Unlike traditional techniques
that struggle with scalability in large systems, our decentralized algorithm
enables multiple autonomous agents to collaboratively estimate the smallest
eigenvalue of large matrices. Each agent uses a localized neural network model,
refining its estimates through inter-agent communication. Our approach
guarantees convergence to the true eigenvalue, even with communication failures
or network disruptions. Theoretical analysis confirms the robustness and
accuracy of the method, while empirical results demonstrate its better
performance compared to some traditional centralized algorithms",2024-09-10 09:26:55+00:00
Double Successive Over-Relaxation Q-Learning with an Extension to Deep Reinforcement Learning,"Q-learning is a widely used algorithm in reinforcement learning (RL), but its
convergence can be slow, especially when the discount factor is close to one.
Successive Over-Relaxation (SOR) Q-learning, which introduces a relaxation
factor to speed up convergence, addresses this issue but has two major
limitations: In the tabular setting, the relaxation parameter depends on
transition probability, making it not entirely model-free, and it suffers from
overestimation bias. To overcome these limitations, we propose a sample-based,
model-free double SOR Q-learning algorithm. Theoretically and empirically, this
algorithm is shown to be less biased than SOR Q-learning. Further, in the
tabular setting, the convergence analysis under boundedness assumptions on
iterates is discussed. The proposed algorithm is extended to large-scale
problems using deep RL. Finally, the tabular version of the proposed algorithm
is compared using roulette and grid world environments, while the deep RL
version is tested on a maximization bias example and OpenAI Gym environments.",2024-09-10 09:23:03+00:00
DiffQRCoder: Diffusion-based Aesthetic QR Code Generation with Scanning Robustness Guided Iterative Refinement,"With the success of Diffusion Models for image generation, the technologies
also have revolutionized the aesthetic Quick Response (QR) code generation.
Despite significant improvements in visual attractiveness for the beautified
codes, their scannabilities are usually sacrificed and thus hinder their
practical uses in real-world scenarios. To address this issue, we propose a
novel Diffusion-based QR Code generator (DiffQRCoder) to effectively craft both
scannable and visually pleasing QR codes. The proposed approach introduces
Scanning-Robust Perceptual Guidance (SRPG), a new diffusion guidance for
Diffusion Models to guarantee the generated aesthetic codes to obey the
ground-truth QR codes while maintaining their attractiveness during the
denoising process. Additionally, we present another post-processing technique,
Scanning Robust Manifold Projected Gradient Descent (SR-MPGD), to further
enhance their scanning robustness through iterative latent space optimization.
With extensive experiments, the results demonstrate that our approach not only
outperforms other compared methods in Scanning Success Rate (SSR) with better
or comparable CLIP aesthetic score (CLIP-aes.) but also significantly improves
the SSR of the ControlNet-only approach from 60% to 99%. The subjective
evaluation indicates that our approach achieves promising visual attractiveness
to users as well. Finally, even with different scanning angles and the most
rigorous error tolerance settings, our approach robustly achieves over 95% SSR,
demonstrating its capability for real-world applications.",2024-09-10 09:22:35+00:00
MAGDA: Multi-agent guideline-driven diagnostic assistance,"In emergency departments, rural hospitals, or clinics in less developed
regions, clinicians often lack fast image analysis by trained radiologists,
which can have a detrimental effect on patients' healthcare. Large Language
Models (LLMs) have the potential to alleviate some pressure from these
clinicians by providing insights that can help them in their decision-making.
While these LLMs achieve high test results on medical exams showcasing their
great theoretical medical knowledge, they tend not to follow medical
guidelines. In this work, we introduce a new approach for zero-shot
guideline-driven decision support. We model a system of multiple LLM agents
augmented with a contrastive vision-language model that collaborate to reach a
patient diagnosis. After providing the agents with simple diagnostic
guidelines, they will synthesize prompts and screen the image for findings
following these guidelines. Finally, they provide understandable
chain-of-thought reasoning for their diagnosis, which is then self-refined to
consider inter-dependencies between diseases. As our method is zero-shot, it is
adaptable to settings with rare diseases, where training data is limited, but
expert-crafted disease descriptions are available. We evaluate our method on
two chest X-ray datasets, CheXpert and ChestX-ray 14 Longtail, showcasing
performance improvement over existing zero-shot methods and generalizability to
rare diseases.",2024-09-10 09:10:30+00:00
Improving Conditional Level Generation using Automated Validation in Match-3 Games,"Generative models for level generation have shown great potential in game
production. However, they often provide limited control over the generation,
and the validity of the generated levels is unreliable. Despite this fact, only
a few approaches that learn from existing data provide the users with ways of
controlling the generation, simultaneously addressing the generation of
unsolvable levels. %One of the main challenges it faces is that levels
generated through automation may not be solvable thus requiring validation. are
not always engaging, challenging, or even solvable. This paper proposes Avalon,
a novel method to improve models that learn from existing level designs using
difficulty statistics extracted from gameplay. In particular, we use a
conditional variational autoencoder to generate layouts for match-3 levels,
conditioning the model on pre-collected statistics such as game mechanics like
difficulty and relevant visual features like size and symmetry. Our method is
general enough that multiple approaches could potentially be used to generate
these statistics. We quantitatively evaluate our approach by comparing it to an
ablated model without difficulty conditioning. Additionally, we analyze both
quantitatively and qualitatively whether the style of the dataset is preserved
in the generated levels. Our approach generates more valid levels than the same
method without difficulty conditioning.",2024-09-10 09:07:47+00:00
VoiceWukong: Benchmarking Deepfake Voice Detection,"With the rapid advancement of technologies like text-to-speech (TTS) and
voice conversion (VC), detecting deepfake voices has become increasingly
crucial. However, both academia and industry lack a comprehensive and intuitive
benchmark for evaluating detectors. Existing datasets are limited in language
diversity and lack many manipulations encountered in real-world production
environments.
  To fill this gap, we propose VoiceWukong, a benchmark designed to evaluate
the performance of deepfake voice detectors. To build the dataset, we first
collected deepfake voices generated by 19 advanced and widely recognized
commercial tools and 15 open-source tools. We then created 38 data variants
covering six types of manipulations, constructing the evaluation dataset for
deepfake voice detection. VoiceWukong thus includes 265,200 English and 148,200
Chinese deepfake voice samples. Using VoiceWukong, we evaluated 12
state-of-the-art detectors. AASIST2 achieved the best equal error rate (EER) of
13.50%, while all others exceeded 20%. Our findings reveal that these detectors
face significant challenges in real-world applications, with dramatically
declining performance. In addition, we conducted a user study with more than
300 participants. The results are compared with the performance of the 12
detectors and a multimodel large language model (MLLM), i.e., Qwen2-Audio,
where different detectors and humans exhibit varying identification
capabilities for deepfake voices at different deception levels, while the LALM
demonstrates no detection ability at all. Furthermore, we provide a leaderboard
for deepfake voice detection, publicly available at
{https://voicewukong.github.io}.",2024-09-10 09:07:12+00:00
Compute-Update Federated Learning: A Lattice Coding Approach,"This paper introduces a federated learning framework that enables
over-the-air computation via digital communications, using a new joint
source-channel coding scheme. Without relying on channel state information at
devices, this scheme employs lattice codes to both quantize model parameters
and exploit interference from the devices. We propose a novel receiver
structure at the server, designed to reliably decode an integer combination of
the quantized model parameters as a lattice point for the purpose of
aggregation. We present a mathematical approach to derive a convergence bound
for the proposed scheme and offer design remarks. In this context, we suggest
an aggregation metric and a corresponding algorithm to determine effective
integer coefficients for the aggregation in each communication round. Our
results illustrate that, regardless of channel dynamics and data heterogeneity,
our scheme consistently delivers superior learning accuracy across various
parameters and markedly surpasses other over-the-air methodologies.",2024-09-10 08:52:24+00:00
Towards Agentic AI on Particle Accelerators,"As particle accelerators grow in complexity, traditional control methods face
increasing challenges in achieving optimal performance. This paper envisions a
paradigm shift: a decentralized multi-agent framework for accelerator control,
powered by Large Language Models (LLMs) and distributed among autonomous
agents. We present a proposition of a self-improving decentralized system where
intelligent agents handle high-level tasks and communication and each agent is
specialized control individual accelerator components.
  This approach raises some questions: What are the future applications of AI
in particle accelerators? How can we implement an autonomous complex system
such as a particle accelerator where agents gradually improve through
experience and human feedback? What are the implications of integrating a
human-in-the-loop component for labeling operational data and providing expert
guidance? We show two examples, where we demonstrate viability of such
architecture.",2024-09-10 08:47:23+00:00
Multi-Weather Image Restoration via Histogram-Based Transformer Feature Enhancement,"Currently, the mainstream restoration tasks under adverse weather conditions
have predominantly focused on single-weather scenarios. However, in reality,
multiple weather conditions always coexist and their degree of mixing is
usually unknown. Under such complex and diverse weather conditions,
single-weather restoration models struggle to meet practical demands. This is
particularly critical in fields such as autonomous driving, where there is an
urgent need for a model capable of effectively handling mixed weather
conditions and enhancing image quality in an automated manner. In this paper,
we propose a Task Sequence Generator module that, in conjunction with the Task
Intra-patch Block, effectively extracts task-specific features embedded in
degraded images. The Task Intra-patch Block introduces an external learnable
sequence that aids the network in capturing task-specific information.
Additionally, we employ a histogram-based transformer module as the backbone of
our network, enabling the capture of both global and local dynamic range
features. Our proposed model achieves state-of-the-art performance on public
datasets.",2024-09-10 08:47:03+00:00
Modified Meta-Thompson Sampling for Linear Bandits and Its Bayes Regret Analysis,"Meta-learning is characterized by its ability to learn how to learn, enabling
the adaptation of learning strategies across different tasks. Recent research
introduced the Meta-Thompson Sampling (Meta-TS), which meta-learns an unknown
prior distribution sampled from a meta-prior by interacting with bandit
instances drawn from it. However, its analysis was limited to Gaussian bandit.
The contextual multi-armed bandit framework is an extension of the Gaussian
Bandit, which challenges agent to utilize context vectors to predict the most
valuable arms, optimally balancing exploration and exploitation to minimize
regret over time. This paper introduces Meta-TSLB algorithm, a modified Meta-TS
for linear contextual bandits. We theoretically analyze Meta-TSLB and derive an
$ O((m+\log(m))\sqrt{n\log(n)})$ bound on its Bayes regret, in which $m$
represents the number of bandit instances, and $n$ the number of rounds of
Thompson Sampling. Additionally, our work complements the analysis of Meta-TS
for linear contextual bandits. The performance of Meta-TSLB is evaluated
experimentally under different settings, and we experimente and analyze the
generalization capability of Meta-TSLB, showcasing its potential to adapt to
unseen instances.",2024-09-10 08:34:55+00:00
SDF-Net: A Hybrid Detection Network for Mediastinal Lymph Node Detection on Contrast CT Images,"Accurate lymph node detection and quantification are crucial for cancer
diagnosis and staging on contrast-enhanced CT images, as they impact treatment
planning and prognosis. However, detecting lymph nodes in the mediastinal area
poses challenges due to their low contrast, irregular shapes and dispersed
distribution. In this paper, we propose a Swin-Det Fusion Network (SDF-Net) to
effectively detect lymph nodes. SDF-Net integrates features from both
segmentation and detection to enhance the detection capability of lymph nodes
with various shapes and sizes. Specifically, an auto-fusion module is designed
to merge the feature maps of segmentation and detection networks at different
levels. To facilitate effective learning without mask annotations, we introduce
a shape-adaptive Gaussian kernel to represent lymph node in the training stage
and provide more anatomical information for effective learning. Comparative
results demonstrate promising performance in addressing the complex lymph node
detection problem.",2024-09-10 08:27:44+00:00
LAMP: Learnable Meta-Path Guided Adversarial Contrastive Learning for Heterogeneous Graphs,"Heterogeneous graph neural networks (HGNNs) have significantly propelled the
information retrieval (IR) field. Still, the effectiveness of HGNNs heavily
relies on high-quality labels, which are often expensive to acquire. This
challenge has shifted attention towards Heterogeneous Graph Contrastive
Learning (HGCL), which usually requires pre-defined meta-paths. However, our
findings reveal that meta-path combinations significantly affect performance in
unsupervised settings, an aspect often overlooked in current literature.
Existing HGCL methods have considerable variability in outcomes across
different meta-path combinations, thereby challenging the optimization process
to achieve consistent and high performance. In response, we introduce
\textsf{LAMP} (\underline{\textbf{L}}earn\underline{\textbf{A}}ble
\underline{\textbf{M}}eta-\underline{\textbf{P}}ath), a novel adversarial
contrastive learning approach that integrates various meta-path sub-graphs into
a unified and stable structure, leveraging the overlap among these sub-graphs.
To address the denseness of this integrated sub-graph, we propose an
adversarial training strategy for edge pruning, maintaining sparsity to enhance
model performance and robustness. \textsf{LAMP} aims to maximize the difference
between meta-path and network schema views for guiding contrastive learning to
capture the most meaningful information. Our extensive experimental study
conducted on four diverse datasets from the Heterogeneous Graph Benchmark (HGB)
demonstrates that \textsf{LAMP} significantly outperforms existing
state-of-the-art unsupervised models in terms of accuracy and robustness.",2024-09-10 08:27:39+00:00
G3PT: Unleash the power of Autoregressive Modeling in 3D Generation via Cross-scale Querying Transformer,"Autoregressive transformers have revolutionized generative models in language
processing and shown substantial promise in image and video generation.
However, these models face significant challenges when extended to 3D
generation tasks due to their reliance on next-token prediction to learn token
sequences, which is incompatible with the unordered nature of 3D data. Instead
of imposing an artificial order on 3D data, in this paper, we introduce G3PT, a
scalable coarse-to-fine 3D generative model utilizing a cross-scale querying
transformer. The key is to map point-based 3D data into discrete tokens with
different levels of detail, naturally establishing a sequential relationship
between different levels suitable for autoregressive modeling. Additionally,
the cross-scale querying transformer connects tokens globally across different
levels of detail without requiring an ordered sequence. Benefiting from this
approach, G3PT features a versatile 3D generation pipeline that effortlessly
supports diverse conditional structures, enabling the generation of 3D shapes
from various types of conditions. Extensive experiments demonstrate that G3PT
achieves superior generation quality and generalization ability compared to
previous 3D generation methods. Most importantly, for the first time in 3D
generation, scaling up G3PT reveals distinct power-law scaling behaviors.",2024-09-10 08:27:19+00:00
Rate-Constrained Quantization for Communication-Efficient Federated Learning,"Quantization is a common approach to mitigate the communication cost of
federated learning (FL). In practice, the quantized local parameters are
further encoded via an entropy coding technique, such as Huffman coding, for
efficient data compression. In this case, the exact communication overhead is
determined by the bit rate of the encoded gradients. Recognizing this fact,
this work deviates from the existing approaches in the literature and develops
a novel quantized FL framework, called \textbf{r}ate-\textbf{c}onstrained
\textbf{fed}erated learning (RC-FED), in which the gradients are quantized
subject to both fidelity and data rate constraints. We formulate this scheme,
as a joint optimization in which the quantization distortion is minimized while
the rate of encoded gradients is kept below a target threshold. This enables
for a tunable trade-off between quantization distortion and communication cost.
We analyze the convergence behavior of RC-FED, and show its superior
performance against baseline quantized FL schemes on several datasets.",2024-09-10 08:22:01+00:00
PharmacoMatch: Efficient 3D Pharmacophore Screening through Neural Subgraph Matching,"The increasing size of screening libraries poses a significant challenge for
the development of virtual screening methods for drug discovery, necessitating
a re-evaluation of traditional approaches in the era of big data. Although 3D
pharmacophore screening remains a prevalent technique, its application to very
large datasets is limited by the computational cost associated with matching
query pharmacophores to database ligands. In this study, we introduce
PharmacoMatch, a novel contrastive learning approach based on neural subgraph
matching. Our method reinterprets pharmacophore screening as an approximate
subgraph matching problem and enables efficient querying of conformational
databases by encoding query-target relationships in the embedding space. We
conduct comprehensive evaluations of the learned representations and benchmark
our method on virtual screening datasets in a zero-shot setting. Our findings
demonstrate significantly shorter runtimes for pharmacophore matching, offering
a promising speed-up for screening very large datasets.",2024-09-10 08:17:06+00:00
Seam Carving as Feature Pooling in CNN,"This work investigates the potential of seam carving as a feature pooling
technique within Convolutional Neural Networks (CNNs) for image classification
tasks. We propose replacing the traditional max pooling layer with a seam
carving operation. Our experiments on the Caltech-UCSD Birds 200-2011 dataset
demonstrate that the seam carving-based CNN achieves better performance
compared to the model utilizing max pooling, based on metrics such as accuracy,
precision, recall, and F1-score. We further analyze the behavior of both
approaches through feature map visualizations, suggesting that seam carving
might preserve more structural information during the pooling process.
Additionally, we discuss the limitations of our approach and propose potential
future directions for research.",2024-09-10 08:11:14+00:00
PPMamba: A Pyramid Pooling Local Auxiliary SSM-Based Model for Remote Sensing Image Semantic Segmentation,"Semantic segmentation is a vital task in the field of remote sensing (RS).
However, conventional convolutional neural network (CNN) and transformer-based
models face limitations in capturing long-range dependencies or are often
computationally intensive. Recently, an advanced state space model (SSM),
namely Mamba, was introduced, offering linear computational complexity while
effectively establishing long-distance dependencies. Despite their advantages,
Mamba-based methods encounter challenges in preserving local semantic
information. To cope with these challenges, this paper proposes a novel network
called Pyramid Pooling Mamba (PPMamba), which integrates CNN and Mamba for RS
semantic segmentation tasks. The core structure of PPMamba, the Pyramid
Pooling-State Space Model (PP-SSM) block, combines a local auxiliary mechanism
with an omnidirectional state space model (OSS) that selectively scans feature
maps from eight directions, capturing comprehensive feature information.
Additionally, the auxiliary mechanism includes pyramid-shaped convolutional
branches designed to extract features at multiple scales. Extensive experiments
on two widely-used datasets, ISPRS Vaihingen and LoveDA Urban, demonstrate that
PPMamba achieves competitive performance compared to state-of-the-art models.",2024-09-10 08:08:50+00:00
An End-to-End Approach for Chord-Conditioned Song Generation,"The Song Generation task aims to synthesize music composed of vocals and
accompaniment from given lyrics. While the existing method, Jukebox, has
explored this task, its constrained control over the generations often leads to
deficiency in music performance. To mitigate the issue, we introduce an
important concept from music composition, namely chords, to song generation
networks. Chords form the foundation of accompaniment and provide vocal melody
with associated harmony. Given the inaccuracy of automatic chord extractors, we
devise a robust cross-attention mechanism augmented with dynamic weight
sequence to integrate extracted chord information into song generations and
reduce frame-level flaws, and propose a novel model termed Chord-Conditioned
Song Generator (CSG) based on it. Experimental evidence demonstrates our
proposed method outperforms other approaches in terms of musical performance
and control precision of generated songs.",2024-09-10 08:07:43+00:00
High-Performance Few-Shot Segmentation with Foundation Models: An Empirical Study,"Existing few-shot segmentation (FSS) methods mainly focus on designing novel
support-query matching and self-matching mechanisms to exploit implicit
knowledge in pre-trained backbones. However, the performance of these methods
is often constrained by models pre-trained on classification tasks. The
exploration of what types of pre-trained models can provide more beneficial
implicit knowledge for FSS remains limited. In this paper, inspired by the
representation consistency of foundational computer vision models, we develop a
FSS framework based on foundation models. To be specific, we propose a simple
approach to extract implicit knowledge from foundation models to construct
coarse correspondence and introduce a lightweight decoder to refine coarse
correspondence for fine-grained segmentation. We systematically summarize the
performance of various foundation models on FSS and discover that the implicit
knowledge within some of these models is more beneficial for FSS than models
pre-trained on classification tasks. Extensive experiments on two widely used
datasets demonstrate the effectiveness of our approach in leveraging the
implicit knowledge of foundation models. Notably, the combination of DINOv2 and
DFN exceeds previous state-of-the-art methods by 17.5% on COCO-20i. Code is
available at https://github.com/DUT-CSJ/FoundationFSS.",2024-09-10 08:04:11+00:00
An Attribute-Enriched Dataset and Auto-Annotated Pipeline for Open Detection,"Detecting objects of interest through language often presents challenges,
particularly with objects that are uncommon or complex to describe, due to
perceptual discrepancies between automated models and human annotators. These
challenges highlight the need for comprehensive datasets that go beyond
standard object labels by incorporating detailed attribute descriptions. To
address this need, we introduce the Objects365-Attr dataset, an extension of
the existing Objects365 dataset, distinguished by its attribute annotations.
This dataset reduces inconsistencies in object detection by integrating a broad
spectrum of attributes, including color, material, state, texture and tone. It
contains an extensive collection of 5.6M object-level attribute descriptions,
meticulously annotated across 1.4M bounding boxes. Additionally, to validate
the dataset's effectiveness, we conduct a rigorous evaluation of YOLO-World at
different scales, measuring their detection performance and demonstrating the
dataset's contribution to advancing object detection.",2024-09-10 07:53:32+00:00
Enhancing Long Video Understanding via Hierarchical Event-Based Memory,"Recently, integrating visual foundation models into large language models
(LLMs) to form video understanding systems has attracted widespread attention.
Most of the existing models compress diverse semantic information within the
whole video and feed it into LLMs for content comprehension. While this method
excels in short video understanding, it may result in a blend of multiple event
information in long videos due to coarse compression, which causes information
redundancy. Consequently, the semantics of key events might be obscured within
the vast information that hinders the model's understanding capabilities. To
address this issue, we propose a Hierarchical Event-based Memory-enhanced LLM
(HEM-LLM) for better understanding of long videos. Firstly, we design a novel
adaptive sequence segmentation scheme to divide multiple events within long
videos. In this way, we can perform individual memory modeling for each event
to establish intra-event contextual connections, thereby reducing information
redundancy. Secondly, while modeling current event, we compress and inject the
information of the previous event to enhance the long-term inter-event
dependencies in videos. Finally, we perform extensive experiments on various
video understanding tasks and the results show that our model achieves
state-of-the-art performances.",2024-09-10 07:53:10+00:00
User Preferences for Large Language Model versus Template-Based Explanations of Movie Recommendations: A Pilot Study,"Recommender systems have become integral to our digital experiences, from
online shopping to streaming platforms. Still, the rationale behind their
suggestions often remains opaque to users. While some systems employ a
graph-based approach, offering inherent explainability through paths
associating recommended items and seed items, non-experts could not easily
understand these explanations. A popular alternative is to convert graph-based
explanations into textual ones using a template and an algorithm, which we
denote here as ''template-based'' explanations. Yet, these can sometimes come
across as impersonal or uninspiring. A novel method would be to employ large
language models (LLMs) for this purpose, which we denote as ''LLM-based''. To
assess the effectiveness of LLMs in generating more resonant explanations, we
conducted a pilot study with 25 participants. They were presented with three
explanations: (1) traditional template-based, (2) LLM-based rephrasing of the
template output, and (3) purely LLM-based explanations derived from the
graph-based explanations. Although subject to high variance, preliminary
findings suggest that LLM-based explanations may provide a richer and more
engaging user experience, further aligning with user expectations. This study
sheds light on the potential limitations of current explanation methods and
offers promising directions for leveraging large language models to improve
user satisfaction and trust in recommender systems.",2024-09-10 07:51:53+00:00
EntAugment: Entropy-Driven Adaptive Data Augmentation Framework for Image Classification,"Data augmentation (DA) has been widely used to improve the generalization of
deep neural networks. While existing DA methods have proven effective, they
often rely on augmentation operations with random magnitudes to each sample.
However, this approach can inadvertently introduce noise, induce distribution
shifts, and increase the risk of overfitting. In this paper, we propose
EntAugment, a tuning-free and adaptive DA framework. Unlike previous work,
EntAugment dynamically assesses and adjusts the augmentation magnitudes for
each sample during training, leveraging insights into both the inherent
complexities of training samples and the evolving status of deep models.
Specifically, in EntAugment, the magnitudes are determined by the information
entropy derived from the probability distribution obtained by applying the
softmax function to the model's output. In addition, to further enhance the
efficacy of EntAugment, we introduce a novel entropy regularization term,
EntLoss, which complements the EntAugment approach. Theoretical analysis
further demonstrates that EntLoss, compared to traditional cross-entropy loss,
achieves closer alignment between the model distributions and underlying
dataset distributions. Moreover, EntAugment and EntLoss can be utilized
separately or jointly. We conduct extensive experiments across multiple image
classification tasks and network architectures with thorough comparisons of
existing DA methods. Importantly, the proposed methods outperform others
without introducing any auxiliary models or noticeable extra computational
costs, highlighting both effectiveness and efficiency. Code is available at
https://github.com/Jackbrocp/EntAugment.",2024-09-10 07:42:47+00:00
Automate Strategy Finding with LLM in Quant investment,"Despite significant progress in deep learning for financial trading, existing
models often face instability and high uncertainty, hindering their practical
application. Leveraging advancements in Large Language Models (LLMs) and
multi-agent architectures, we propose a novel framework for quantitative stock
investment in portfolio management and alpha mining. Our framework addresses
these issues by integrating LLMs to generate diversified alphas and employing a
multi-agent approach to dynamically evaluate market conditions. This paper
proposes a framework where large language models (LLMs) mine alpha factors from
multimodal financial data, ensuring a comprehensive understanding of market
dynamics. The first module extracts predictive signals by integrating numerical
data, research papers, and visual charts. The second module uses ensemble
learning to construct a diverse pool of trading agents with varying risk
preferences, enhancing strategy performance through a broader market analysis.
In the third module, a dynamic weight-gating mechanism selects and assigns
weights to the most relevant agents based on real-time market conditions,
enabling the creation of an adaptive and context-aware composite alpha formula.
Extensive experiments on the Chinese stock markets demonstrate that this
framework significantly outperforms state-of-the-art baselines across multiple
financial metrics. The results underscore the efficacy of combining
LLM-generated alphas with a multi-agent architecture to achieve superior
trading performance and stability. This work highlights the potential of
AI-driven approaches in enhancing quantitative investment strategies and sets a
new benchmark for integrating advanced machine learning techniques in financial
trading can also be applied on diverse markets.",2024-09-10 07:42:28+00:00
Context Enhancement with Reconstruction as Sequence for Unified Unsupervised Anomaly Detection,"Unsupervised anomaly detection (AD) aims to train robust detection models
using only normal samples, while can generalize well to unseen anomalies.
Recent research focuses on a unified unsupervised AD setting in which only one
model is trained for all classes, i.e., n-class-one-model paradigm.
Feature-reconstruction-based methods achieve state-of-the-art performance in
this scenario. However, existing methods often suffer from a lack of sufficient
contextual awareness, thereby compromising the quality of the reconstruction.
To address this issue, we introduce a novel Reconstruction as Sequence (RAS)
method, which enhances the contextual correspondence during feature
reconstruction from a sequence modeling perspective. In particular, based on
the transformer technique, we integrate a specialized RASFormer block into RAS.
This block enables the capture of spatial relationships among different image
regions and enhances sequential dependencies throughout the reconstruction
process. By incorporating the RASFormer block, our RAS method achieves superior
contextual awareness capabilities, leading to remarkable performance.
Experimental results show that our RAS significantly outperforms competing
methods, well demonstrating the effectiveness and superiority of our method.
Our code is available at https://github.com/Nothingtolose9979/RAS.",2024-09-10 07:37:58+00:00
Learning Augmentation Policies from A Model Zoo for Time Series Forecasting,"Time series forecasting models typically rely on a fixed-size training set
and treat all data uniformly, which may not effectively capture the specific
patterns present in more challenging training samples. To address this issue,
we introduce AutoTSAug, a learnable data augmentation method based on
reinforcement learning. Our approach begins with an empirical analysis to
determine which parts of the training data should be augmented. Specifically,
we identify the so-called marginal samples by considering the prediction
diversity across a set of pretrained forecasting models. Next, we propose using
variational masked autoencoders as the augmentation model and applying the
REINFORCE algorithm to transform the marginal samples into new data. The goal
of this generative model is not only to mimic the distribution of real data but
also to reduce the variance of prediction errors across the model zoo. By
augmenting the marginal samples with a learnable policy, AutoTSAug
substantially improves forecasting performance, advancing the prior art in this
field with minimal additional computational cost.",2024-09-10 07:34:19+00:00
Catch Me if You Can: Detecting Unauthorized Data Use in Deep Learning Models,"The rise of deep learning (DL) has led to a surging demand for training data,
which incentivizes the creators of DL models to trawl through the Internet for
training materials. Meanwhile, users often have limited control over whether
their data (e.g., facial images) are used to train DL models without their
consent, which has engendered pressing concerns.
  This work proposes MembershipTracker, a practical data provenance tool that
can empower ordinary users to take agency in detecting the unauthorized use of
their data in training DL models. We view tracing data provenance through the
lens of membership inference (MI). MembershipTracker consists of a lightweight
data marking component to mark the target data with small and targeted changes,
which can be strongly memorized by the model trained on them; and a specialized
MI-based verification process to audit whether the model exhibits strong
memorization on the target samples.
  Overall, MembershipTracker only requires the users to mark a small fraction
of data (0.005% to 0.1% in proportion to the training set), and it enables the
users to reliably detect the unauthorized use of their data (average 0%
FPR@100% TPR). We show that MembershipTracker is highly effective across
various settings, including industry-scale training on the full-size
ImageNet-1k dataset. We finally evaluate MembershipTracker under multiple
classes of countermeasures.",2024-09-10 07:31:56+00:00
Ferret: Federated Full-Parameter Tuning at Scale for Large Language Models,"Large Language Models (LLMs) have become indispensable in numerous real-world
applications. Unfortunately, fine-tuning these models at scale, especially in
federated settings where data privacy and communication efficiency are
critical, presents significant challenges. Existing methods often resort to
parameter-efficient fine-tuning (PEFT) to mitigate communication overhead, but
this typically comes at the cost of model accuracy. To address these
limitations, we propose federated full-parameter tuning at scale for LLMs
(Ferret), the first first-order method with shared randomness to enable
scalable full-parameter tuning of LLMs across decentralized data sources while
maintaining competitive model accuracy. Ferret accomplishes this through three
aspects: (1) it employs widely applied first-order methods for efficient local
updates; (2) it projects these updates into a low-dimensional space to
considerably reduce communication overhead; and (3) it reconstructs local
updates from this low-dimensional space with shared randomness to facilitate
effective full-parameter global aggregation, ensuring fast convergence and
competitive final performance. Our rigorous theoretical analyses and insights
along with extensive experiments, show that Ferret significantly enhances the
scalability of existing federated full-parameter tuning approaches by achieving
high computational efficiency, reduced communication overhead, and fast
convergence, all while maintaining competitive model accuracy. Our
implementation is available at https://github.com/allen4747/Ferret.",2024-09-10 07:28:13+00:00
A new paradigm for global sensitivity analysis,"<div><p>Current theory of global sensitivity analysis, based on a nonlinear
functional ANOVA decomposition of the random output, is limited in scope-for
instance, the analysis is limited to the output's variance and the inputs have
to be mutually independent-and leads to sensitivity indices the interpretation
of which is not fully clear, especially interaction effects. Alternatively,
sensitivity indices built for arbitrary user-defined importance measures have
been proposed but a theory to define interactions in a systematic fashion
and/or establish a decomposition of the total importance measure is still
missing. It is shown that these important problems are solved all at once by
adopting a new paradigm. By partitioning the inputs into those causing the
change in the output and those which do not, arbitrary user-defined variability
measures are identified with the outcomes of a factorial experiment at two
levels, leading to all factorial effects without assuming any functional
decomposition. To link various well-known sensitivity indices of the literature
(Sobol indices and Shapley effects), weighted factorial effects are studied and
utilized.</p></div>",2024-09-10 07:20:51+00:00
Towards Robust Uncertainty-Aware Incomplete Multi-View Classification,"Handling incomplete data in multi-view classification is challenging,
especially when traditional imputation methods introduce biases that compromise
uncertainty estimation. Existing Evidential Deep Learning (EDL) based
approaches attempt to address these issues, but they often struggle with
conflicting evidence due to the limitations of the Dempster-Shafer combination
rule, leading to unreliable decisions. To address these challenges, we propose
the Alternating Progressive Learning Network (APLN), specifically designed to
enhance EDL-based methods in incomplete MVC scenarios. Our approach mitigates
bias from corrupted observed data by first applying coarse imputation, followed
by mapping the data to a latent space. In this latent space, we progressively
learn an evidence distribution aligned with the target domain, incorporating
uncertainty considerations through EDL. Additionally, we introduce a
conflict-aware Dempster-Shafer combination rule (DSCR) to better handle
conflicting evidence. By sampling from the learned distribution, we optimize
the latent representations of missing views, reducing bias and enhancing
decision-making robustness. Extensive experiments demonstrate that APLN,
combined with DSCR, significantly outperforms traditional methods, particularly
in environments characterized by high uncertainty and conflicting evidence,
establishing it as a promising solution for incomplete multi-view
classification.",2024-09-10 07:18:57+00:00
Mahalanobis k-NN: A Statistical Lens for Robust Point-Cloud Registrations,"In this paper, we discuss Mahalanobis k-NN: a statistical lens designed to
address the challenges of feature matching in learning-based point cloud
registration when confronted with an arbitrary density of point clouds, either
in the source or target point cloud. We tackle this by adopting Mahalanobis
k-NN's inherent property to capture the distribution of the local neighborhood
and surficial geometry. Our method can be seamlessly integrated into any
local-graph-based point cloud analysis method. In this paper, we focus on two
distinct methodologies: Deep Closest Point (DCP) and Deep Universal Manifold
Embedding (DeepUME). Our extensive benchmarking on the ModelNet40 and Faust
datasets highlights the efficacy of the proposed method in point cloud
registration tasks. Moreover, we establish for the first time that the features
acquired through point cloud registration inherently can possess discriminative
capabilities. This is evident by a substantial improvement of about 20\% in the
average accuracy observed in the point cloud few-shot classification task
benchmarked on ModelNet40 and ScanObjectNN. The code is publicly available at
https://github.com/TejasAnvekar/Mahalanobis-k-NN",2024-09-10 07:12:18+00:00
Keyword-Aware ASR Error Augmentation for Robust Dialogue State Tracking,"Dialogue State Tracking (DST) is a key part of task-oriented dialogue
systems, identifying important information in conversations. However, its
accuracy drops significantly in spoken dialogue environments due to named
entity errors from Automatic Speech Recognition (ASR) systems. We introduce a
simple yet effective data augmentation method that targets those entities to
improve the robustness of DST model. Our novel method can control the placement
of errors using keyword-highlighted prompts while introducing phonetically
similar errors. As a result, our method generated sufficient error patterns on
keywords, leading to improved accuracy in noised and low-accuracy ASR
environments.",2024-09-10 07:06:40+00:00
Personalized Knowledge Tracing through Student Representation Reconstruction and Class Imbalance Mitigation,"Knowledge tracing is a technique that predicts students' future performance
by analyzing their learning process through historical interactions with
intelligent educational platforms, enabling a precise evaluation of their
knowledge mastery. Recent studies have achieved significant progress by
leveraging powerful deep neural networks. These models construct complex input
representations using questions, skills, and other auxiliary information but
overlook individual student characteristics, which limits the capability for
personalized assessment. Additionally, the available datasets in the field
exhibit class imbalance issues. The models that simply predict all responses as
correct without substantial effort can yield impressive accuracy. In this
paper, we propose PKT, a novel approach for personalized knowledge tracing. PKT
reconstructs representations from sequences of interactions with a tutoring
platform to capture latent information about the students. Moreover, PKT
incorporates focal loss to improve prioritize minority classes, thereby
achieving more balanced predictions. Extensive experimental results on four
publicly available educational datasets demonstrate the advanced predictive
performance of PKT in comparison with 16 state-of-the-art models. To ensure the
reproducibility of our research, the code is publicly available at
https://anonymous.4open.science/r/PKT.",2024-09-10 07:02:46+00:00
ALSS-YOLO: An Adaptive Lightweight Channel Split and Shuffling Network for TIR Wildlife Detection in UAV Imagery,"Unmanned aerial vehicles (UAVs) equipped with thermal infrared (TIR) cameras
play a crucial role in combating nocturnal wildlife poaching. However, TIR
images often face challenges such as jitter, and wildlife overlap,
necessitating UAVs to possess the capability to identify blurred and
overlapping small targets. Current traditional lightweight networks deployed on
UAVs struggle to extract features from blurry small targets. To address this
issue, we developed ALSS-YOLO, an efficient and lightweight detector optimized
for TIR aerial images. Firstly, we propose a novel Adaptive Lightweight Channel
Split and Shuffling (ALSS) module. This module employs an adaptive channel
split strategy to optimize feature extraction and integrates a channel
shuffling mechanism to enhance information exchange between channels. This
improves the extraction of blurry features, crucial for handling jitter-induced
blur and overlapping targets. Secondly, we developed a Lightweight Coordinate
Attention (LCA) module that employs adaptive pooling and grouped convolution to
integrate feature information across dimensions. This module ensures
lightweight operation while maintaining high detection precision and robustness
against jitter and target overlap. Additionally, we developed a single-channel
focus module to aggregate the width and height information of each channel into
four-dimensional channel fusion, which improves the feature representation
efficiency of infrared images. Finally, we modify the localization loss
function to emphasize the loss value associated with small objects to improve
localization accuracy. Extensive experiments on the BIRDSAI and ISOD TIR UAV
wildlife datasets show that ALSS-YOLO achieves state-of-the-art performance,
Our code is openly available at
https://github.com/helloworlder8/computer_vision.",2024-09-10 07:02:01+00:00
Market Reaction to News Flows in Supply Chain Networks,"This study examines whether positive news about firms increases their stock
prices and, moreover, whether it increases stock prices of the firms' suppliers
and customers, using a large sample of publicly listed firms across the world
and another of Japanese listed firms. The level of positiveness of each news
article is determined by FinBERT, a natural language processing model
fine-tuned specifically for financial information. Supply chains of firms
across the world are identified mostly by financial statements, while those of
Japanese firms are taken from large-scale firm-level surveys. We find that
positive news increases the change rate of stock prices of firms mentioned in
the news before its disclosure, most likely because of diffusion of information
through informal channels. Positive news also raises stock prices of the firms'
suppliers and customers before its disclosure, confirming propagation of market
values through supply chains. In addition, we generally find a larger post-news
effect on stock prices of the mentioned firms and their suppliers and customers
than the pre-news effect. The positive difference between the post- and
pre-news effects can be considered as the net effect of the disclosure of
positive news, controlling for informal information diffusion. However, the
post-news effect on suppliers and customers in Japan is smaller than the
pre-news effect, a result opposite to those from firms across the world. This
notable result is possibly because supply chain links of Japanese firms are
stronger than global supply chains while such knowledge is restricted to
selected investors.",2024-09-10 06:55:17+00:00
ProteinBench: A Holistic Evaluation of Protein Foundation Models,"Recent years have witnessed a surge in the development of protein foundation
models, significantly improving performance in protein prediction and
generative tasks ranging from 3D structure prediction and protein design to
conformational dynamics. However, the capabilities and limitations associated
with these models remain poorly understood due to the absence of a unified
evaluation framework. To fill this gap, we introduce ProteinBench, a holistic
evaluation framework designed to enhance the transparency of protein foundation
models. Our approach consists of three key components: (i) A taxonomic
classification of tasks that broadly encompass the main challenges in the
protein domain, based on the relationships between different protein
modalities; (ii) A multi-metric evaluation approach that assesses performance
across four key dimensions: quality, novelty, diversity, and robustness; and
(iii) In-depth analyses from various user objectives, providing a holistic view
of model performance. Our comprehensive evaluation of protein foundation models
reveals several key findings that shed light on their current capabilities and
limitations. To promote transparency and facilitate further research, we
release the evaluation dataset, code, and a public leaderboard publicly for
further analysis and a general modular toolkit. We intend for ProteinBench to
be a living benchmark for establishing a standardized, in-depth evaluation
framework for protein foundation models, driving their development and
application while fostering collaboration within the field.",2024-09-10 06:52:33+00:00
DiPT: Enhancing LLM reasoning through diversified perspective-taking,"Existing work on improving language model reasoning typically explores a
single solution path, which can be prone to errors. Inspired by
perspective-taking in social studies, this paper introduces DiPT, a novel
approach that complements current reasoning methods by explicitly incorporating
diversified viewpoints. This approach allows the model to gain a deeper
understanding of the problem's context and identify the most effective solution
path during the inference stage. Additionally, it provides a general
data-centric AI recipe for augmenting existing data to improve their quality
for fine-tuning.
  Our empirical results demonstrate that DiPT can be flexibly integrated into
existing methods that focus on a single reasoning approach, enhancing their
reasoning performance and stability when presented with paraphrased problems.
Furthermore, we illustrate improved context understanding by maintaining the
model's safe outputs against ""jailbreaking"" prompts intentionally designed to
bypass safeguards built into deployed models. Lastly, we show that fine-tuning
with data enriched with diverse perspectives can boost the reasoning
capabilities of the model compared to fine-tuning with raw data alone.",2024-09-10 06:17:27+00:00
Test-Time Certifiable Self-Supervision to Bridge the Sim2Real Gap in Event-Based Satellite Pose Estimation,"Deep learning plays a critical role in vision-based satellite pose
estimation. However, the scarcity of real data from the space environment means
that deep models need to be trained using synthetic data, which raises the
Sim2Real domain gap problem. A major cause of the Sim2Real gap are novel
lighting conditions encountered during test time. Event sensors have been shown
to provide some robustness against lighting variations in vision-based pose
estimation. However, challenging lighting conditions due to strong directional
light can still cause undesirable effects in the output of commercial
off-the-shelf event sensors, such as noisy/spurious events and inhomogeneous
event densities on the object. Such effects are non-trivial to simulate in
software, thus leading to Sim2Real gap in the event domain. To close the
Sim2Real gap in event-based satellite pose estimation, the paper proposes a
test-time self-supervision scheme with a certifier module. Self-supervision is
enabled by an optimisation routine that aligns a dense point cloud of the
predicted satellite pose with the event data to attempt to rectify the
inaccurately estimated pose. The certifier attempts to verify the corrected
pose, and only certified test-time inputs are backpropagated via implicit
differentiation to refine the predicted landmarks, thus improving the pose
estimates and closing the Sim2Real gap. Results show that the our method
outperforms established test-time adaptation schemes.",2024-09-10 06:17:07+00:00
Recurrent Neural Networks for Still Images,"In this paper, we explore the application of Recurrent Neural Network (RNN)
for still images. Typically, Convolutional Neural Networks (CNNs) are the
prevalent method applied for this type of data, and more recently, transformers
have gained popularity, although they often require large models. Unlike these
methods, RNNs are generally associated with processing sequences over time
rather than single images. We argue that RNNs can effectively handle still
images by interpreting the pixels as a sequence. This approach could be
particularly advantageous for compact models designed for embedded systems,
where resources are limited. Additionally, we introduce a novel RNN design
tailored for two-dimensional inputs, such as images, and a custom version of
BiDirectional RNN (BiRNN) that is more memory-efficient than traditional
implementations. In our research, we have tested these layers in Convolutional
Recurrent Neural Networks (CRNNs), predominantly composed of Conv2D layers,
with RNN layers at or close to the end. Experiments on the COCO and CIFAR100
datasets show better results, particularly for small networks.",2024-09-10 06:07:20+00:00
A Latent Implicit 3D Shape Model for Multiple Levels of Detail,"Implicit neural representations map a shape-specific latent code and a 3D
coordinate to its corresponding signed distance (SDF) value. However, this
approach only offers a single level of detail. Emulating low levels of detail
can be achieved with shallow networks, but the generated shapes are typically
not smooth. Alternatively, some network designs offer multiple levels of
detail, but are limited to overfitting a single object.
  To address this, we propose a new shape modeling approach, which enables
multiple levels of detail and guarantees a smooth surface at each level. At the
core, we introduce a novel latent conditioning for a multiscale and
bandwith-limited neural architecture. This results in a deep parameterization
of multiple shapes, where early layers quickly output approximated SDF values.
This allows to balance speed and accuracy within a single network and enhance
the efficiency of implicit scene rendering. We demonstrate that by limiting the
bandwidth of the network, we can maintain smooth surfaces across all levels of
detail. At finer levels, reconstruction quality is on par with the state of the
art models, which are limited to a single level of detail.",2024-09-10 05:57:58+00:00
NLP-Powered Repository and Search Engine for Academic Papers: A Case Study on Cyber Risk Literature with CyLit,"As the body of academic literature continues to grow, researchers face
increasing difficulties in effectively searching for relevant resources.
Existing databases and search engines often fall short of providing a
comprehensive and contextually relevant collection of academic literature. To
address this issue, we propose a novel framework that leverages Natural
Language Processing (NLP) techniques. This framework automates the retrieval,
summarization, and clustering of academic literature within a specific research
domain. To demonstrate the effectiveness of our approach, we introduce CyLit,
an NLP-powered repository specifically designed for the cyber risk literature.
CyLit empowers researchers by providing access to context-specific resources
and enabling the tracking of trends in the dynamic and rapidly evolving field
of cyber risk. Through the automatic processing of large volumes of data, our
NLP-powered solution significantly enhances the efficiency and specificity of
academic literature searches. We compare the literature categorization results
of CyLit to those presented in survey papers or generated by ChatGPT,
highlighting the distinctive insights this tool provides into cyber risk
research literature. Using NLP techniques, we aim to revolutionize the way
researchers discover, analyze, and utilize academic resources, ultimately
fostering advancements in various domains of knowledge.",2024-09-10 05:41:40+00:00
MIP-GAF: A MLLM-annotated Benchmark for Most Important Person Localization and Group Context Understanding,"Estimating the Most Important Person (MIP) in any social event setup is a
challenging problem mainly due to contextual complexity and scarcity of labeled
data. Moreover, the causality aspects of MIP estimation are quite subjective
and diverse. To this end, we aim to address the problem by annotating a
large-scale `in-the-wild' dataset for identifying human perceptions about the
`Most Important Person (MIP)' in an image. The paper provides a thorough
description of our proposed Multimodal Large Language Model (MLLM) based data
annotation strategy, and a thorough data quality analysis. Further, we perform
a comprehensive benchmarking of the proposed dataset utilizing state-of-the-art
MIP localization methods, indicating a significant drop in performance compared
to existing datasets. The performance drop shows that the existing MIP
localization algorithms must be more robust with respect to `in-the-wild'
situations. We believe the proposed dataset will play a vital role in building
the next-generation social situation understanding methods. The code and data
is available at https://github.com/surbhimadan92/MIP-GAF.",2024-09-10 05:28:38+00:00
CerviXpert: A Multi-Structural Convolutional Neural Network for Predicting Cervix Type and Cervical Cell Abnormalities,"Cervical cancer affects millions of women worldwide and has a significantly
higher survival rate when diagnosed early. Pap smears and cervical biopsies are
vital screening tools for detecting such cancer. However, the success of these
screening processes depends on the skills of cytologists. A recent trend in
diagnostic cytology is to apply machine-learning-based models to classify
cancer using cell images. These automated models have been shown to perform
just as well as, or even better than, expert cytologists. Some notable methods
for classifying cervix cancers include ResNet50, VGG16, MobileNetV2, and
InceptionV3, based on deep convolutional neural networks (CNN). However, these
methods are computationally expensive. We present CerviXpert, a
multi-structural Convolutional Neural Network, to identify cervix cancer. We
perform extensive experiments on a publicly available dataset, SiPaKMeD, to
show the efficacy of our method. CerviXpert presents a promising solution for
efficient cervical cancer screening and diagnosis by striking a balance between
accuracy and practical feasibility.",2024-09-10 05:08:26+00:00
"Denoising: A Powerful Building-Block for Imaging, Inverse Problems, and Machine Learning","Denoising, the process of reducing random fluctuations in a signal to
emphasize essential patterns, has been a fundamental problem of interest since
the dawn of modern scientific inquiry. Recent denoising techniques,
particularly in imaging, have achieved remarkable success, nearing theoretical
limits by some measures. Yet, despite tens of thousands of research papers, the
wide-ranging applications of denoising beyond noise removal have not been fully
recognized. This is partly due to the vast and diverse literature, making a
clear overview challenging.
  This paper aims to address this gap. We present a comprehensive perspective
on denoisers, their structure, and desired properties. We emphasize the
increasing importance of denoising and showcase its evolution into an essential
building block for complex tasks in imaging, inverse problems, and machine
learning. Despite its long history, the community continues to uncover
unexpected and groundbreaking uses for denoising, further solidifying its place
as a cornerstone of scientific and engineering practice.",2024-09-10 05:05:34+00:00
DACAT: Dual-stream Adaptive Clip-aware Time Modeling for Robust Online Surgical Phase Recognition,"Surgical phase recognition has become a crucial requirement in laparoscopic
surgery, enabling various clinical applications like surgical risk forecasting.
Current methods typically identify the surgical phase using individual
frame-wise embeddings as the fundamental unit for time modeling. However, this
approach is overly sensitive to current observations, often resulting in
discontinuous and erroneous predictions within a complete surgical phase. In
this paper, we propose DACAT, a novel dual-stream model that adaptively learns
clip-aware context information to enhance the temporal relationship. In one
stream, DACAT pretrains a frame encoder, caching all historical frame-wise
features. In the other stream, DACAT fine-tunes a new frame encoder to extract
the frame-wise feature at the current moment. Additionally, a max clip-response
read-out (Max-R) module is introduced to bridge the two streams by using the
current frame-wise feature to adaptively fetch the most relevant past clip from
the feature cache. The clip-aware context feature is then encoded via
cross-attention between the current frame and its fetched adaptive clip, and
further utilized to enhance the time modeling for accurate online surgical
phase recognition. The benchmark results on three public datasets, i.e.,
Cholec80, M2CAI16, and AutoLaparo, demonstrate the superiority of our proposed
DACAT over existing state-of-the-art methods, with improvements in Jaccard
scores of at least 4.5%, 4.6%, and 2.7%, respectively. Our code and models have
been released at https://github.com/kk42yy/DACAT.",2024-09-10 04:58:48+00:00
Towards Generalizable Scene Change Detection,"Scene Change Detection (SCD) is vital for applications such as visual
surveillance and mobile robotics. However, current SCD methods exhibit a bias
to the temporal order of training datasets and limited performance on unseen
domains; coventional SCD benchmarks are not able to evaluate generalization or
temporal consistency. To tackle these limitations, we introduce a Generalizable
Scene Change Detection Framework (GeSCF) in this work. The proposed GeSCF
leverages localized semantics of a foundation model without any re-training or
fine-tuning -- for generalization over unseen domains. Specifically, we design
an adaptive thresholding of the similarity distribution derived from facets of
the pre-trained foundation model to generate initial pseudo-change mask. We
further utilize Segment Anything Model's (SAM) class-agnostic masks to refine
pseudo-masks. Moreover, our proposed framework maintains commutative operations
in all settings to ensure complete temporal consistency. Finally, we define new
metrics, evaluation dataset, and evaluation protocol for Generalizable Scene
Change Detection (GeSCD). Extensive experiments demonstrate that GeSCF excels
across diverse and challenging environments -- establishing a new benchmark for
SCD performance.",2024-09-10 04:45:25+00:00
STUN: Structured-Then-Unstructured Pruning for Scalable MoE Pruning,"Mixture-of-experts (MoEs) have been adopted for reducing inference costs by
sparsely activating experts in Large language models (LLMs). Despite this
reduction, the massive number of experts in MoEs still makes them expensive to
serve. In this paper, we study how to address this, by pruning MoEs. Among
pruning methodologies, unstructured pruning has been known to achieve the
highest performance for a given pruning ratio, compared to structured pruning,
since the latter imposes constraints on the sparsification structure. This is
intuitive, as the solution space of unstructured pruning subsumes that of
structured pruning. However, our counterintuitive finding reveals that expert
pruning, a form of structured pruning, can actually precede unstructured
pruning to outperform unstructured-only pruning. As existing expert pruning,
requiring $O(\frac{k^n}{\sqrt{n}})$ forward passes for $n$ experts, cannot
scale for recent MoEs, we propose a scalable alternative with $O(1)$
complexity, yet outperforming the more expensive methods. The key idea is
leveraging a latent structure between experts, based on behavior similarity,
such that the greedy decision of whether to prune closely captures the joint
pruning effect. Ours is highly effective -- for Snowflake Arctic, a 480B-sized
MoE with 128 experts, our method needs only one H100 and two hours to achieve
nearly no loss in performance with 40% sparsity, even in generative tasks such
as GSM8K, where state-of-the-art unstructured pruning fails to. The code will
be made publicly available.",2024-09-10 04:34:42+00:00
INTRA: Interaction Relationship-aware Weakly Supervised Affordance Grounding,"Affordance denotes the potential interactions inherent in objects. The
perception of affordance can enable intelligent agents to navigate and interact
with new environments efficiently. Weakly supervised affordance grounding
teaches agents the concept of affordance without costly pixel-level
annotations, but with exocentric images. Although recent advances in weakly
supervised affordance grounding yielded promising results, there remain
challenges including the requirement for paired exocentric and egocentric image
dataset, and the complexity in grounding diverse affordances for a single
object. To address them, we propose INTeraction Relationship-aware weakly
supervised Affordance grounding (INTRA). Unlike prior arts, INTRA recasts this
problem as representation learning to identify unique features of interactions
through contrastive learning with exocentric images only, eliminating the need
for paired datasets. Moreover, we leverage vision-language model embeddings for
performing affordance grounding flexibly with any text, designing
text-conditioned affordance map generation to reflect interaction relationship
for contrastive learning and enhancing robustness with our text synonym
augmentation. Our method outperformed prior arts on diverse datasets such as
AGD20K, IIT-AFF, CAD and UMD. Additionally, experimental results demonstrate
that our method has remarkable domain scalability for synthesized images /
illustrations and is capable of performing affordance grounding for novel
interactions and objects.",2024-09-10 04:31:51+00:00
Adaptive Transformer Modelling of Density Function for Nonparametric Survival Analysis,"Survival analysis holds a crucial role across diverse disciplines, such as
economics, engineering and healthcare. It empowers researchers to analyze both
time-invariant and time-varying data, encompassing phenomena like customer
churn, material degradation and various medical outcomes. Given the complexity
and heterogeneity of such data, recent endeavors have demonstrated successful
integration of deep learning methodologies to address limitations in
conventional statistical approaches. However, current methods typically involve
cluttered probability distribution function (PDF), have lower sensitivity in
censoring prediction, only model static datasets, or only rely on recurrent
neural networks for dynamic modelling. In this paper, we propose a novel
survival regression method capable of producing high-quality unimodal PDFs
without any prior distribution assumption, by optimizing novel
Margin-Mean-Variance loss and leveraging the flexibility of Transformer to
handle both temporal and non-temporal data, coined UniSurv. Extensive
experiments on several datasets demonstrate that UniSurv places a significantly
higher emphasis on censoring compared to other methods.",2024-09-10 04:29:59+00:00
AgileIR: Memory-Efficient Group Shifted Windows Attention for Agile Image Restoration,"Image Transformers show a magnificent success in Image Restoration tasks.
Nevertheless, most of transformer-based models are strictly bounded by
exorbitant memory occupancy. Our goal is to reduce the memory consumption of
Swin Transformer and at the same time speed up the model during training
process. Thus, we introduce AgileIR, group shifted attention mechanism along
with window attention, which sparsely simplifies the model in architecture. We
propose Group Shifted Window Attention (GSWA) to decompose Shift Window
Multi-head Self Attention (SW-MSA) and Window Multi-head Self Attention (W-MSA)
into groups across their attention heads, contributing to shrinking memory
usage in back propagation. In addition to that, we keep shifted window masking
and its shifted learnable biases during training, in order to induce the model
interacting across windows within the channel. We also re-allocate projection
parameters to accelerate attention matrix calculation, which we found a
negligible decrease in performance. As a result of experiment, compared with
our baseline SwinIR and other efficient quantization models, AgileIR keeps the
performance still at 32.20 dB on Set5 evaluation dataset, exceeding other
methods with tailor-made efficient methods and saves over 50% memory while a
large batch size is employed.",2024-09-10 04:20:59+00:00
RealisDance: Equip controllable character animation with realistic hands,"Controllable character animation is an emerging task that generates character
videos controlled by pose sequences from given character images. Although
character consistency has made significant progress via reference UNet, another
crucial factor, pose control, has not been well studied by existing methods
yet, resulting in several issues: 1) The generation may fail when the input
pose sequence is corrupted. 2) The hands generated using the DWPose sequence
are blurry and unrealistic. 3) The generated video will be shaky if the pose
sequence is not smooth enough. In this paper, we present RealisDance to handle
all the above issues. RealisDance adaptively leverages three types of poses,
avoiding failed generation caused by corrupted pose sequences. Among these pose
types, HaMeR provides accurate 3D and depth information of hands, enabling
RealisDance to generate realistic hands even for complex gestures. Besides
using temporal attention in the main UNet, RealisDance also inserts temporal
attention into the pose guidance network, smoothing the video from the pose
condition aspect. Moreover, we introduce pose shuffle augmentation during
training to further improve generation robustness and video smoothness.
Qualitative experiments demonstrate the superiority of RealisDance over other
existing methods, especially in hand quality.",2024-09-10 04:14:11+00:00
Deep kernel representations of latent space features for low-dose PET-MR imaging robust to variable dose reduction,"Low-dose positron emission tomography (PET) image reconstruction methods have
potential to significantly improve PET as an imaging modality. Deep learning
provides a promising means of incorporating prior information into the image
reconstruction problem to produce quantitatively accurate images from
compromised signal. Deep learning-based methods for low-dose PET are generally
poorly conditioned and perform unreliably on images with features not present
in the training distribution. We present a method which explicitly models deep
latent space features using a robust kernel representation, providing robust
performance on previously unseen dose reduction factors. Additional constraints
on the information content of deep latent features allow for tuning
in-distribution accuracy and generalisability. Tests with out-of-distribution
dose reduction factors ranging from $\times 10$ to $\times 1000$ and with both
paired and unpaired MR, demonstrate significantly improved performance relative
to conventional deep-learning methods trained using the same data.
Code:https://github.com/cameronPain",2024-09-10 03:57:31+00:00
"UdeerLID+: Integrating LiDAR, Image, and Relative Depth with Semi-Supervised","Road segmentation is a critical task for autonomous driving systems,
requiring accurate and robust methods to classify road surfaces from various
environmental data. Our work introduces an innovative approach that integrates
LiDAR point cloud data, visual image, and relative depth maps derived from
images. The integration of multiple data sources in road segmentation presents
both opportunities and challenges. One of the primary challenges is the
scarcity of large-scale, accurately labeled datasets that are necessary for
training robust deep learning models. To address this, we have developed the
[UdeerLID+] framework under a semi-supervised learning paradigm. Experiments
results on KITTI datasets validate the superior performance.",2024-09-10 03:57:30+00:00
MTDA-HSED: Mutual-Assistance Tuning and Dual-Branch Aggregating for Heterogeneous Sound Event Detection,"Sound Event Detection (SED) plays a vital role in comprehending and
perceiving acoustic scenes. Previous methods have demonstrated impressive
capabilities. However, they are deficient in learning features of complex
scenes from heterogeneous dataset. In this paper, we introduce a novel
dual-branch architecture named Mutual-Assistance Tuning and Dual-Branch
Aggregating for Heterogeneous Sound Event Detection (MTDA-HSED). The MTDA-HSED
architecture employs the Mutual-Assistance Audio Adapter (M3A) to effectively
tackle the multi-scenario problem and uses the Dual-Branch Mid-Fusion (DBMF)
module to tackle the multi-granularity problem. Specifically, M3A is integrated
into the BEATs block as an adapter to improve the BEATs' performance by
fine-tuning it on the multi-scenario dataset. The DBMF module connects BEATs
and CNN branches, which facilitates the deep fusion of information from the
BEATs and the CNN branches. Experimental results show that the proposed methods
exceed the baseline of mpAUC by \textbf{$5\%$} on the DESED and MAESTRO Real
datasets. Code is available at https://github.com/Visitor-W/MTDA.",2024-09-10 03:57:21+00:00
NOVI : Chatbot System for University Novice with BERT and LLMs,"To mitigate the difficulties of university freshmen in adapting to university
life, we developed NOVI, a chatbot system based on GPT-4o. This system utilizes
post and comment data from SKKU 'Everytime', a university community site.
Developed using LangChain, NOVI's performance has been evaluated with a BLEU
score, Perplexity score, ROUGE-1 score, ROUGE-2 score, ROUGE-L score and METEOR
score. This approach is not only limited to help university freshmen but is
also expected to help various people adapting to new environments with
different data. This research explores the development and potential
application of new educational technology tools, contributing to easier social
adaptation for beginners and settling a foundation for future advancement in
LLM studies.",2024-09-10 03:43:26+00:00
Multi-Source Music Generation with Latent Diffusion,"Most music generation models directly generate a single music mixture. To
allow for more flexible and controllable generation, the Multi-Source Diffusion
Model (MSDM) has been proposed to model music as a mixture of multiple
instrumental sources (e.g. piano, drums, bass, and guitar). Its goal is to use
one single diffusion model to generate mutually-coherent music sources, that
are then mixed to form the music. Despite its capabilities, MSDM is unable to
generate music with rich melodies and often generates empty sounds. Its
waveform diffusion approach also introduces significant Gaussian noise
artifacts that compromise audio quality. In response, we introduce a
Multi-Source Latent Diffusion Model (MSLDM) that employs Variational
Autoencoders (VAEs) to encode each instrumental source into a distinct latent
representation. By training a VAE on all music sources, we efficiently capture
each source's unique characteristics in a ""source latent."" The source latents
are concatenated and our diffusion model learns this joint latent space. This
approach significantly enhances the total and partial generation of music by
leveraging the VAE's latent compression and noise-robustness. The compressed
source latent also facilitates more efficient generation. Subjective listening
tests and Frechet Audio Distance (FAD) scores confirm that our model
outperforms MSDM, showcasing its practical and enhanced applicability in music
generation systems. We also emphasize that modeling sources is more effective
than direct music mixture modeling. Codes and models are available at
https://github.com/XZWY/MSLDM. Demos are available at
https://xzwy.github.io/MSLDMDemo/.",2024-09-10 03:41:10+00:00
MyGo: Consistent and Controllable Multi-View Driving Video Generation with Camera Control,"High-quality driving video generation is crucial for providing training data
for autonomous driving models. However, current generative models rarely focus
on enhancing camera motion control under multi-view tasks, which is essential
for driving video generation. Therefore, we propose MyGo, an end-to-end
framework for video generation, introducing motion of onboard cameras as
conditions to make progress in camera controllability and multi-view
consistency. MyGo employs additional plug-in modules to inject camera
parameters into the pre-trained video diffusion model, which retains the
extensive knowledge of the pre-trained model as much as possible. Furthermore,
we use epipolar constraints and neighbor view information during the generation
process of each view to enhance spatial-temporal consistency. Experimental
results show that MyGo has achieved state-of-the-art results in both general
camera-controlled video generation and multi-view driving video generation
tasks, which lays the foundation for more accurate environment simulation in
autonomous driving. Project page:
https://metadrivescape.github.io/papers_project/MyGo/page.html",2024-09-10 03:39:08+00:00
Bottleneck-based Encoder-decoder ARchitecture (BEAR) for Learning Unbiased Consumer-to-Consumer Image Representations,"Unbiased representation learning is still an object of study under specific
applications and contexts. Novel architectures are usually crafted to resolve
particular problems using mixtures of fundamental pieces. This paper presents
different image feature extraction mechanisms that work together with residual
connections to encode perceptual image information in an autoencoder
configuration. We use image data that aims to support a larger research agenda
dealing with issues regarding criminal activity in consumer-to-consumer online
platforms. Preliminary results suggest that the proposed architecture can learn
rich spaces using ours and other image datasets resolving important challenges
that are identified.",2024-09-10 03:31:18+00:00
Can Large Language Models Unlock Novel Scientific Research Ideas?,"""An idea is nothing more nor less than a new combination of old elements""
(Young, J.W.). The widespread adoption of Large Language Models (LLMs) and
publicly available ChatGPT have marked a significant turning point in the
integration of Artificial Intelligence (AI) into people's everyday lives. This
study explores the capability of LLMs in generating novel research ideas based
on information from research papers. We conduct a thorough examination of 4
LLMs in five domains (e.g., Chemistry, Computer, Economics, Medical, and
Physics). We found that the future research ideas generated by Claude-2 and
GPT-4 are more aligned with the author's perspective than GPT-3.5 and Gemini.
We also found that Claude-2 generates more diverse future research ideas than
GPT-4, GPT-3.5, and Gemini 1.0. We further performed a human evaluation of the
novelty, relevancy, and feasibility of the generated future research ideas.
This investigation offers insights into the evolving role of LLMs in idea
generation, highlighting both its capability and limitations. Our work
contributes to the ongoing efforts in evaluating and utilizing language models
for generating future research ideas. We make our datasets and codes publicly
available.",2024-09-10 03:26:42+00:00
EDADepth: Enhanced Data Augmentation for Monocular Depth Estimation,"Due to their text-to-image synthesis feature, diffusion models have recently
seen a rise in visual perception tasks, such as depth estimation. The lack of
good-quality datasets makes the extraction of a fine-grain semantic context
challenging for the diffusion models. The semantic context with fewer details
further worsens the process of creating effective text embeddings that will be
used as input for diffusion models. In this paper, we propose a novel EDADepth,
an enhanced data augmentation method to estimate monocular depth without using
additional training data. We use Swin2SR, a super-resolution model, to enhance
the quality of input images. We employ the BEiT pre-trained semantic
segmentation model for better extraction of text embeddings. We introduce
BLIP-2 tokenizer to generate tokens from these text embeddings. The novelty of
our approach is the introduction of Swin2SR, the BEiT model, and the BLIP-2
tokenizer in the diffusion-based pipeline for the monocular depth estimation.
Our model achieves state-of-the-art results (SOTA) on the {\delta}3 metric on
NYUv2 and KITTI datasets. It also achieves results comparable to those of the
SOTA models in the RMSE and REL metrics. Finally, we also show improvements in
the visualization of the estimated depth compared to the SOTA diffusion-based
monocular depth estimation models. Code:
https://github.com/edadepthmde/EDADepth_ICMLA.",2024-09-10 03:25:24+00:00
Larger Language Models Don't Care How You Think: Why Chain-of-Thought Prompting Fails in Subjective Tasks,"In-Context Learning (ICL) in Large Language Models (LLM) has emerged as the
dominant technique for performing natural language tasks, as it does not
require updating the model parameters with gradient-based methods. ICL promises
to ""adapt"" the LLM to perform the present task at a competitive or
state-of-the-art level at a fraction of the computational cost. ICL can be
augmented by incorporating the reasoning process to arrive at the final label
explicitly in the prompt, a technique called Chain-of-Thought (CoT) prompting.
However, recent work has found that ICL relies mostly on the retrieval of task
priors and less so on ""learning"" to perform tasks, especially for complex
subjective domains like emotion and morality, where priors ossify posterior
predictions. In this work, we examine whether ""enabling"" reasoning also creates
the same behavior in LLMs, wherein the format of CoT retrieves reasoning priors
that remain relatively unchanged despite the evidence in the prompt. We find
that, surprisingly, CoT indeed suffers from the same posterior collapse as ICL
for larger language models. Code is avalaible at
https://github.com/gchochla/cot-priors.",2024-09-10 03:06:17+00:00
Loss Distillation via Gradient Matching for Point Cloud Completion with Weighted Chamfer Distance,"3D point clouds enhanced the robot's ability to perceive the geometrical
information of the environments, making it possible for many downstream tasks
such as grasp pose detection and scene understanding. The performance of these
tasks, though, heavily relies on the quality of data input, as incomplete can
lead to poor results and failure cases. Recent training loss functions designed
for deep learning-based point cloud completion, such as Chamfer distance (CD)
and its variants (\eg HyperCD ), imply a good gradient weighting scheme can
significantly boost performance. However, these CD-based loss functions usually
require data-related parameter tuning, which can be time-consuming for
data-extensive tasks. To address this issue, we aim to find a family of
weighted training losses ({\em weighted CD}) that requires no parameter tuning.
To this end, we propose a search scheme, {\em Loss Distillation via Gradient
Matching}, to find good candidate loss functions by mimicking the learning
behavior in backpropagation between HyperCD and weighted CD. Once this is done,
we propose a novel bilevel optimization formula to train the backbone network
based on the weighted CD loss. We observe that: (1) with proper weighted
functions, the weighted CD can always achieve similar performance to HyperCD,
and (2) the Landau weighted CD, namely {\em Landau CD}, can outperform HyperCD
for point cloud completion and lead to new state-of-the-art results on several
benchmark datasets. {\it Our demo code is available at
\url{https://github.com/Zhang-VISLab/IROS2024-LossDistillationWeightedCD}.}",2024-09-10 03:02:39+00:00
VE: Modeling Multivariate Time Series Correlation with Variate Embedding,"Multivariate time series forecasting relies on accurately capturing the
correlations among variates. Current channel-independent (CI) models and models
with a CI final projection layer are unable to capture these dependencies. In
this paper, we present the variate embedding (VE) pipeline, which learns a
unique and consistent embedding for each variate and combines it with Mixture
of Experts (MoE) and Low-Rank Adaptation (LoRA) techniques to enhance
forecasting performance while controlling parameter size. The VE pipeline can
be integrated into any model with a CI final projection layer to improve
multivariate forecasting. The learned VE effectively groups variates with
similar temporal patterns and separates those with low correlations. The
effectiveness of the VE pipeline is demonstrated through extensive experiments
on four widely-used datasets. The code is available at:
\url{https://github.com/swang-song/VE}.",2024-09-10 02:49:30+00:00
Generative AI for Requirements Engineering: A Systematic Literature Review,"Context: Generative AI (GenAI) has emerged as a transformative tool in
software engineering, with requirements engineering (RE) actively exploring its
potential to revolutionize processes and outcomes. The integration of GenAI
into RE presents both promising opportunities and significant challenges that
necessitate systematic analysis and evaluation. Objective: This paper presents
a comprehensive systematic literature review (SLR) analyzing state-of-the-art
applications and innovative proposals leveraging GenAI in RE. It surveys
studies focusing on the utilization of GenAI to enhance RE processes while
identifying key challenges and opportunities in this rapidly evolving field.
Method: A rigorous SLR methodology was used to analyze 27 carefully selected
primary studies in-depth. The review examined research questions pertaining to
the application of GenAI across various RE phases, the models and techniques
used, and the challenges encountered in implementation and adoption. Results:
The most salient findings include i) a predominant focus on the early stages of
RE, particularly the elicitation and analysis of requirements, indicating
potential for expansion into later phases; ii) the dominance of large language
models, especially the GPT series, highlighting the need for diverse AI
approaches; and iii) persistent challenges in domain-specific applications and
the interpretability of AI-generated outputs, underscoring areas requiring
further research and development. Conclusions: The results highlight the
critical need for comprehensive evaluation frameworks, improved human-AI
collaboration models, and thorough consideration of ethical implications in
GenAI-assisted RE. Future research should prioritize extending GenAI
applications across the entire RE lifecycle, enhancing domain-specific
capabilities, and developing strategies for responsible AI integration in RE
practices.",2024-09-10 02:44:39+00:00
Revisiting Prompt Pretraining of Vision-Language Models,"Prompt learning is an effective method to customize Vision-Language Models
(VLMs) for various downstream tasks, involving tuning very few parameters of
input prompt tokens. Recently, prompt pretraining in large-scale dataset (e.g.,
ImageNet-21K) has played a crucial role in prompt learning for universal visual
discrimination. However, we revisit and observe that the limited learnable
prompts could face underfitting risks given the extensive images during prompt
pretraining, simultaneously leading to poor generalization. To address the
above issues, in this paper, we propose a general framework termed Revisiting
Prompt Pretraining (RPP), which targets at improving the fitting and
generalization ability from two aspects: prompt structure and prompt
supervision. For prompt structure, we break the restriction in common practice
where query, key, and value vectors are derived from the shared learnable
prompt token. Instead, we introduce unshared individual query, key, and value
learnable prompts, thereby enhancing the model's fitting capacity through
increased parameter diversity. For prompt supervision, we additionally utilize
soft labels derived from zero-shot probability predictions provided by a
pretrained Contrastive Language Image Pretraining (CLIP) teacher model. These
soft labels yield more nuanced and general insights into the inter-class
relationships, thereby endowing the pretraining process with better
generalization ability. RPP produces a more resilient prompt initialization,
enhancing its robust transferability across diverse visual recognition tasks.
Experiments across various benchmarks consistently confirm the state-of-the-art
(SOTA) performance of our pretrained prompts. Codes and models will be made
available soon.",2024-09-10 02:36:13+00:00
MCDGLN: Masked Connection-based Dynamic Graph Learning Network for Autism Spectrum Disorder,"Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized
by complex physiological processes. Previous research has predominantly focused
on static cerebral interactions, often neglecting the brain's dynamic nature
and the challenges posed by network noise. To address these gaps, we introduce
the Masked Connection-based Dynamic Graph Learning Network (MCDGLN). Our
approach first segments BOLD signals using sliding temporal windows to capture
dynamic brain characteristics. We then employ a specialized weighted edge
aggregation (WEA) module, which uses the cross convolution with channel-wise
element-wise convolutional kernel, to integrate dynamic functional connectivity
and to isolating task-relevant connections. This is followed by topological
feature extraction via a hierarchical graph convolutional network (HGCN), with
key attributes highlighted by a self-attention module. Crucially, we refine
static functional connections using a customized task-specific mask, reducing
noise and pruning irrelevant links. The attention-based connection encoder
(ACE) then enhances critical connections and compresses static features. The
combined features are subsequently used for classification. Applied to the
Autism Brain Imaging Data Exchange I (ABIDE I) dataset, our framework achieves
a 73.3\% classification accuracy between ASD and Typical Control (TC) groups
among 1,035 subjects. The pivotal roles of WEA and ACE in refining connectivity
and enhancing classification accuracy underscore their importance in capturing
ASD-specific features, offering new insights into the disorder.",2024-09-10 02:21:29+00:00
Data-efficient and Interpretable Inverse Materials Design using a Disentangled Variational Autoencoder,"Inverse materials design has proven successful in accelerating novel material
discovery. Many inverse materials design methods use unsupervised learning
where a latent space is learned to offer a compact description of materials
representations. A latent space learned this way is likely to be entangled, in
terms of the target property and other properties of the materials. This makes
the inverse design process ambiguous. Here, we present a semi-supervised
learning approach based on a disentangled variational autoencoder to learn a
probabilistic relationship between features, latent variables and target
properties. This approach is data efficient because it combines all labelled
and unlabelled data in a coherent manner, and it uses expert-informed prior
distributions to improve model robustness even with limited labelled data. It
is in essence interpretable, as the learnable target property is disentangled
out of the other properties of the materials, and an extra layer of
interpretability can be provided by a post-hoc analysis of the classification
head of the model. We demonstrate this new approach on an experimental
high-entropy alloy dataset with chemical compositions as input and single-phase
formation as the single target property. While single property is used in this
work, the disentangled model can be extended to customize for inverse design of
materials with multiple target properties.",2024-09-10 02:21:13+00:00
Causal Analysis of Shapley Values: Conditional vs. Marginal,"Shapley values, a game theoretic concept, has been one of the most popular
tools for explaining Machine Learning (ML) models in recent years.
Unfortunately, the two most common approaches, conditional and marginal, to
calculating Shapley values can lead to different results along with some
undesirable side effects when features are correlated. This in turn has led to
the situation in the literature where contradictory recommendations regarding
choice of an approach are provided by different authors. In this paper we aim
to resolve this controversy through the use of causal arguments. We show that
the differences arise from the implicit assumptions that are made within each
method to deal with missing causal information. We also demonstrate that the
conditional approach is fundamentally unsound from a causal perspective. This,
together with previous work in [1], leads to the conclusion that the marginal
approach should be preferred over the conditional one.",2024-09-10 02:07:39+00:00
UniLearn: Enhancing Dynamic Facial Expression Recognition through Unified Pre-Training and Fine-Tuning on Images and Videos,"Dynamic facial expression recognition (DFER) is essential for understanding
human emotions and behavior. However, conventional DFER methods, which
primarily use dynamic facial data, often underutilize static expression images
and their labels, limiting their performance and robustness. To overcome this,
we introduce UniLearn, a novel unified learning paradigm that integrates static
facial expression recognition (SFER) data to enhance DFER task. UniLearn
employs a dual-modal self-supervised pre-training method, leveraging both
facial expression images and videos to enhance a ViT model's spatiotemporal
representation capability. Then, the pre-trained model is fine-tuned on both
static and dynamic expression datasets using a joint fine-tuning strategy. To
prevent negative transfer during joint fine-tuning, we introduce an innovative
Mixture of Adapter Experts (MoAE) module that enables task-specific knowledge
acquisition and effectively integrates information from both static and dynamic
expression data. Extensive experiments demonstrate UniLearn's effectiveness in
leveraging complementary information from static and dynamic facial data,
leading to more accurate and robust DFER. UniLearn consistently achieves
state-of-the-art performance on FERV39K, MAFW, and DFEW benchmarks, with
weighted average recall (WAR) of 53.65\%, 58.44\%, and 76.68\%, respectively.
The source code and model weights will be publicly available at
\url{https://github.com/MSA-LMC/UniLearn}.",2024-09-10 01:57:57+00:00
Multiclass Arrhythmia Classification using Smartwatch Photoplethysmography Signals Collected in Real-life Settings,"Most deep learning models of multiclass arrhythmia classification are tested
on fingertip photoplethysmographic (PPG) data, which has higher signal-to-noise
ratios compared to smartwatch-derived PPG, and the best reported sensitivity
value for premature atrial/ventricular contraction (PAC/PVC) detection is only
75%. To improve upon PAC/PVC detection sensitivity while maintaining high AF
detection, we use multi-modal data which incorporates 1D PPG, accelerometers,
and heart rate data as the inputs to a computationally efficient 1D
bi-directional Gated Recurrent Unit (1D-Bi-GRU) model to detect three
arrhythmia classes. We used motion-artifact prone smartwatch PPG data from the
NIH-funded Pulsewatch clinical trial. Our multimodal model tested on 72
subjects achieved an unprecedented 83% sensitivity for PAC/PVC detection while
maintaining a high accuracy of 97.31% for AF detection. These results
outperformed the best state-of-the-art model by 20.81% for PAC/PVC and 2.55%
for AF detection even while our model was computationally more efficient (14
times lighter and 2.7 faster).",2024-09-10 01:44:56+00:00
Configuration Interaction Guided Sampling with Interpretable Restricted Boltzmann Machine,"We propose a data-driven approach using a Restricted Boltzmann Machine (RBM)
to solve the Schr\""odinger equation in configuration space. Traditional
Configuration Interaction (CI) methods, while powerful, are computationally
expensive due to the large number of determinants required. Our approach
leverages RBMs to efficiently identify and sample the most significant
determinants, accelerating convergence and reducing computational cost. This
method achieves up to 99.99\% of the correlation energy even by four orders of
magnitude less determinants compared to full CI calculations and up to two
orders of magnitude less than previous state of the art works. Additionally,
our study demonstrate that the RBM can learn the underlying quantum properties,
providing more detail insights than other methods . This innovative data-driven
approach offers a promising tool for quantum chemistry, enhancing both
efficiency and understanding of complex systems.",2024-09-10 01:42:10+00:00
Variational Search Distributions,"We develop variational search distributions (VSD), a method for finding
discrete, combinatorial designs of a rare desired class in a batch sequential
manner with a fixed experimental budget. We formalize the requirements and
desiderata for this problem and formulate a solution via variational inference
that fulfill these. In particular, VSD uses off-the-shelf gradient based
optimization routines, and can take advantage of scalable predictive models. We
show that VSD can outperform existing baseline methods on a set of real
sequence-design problems in various biological systems.",2024-09-10 01:33:31+00:00
Draw an Audio: Leveraging Multi-Instruction for Video-to-Audio Synthesis,"Foley is a term commonly used in filmmaking, referring to the addition of
daily sound effects to silent films or videos to enhance the auditory
experience. Video-to-Audio (V2A), as a particular type of automatic foley task,
presents inherent challenges related to audio-visual synchronization. These
challenges encompass maintaining the content consistency between the input
video and the generated audio, as well as the alignment of temporal and
loudness properties within the video. To address these issues, we construct a
controllable video-to-audio synthesis model, termed Draw an Audio, which
supports multiple input instructions through drawn masks and loudness signals.
To ensure content consistency between the synthesized audio and target video,
we introduce the Mask-Attention Module (MAM), which employs masked video
instruction to enable the model to focus on regions of interest. Additionally,
we implement the Time-Loudness Module (TLM), which uses an auxiliary loudness
signal to ensure the synthesis of sound that aligns with the video in both
loudness and temporal dimensions. Furthermore, we have extended a large-scale
V2A dataset, named VGGSound-Caption, by annotating caption prompts. Extensive
experiments on challenging benchmarks across two large-scale V2A datasets
verify Draw an Audio achieves the state-of-the-art. Project page:
https://yannqi.github.io/Draw-an-Audio/.",2024-09-10 01:07:20+00:00
"Accelerating Large Language Model Pretraining via LFR Pedagogy: Learn, Focus, and Review","Large Language Model (LLM) pretraining traditionally relies on autoregressive
language modeling on randomly sampled data blocks from web-scale datasets. We
take inspiration from human learning techniques like spaced repetition to
hypothesize that random data sampling for LLMs leads to high training cost and
low quality models which tend to forget data. In order to effectively commit
web-scale information to long-term memory, we propose the LFR (Learn, Focus,
and Review) pedagogy, a new dynamic training paradigm which focuses and
repeatedly reviews complex data blocks at systematic intervals based on the
model's learning pace and progress. LFR records the model perplexities for
different data blocks and frequently revisits blocks with higher perplexity
which are more likely to be forgotten. We pretrain the GPT-2 models (124M -
1.5B) from scratch on the OpenWebText dataset using LFR. We test on downstream
tasks from the language modeling, question answering, translation, and problem
solving domains to achieve consistently lower perplexity and higher accuracy
than the baseline OpenAI models, while obtaining a 20x pretraining speed-up.",2024-09-10 00:59:18+00:00
On the Weaknesses of Backdoor-based Model Watermarking: An Information-theoretic Perspective,"Safeguarding the intellectual property of machine learning models has emerged
as a pressing concern in AI security. Model watermarking is a powerful
technique for protecting ownership of machine learning models, yet its
reliability has been recently challenged by recent watermark removal attacks.
In this work, we investigate why existing watermark embedding techniques
particularly those based on backdooring are vulnerable. Through an
information-theoretic analysis, we show that the resilience of watermarking
against erasure attacks hinges on the choice of trigger-set samples, where
current uses of out-distribution trigger-set are inherently vulnerable to
white-box adversaries. Based on this discovery, we propose a novel model
watermarking scheme, In-distribution Watermark Embedding (IWE), to overcome the
limitations of existing method. To further minimise the gap to clean models, we
analyze the role of logits as watermark information carriers and propose a new
approach to better conceal watermark information within the logits. Experiments
on real-world datasets including CIFAR-100 and Caltech-101 demonstrate that our
method robustly defends against various adversaries with negligible accuracy
loss (< 0.1%).",2024-09-10 00:55:21+00:00
"DECOLLAGE: 3D Detailization by Controllable, Localized, and Learned Geometry Enhancement","We present a 3D modeling method which enables end-users to refine or
detailize 3D shapes using machine learning, expanding the capabilities of
AI-assisted 3D content creation. Given a coarse voxel shape (e.g., one produced
with a simple box extrusion tool or via generative modeling), a user can
directly ""paint"" desired target styles representing compelling geometric
details, from input exemplar shapes, over different regions of the coarse
shape. These regions are then up-sampled into high-resolution geometries which
adhere with the painted styles. To achieve such controllable and localized 3D
detailization, we build on top of a Pyramid GAN by making it masking-aware. We
devise novel structural losses and priors to ensure that our method preserves
both desired coarse structures and fine-grained features even if the painted
styles are borrowed from diverse sources, e.g., different semantic parts and
even different shape categories. Through extensive experiments, we show that
our ability to localize details enables novel interactive creative workflows
and applications. Our experiments further demonstrate that in comparison to
prior techniques built on global detailization, our method generates
structure-preserving, high-resolution stylized geometries with more coherent
shape details and style transitions.",2024-09-10 00:51:49+00:00
Contrastive Federated Learning with Tabular Data Silos,"Learning from data silos is a difficult task for organizations that need to
obtain knowledge of objects that appeared in multiple independent data silos.
Objects in multi-organizations, such as government agents, are referred by
different identifiers, such as driver license, passport number, and tax file
number. The data distributions in data silos are mostly non-IID (Independently
and Identically Distributed), labelless, and vertically partitioned (i.e.,
having different attributes). Privacy concerns harden the above issues.
Conditions inhibit enthusiasm for collaborative work. While Federated Learning
(FL) has been proposed to address these issues, the difficulty of labeling,
namely, label costliness, often hinders optimal model performance. A potential
solution lies in contrastive learning, an unsupervised self-learning technique
to represent semantic data by contrasting similar data pairs. However,
contrastive learning is currently not designed to handle tabular data silos
that existed within multiple organizations where data linkage by quasi
identifiers are needed. To address these challenges, we propose using
semi-supervised contrastive federated learning, which we refer to as
Contrastive Federated Learning with Data Silos (CFL). Our approach tackles the
aforementioned issues with an integrated solution. Our experimental results
demonstrate that CFL outperforms current methods in addressing these challenges
and providing improvements in accuracy. Additionally, we present positive
results that showcase the advantages of our contrastive federated learning
approach in complex client environments.",2024-09-10 00:24:59+00:00
Case Study: Leveraging GenAI to Build AI-based Surrogates and Regressors for Modeling Radio Frequency Heating in Fusion Energy Science,"This work presents a detailed case study on using Generative AI (GenAI) to
develop AI surrogates for simulation models in fusion energy research. The
scope includes the methodology, implementation, and results of using GenAI to
assist in model development and optimization, comparing these results with
previous manually developed models.",2024-09-10 00:22:19+00:00
PaRCE: Probabilistic and Reconstruction-Based Competency Estimation for Safe Navigation Under Perception Uncertainty,"Perception-based navigation systems are useful for unmanned ground vehicle
(UGV) navigation in complex terrains, where traditional depth-based navigation
schemes are insufficient. However, these data-driven methods are highly
dependent on their training data and can fail in surprising and dramatic ways
with little warning. To ensure the safety of the vehicle and the surrounding
environment, it is imperative that the navigation system is able to recognize
the predictive uncertainty of the perception model and respond safely and
effectively in the face of uncertainty. In an effort to enable safe navigation
under perception uncertainty, we develop a probabilistic and
reconstruction-based competency estimation (PaRCE) method to estimate the
model's level of familiarity with an input image as a whole and with specific
regions in the image. We find that the overall competency score can correctly
predict correctly classified, misclassified, and out-of-distribution (OOD)
samples. We also confirm that the regional competency maps can accurately
distinguish between familiar and unfamiliar regions across images. We then use
this competency information to develop a planning and control scheme that
enables effective navigation while maintaining a low probability of error. We
find that the competency-aware scheme greatly reduces the number of collisions
with unfamiliar obstacles, compared to a baseline controller with no competency
awareness. Furthermore, the regional competency information is very valuable in
enabling efficient navigation.",2024-09-09 23:34:24+00:00
Doppelgänger's Watch: A Split Objective Approach to Large Language Models,"In this paper, we investigate the problem of ""generation supervision"" in
large language models, and present a novel bicameral architecture to separate
supervision signals from their core capability, helpfulness. Doppelg\""anger, a
new module parallel to the underlying language model, supervises the generation
of each token, and learns to concurrently predict the supervision score(s) of
the sequences up to and including each token. In this work, we present the
theoretical findings, and leave the report on experimental results to a
forthcoming publication.",2024-09-09 23:22:27+00:00
SGC-VQGAN: Towards Complex Scene Representation via Semantic Guided Clustering Codebook,"Vector quantization (VQ) is a method for deterministically learning features
through discrete codebook representations. Recent works have utilized visual
tokenizers to discretize visual regions for self-supervised representation
learning. However, a notable limitation of these tokenizers is lack of
semantics, as they are derived solely from the pretext task of reconstructing
raw image pixels in an auto-encoder paradigm. Additionally, issues like
imbalanced codebook distribution and codebook collapse can adversely impact
performance due to inefficient codebook utilization. To address these
challenges, We introduce SGC-VQGAN through Semantic Online Clustering method to
enhance token semantics through Consistent Semantic Learning. Utilizing
inference results from segmentation model , our approach constructs a
temporospatially consistent semantic codebook, addressing issues of codebook
collapse and imbalanced token semantics. Our proposed Pyramid Feature Learning
pipeline integrates multi-level features to capture both image details and
semantics simultaneously. As a result, SGC-VQGAN achieves SOTA performance in
both reconstruction quality and various downstream tasks. Its simplicity,
requiring no additional parameter learning, enables its direct application in
downstream tasks, presenting significant potential.",2024-09-09 23:12:43+00:00
LSE-NeRF: Learning Sensor Modeling Errors for Deblured Neural Radiance Fields with RGB-Event Stereo,"We present a method for reconstructing a clear Neural Radiance Field (NeRF)
even with fast camera motions. To address blur artifacts, we leverage both
(blurry) RGB images and event camera data captured in a binocular
configuration. Importantly, when reconstructing our clear NeRF, we consider the
camera modeling imperfections that arise from the simple pinhole camera model
as learned embeddings for each camera measurement, and further learn a mapper
that connects event camera measurements with RGB data. As no previous dataset
exists for our binocular setting, we introduce an event camera dataset with
captures from a 3D-printed stereo configuration between RGB and event cameras.
Empirically, we evaluate our introduced dataset and EVIMOv2 and show that our
method leads to improved reconstructions. Our code and dataset are available at
https://github.com/ubc-vision/LSENeRF.",2024-09-09 23:11:46+00:00
Bridging Autoencoders and Dynamic Mode Decomposition for Reduced-order Modeling and Control of PDEs,"Modeling and controlling complex spatiotemporal dynamical systems driven by
partial differential equations (PDEs) often necessitate dimensionality
reduction techniques to construct lower-order models for computational
efficiency. This paper explores a deep autoencoding learning method for
reduced-order modeling and control of dynamical systems governed by
spatiotemporal PDEs. We first analytically show that an optimization objective
for learning a linear autoencoding reduced-order model can be formulated to
yield a solution closely resembling the result obtained through the dynamic
mode decomposition with control algorithm. We then extend this linear
autoencoding architecture to a deep autoencoding framework, enabling the
development of a nonlinear reduced-order model. Furthermore, we leverage the
learned reduced-order model to design controllers using stability-constrained
deep neural networks. Numerical experiments are presented to validate the
efficacy of our approach in both modeling and control using the example of a
reaction-diffusion system.",2024-09-09 22:56:40+00:00
Latent Diffusion Bridges for Unsupervised Musical Audio Timbre Transfer,"Music timbre transfer is a challenging task that involves modifying the
timbral characteristics of an audio signal while preserving its melodic
structure. In this paper, we propose a novel method based on dual diffusion
bridges, trained using the CocoChorales Dataset, which consists of unpaired
monophonic single-instrument audio data. Each diffusion model is trained on a
specific instrument with a Gaussian prior. During inference, a model is
designated as the source model to map the input audio to its corresponding
Gaussian prior, and another model is designated as the target model to
reconstruct the target audio from this Gaussian prior, thereby facilitating
timbre transfer. We compare our approach against existing unsupervised timbre
transfer models such as VAEGAN and Gaussian Flow Bridges (GFB). Experimental
results demonstrate that our method achieves both better Fr\'echet Audio
Distance (FAD) and melody preservation, as reflected by lower pitch distances
(DPD) compared to VAEGAN and GFB. Additionally, we discover that the noise
level from the Gaussian prior, $\sigma$, can be adjusted to control the degree
of melody preservation and amount of timbre transferred.",2024-09-09 22:16:48+00:00
Scalable Multitask Learning Using Gradient-based Estimation of Task Affinity,"Multitask learning is a widely used paradigm for training models on diverse
tasks, with applications ranging from graph neural networks to language model
fine-tuning. Since tasks may interfere with each other, a key notion for
modeling their relationships is task affinity. This includes pairwise task
affinity, computed among pairs of tasks, and higher-order affinity, computed
among subsets of tasks. Naively computing either of them requires repeatedly
training on data from various task combinations, which is computationally
intensive. We present a new algorithm Grad-TAG that can estimate task
affinities without this repeated training.
  The key idea of Grad-TAG is to train a ""base"" model for all tasks and then
use a linearization technique to estimate the loss of the model for a specific
task combination. The linearization works by computing a gradient-based
approximation of the loss, using low-dimensional projections of gradients as
features in a logistic regression to predict labels for the task combination.
We show that the linearized model can provably approximate the loss when the
gradient-based approximation is accurate, and also empirically verify that on
several large models. Then, given the estimated task affinity, we design a
semi-definite program for clustering similar tasks by maximizing the average
density of clusters.
  We evaluate Grad-TAG's performance across seven datasets, including
multi-label classification on graphs, and instruction fine-tuning of language
models. Our task affinity estimates are within 2.7% distance to the true
affinities while needing only 3% of FLOPs in full training. On our largest
graph with 21M edges and 500 labeling tasks, our algorithm delivers estimates
within 5% distance to the true affinities, using only 112 GPU hours. Our
results show that Grad-TAG achieves excellent performance and runtime tradeoffs
compared to existing approaches.",2024-09-09 21:59:27+00:00
Differentiable programming across the PDE and Machine Learning barrier,"The combination of machine learning and physical laws has shown immense
potential for solving scientific problems driven by partial differential
equations (PDEs) with the promise of fast inference, zero-shot generalisation,
and the ability to discover new physics. Examples include the use of
fundamental physical laws as inductive bias to machine learning algorithms,
also referred to as physics-driven machine learning, and the application of
machine learning to represent features not represented in the differential
equations such as closures for unresolved spatiotemporal scales. However, the
simulation of complex physical systems by coupling advanced numerics for PDEs
with state-of-the-art machine learning demands the composition of specialist
PDE solving frameworks with industry-standard machine learning tools.
Hand-rolling either the PDE solver or the neural net will not cut it. In this
work, we introduce a generic differentiable programming abstraction that
provides scientists and engineers with a highly productive way of specifying
end-to-end differentiable models coupling machine learning and PDE-based
components, while relying on code generation for high performance. Our
interface automates the coupling of arbitrary PDE-based systems and machine
learning models and unlocks new applications that could not hitherto be
tackled, while only requiring trivial changes to existing code. Our framework
has been adopted in the Firedrake finite-element library and supports the
PyTorch and JAX ecosystems, as well as downstream libraries.",2024-09-09 21:36:38+00:00
Symmetry constrained neural networks for detection and localization of damage in metal plates,"The present paper is concerned with deep learning techniques applied to
detection and localization of damage in a thin aluminum plate. We used data
generated on a tabletop apparatus by mounting to the plate four piezoelectric
transducers, each of which took turn to generate a Lamb wave that then
traversed the region of interest before being received by the remaining three
sensors. On training a neural network to analyze time-series data of the
material response, which displayed damage-reflective features whenever the
plate guided waves interacted with a contact load, we achieved a model that
detected with greater than 99% accuracy in addition to a model that localized
with $3.14 \pm 0.21$ mm mean distance error and captured more than 60% of test
examples within the diffraction limit. For each task, the best-performing model
was designed according to the inductive bias that our transducers were both
similar and arranged in a square pattern on a nearly uniform plate.",2024-09-09 21:36:08+00:00
Regression with Large Language Models for Materials and Molecular Property Prediction,"We demonstrate the ability of large language models (LLMs) to perform
material and molecular property regression tasks, a significant deviation from
the conventional LLM use case. We benchmark the Large Language Model Meta AI
(LLaMA) 3 on several molecular properties in the QM9 dataset and 24 materials
properties. Only composition-based input strings are used as the model input
and we fine tune on only the generative loss. We broadly find that LLaMA 3,
when fine-tuned using the SMILES representation of molecules, provides useful
regression results which can rival standard materials property prediction
models like random forest or fully connected neural networks on the QM9
dataset. Not surprisingly, LLaMA 3 errors are 5-10x higher than those of the
state-of-the-art models that were trained using far more granular
representation of molecules (e.g., atom types and their coordinates) for the
same task. Interestingly, LLaMA 3 provides improved predictions compared to
GPT-3.5 and GPT-4o. This work highlights the versatility of LLMs, suggesting
that LLM-like generative models can potentially transcend their traditional
applications to tackle complex physical phenomena, thus paving the way for
future research and applications in chemistry, materials science and other
scientific domains.",2024-09-09 21:26:32+00:00
MTLSO: A Multi-Task Learning Approach for Logic Synthesis Optimization,"Electronic Design Automation (EDA) is essential for IC design and has
recently benefited from AI-based techniques to improve efficiency. Logic
synthesis, a key EDA stage, transforms high-level hardware descriptions into
optimized netlists. Recent research has employed machine learning to predict
Quality of Results (QoR) for pairs of And-Inverter Graphs (AIGs) and synthesis
recipes. However, the severe scarcity of data due to a very limited number of
available AIGs results in overfitting, significantly hindering performance.
Additionally, the complexity and large number of nodes in AIGs make plain GNNs
less effective for learning expressive graph-level representations. To tackle
these challenges, we propose MTLSO - a Multi-Task Learning approach for Logic
Synthesis Optimization. On one hand, it maximizes the use of limited data by
training the model across different tasks. This includes introducing an
auxiliary task of binary multi-label graph classification alongside the primary
regression task, allowing the model to benefit from diverse supervision
sources. On the other hand, we employ a hierarchical graph representation
learning strategy to improve the model's capacity for learning expressive
graph-level representations of large AIGs, surpassing traditional plain GNNs.
Extensive experiments across multiple datasets and against state-of-the-art
baselines demonstrate the superiority of our method, achieving an average
performance gain of 8.22\% for delay and 5.95\% for area.",2024-09-09 21:20:36+00:00
SVS-GAN: Leveraging GANs for Semantic Video Synthesis,"In recent years, there has been a growing interest in Semantic Image
Synthesis (SIS) through the use of Generative Adversarial Networks (GANs) and
diffusion models. This field has seen innovations such as the implementation of
specialized loss functions tailored for this task, diverging from the more
general approaches in Image-to-Image (I2I) translation. While the concept of
Semantic Video Synthesis (SVS)$\unicode{x2013}$the generation of temporally
coherent, realistic sequences of images from semantic maps$\unicode{x2013}$is
newly formalized in this paper, some existing methods have already explored
aspects of this field. Most of these approaches rely on generic loss functions
designed for video-to-video translation or require additional data to achieve
temporal coherence. In this paper, we introduce the SVS-GAN, a framework
specifically designed for SVS, featuring a custom architecture and loss
functions. Our approach includes a triple-pyramid generator that utilizes SPADE
blocks. Additionally, we employ a U-Net-based network for the image
discriminator, which performs semantic segmentation for the OASIS loss. Through
this combination of tailored architecture and objective engineering, our
framework aims to bridge the existing gap between SIS and SVS, outperforming
current state-of-the-art models on datasets like Cityscapes and KITTI-360.",2024-09-09 21:14:44+00:00
DetoxBench: Benchmarking Large Language Models for Multitask Fraud & Abuse Detection,"Large language models (LLMs) have demonstrated remarkable capabilities in
natural language processing tasks. However, their practical application in
high-stake domains, such as fraud and abuse detection, remains an area that
requires further exploration. The existing applications often narrowly focus on
specific tasks like toxicity or hate speech detection. In this paper, we
present a comprehensive benchmark suite designed to assess the performance of
LLMs in identifying and mitigating fraudulent and abusive language across
various real-world scenarios. Our benchmark encompasses a diverse set of tasks,
including detecting spam emails, hate speech, misogynistic language, and more.
We evaluated several state-of-the-art LLMs, including models from Anthropic,
Mistral AI, and the AI21 family, to provide a comprehensive assessment of their
capabilities in this critical domain. The results indicate that while LLMs
exhibit proficient baseline performance in individual fraud and abuse detection
tasks, their performance varies considerably across tasks, particularly
struggling with tasks that demand nuanced pragmatic reasoning, such as
identifying diverse forms of misogynistic language. These findings have
important implications for the responsible development and deployment of LLMs
in high-risk applications. Our benchmark suite can serve as a tool for
researchers and practitioners to systematically evaluate LLMs for multi-task
fraud detection and drive the creation of more robust, trustworthy, and
ethically-aligned systems for fraud and abuse detection.",2024-09-09 21:12:03+00:00
Privacy-Preserving Data Linkage Across Private and Public Datasets for Collaborative Agriculture Research,"Digital agriculture leverages technology to enhance crop yield, disease
resilience, and soil health, playing a critical role in agricultural research.
However, it raises privacy concerns such as adverse pricing, price
discrimination, higher insurance costs, and manipulation of resources,
deterring farm operators from sharing data due to potential misuse. This study
introduces a privacy-preserving framework that addresses these risks while
allowing secure data sharing for digital agriculture. Our framework enables
comprehensive data analysis while protecting privacy. It allows stakeholders to
harness research-driven policies that link public and private datasets. The
proposed algorithm achieves this by: (1) identifying similar farmers based on
private datasets, (2) providing aggregate information like time and location,
(3) determining trends in price and product availability, and (4) correlating
trends with public policy data, such as food insecurity statistics. We validate
the framework with real-world Farmer's Market datasets, demonstrating its
efficacy through machine learning models trained on linked privacy-preserved
data. The results support policymakers and researchers in addressing food
insecurity and pricing issues. This work significantly contributes to digital
agriculture by providing a secure method for integrating and analyzing data,
driving advancements in agricultural technology and development.",2024-09-09 21:07:13+00:00
MLLM-FL: Multimodal Large Language Model Assisted Federated Learning on Heterogeneous and Long-tailed Data,"Previous studies on federated learning (FL) often encounter performance
degradation due to data heterogeneity among different clients. In light of the
recent advances in multimodal large language models (MLLMs), such as GPT-4v and
LLaVA, which demonstrate their exceptional proficiency in multimodal tasks,
such as image captioning and multimodal question answering. We introduce a
novel federated learning framework, named Multimodal Large Language Model
Assisted Federated Learning (MLLM-FL), which which employs powerful MLLMs at
the server end to address the heterogeneous and long-tailed challenges. Owing
to the advanced cross-modality representation capabilities and the extensive
open-vocabulary prior knowledge of MLLMs, our framework is adept at harnessing
the extensive, yet previously underexploited, open-source data accessible from
websites and powerful server-side computational resources. Hence, the MLLM-FL
not only enhances the performance but also avoids increasing the risk of
privacy leakage and the computational burden on local devices, distinguishing
it from prior methodologies. Our framework has three key stages. Initially,
prior to local training on local datasets of clients, we conduct global
visual-text pretraining of the model. This pretraining is facilitated by
utilizing the extensive open-source data available online, with the assistance
of multimodal large language models. Subsequently, the pretrained model is
distributed among various clients for local training. Finally, once the locally
trained models are transmitted back to the server, a global alignment is
carried out under the supervision of MLLMs to further enhance the performance.
Experimental evaluations on established benchmarks, show that our framework
delivers promising performance in the typical scenarios with data heterogeneity
and long-tail distribution across different clients in FL.",2024-09-09 21:04:16+00:00
DiffusionPen: Towards Controlling the Style of Handwritten Text Generation,"Handwritten Text Generation (HTG) conditioned on text and style is a
challenging task due to the variability of inter-user characteristics and the
unlimited combinations of characters that form new words unseen during
training. Diffusion Models have recently shown promising results in HTG but
still remain under-explored. We present DiffusionPen (DiffPen), a 5-shot style
handwritten text generation approach based on Latent Diffusion Models. By
utilizing a hybrid style extractor that combines metric learning and
classification, our approach manages to capture both textual and stylistic
characteristics of seen and unseen words and styles, generating realistic
handwritten samples. Moreover, we explore several variation strategies of the
data with multi-style mixtures and noisy embeddings, enhancing the robustness
and diversity of the generated data. Extensive experiments using IAM offline
handwriting database show that our method outperforms existing methods
qualitatively and quantitatively, and its additional generated data can improve
the performance of Handwriting Text Recognition (HTR) systems. The code is
available at: https://github.com/koninik/DiffusionPen.",2024-09-09 20:58:25+00:00
Statistical Mechanics of Min-Max Problems,"Min-max optimization problems, also known as saddle point problems, have
attracted significant attention due to their applications in various fields,
such as fair beamforming, generative adversarial networks (GANs), and
adversarial learning. However, understanding the properties of these min-max
problems has remained a substantial challenge. This study introduces a
statistical mechanical formalism for analyzing the equilibrium values of
min-max problems in the high-dimensional limit, while appropriately addressing
the order of operations for min and max. As a first step, we apply this
formalism to bilinear min-max games and simple GANs, deriving the relationship
between the amount of training data and generalization error and indicating the
optimal ratio of fake to real data for effective learning. This formalism
provides a groundwork for a deeper theoretical analysis of the equilibrium
properties in various machine learning methods based on min-max problems and
encourages the development of new algorithms and architectures.",2024-09-09 20:24:19+00:00
Online 3D reconstruction and dense tracking in endoscopic videos,"3D scene reconstruction from stereo endoscopic video data is crucial for
advancing surgical interventions. In this work, we present an online framework
for online, dense 3D scene reconstruction and tracking, aimed at enhancing
surgical scene understanding and assisting interventions. Our method
dynamically extends a canonical scene representation using Gaussian splatting,
while modeling tissue deformations through a sparse set of control points. We
introduce an efficient online fitting algorithm that optimizes the scene
parameters, enabling consistent tracking and accurate reconstruction. Through
experiments on the StereoMIS dataset, we demonstrate the effectiveness of our
approach, outperforming state-of-the-art tracking methods and achieving
comparable performance to offline reconstruction techniques. Our work enables
various downstream applications thus contributing to advancing the capabilities
of surgical assistance systems.",2024-09-09 19:58:42+00:00
Analyzing Tumors by Synthesis,"Computer-aided tumor detection has shown great potential in enhancing the
interpretation of over 80 million CT scans performed annually in the United
States. However, challenges arise due to the rarity of CT scans with tumors,
especially early-stage tumors. Developing AI with real tumor data faces issues
of scarcity, annotation difficulty, and low prevalence. Tumor synthesis
addresses these challenges by generating numerous tumor examples in medical
images, aiding AI training for tumor detection and segmentation. Successful
synthesis requires realistic and generalizable synthetic tumors across various
organs. This chapter reviews AI development on real and synthetic data and
summarizes two key trends in synthetic data for cancer imaging research:
modeling-based and learning-based approaches. Modeling-based methods, like
Pixel2Cancer, simulate tumor development over time using generic rules, while
learning-based methods, like DiffTumor, learn from a few annotated examples in
one organ to generate synthetic tumors in others. Reader studies with expert
radiologists show that synthetic tumors can be convincingly realistic. We also
present case studies in the liver, pancreas, and kidneys reveal that AI trained
on synthetic tumors can achieve performance comparable to, or better than, AI
only trained on real data. Tumor synthesis holds significant promise for
expanding datasets, enhancing AI reliability, improving tumor detection
performance, and preserving patient privacy.",2024-09-09 19:51:44+00:00
NESI: Shape Representation via Neural Explicit Surface Intersection,"Compressed representations of 3D shapes that are compact, accurate, and can
be processed efficiently directly in compressed form, are extremely useful for
digital media applications. Recent approaches in this space focus on learned
implicit or parametric representations. While implicits are well suited for
tasks such as in-out queries, they lack natural 2D parameterization,
complicating tasks such as texture or normal mapping. Conversely, parametric
representations support the latter tasks but are ill-suited for occupancy
queries. We propose a novel learned alternative to these approaches, based on
intersections of localized explicit, or height-field, surfaces. Since explicits
can be trivially expressed both implicitly and parametrically, NESI directly
supports a wider range of processing operations than implicit alternatives,
including occupancy queries and parametric access. We represent input shapes
using a collection of differently oriented height-field bounded half-spaces
combined using volumetric Boolean intersections. We first tightly bound each
input using a pair of oppositely oriented height-fields, forming a Double
Height-Field (DHF) Hull. We refine this hull by intersecting it with additional
localized height-fields (HFs) that capture surface regions in its interior. We
minimize the number of HFs necessary to accurately capture each input and
compactly encode both the DHF hull and the local HFs as neural functions
defined over subdomains of R^2. This reduced dimensionality encoding delivers
high-quality compact approximations. Given similar parameter count, or storage
capacity, NESI significantly reduces approximation error compared to the state
of the art, especially at lower parameter counts.",2024-09-09 19:40:52+00:00
SongCreator: Lyrics-based Universal Song Generation,"Music is an integral part of human culture, embodying human intelligence and
creativity, of which songs compose an essential part. While various aspects of
song generation have been explored by previous works, such as singing voice,
vocal composition and instrumental arrangement, etc., generating songs with
both vocals and accompaniment given lyrics remains a significant challenge,
hindering the application of music generation models in the real world. In this
light, we propose SongCreator, a song-generation system designed to tackle this
challenge. The model features two novel designs: a meticulously designed
dual-sequence language model (DSLM) to capture the information of vocals and
accompaniment for song generation, and an additional attention mask strategy
for DSLM, which allows our model to understand, generate and edit songs, making
it suitable for various song-related generation tasks. Extensive experiments
demonstrate the effectiveness of SongCreator by achieving state-of-the-art or
competitive performances on all eight tasks. Notably, it surpasses previous
works by a large margin in lyrics-to-song and lyrics-to-vocals. Additionally,
it is able to independently control the acoustic conditions of the vocals and
accompaniment in the generated song through different prompts, exhibiting its
potential applicability. Our samples are available at
https://songcreator.github.io/.",2024-09-09 19:37:07+00:00
Pioneering Precision in Lumbar Spine MRI Segmentation with Advanced Deep Learning and Data Enhancement,"This study presents an advanced approach to lumbar spine segmentation using
deep learning techniques, focusing on addressing key challenges such as class
imbalance and data preprocessing. Magnetic resonance imaging (MRI) scans of
patients with low back pain are meticulously preprocessed to accurately
represent three critical classes: vertebrae, spinal canal, and intervertebral
discs (IVDs). By rectifying class inconsistencies in the data preprocessing
stage, the fidelity of the training data is ensured. The modified U-Net model
incorporates innovative architectural enhancements, including an upsample block
with leaky Rectified Linear Units (ReLU) and Glorot uniform initializer, to
mitigate common issues such as the dying ReLU problem and improve stability
during training. Introducing a custom combined loss function effectively
tackles class imbalance, significantly improving segmentation accuracy.
Evaluation using a comprehensive suite of metrics showcases the superior
performance of this approach, outperforming existing methods and advancing the
current techniques in lumbar spine segmentation. These findings hold
significant advancements for enhanced lumbar spine MRI and segmentation
diagnostic accuracy.",2024-09-09 19:22:17+00:00
Deep Generative Model for Mechanical System Configuration Design,"Generative AI has made remarkable progress in addressing various design
challenges. One prominent area where generative AI could bring significant
value is in engineering design. In particular, selecting an optimal set of
components and their interfaces to create a mechanical system that meets design
requirements is one of the most challenging and time-consuming tasks for
engineers. This configuration design task is inherently challenging due to its
categorical nature, multiple design requirements a solution must satisfy, and
the reliance on physics simulations for evaluating potential solutions. These
characteristics entail solving a combinatorial optimization problem with
multiple constraints involving black-box functions. To address this challenge,
we propose a deep generative model to predict the optimal combination of
components and interfaces for a given design problem. To demonstrate our
approach, we solve a gear train synthesis problem by first creating a synthetic
dataset using a grammar, a parts catalogue, and a physics simulator. We then
train a Transformer using this dataset, named GearFormer, which can not only
generate quality solutions on its own, but also augment search methods such as
an evolutionary algorithm and Monte Carlo tree search. We show that GearFormer
outperforms such search methods on their own in terms of satisfying the
specified design requirements with orders of magnitude faster generation time.
Additionally, we showcase the benefit of hybrid methods that leverage both
GearFormer and search methods, which further improve the quality of the
solutions.",2024-09-09 19:15:45+00:00
Improved Visually Prompted Keyword Localisation in Real Low-Resource Settings,"Given an image query, visually prompted keyword localisation (VPKL) aims to
find occurrences of the depicted word in a speech collection. This can be
useful when transcriptions are not available for a low-resource language (e.g.
if it is unwritten). Previous work showed that VPKL can be performed with a
visually grounded speech model trained on paired images and unlabelled speech.
But all experiments were done on English. Moreover, transcriptions were used to
get positive and negative pairs for the contrastive loss. This paper introduces
a few-shot learning scheme to mine pairs automatically without transcriptions.
On English, this results in only a small drop in performance. We also - for the
first time - consider VPKL on a real low-resource language, Yoruba. While
scores are reasonable, here we see a bigger drop in performance compared to
using ground truth pairs because the mining is less accurate in Yoruba.",2024-09-09 19:12:03+00:00
Enhanced Generative Data Augmentation for Semantic Segmentation via Stronger Guidance,"Data augmentation is a widely used technique for creating training data for
tasks that require labeled data, such as semantic segmentation. This method
benefits pixel-wise annotation tasks requiring much effort and intensive labor.
Traditional data augmentation methods involve simple transformations like
rotations and flips to create new images from existing ones. However, these new
images may lack diversity along the main semantic axes in the data and not
change high-level semantic properties. To address this issue, generative models
have emerged as an effective solution for augmenting data by generating
synthetic images. Controllable generative models offer a way to augment data
for semantic segmentation tasks using a prompt and visual reference from the
original image. However, using these models directly presents challenges, such
as creating an effective prompt and visual reference to generate a synthetic
image that accurately reflects the content and structure of the original. In
this work, we introduce an effective data augmentation method for semantic
segmentation using the Controllable Diffusion Model. Our proposed method
includes efficient prompt generation using Class-Prompt Appending and Visual
Prior Combination to enhance attention to labeled classes in real images. These
techniques allow us to generate images that accurately depict segmented classes
in the real image. In addition, we employ the class balancing algorithm to
ensure efficiency when merging the synthetic and original images to generate
balanced data for the training dataset. We evaluated our method on the PASCAL
VOC datasets and found it highly effective for synthesizing images in semantic
segmentation.",2024-09-09 19:01:14+00:00
Adapting to Shifting Correlations with Unlabeled Data Calibration,"Distribution shifts between sites can seriously degrade model performance
since models are prone to exploiting unstable correlations. Thus, many methods
try to find features that are stable across sites and discard unstable
features. However, unstable features might have complementary information that,
if used appropriately, could increase accuracy. More recent methods try to
adapt to unstable features at the new sites to achieve higher accuracy.
However, they make unrealistic assumptions or fail to scale to multiple
confounding features. We propose Generalized Prevalence Adjustment (GPA for
short), a flexible method that adjusts model predictions to the shifting
correlations between prediction target and confounders to safely exploit
unstable features. GPA can infer the interaction between target and confounders
in new sites using unlabeled samples from those sites. We evaluate GPA on
several real and synthetic datasets, and show that it outperforms competitive
baselines.",2024-09-09 18:45:43+00:00
MessIRve: A Large-Scale Spanish Information Retrieval Dataset,"Information retrieval (IR) is the task of finding relevant documents in
response to a user query. Although Spanish is the second most spoken native
language, current IR benchmarks lack Spanish data, hindering the development of
information access tools for Spanish speakers. We introduce MessIRve, a
large-scale Spanish IR dataset with around 730 thousand queries from Google's
autocomplete API and relevant documents sourced from Wikipedia. MessIRve's
queries reflect diverse Spanish-speaking regions, unlike other datasets that
are translated from English or do not consider dialectal variations. The large
size of the dataset allows it to cover a wide variety of topics, unlike smaller
datasets. We provide a comprehensive description of the dataset, comparisons
with existing datasets, and baseline evaluations of prominent IR models. Our
contributions aim to advance Spanish IR research and improve information access
for Spanish speakers.",2024-09-09 18:45:04+00:00
FairHome: A Fair Housing and Fair Lending Dataset,"We present a Fair Housing and Fair Lending dataset (FairHome): A dataset with
around 75,000 examples across 9 protected categories. To the best of our
knowledge, FairHome is the first publicly available dataset labeled with binary
labels for compliance risk in the housing domain. We demonstrate the usefulness
and effectiveness of such a dataset by training a classifier and using it to
detect potential violations when using a large language model (LLM) in the
context of real-estate transactions. We benchmark the trained classifier
against state-of-the-art LLMs including GPT-3.5, GPT-4, LLaMA-3, and Mistral
Large in both zero-shot and few-shot contexts. Our classifier outperformed with
an F1-score of 0.91, underscoring the effectiveness of our dataset.",2024-09-09 18:34:26+00:00
A Comprehensive Comparison Between ANNs and KANs For Classifying EEG Alzheimer's Data,"Alzheimer's Disease is an incurable cognitive condition that affects
thousands of people globally. While some diagnostic methods exist for
Alzheimer's Disease, many of these methods cannot detect Alzheimer's in its
earlier stages. Recently, researchers have explored the use of
Electroencephalogram (EEG) technology for diagnosing Alzheimer's. EEG is a
noninvasive method of recording the brain's electrical signals, and EEG data
has shown distinct differences between patients with and without Alzheimer's.
In the past, Artificial Neural Networks (ANNs) have been used to predict
Alzheimer's from EEG data, but these models sometimes produce false positive
diagnoses. This study aims to compare losses between ANNs and Kolmogorov-Arnold
Networks (KANs) across multiple types of epochs, learning rates, and nodes. The
results show that across these different parameters, ANNs are more accurate in
predicting Alzheimer's Disease from EEG signals.",2024-09-09 18:31:39+00:00
Advance and Refinement: The Evolution of UAV Detection and Classification Technologies,"This review provides a detailed analysis of the advancements in unmanned
aerial vehicle (UAV) detection and classification systems from 2020 to today.
It covers various detection methodologies such as radar, radio frequency,
optical, and acoustic sensors, and emphasizes their integration via
sophisticated sensor fusion techniques. The fundamental technologies driving
UAV detection and classification are thoroughly examined, with a focus on their
accuracy and range. Additionally, the paper discusses the latest innovations in
artificial intelligence and machine learning, illustrating their impact on
improving the accuracy and efficiency of these systems. The review concludes by
predicting further technological developments in UAV detection, which are
expected to enhance both performance and reliability.",2024-09-09 18:28:32+00:00
Enhancing Cross-Modality Synthesis: Subvolume Merging for MRI-to-CT Conversion,"Providing more precise tissue attenuation information, synthetic computed
tomography (sCT) generated from magnetic resonance imaging (MRI) contributes to
improved radiation therapy treatment planning. In our study, we employ the
advanced SwinUNETR framework for synthesizing CT from MRI images. Additionally,
we introduce a three-dimensional subvolume merging technique in the prediction
process. By selecting an optimal overlap percentage for adjacent subvolumes,
stitching artifacts are effectively mitigated, leading to a decrease in the
mean absolute error (MAE) between sCT and the labels from 52.65 HU to 47.75 HU.
Furthermore, implementing a weight function with a gamma value of 0.9 results
in the lowest MAE within the same overlap area. By setting the overlap
percentage between 50% and 70%, we achieve a balance between image quality and
computational efficiency.",2024-09-09 18:25:26+00:00
Bridging Rested and Restless Bandits with Graph-Triggering: Rising and Rotting,"Rested and Restless Bandits are two well-known bandit settings that are
useful to model real-world sequential decision-making problems in which the
expected reward of an arm evolves over time due to the actions we perform or
due to the nature. In this work, we propose Graph-Triggered Bandits (GTBs), a
unifying framework to generalize and extend rested and restless bandits. In
this setting, the evolution of the arms' expected rewards is governed by a
graph defined over the arms. An edge connecting a pair of arms $(i,j)$
represents the fact that a pull of arm $i$ triggers the evolution of arm $j$,
and vice versa. Interestingly, rested and restless bandits are both special
cases of our model for some suitable (degenerated) graph. As relevant case
studies for this setting, we focus on two specific types of monotonic bandits:
rising, where the expected reward of an arm grows as the number of triggers
increases, and rotting, where the opposite behavior occurs. For these cases, we
study the optimal policies. We provide suitable algorithms for all scenarios
and discuss their theoretical guarantees, highlighting the complexity of the
learning problem concerning instance-dependent terms that encode specific
properties of the underlying graph structure.",2024-09-09 18:23:07+00:00
FLoRA: Federated Fine-Tuning Large Language Models with Heterogeneous Low-Rank Adaptations,"The rapid development of Large Language Models (LLMs) has been pivotal in
advancing AI, with pre-trained LLMs being adaptable to diverse downstream tasks
through fine-tuning. Federated learning (FL) further enhances fine-tuning in a
privacy-aware manner by utilizing clients' local data through in-situ
computation, eliminating the need for data movement. However, fine-tuning LLMs,
given their massive scale of parameters, poses challenges for clients with
constrained and heterogeneous resources in FL. Previous methods employed
low-rank adaptation (LoRA) for efficient federated fine-tuning but utilized
traditional FL aggregation strategies on LoRA adapters. These approaches led to
mathematically inaccurate aggregation noise, reducing fine-tuning effectiveness
and failing to address heterogeneous LoRAs. In this work, we first highlight
the mathematical incorrectness of LoRA aggregation in existing federated
fine-tuning methods. We introduce a new approach called FLORA that enables
federated fine-tuning on heterogeneous LoRA adapters across clients through a
novel stacking-based aggregation method. Our approach is noise-free and
seamlessly supports heterogeneous LoRA adapters. Extensive experiments
demonstrate FLORA' s superior performance in both homogeneous and heterogeneous
settings, surpassing state-of-the-art methods. We envision this work as a
milestone for efficient, privacy-preserving, and accurate federated fine-tuning
of LLMs. Our code is available at https://github.com/ATP-1010/FederatedLLM.",2024-09-09 18:21:23+00:00
CoDiCast: Conditional Diffusion Model for Weather Prediction with Uncertainty Quantification,"Accurate weather forecasting is critical for science and society. Yet,
existing methods have not managed to simultaneously have the properties of high
accuracy, low uncertainty, and high computational efficiency. On one hand, to
quantify the uncertainty in weather predictions, the strategy of ensemble
forecast (i.e., generating a set of diverse predictions) is often employed.
However, traditional ensemble numerical weather prediction (NWP) is
computationally intensive. On the other hand, most existing machine
learning-based weather prediction (MLWP) approaches are efficient and accurate.
Nevertheless, they are deterministic and cannot capture the uncertainty of
weather forecasting. In this work, we propose CoDiCast, a conditional diffusion
model to generate accurate global weather prediction, while achieving
uncertainty quantification with ensemble forecasts and modest computational
cost. The key idea is to simulate a conditional version of the reverse
denoising process in diffusion models, which starts from pure Gaussian noise to
generate realistic weather scenarios for a future time point. Each denoising
step is conditioned on observations from the recent past. Ensemble forecasts
are achieved by repeatedly sampling from stochastic Gaussian noise to represent
uncertainty quantification. CoDiCast is trained on a decade of ERA5 reanalysis
data from the European Centre for Medium-Range Weather Forecasts (ECMWF).
Experimental results demonstrate that our approach outperforms several existing
data-driven methods in accuracy. Our conditional diffusion model, CoDiCast, can
generate 3-day global weather forecasts, at 6-hour steps and $5.625^\circ$
latitude-longitude resolution, for over 5 variables, in about 12 minutes on a
commodity A100 GPU machine with 80GB memory. The open-souced code is provided
at \url{https://github.com/JimengShi/CoDiCast}.",2024-09-09 18:18:47+00:00
A Small Claims Court for the NLP: Judging Legal Text Classification Strategies With Small Datasets,"Recent advances in language modelling has significantly decreased the need of
labelled data in text classification tasks. Transformer-based models,
pre-trained on unlabeled data, can outmatch the performance of models trained
from scratch for each task. However, the amount of labelled data need to
fine-tune such type of model is still considerably high for domains requiring
expert-level annotators, like the legal domain. This paper investigates the
best strategies for optimizing the use of a small labeled dataset and large
amounts of unlabeled data and perform a classification task in the legal area
with 50 predefined topics. More specifically, we use the records of demands to
a Brazilian Public Prosecutor's Office aiming to assign the descriptions in one
of the subjects, which currently demands deep legal knowledge for manual
filling. The task of optimizing the performance of classifiers in this scenario
is especially challenging, given the low amount of resources available
regarding the Portuguese language, especially in the legal domain. Our results
demonstrate that classic supervised models such as logistic regression and SVM
and the ensembles random forest and gradient boosting achieve better
performance along with embeddings extracted with word2vec when compared to BERT
language model. The latter demonstrates superior performance in association
with the architecture of the model itself as a classifier, having surpassed all
previous models in that regard. The best result was obtained with Unsupervised
Data Augmentation (UDA), which jointly uses BERT, data augmentation, and
strategies of semi-supervised learning, with an accuracy of 80.7% in the
aforementioned task.",2024-09-09 18:10:05+00:00
Flash Cache: Reducing Bias in Radiance Cache Based Inverse Rendering,"State-of-the-art techniques for 3D reconstruction are largely based on
volumetric scene representations, which require sampling multiple points to
compute the color arriving along a ray. Using these representations for more
general inverse rendering -- reconstructing geometry, materials, and lighting
from observed images -- is challenging because recursively path-tracing such
volumetric representations is expensive. Recent works alleviate this issue
through the use of radiance caches: data structures that store the
steady-state, infinite-bounce radiance arriving at any point from any
direction. However, these solutions rely on approximations that introduce bias
into the renderings and, more importantly, into the gradients used for
optimization. We present a method that avoids these approximations while
remaining computationally efficient. In particular, we leverage two techniques
to reduce variance for unbiased estimators of the rendering equation: (1) an
occlusion-aware importance sampler for incoming illumination and (2) a fast
cache architecture that can be used as a control variate for the radiance from
a high-quality, but more expensive, volumetric cache. We show that by removing
these biases our approach improves the generality of radiance cache based
inverse rendering, as well as increasing quality in the presence of challenging
light transport effects such as specular reflections.",2024-09-09 17:59:57+00:00
A Framework for Evaluating PM2.5 Forecasts from the Perspective of Individual Decision Making,"Wildfire frequency is increasing as the climate changes, and the resulting
air pollution poses health risks. Just as people routinely use weather
forecasts to plan their activities around precipitation, reliable air quality
forecasts could help individuals reduce their exposure to air pollution. In the
present work, we evaluate several existing forecasts of fine particular matter
(PM2.5) within the continental United States in the context of individual
decision-making. Our comparison suggests there is meaningful room for
improvement in air pollution forecasting, which might be realized by
incorporating more data sources and using machine learning tools. To facilitate
future machine learning development and benchmarking, we set up a framework to
evaluate and compare air pollution forecasts for individual decision making. We
introduce a new loss to capture decisions about when to use mitigation
measures. We highlight the importance of visualizations when comparing
forecasts. Finally, we provide code to download and compare archived forecast
predictions.",2024-09-09 17:59:54+00:00
Robot Utility Models: General Policies for Zero-Shot Deployment in New Environments,"Robot models, particularly those trained with large amounts of data, have
recently shown a plethora of real-world manipulation and navigation
capabilities. Several independent efforts have shown that given sufficient
training data in an environment, robot policies can generalize to demonstrated
variations in that environment. However, needing to finetune robot models to
every new environment stands in stark contrast to models in language or vision
that can be deployed zero-shot for open-world problems. In this work, we
present Robot Utility Models (RUMs), a framework for training and deploying
zero-shot robot policies that can directly generalize to new environments
without any finetuning. To create RUMs efficiently, we develop new tools to
quickly collect data for mobile manipulation tasks, integrate such data into a
policy with multi-modal imitation learning, and deploy policies on-device on
Hello Robot Stretch, a cheap commodity robot, with an external mLLM verifier
for retrying. We train five such utility models for opening cabinet doors,
opening drawers, picking up napkins, picking up paper bags, and reorienting
fallen objects. Our system, on average, achieves 90% success rate in unseen,
novel environments interacting with unseen objects. Moreover, the utility
models can also succeed in different robot and camera set-ups with no further
data, training, or fine-tuning. Primary among our lessons are the importance of
training data over training algorithm and policy class, guidance about data
scaling, necessity for diverse yet high-quality demonstrations, and a recipe
for robot introspection and retrying to improve performance on individual
environments. Our code, data, models, hardware designs, as well as our
experiment and deployment videos are open sourced and can be found on our
project website: https://robotutilitymodels.com",2024-09-09 17:59:50+00:00
Neural MP: A Generalist Neural Motion Planner,"The current paradigm for motion planning generates solutions from scratch for
every new problem, which consumes significant amounts of time and computational
resources. For complex, cluttered scenes, motion planning approaches can often
take minutes to produce a solution, while humans are able to accurately and
safely reach any goal in seconds by leveraging their prior experience. We seek
to do the same by applying data-driven learning at scale to the problem of
motion planning. Our approach builds a large number of complex scenes in
simulation, collects expert data from a motion planner, then distills it into a
reactive generalist policy. We then combine this with lightweight optimization
to obtain a safe path for real world deployment. We perform a thorough
evaluation of our method on 64 motion planning tasks across four diverse
environments with randomized poses, scenes and obstacles, in the real world,
demonstrating an improvement of 23%, 17% and 79% motion planning success rate
over state of the art sampling, optimization and learning based planning
methods. Video results available at mihdalal.github.io/neuralmotionplanner",2024-09-09 17:59:45+00:00
Promptable Closed-loop Traffic Simulation,"Simulation stands as a cornerstone for safe and efficient autonomous driving
development. At its core a simulation system ought to produce realistic,
reactive, and controllable traffic patterns. In this paper, we propose ProSim,
a multimodal promptable closed-loop traffic simulation framework. ProSim allows
the user to give a complex set of numerical, categorical or textual prompts to
instruct each agent's behavior and intention. ProSim then rolls out a traffic
scenario in a closed-loop manner, modeling each agent's interaction with other
traffic participants. Our experiments show that ProSim achieves high prompt
controllability given different user prompts, while reaching competitive
performance on the Waymo Sim Agents Challenge when no prompt is given. To
support research on promptable traffic simulation, we create
ProSim-Instruct-520k, a multimodal prompt-scenario paired driving dataset with
over 10M text prompts for over 520k real-world driving scenarios. We will
release code of ProSim as well as data and labeling tools of
ProSim-Instruct-520k at https://ariostgx.github.io/ProSim.",2024-09-09 17:59:15+00:00
Evaluating Multiview Object Consistency in Humans and Image Models,"We introduce a benchmark to directly evaluate the alignment between human
observers and vision models on a 3D shape inference task. We leverage an
experimental design from the cognitive sciences which requires zero-shot visual
inferences about object shape: given a set of images, participants identify
which contain the same/different objects, despite considerable viewpoint
variation. We draw from a diverse range of images that include common objects
(e.g., chairs) as well as abstract shapes (i.e., procedurally generated
`nonsense' objects). After constructing over 2000 unique image sets, we
administer these tasks to human participants, collecting 35K trials of
behavioral data from over 500 participants. This includes explicit choice
behaviors as well as intermediate measures, such as reaction time and gaze
data. We then evaluate the performance of common vision models (e.g., DINOv2,
MAE, CLIP). We find that humans outperform all models by a wide margin. Using a
multi-scale evaluation approach, we identify underlying similarities and
differences between models and humans: while human-model performance is
correlated, humans allocate more time/processing on challenging trials. All
images, data, and code can be accessed via our project page.",2024-09-09 17:59:13+00:00
LSVOS Challenge Report: Large-scale Complex and Long Video Object Segmentation,"Despite the promising performance of current video segmentation models on
existing benchmarks, these models still struggle with complex scenes. In this
paper, we introduce the 6th Large-scale Video Object Segmentation (LSVOS)
challenge in conjunction with ECCV 2024 workshop. This year's challenge
includes two tasks: Video Object Segmentation (VOS) and Referring Video Object
Segmentation (RVOS). In this year, we replace the classic YouTube-VOS and
YouTube-RVOS benchmark with latest datasets MOSE, LVOS, and MeViS to assess VOS
under more challenging complex environments. This year's challenge attracted
129 registered teams from more than 20 institutes across over 8 countries. This
report include the challenge and dataset introduction, and the methods used by
top 7 teams in two tracks. More details can be found in our homepage
https://lsvos.github.io/.",2024-09-09 17:45:45+00:00
An Introduction to Quantum Reinforcement Learning (QRL),"Recent advancements in quantum computing (QC) and machine learning (ML) have
sparked considerable interest in the integration of these two cutting-edge
fields. Among the various ML techniques, reinforcement learning (RL) stands out
for its ability to address complex sequential decision-making problems. RL has
already demonstrated substantial success in the classical ML community. Now,
the emerging field of Quantum Reinforcement Learning (QRL) seeks to enhance RL
algorithms by incorporating principles from quantum computing. This paper
offers an introduction to this exciting area for the broader AI and ML
community.",2024-09-09 17:45:37+00:00
Vision-Driven 2D Supervised Fine-Tuning Framework for Bird's Eye View Perception,"Visual bird's eye view (BEV) perception, due to its excellent perceptual
capabilities, is progressively replacing costly LiDAR-based perception systems,
especially in the realm of urban intelligent driving. However, this type of
perception still relies on LiDAR data to construct ground truth databases, a
process that is both cumbersome and time-consuming. Moreover, most massproduced
autonomous driving systems are only equipped with surround camera sensors and
lack LiDAR data for precise annotation. To tackle this challenge, we propose a
fine-tuning method for BEV perception network based on visual 2D semantic
perception, aimed at enhancing the model's generalization capabilities in new
scene data. Considering the maturity and development of 2D perception
technologies, our method significantly reduces the dependency on high-cost BEV
ground truths and shows promising industrial application prospects. Extensive
experiments and comparative analyses conducted on the nuScenes and Waymo public
datasets demonstrate the effectiveness of our proposed method.",2024-09-09 17:40:30+00:00
Applying Attribution Explanations in Truth-Discovery Quantitative Bipolar Argumentation Frameworks,"Explaining the strength of arguments under gradual semantics is receiving
increasing attention. For example, various studies in the literature offer
explanations by computing the attribution scores of arguments or edges in
Quantitative Bipolar Argumentation Frameworks (QBAFs). These explanations,
known as Argument Attribution Explanations (AAEs) and Relation Attribution
Explanations (RAEs), commonly employ removal-based and Shapley-based techniques
for computing the attribution scores. While AAEs and RAEs have proven useful in
several applications with acyclic QBAFs, they remain largely unexplored for
cyclic QBAFs. Furthermore, existing applications tend to focus solely on either
AAEs or RAEs, but do not compare them directly. In this paper, we apply both
AAEs and RAEs, to Truth Discovery QBAFs (TD-QBAFs), which assess the
trustworthiness of sources (e.g., websites) and their claims (e.g., the
severity of a virus), and feature complex cycles. We find that both AAEs and
RAEs can provide interesting explanations and can give non-trivial and
surprising insights.",2024-09-09 17:36:39+00:00
DeepFM-Crispr: Prediction of CRISPR On-Target Effects via Deep Learning,"Since the advent of CRISPR-Cas9, a groundbreaking gene-editing technology
that enables precise genomic modifications via a short RNA guide sequence,
there has been a marked increase in the accessibility and application of this
technology across various fields. The success of CRISPR-Cas9 has spurred
further investment and led to the discovery of additional CRISPR systems,
including CRISPR-Cas13. Distinct from Cas9, which targets DNA, Cas13 targets
RNA, offering unique advantages for gene modulation. We focus on Cas13d, a
variant known for its collateral activity where it non-specifically cleaves
adjacent RNA molecules upon activation, a feature critical to its function. We
introduce DeepFM-Crispr, a novel deep learning model developed to predict the
on-target efficiency and evaluate the off-target effects of Cas13d. This model
harnesses a large language model to generate comprehensive representations rich
in evolutionary and structural data, thereby enhancing predictions of RNA
secondary structures and overall sgRNA efficacy. A transformer-based
architecture processes these inputs to produce a predictive efficacy score.
Comparative experiments show that DeepFM-Crispr not only surpasses traditional
models but also outperforms recent state-of-the-art deep learning methods in
terms of prediction accuracy and reliability.",2024-09-09 17:33:54+00:00
GASP: Gaussian Splatting for Physic-Based Simulations,"Physics simulation is paramount for modeling and utilization of 3D scenes in
various real-world applications. However, its integration with state-of-the-art
3D scene rendering techniques such as Gaussian Splatting (GS) remains
challenging. Existing models use additional meshing mechanisms, including
triangle or tetrahedron meshing, marching cubes, or cage meshes. As an
alternative, we can modify the physics grounded Newtonian dynamics to align
with 3D Gaussian components. Current models take the first-order approximation
of a deformation map, which locally approximates the dynamics by linear
transformations. In contrast, our Gaussian Splatting for Physics-Based
Simulations (GASP) model uses such a map (without any modifications) and flat
Gaussian distributions, which are parameterized by three points (mesh faces).
Subsequently, each 3D point (mesh face node) is treated as a discrete entity
within a 3D space. Consequently, the problem of modeling Gaussian components is
reduced to working with 3D points. Additionally, the information on mesh faces
can be used to incorporate further properties into the physics model,
facilitating the use of triangles. Resulting solution can be integrated into
any physics engine that can be treated as a black box. As demonstrated in our
studies, the proposed model exhibits superior performance on a diverse range of
benchmark datasets designed for 3D object rendering.",2024-09-09 17:28:57+00:00
VFA: Vision Frequency Analysis of Foundation Models and Human,"Machine learning models often struggle with distribution shifts in real-world
scenarios, whereas humans exhibit robust adaptation. Models that better align
with human perception may achieve higher out-of-distribution generalization. In
this study, we investigate how various characteristics of large-scale computer
vision models influence their alignment with human capabilities and robustness.
Our findings indicate that increasing model and data size and incorporating
rich semantic information and multiple modalities enhance models' alignment
with human perception and their overall robustness. Our empirical analysis
demonstrates a strong correlation between out-of-distribution accuracy and
human alignment.",2024-09-09 17:23:39+00:00
Improving Pretraining Data Using Perplexity Correlations,"Quality pretraining data is often seen as the key to high-performance
language models. However, progress in understanding pretraining data has been
slow due to the costly pretraining runs required for data selection
experiments. We present a framework that avoids these costs and selects
high-quality pretraining data without any LLM training of our own. Our work is
based on a simple observation: LLM losses on many pretraining texts are
correlated with downstream benchmark performance, and selecting
high-correlation documents is an effective pretraining data selection method.
We build a new statistical framework for data selection centered around
estimates of perplexity-benchmark correlations and perform data selection using
a sample of 90 LLMs taken from the Open LLM Leaderboard on texts from tens of
thousands of web domains. In controlled pretraining experiments at the 160M
parameter scale on 8 benchmarks, our approach outperforms DSIR on every
benchmark, while matching the best data selector found in DataComp-LM, a
hand-engineered bigram classifier.",2024-09-09 17:23:29+00:00
A Flexible Framework for Universal Computational Aberration Correction via Automatic Lens Library Generation and Domain Adaptation,"Emerging universal Computational Aberration Correction (CAC) paradigms
provide an inspiring solution to light-weight and high-quality imaging without
repeated data preparation and model training to accommodate new lens designs.
However, the training databases in these approaches, i.e., the lens libraries
(LensLibs), suffer from their limited coverage of real-world aberration
behaviors. In this work, we set up an OmniLens framework for universal CAC,
considering both the generalization ability and flexibility. OmniLens extends
the idea of universal CAC to a broader concept, where a base model is trained
for three cases, including zero-shot CAC with the pre-trained model, few-shot
CAC with a little lens-specific data for fine-tuning, and domain adaptive CAC
using domain adaptation for lens-descriptions-unknown lens. In terms of
OmniLens's data foundation, we first propose an Evolution-based Automatic
Optical Design (EAOD) pipeline to construct LensLib automatically, coined
AODLib, whose diversity is enriched by an evolution framework, with
comprehensive constraints and a hybrid optimization strategy for achieving
realistic aberration behaviors. For network design, we introduce the guidance
of high-quality codebook priors to facilitate zero-shot CAC and few-shot CAC,
which enhances the model's generalization ability, while also boosting its
convergence in a few-shot case. Furthermore, based on the statistical
observation of dark channel priors in optical degradation, we design an
unsupervised regularization term to adapt the base model to the target
descriptions-unknown lens using its aberration images without ground truth. We
validate OmniLens on 4 manually designed low-end lenses with various structures
and aberration behaviors. Remarkably, the base model trained on AODLib exhibits
strong generalization capabilities, achieving 97% of the lens-specific
performance in a zero-shot setting.",2024-09-09 17:12:42+00:00
The Future of Software Testing: AI-Powered Test Case Generation and Validation,"Software testing is a crucial phase in the software development lifecycle
(SDLC), ensuring that products meet necessary functional, performance, and
quality benchmarks before release. Despite advancements in automation,
traditional methods of generating and validating test cases still face
significant challenges, including prolonged timelines, human error, incomplete
test coverage, and high costs of manual intervention. These limitations often
lead to delayed product launches and undetected defects that compromise
software quality and user satisfaction. The integration of artificial
intelligence (AI) into software testing presents a promising solution to these
persistent challenges. AI-driven testing methods automate the creation of
comprehensive test cases, dynamically adapt to changes, and leverage machine
learning to identify high-risk areas in the codebase. This approach enhances
regression testing efficiency while expanding overall test coverage.
Furthermore, AI-powered tools enable continuous testing and self-healing test
cases, significantly reducing manual oversight and accelerating feedback loops,
ultimately leading to faster and more reliable software releases. This paper
explores the transformative potential of AI in improving test case generation
and validation, focusing on its ability to enhance efficiency, accuracy, and
scalability in testing processes. It also addresses key challenges associated
with adapting AI for testing, including the need for high quality training
data, ensuring model transparency, and maintaining a balance between automation
and human oversight. Through case studies and examples of real-world
applications, this paper illustrates how AI can significantly enhance testing
efficiency across both legacy and modern software systems.",2024-09-09 17:12:40+00:00
Benchmarking Chinese Knowledge Rectification in Large Language Models,"While Large Language Models (LLMs) exhibit remarkable generative
capabilities, they are not without flaws, particularly in the form of
hallucinations. This issue is even more pronounced when LLMs are applied to
specific languages and domains. For example, LLMs may generate nonsense
information when handling Chinese ancient poetry, proverbs, or idioms, owing to
the lack of specific knowledge. To this end, this paper introduces a benchmark
for rectifying Chinese knowledge in LLMs via knowledge editing. Specifically,
we introduce a new Chinese dataset, CKnowEdit, by collecting seven type of
knowledge from various sources, including classical texts, idioms, and content
from Baidu Tieba Ruozhiba, thereby accounting for the unique polyphony,
antithesis, and logical constructs inherent in the Chinese language. Through
the analysis of this dataset, we uncover the challenges faced by current LLMs
in mastering Chinese. Furthermore, our evaluation of state-of-the-art knowledge
editing techniques on this dataset unveil the substantial scope for advancement
in the rectification of Chinese knowledge. Code and dataset are available at
https://github.com/zjunlp/EasyEdit.",2024-09-09 17:11:51+00:00
Celcomen: spatial causal disentanglement for single-cell and tissue perturbation modeling,"Celcomen leverages a mathematical causality framework to disentangle intra-
and inter- cellular gene regulation programs in spatial transcriptomics and
single-cell data through a generative graph neural network. It can learn
gene-gene interactions, as well as generate post-perturbation counterfactual
spatial transcriptomics, thereby offering access to experimentally inaccessible
samples. We validated its disentanglement, identifiability, and counterfactual
prediction capabilities through simulations and in clinically relevant human
glioblastoma, human fetal spleen, and mouse lung cancer samples. Celcomen
provides the means to model disease and therapy induced changes allowing for
new insights into single-cell spatially resolved tissue responses relevant to
human health.",2024-09-09 17:10:36+00:00
Input Space Mode Connectivity in Deep Neural Networks,"We extend the concept of loss landscape mode connectivity to the input space
of deep neural networks. Mode connectivity was originally studied within
parameter space, where it describes the existence of low-loss paths between
different solutions (loss minimizers) obtained through gradient descent. We
present theoretical and empirical evidence of its presence in the input space
of deep networks, thereby highlighting the broader nature of the phenomenon. We
observe that different input images with similar predictions are generally
connected, and for trained models, the path tends to be simple, with only a
small deviation from being a linear path. Our methodology utilizes real,
interpolated, and synthetic inputs created using the input optimization
technique for feature visualization. We conjecture that input space mode
connectivity in high-dimensional spaces is a geometric effect that takes place
even in untrained models and can be explained through percolation theory. We
exploit mode connectivity to obtain new insights about adversarial examples and
demonstrate its potential for adversarial detection. Additionally, we discuss
applications for the interpretability of deep networks.",2024-09-09 17:03:43+00:00
Enhancing Preference-based Linear Bandits via Human Response Time,"Binary human choice feedback is widely used in interactive preference
learning for its simplicity, but it provides limited information about
preference strength. To overcome this limitation, we leverage human response
times, which inversely correlate with preference strength, as complementary
information. Our work integrates the EZ-diffusion model, which jointly models
human choices and response times, into preference-based linear bandits. We
introduce a computationally efficient utility estimator that reformulates the
utility estimation problem using both choices and response times as a linear
regression problem. Theoretical and empirical comparisons with traditional
choice-only estimators reveal that for queries with strong preferences (""easy""
queries), choices alone provide limited information, while response times offer
valuable complementary information about preference strength. As a result,
incorporating response times makes easy queries more useful. We demonstrate
this advantage in the fixed-budget best-arm identification problem, with
simulations based on three real-world datasets, consistently showing
accelerated learning when response times are incorporated.",2024-09-09 17:02:47+00:00
Predicting Critical Heat Flux with Uncertainty Quantification and Domain Generalization Using Conditional Variational Autoencoders and Deep Neural Networks,"Deep generative models (DGMs) have proven to be powerful in generating
realistic data samples. Their capability to learn the underlying distribution
of a dataset enable them to generate synthetic data samples that closely
resemble the original training dataset, thus addressing the challenge of data
scarcity. In this work, we investigated the capabilities of DGMs by developing
a conditional variational autoencoder (CVAE) model to augment the critical heat
flux (CHF) measurement data that was used to generate the 2006 Groeneveld
lookup table. To determine how this approach compared to traditional methods, a
fine-tuned deep neural network (DNN) regression model was created and evaluated
with the same dataset. Both the CVAE and DNN models achieved small mean
absolute relative errors, with the CVAE model maintaining more favorable
results. To quantify the uncertainty in the model's predictions, uncertainty
quantification (UQ) was performed with repeated sampling of the CVAE model and
ensembling of the DNN model. Following UQ, the DNN ensemble notably improved
performance when compared to the baseline DNN model, while the CVAE model
achieved similar results to its non-UQ results. The CVAE model was shown to
have significantly less variability and a higher confidence after assessment of
the prediction-wise relative standard deviations. Evaluating domain
generalization, both models achieved small mean error values when predicting
both inside and outside the training domain, with predictions outside the
training domain showing slightly larger errors. Overall, the CVAE model was
comparable to the DNN regression model in predicting CHF values but with better
uncertainty behavior.",2024-09-09 16:50:41+00:00
Hierarchical novel class discovery for single-cell transcriptomic profiles,"One of the major challenges arising from single-cell transcriptomics
experiments is the question of how to annotate the associated single-cell
transcriptomic profiles. Because of the large size and the high dimensionality
of the data, automated methods for annotation are needed. We focus here on
datasets obtained in the context of developmental biology, where the
differentiation process leads to a hierarchical structure. We consider a
frequent setting where both labeled and unlabeled data are available at
training time, but the sets of the labels of labeled data on one side and of
the unlabeled data on the other side, are disjoint. It is an instance of the
Novel Class Discovery problem. The goal is to achieve two objectives,
clustering the data and mapping the clusters with labels. We propose extensions
of k-Means and GMM clustering methods for solving the problem and report
comparative results on artificial and experimental transcriptomic datasets. Our
approaches take advantage of the hierarchical nature of the data.",2024-09-09 16:49:09+00:00
Leveraging Object Priors for Point Tracking,"Point tracking is a fundamental problem in computer vision with numerous
applications in AR and robotics. A common failure mode in long-term point
tracking occurs when the predicted point leaves the object it belongs to and
lands on the background or another object. We identify this as the failure to
correctly capture objectness properties in learning to track. To address this
limitation of prior work, we propose a novel objectness regularization approach
that guides points to be aware of object priors by forcing them to stay inside
the the boundaries of object instances. By capturing objectness cues at
training time, we avoid the need to compute object masks during testing. In
addition, we leverage contextual attention to enhance the feature
representation for capturing objectness at the feature level more effectively.
As a result, our approach achieves state-of-the-art performance on three point
tracking benchmarks, and we further validate the effectiveness of our
components via ablation studies. The source code is available at:
https://github.com/RehgLab/tracking_objectness",2024-09-09 16:48:42+00:00
NeurLZ: On Enhancing Lossy Compression Performance based on Error-Controlled Neural Learning for Scientific Data,"Large-scale scientific simulations generate massive datasets that pose
significant challenges for storage and I/O. While traditional lossy compression
techniques can improve performance, balancing compression ratio, data quality,
and throughput remains difficult. To address this, we propose NeurLZ, a novel
cross-field learning-based and error-controlled compression framework for
scientific data. By integrating skipping DNN models, cross-field learning, and
error control, our framework aims to substantially enhance lossy compression
performance. Our contributions are three-fold: (1) We design a lightweight
skipping model to provide high-fidelity detail retention, further improving
prediction accuracy. (2) We adopt a cross-field learning approach to
significantly improve data prediction accuracy, resulting in a substantially
improved compression ratio. (3) We develop an error control approach to provide
strict error bounds according to user requirements. We evaluated NeurLZ on
several real-world HPC application datasets, including Nyx (cosmological
simulation), Miranda (large turbulence simulation), and Hurricane (weather
simulation). Experiments demonstrate that our framework achieves up to a 90%
relative reduction in bit rate under the same data distortion, compared to the
best existing approach.",2024-09-09 16:48:09+00:00
OneEdit: A Neural-Symbolic Collaboratively Knowledge Editing System,"Knowledge representation has been a central aim of AI since its inception.
Symbolic Knowledge Graphs (KGs) and neural Large Language Models (LLMs) can
both represent knowledge. KGs provide highly accurate and explicit knowledge
representation, but face scalability issue; while LLMs offer expansive coverage
of knowledge, but incur significant training costs and struggle with precise
and reliable knowledge manipulation. To this end, we introduce OneEdit, a
neural-symbolic prototype system for collaborative knowledge editing using
natural language, which facilitates easy-to-use knowledge management with KG
and LLM. OneEdit consists of three modules: 1) The Interpreter serves for user
interaction with natural language; 2) The Controller manages editing requests
from various users, leveraging the KG with rollbacks to handle knowledge
conflicts and prevent toxic knowledge attacks; 3) The Editor utilizes the
knowledge from the Controller to edit KG and LLM. We conduct experiments on two
new datasets with KGs which demonstrate that OneEdit can achieve superior
performance.",2024-09-09 16:46:47+00:00
Unified Neural Network Scaling Laws and Scale-time Equivalence,"As neural networks continue to grow in size but datasets might not, it is
vital to understand how much performance improvement can be expected: is it
more important to scale network size or data volume? Thus, neural network
scaling laws, which characterize how test error varies with network size and
data volume, have become increasingly important. However, existing scaling laws
are often applicable only in limited regimes and often do not incorporate or
predict well-known phenomena such as double descent. Here, we present a novel
theoretical characterization of how three factors -- model size, training time,
and data volume -- interact to determine the performance of deep neural
networks. We first establish a theoretical and empirical equivalence between
scaling the size of a neural network and increasing its training time
proportionally. Scale-time equivalence challenges the current practice, wherein
large models are trained for small durations, and suggests that smaller models
trained over extended periods could match their efficacy. It also leads to a
novel method for predicting the performance of large-scale networks from
small-scale networks trained for extended epochs, and vice versa. We next
combine scale-time equivalence with a linear model analysis of double descent
to obtain a unified theoretical scaling law, which we confirm with experiments
across vision benchmarks and network architectures. These laws explain several
previously unexplained phenomena: reduced data requirements for generalization
in larger models, heightened sensitivity to label noise in overparameterized
models, and instances where increasing model scale does not necessarily enhance
performance. Our findings hold significant implications for the practical
deployment of neural networks, offering a more accessible and efficient path to
training and fine-tuning large models.",2024-09-09 16:45:26+00:00
Breaking Neural Network Scaling Laws with Modularity,"Modular neural networks outperform nonmodular neural networks on tasks
ranging from visual question answering to robotics. These performance
improvements are thought to be due to modular networks' superior ability to
model the compositional and combinatorial structure of real-world problems.
However, a theoretical explanation of how modularity improves generalizability,
and how to leverage task modularity while training networks remains elusive.
Using recent theoretical progress in explaining neural network generalization,
we investigate how the amount of training data required to generalize on a task
varies with the intrinsic dimensionality of a task's input. We show
theoretically that when applied to modularly structured tasks, while nonmodular
networks require an exponential number of samples with task dimensionality,
modular networks' sample complexity is independent of task dimensionality:
modular networks can generalize in high dimensions. We then develop a novel
learning rule for modular networks to exploit this advantage and empirically
show the improved generalization of the rule, both in- and out-of-distribution,
on high-dimensional, modular tasks.",2024-09-09 16:43:09+00:00
Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machine Learning Techniques,"Trading and investing in stocks for some is their full-time career, while for
others, it's simply a supplementary income stream. Universal among all
investors is the desire to turn a profit. The key to achieving this goal is
diversification. Spreading investments across sectors is critical to
profitability and maximizing returns. This study aims to gauge the viability of
machine learning methods in practicing the principle of diversification to
maximize portfolio returns. To test this, the study evaluates the Long-Short
Term Memory (LSTM) model across nine different sectors and over 2,200 stocks
using Vanguard's sector-based ETFs. The R-squared value across all sectors
showed promising results, with an average of 0.8651 and a high of 0.942 for the
VNQ ETF. These findings suggest that the LSTM model is a capable and viable
model for accurately predicting directional changes across various industry
sectors, helping investors diversify and grow their portfolios.",2024-09-09 16:41:04+00:00
Creativity and Visual Communication from Machine to Musician: Sharing a Score through a Robotic Camera,"This paper explores the integration of visual communication and musical
interaction by implementing a robotic camera within a ""Guided Harmony"" musical
game. We aim to examine co-creative behaviors between human musicians and
robotic systems. Our research explores existing methodologies like
improvisational game pieces and extends these concepts to include robotic
participation using a PTZ camera. The robotic system interprets and responds to
nonverbal cues from musicians, creating a collaborative and adaptive musical
experience. This initial case study underscores the importance of intuitive
visual communication channels. We also propose future research directions,
including parameters for refining the visual cue toolkit and data collection
methods to understand human-machine co-creativity further. Our findings
contribute to the broader understanding of machine intelligence in augmenting
human creativity, particularly in musical settings.",2024-09-09 16:34:36+00:00
Evidence from fMRI Supports a Two-Phase Abstraction Process in Language Models,"Research has repeatedly demonstrated that intermediate hidden states
extracted from large language models are able to predict measured brain
response to natural language stimuli. Yet, very little is known about the
representation properties that enable this high prediction performance. Why is
it the intermediate layers, and not the output layers, that are most capable
for this unique and highly general transfer task? In this work, we show that
evidence from language encoding models in fMRI supports the existence of a
two-phase abstraction process within LLMs. We use manifold learning methods to
show that this abstraction process naturally arises over the course of training
a language model and that the first ""composition"" phase of this abstraction
process is compressed into fewer layers as training continues. Finally, we
demonstrate a strong correspondence between layerwise encoding performance and
the intrinsic dimensionality of representations from LLMs. We give initial
evidence that this correspondence primarily derives from the inherent
compositionality of LLMs and not their next-word prediction properties.",2024-09-09 16:33:16+00:00
Consensus-based Distributed Quantum Kernel Learning for Speech Recognition,"This paper presents a Consensus-based Distributed Quantum Kernel Learning
(CDQKL) framework aimed at improving speech recognition through distributed
quantum computing.CDQKL addresses the challenges of scalability and data
privacy in centralized quantum kernel learning. It does this by distributing
computational tasks across quantum terminals, which are connected through
classical channels. This approach enables the exchange of model parameters
without sharing local training data, thereby maintaining data privacy and
enhancing computational efficiency. Experimental evaluations on benchmark
speech emotion recognition datasets demonstrate that CDQKL achieves competitive
classification accuracy and scalability compared to centralized and local
quantum kernel learning models. The distributed nature of CDQKL offers
advantages in privacy preservation and computational efficiency, making it
suitable for data-sensitive fields such as telecommunications, automotive, and
finance. The findings suggest that CDQKL can effectively leverage distributed
quantum computing for large-scale machine-learning tasks.",2024-09-09 16:33:00+00:00
Elucidating Optimal Reward-Diversity Tradeoffs in Text-to-Image Diffusion Models,"Text-to-image (T2I) diffusion models have become prominent tools for
generating high-fidelity images from text prompts. However, when trained on
unfiltered internet data, these models can produce unsafe, incorrect, or
stylistically undesirable images that are not aligned with human preferences.
To address this, recent approaches have incorporated human preference datasets
to fine-tune T2I models or to optimize reward functions that capture these
preferences. Although effective, these methods are vulnerable to reward
hacking, where the model overfits to the reward function, leading to a loss of
diversity in the generated images. In this paper, we prove the inevitability of
reward hacking and study natural regularization techniques like KL divergence
and LoRA scaling, and their limitations for diffusion models. We also introduce
Annealed Importance Guidance (AIG), an inference-time regularization inspired
by Annealed Importance Sampling, which retains the diversity of the base model
while achieving Pareto-Optimal reward-diversity tradeoffs. Our experiments
demonstrate the benefits of AIG for Stable Diffusion models, striking the
optimal balance between reward optimization and image diversity. Furthermore, a
user study confirms that AIG improves diversity and quality of generated images
across different model architectures and reward functions.",2024-09-09 16:27:26+00:00
Are Heterophily-Specific GNNs and Homophily Metrics Really Effective? Evaluation Pitfalls and New Benchmarks,"Over the past decade, Graph Neural Networks (GNNs) have achieved great
success on machine learning tasks with relational data. However, recent studies
have found that heterophily can cause significant performance degradation of
GNNs, especially on node-level tasks. Numerous heterophilic benchmark datasets
have been put forward to validate the efficacy of heterophily-specific GNNs and
various homophily metrics have been designed to help people recognize these
malignant datasets. Nevertheless, there still exist multiple pitfalls that
severely hinder the proper evaluation of new models and metrics. In this paper,
we point out three most serious pitfalls: 1) a lack of hyperparameter tuning;
2) insufficient model evaluation on the real challenging heterophilic datasets;
3) missing quantitative evaluation benchmark for homophily metrics on synthetic
graphs. To overcome these challenges, we first train and fine-tune baseline
models on $27$ most widely used benchmark datasets, categorize them into three
distinct groups: malignant, benign and ambiguous heterophilic datasets, and
identify the real challenging subsets of tasks. To our best knowledge, we are
the first to propose such taxonomy. Then, we re-evaluate $10$
heterophily-specific state-of-the-arts (SOTA) GNNs with fine-tuned
hyperparameters on different groups of heterophilic datasets. Based on the
model performance, we reassess their effectiveness on addressing heterophily
challenge. At last, we evaluate $11$ popular homophily metrics on synthetic
graphs with three different generation approaches. To compare the metrics
strictly, we propose the first quantitative evaluation method based on
Fr\'echet distance.",2024-09-09 16:11:07+00:00
ReL-SAR: Representation Learning for Skeleton Action Recognition with Convolutional Transformers and BYOL,"To extract robust and generalizable skeleton action recognition features,
large amounts of well-curated data are typically required, which is a
challenging task hindered by annotation and computation costs. Therefore,
unsupervised representation learning is of prime importance to leverage
unlabeled skeleton data. In this work, we investigate unsupervised
representation learning for skeleton action recognition. For this purpose, we
designed a lightweight convolutional transformer framework, named ReL-SAR,
exploiting the complementarity of convolutional and attention layers for
jointly modeling spatial and temporal cues in skeleton sequences. We also use a
Selection-Permutation strategy for skeleton joints to ensure more informative
descriptions from skeletal data. Finally, we capitalize on Bootstrap Your Own
Latent (BYOL) to learn robust representations from unlabeled skeleton sequence
data. We achieved very competitive results on limited-size datasets: MCAD,
IXMAS, JHMDB, and NW-UCLA, showing the effectiveness of our proposed method
against state-of-the-art methods in terms of both performance and computational
efficiency. To ensure reproducibility and reusability, the source code
including all implementation parameters is provided at:
https://github.com/SafwenNaimi/Representation-Learning-for-Skeleton-Action-Recognition-with-Convolutional-Transformers-and-BYOL",2024-09-09 16:03:26+00:00
A Novel Idea Generation Tool using a Structured Conversational AI (CAI) System,"This paper presents a novel conversational AI-enabled active ideation
interface as a creative idea-generation tool to assist novice designers in
mitigating the initial latency and ideation bottlenecks that are commonly
observed. It is a dynamic, interactive, and contextually responsive approach,
actively involving a large language model (LLM) from the domain of natural
language processing (NLP) in artificial intelligence (AI) to produce multiple
statements of potential ideas for different design problems. Integrating such
AI models with ideation creates what we refer to as an Active Ideation
scenario, which helps foster continuous dialogue-based interaction,
context-sensitive conversation, and prolific idea generation. A pilot study was
conducted with thirty novice designers to generate ideas for given problems
using traditional methods and the new CAI-based interface. The key parameters
of fluency, novelty, and variety were used to compare the outcomes
qualitatively by a panel of experts. The findings demonstrated the
effectiveness of the proposed tool for generating prolific, diverse and novel
ideas. The interface was enhanced by incorporating a prompt-engineered
structured dialogue style for each ideation stage to make it uniform and more
convenient for the designers. The resulting responses of such a structured CAI
interface were found to be more succinct and aligned towards the subsequent
design stage, namely conceptualization. The paper thus established the rich
potential of using Generative AI (Gen-AI) for the early ill-structured phase of
the creative product design process.",2024-09-09 16:02:27+00:00
"LLMs Will Always Hallucinate, and We Need to Live With This","As Large Language Models become more ubiquitous across domains, it becomes
important to examine their inherent limitations critically. This work argues
that hallucinations in language models are not just occasional errors but an
inevitable feature of these systems. We demonstrate that hallucinations stem
from the fundamental mathematical and logical structure of LLMs. It is,
therefore, impossible to eliminate them through architectural improvements,
dataset enhancements, or fact-checking mechanisms. Our analysis draws on
computational theory and Godel's First Incompleteness Theorem, which references
the undecidability of problems like the Halting, Emptiness, and Acceptance
Problems. We demonstrate that every stage of the LLM process-from training data
compilation to fact retrieval, intent classification, and text generation-will
have a non-zero probability of producing hallucinations. This work introduces
the concept of Structural Hallucination as an intrinsic nature of these
systems. By establishing the mathematical certainty of hallucinations, we
challenge the prevailing notion that they can be fully mitigated.",2024-09-09 16:01:58+00:00
Robust Loss Functions for Object Grasping under Limited Ground Truth,"Object grasping is a crucial technology enabling robots to perceive and
interact with the environment sufficiently. However, in practical applications,
researchers are faced with missing or noisy ground truth while training the
convolutional neural network, which decreases the accuracy of the model.
Therefore, different loss functions are proposed to deal with these problems to
improve the accuracy of the neural network. For missing ground truth, a new
predicted category probability method is defined for unlabeled samples, which
works effectively in conjunction with the pseudo-labeling method. Furthermore,
for noisy ground truth, a symmetric loss function is introduced to resist the
corruption of label noises. The proposed loss functions are powerful, robust,
and easy to use. Experimental results based on the typical grasping neural
network show that our method can improve performance by 2 to 13 percent.",2024-09-09 15:56:34+00:00
Predicting Electricity Consumption with Random Walks on Gaussian Processes,"We consider time-series forecasting problems where data is scarce, difficult
to gather, or induces a prohibitive computational cost. As a first attempt, we
focus on short-term electricity consumption in France, which is of strategic
importance for energy suppliers and public stakeholders. The complexity of this
problem and the many levels of geospatial granularity motivate the use of an
ensemble of Gaussian Processes (GPs). Whilst GPs are remarkable predictors,
they are computationally expensive to train, which calls for a frugal few-shot
learning approach. By taking into account performance on GPs trained on a
dataset and designing a random walk on these, we mitigate the training cost of
our entire Bayesian decision-making procedure. We introduce our algorithm
called \textsc{Domino} (ranDOM walk on gaussIaN prOcesses) and present
numerical experiments to support its merits.",2024-09-09 15:54:16+00:00
A System and Benchmark for LLM-based Q&A on Heterogeneous Data,"In many industrial settings, users wish to ask questions whose answers may be
found in structured data sources such as a spreadsheets, databases, APIs, or
combinations thereof. Often, the user doesn't know how to identify or access
the right data source. This problem is compounded even further if multiple (and
potentially siloed) data sources must be assembled to derive the answer.
Recently, various Text-to-SQL applications that leverage Large Language Models
(LLMs) have addressed some of these problems by enabling users to ask questions
in natural language. However, these applications remain impractical in
realistic industrial settings because they fail to cope with the data source
heterogeneity that typifies such environments. In this paper, we address
heterogeneity by introducing the siwarex platform, which enables seamless
natural language access to both databases and APIs. To demonstrate the
effectiveness of siwarex, we extend the popular Spider dataset and benchmark by
replacing some of its tables by data retrieval APIs. We find that siwarex does
a good job of coping with data source heterogeneity. Our modified Spider
benchmark will soon be available to the research community",2024-09-09 15:44:39+00:00
"What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence","Explanations for autonomous vehicle (AV) decisions may build trust, however,
explanations can contain errors. In a simulated driving study (n = 232), we
tested how AV explanation errors, driving context characteristics (perceived
harm and driving difficulty), and personal traits (prior trust and expertise)
affected a passenger's comfort in relying on an AV, preference for control,
confidence in the AV's ability, and explanation satisfaction. Errors negatively
affected all outcomes. Surprisingly, despite identical driving, explanation
errors reduced ratings of the AV's driving ability. Severity and potential harm
amplified the negative impact of errors. Contextual harm and driving difficulty
directly impacted outcome ratings and influenced the relationship between
errors and outcomes. Prior trust and expertise were positively associated with
outcome ratings. Results emphasize the need for accurate, contextually
adaptive, and personalized AV explanations to foster trust, reliance,
satisfaction, and confidence. We conclude with design, research, and deployment
recommendations for trustworthy AV explanation systems.",2024-09-09 15:41:53+00:00
Referring Expression Generation in Visually Grounded Dialogue with Discourse-aware Comprehension Guiding,"We propose an approach to referring expression generation (REG) in visually
grounded dialogue that is meant to produce referring expressions (REs) that are
both discriminative and discourse-appropriate. Our method constitutes a
two-stage process. First, we model REG as a text- and image-conditioned
next-token prediction task. REs are autoregressively generated based on their
preceding linguistic context and a visual representation of the referent.
Second, we propose the use of discourse-aware comprehension guiding as part of
a generate-and-rerank strategy through which candidate REs generated with our
REG model are reranked based on their discourse-dependent discriminatory power.
Results from our human evaluation indicate that our proposed two-stage approach
is effective in producing discriminative REs, with higher performance in terms
of text-image retrieval accuracy for reranked REs compared to those generated
using greedy decoding.",2024-09-09 15:33:07+00:00
Real-time optimal control of high-dimensional parametrized systems by deep learning-based reduced order models,"Steering a system towards a desired target in a very short amount of time is
challenging from a computational standpoint. Indeed, the intrinsically
iterative nature of optimal control problems requires multiple simulations of
the physical system to be controlled. Moreover, the control action needs to be
updated whenever the underlying scenario undergoes variations. Full-order
models based on, e.g., the Finite Element Method, do not meet these
requirements due to the computational burden they usually entail. On the other
hand, conventional reduced order modeling techniques such as the Reduced Basis
method, are intrusive, rely on a linear superimposition of modes, and lack of
efficiency when addressing nonlinear time-dependent dynamics. In this work, we
propose a non-intrusive Deep Learning-based Reduced Order Modeling (DL-ROM)
technique for the rapid control of systems described in terms of parametrized
PDEs in multiple scenarios. In particular, optimal full-order snapshots are
generated and properly reduced by either Proper Orthogonal Decomposition or
deep autoencoders (or a combination thereof) while feedforward neural networks
are exploited to learn the map from scenario parameters to reduced optimal
solutions. Nonlinear dimensionality reduction therefore allows us to consider
state variables and control actions that are both low-dimensional and
distributed. After (i) data generation, (ii) dimensionality reduction, and
(iii) neural networks training in the offline phase, optimal control strategies
can be rapidly retrieved in an online phase for any scenario of interest. The
computational speedup and the high accuracy obtained with the proposed approach
are assessed on different PDE-constrained optimization problems, ranging from
the minimization of energy dissipation in incompressible flows modelled through
Navier-Stokes equations to the thermal active cooling in heat transfer.",2024-09-09 15:20:24+00:00
pFedGPA: Diffusion-based Generative Parameter Aggregation for Personalized Federated Learning,"Federated Learning (FL) offers a decentralized approach to model training,
where data remains local and only model parameters are shared between the
clients and the central server. Traditional methods, such as Federated
Averaging (FedAvg), linearly aggregate these parameters which are usually
trained on heterogeneous data distributions, potentially overlooking the
complex, high-dimensional nature of the parameter space. This can result in
degraded performance of the aggregated model. While personalized FL approaches
can mitigate the heterogeneous data issue to some extent, the limitation of
linear aggregation remains unresolved. To alleviate this issue, we investigate
the generative approach of diffusion model and propose a novel generative
parameter aggregation framework for personalized FL, \texttt{pFedGPA}. In this
framework, we deploy a diffusion model on the server to integrate the diverse
parameter distributions and propose a parameter inversion method to efficiently
generate a set of personalized parameters for each client. This inversion
method transforms the uploaded parameters into a latent code, which is then
aggregated through denoising sampling to produce the final personalized
parameters. By encoding the dependence of a client's model parameters on the
specific data distribution using the high-capacity diffusion model,
\texttt{pFedGPA} can effectively decouple the complexity of the overall
distribution of all clients' model parameters from the complexity of each
individual client's parameter distribution. Our experimental results
consistently demonstrate the superior performance of the proposed method across
multiple datasets, surpassing baseline approaches.",2024-09-09 15:13:56+00:00
Boosting CNN-based Handwriting Recognition Systems with Learnable Relaxation Labeling,"The primary challenge for handwriting recognition systems lies in managing
long-range contextual dependencies, an issue that traditional models often
struggle with. To mitigate it, attention mechanisms have recently been employed
to enhance context-aware labelling, thereby achieving state-of-the-art
performance. In the field of pattern recognition and image analysis, however,
the use of contextual information in labelling problems has a long history and
goes back at least to the early 1970's. Among the various approaches developed
in those years, Relaxation Labelling (RL) processes have played a prominent
role and have been the method of choice in the field for more than a decade.
Contrary to recent transformer-based architectures, RL processes offer a
principled approach to the use of contextual constraints, having a solid
theoretic foundation grounded on variational inequality and game theory, as
well as effective algorithms with convergence guarantees. In this paper, we
propose a novel approach to handwriting recognition that integrates the
strengths of two distinct methodologies. In particular, we propose integrating
(trainable) RL processes with various well-established neural architectures and
we introduce a sparsification technique that accelerates the convergence of the
algorithm and enhances the overall system's performance. Experiments over
several benchmark datasets show that RL processes can improve the
generalisation ability, even surpassing in some cases transformer-based
architectures.",2024-09-09 15:12:28+00:00
MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction,"It is widely acknowledged that extracting market sentiments from news data
benefits market predictions. However, existing methods of using financial
sentiments remain simplistic, relying on equal-weight and static aggregation to
manage sentiments from multiple news items. This leads to a critical issue
termed ``Aggregated Sentiment Homogenization'', which has been explored through
our analysis of a large financial news dataset from industry practice. This
phenomenon occurs when aggregating numerous sentiments, causing representations
to converge towards the mean values of sentiment distributions and thereby
smoothing out unique and important information. Consequently, the aggregated
sentiment representations lose much predictive value of news data. To address
this problem, we introduce the Market Attention-weighted News Aggregation
Network (MANA-Net), a novel method that leverages a dynamic market-news
attention mechanism to aggregate news sentiments for market prediction.
MANA-Net learns the relevance of news sentiments to price changes and assigns
varying weights to individual news items. By integrating the news aggregation
step into the networks for market prediction, MANA-Net allows for trainable
sentiment representations that are optimized directly for prediction. We
evaluate MANA-Net using the S&P 500 and NASDAQ 100 indices, along with
financial news spanning from 2003 to 2018. Experimental results demonstrate
that MANA-Net outperforms various recent market prediction methods, enhancing
Profit & Loss by 1.1% and the daily Sharpe ratio by 0.252.",2024-09-09 15:12:24+00:00
Segmentation by Factorization: Unsupervised Semantic Segmentation for Pathology by Factorizing Foundation Model Features,"We introduce Segmentation by Factorization (F-SEG), an unsupervised
segmentation method for pathology that generates segmentation masks from
pre-trained deep learning models. F-SEG allows the use of pre-trained deep
neural networks, including recently developed pathology foundation models, for
semantic segmentation. It achieves this without requiring additional training
or finetuning, by factorizing the spatial features extracted by the models into
segmentation masks and their associated concept features. We create generic
tissue phenotypes for H&E images by training clustering models for multiple
numbers of clusters on features extracted from several deep learning models on
The Cancer Genome Atlas Program (TCGA), and then show how the clusters can be
used for factorizing corresponding segmentation masks using off-the-shelf deep
learning models. Our results show that F-SEG provides robust unsupervised
segmentation capabilities for H&E pathology images, and that the segmentation
quality is greatly improved by utilizing pathology foundation models. We
discuss and propose methods for evaluating the performance of unsupervised
segmentation in pathology.",2024-09-09 15:11:45+00:00
Extracting the U.S. building types from OpenStreetMap data,"Building type information is crucial for population estimation, traffic
planning, urban planning, and emergency response applications. Although
essential, such data is often not readily available. To alleviate this problem,
this work creates a comprehensive dataset by providing
residential/non-residential building classification covering the entire United
States. We propose and utilize an unsupervised machine learning method to
classify building types based on building footprints and available
OpenStreetMap information. The classification result is validated using
authoritative ground truth data for select counties in the U.S. The validation
shows a high precision for non-residential building classification and a high
recall for residential buildings. We identified various approaches to improving
the quality of the classification, such as removing sheds and garages from the
dataset. Furthermore, analyzing the misclassifications revealed that they are
mainly due to missing and scarce metadata in OSM. A major result of this work
is the resulting dataset of classifying 67,705,475 buildings. We hope that this
data is of value to the scientific community, including urban and
transportation planners.",2024-09-09 15:05:27+00:00
LayeredFlow: A Real-World Benchmark for Non-Lambertian Multi-Layer Optical Flow,"Achieving 3D understanding of non-Lambertian objects is an important task
with many useful applications, but most existing algorithms struggle to deal
with such objects. One major obstacle towards progress in this field is the
lack of holistic non-Lambertian benchmarks -- most benchmarks have low scene
and object diversity, and none provide multi-layer 3D annotations for objects
occluded by transparent surfaces. In this paper, we introduce LayeredFlow, a
real world benchmark containing multi-layer ground truth annotation for optical
flow of non-Lambertian objects. Compared to previous benchmarks, our benchmark
exhibits greater scene and object diversity, with 150k high quality optical
flow and stereo pairs taken over 185 indoor and outdoor scenes and 360 unique
objects. Using LayeredFlow as evaluation data, we propose a new task called
multi-layer optical flow. To provide training data for this task, we introduce
a large-scale densely-annotated synthetic dataset containing 60k images within
30 scenes tailored for non-Lambertian objects. Training on our synthetic
dataset enables model to predict multi-layer optical flow, while fine-tuning
existing optical flow methods on the dataset notably boosts their performance
on non-Lambertian objects without compromising the performance on diffuse
objects. Data is available at https://layeredflow.cs.princeton.edu.",2024-09-09 15:01:29+00:00
SX-Stitch: An Efficient VMS-UNet Based Framework for Intraoperative Scoliosis X-Ray Image Stitching,"In scoliosis surgery, the limited field of view of the C-arm X-ray machine
restricts the surgeons' holistic analysis of spinal structures .This paper
presents an end-to-end efficient and robust intraoperative X-ray image
stitching method for scoliosis surgery,named SX-Stitch. The method is divided
into two stages:segmentation and stitching. In the segmentation stage, We
propose a medical image segmentation model named Vision Mamba of Spine-UNet
(VMS-UNet), which utilizes the state space Mamba to capture long-distance
contextual information while maintaining linear computational complexity, and
incorporates the SimAM attention mechanism, significantly improving the
segmentation performance.In the stitching stage, we simplify the alignment
process between images to the minimization of a registration energy function.
The total energy function is then optimized to order unordered images, and a
hybrid energy function is introduced to optimize the best seam, effectively
eliminating parallax artifacts. On the clinical dataset, Sx-Stitch demonstrates
superiority over SOTA schemes both qualitatively and quantitatively.",2024-09-09 14:49:54+00:00
Cherenkov Imaged Bio-morphological Features Verify Patient Positioning with Deformable Tissue Translocation in Breast Radiotherapy,"Accurate patient positioning is critical for precise radiotherapy dose
delivery, as positioning errors can significantly affect treatment outcomes.
This study introduces a novel method for tracking loco-regional tissue
deformation through Cherenkov image analysis during fractionated breast cancer
radiotherapy. The primary goal was to develop and test an algorithm for
Cherenkov-based regional position accuracy quantification, specifically for
loco-regional deformations, which lack ideal quantification methods in
radiotherapy. Blood vessel detection and segmentation were developed in
Cherenkov images using a tissue phantom with incremental movements, and later
applied to images from fractionated whole breast radiotherapy in human patients
(n=10). A combined rigid and non-rigid registration technique was used to
detect inter- and intra-fractional positioning variations. This approach
quantified positioning variations in two parts: a global shift from rigid
registration and a two-dimensional variation map of loco-regional deformation
from non-rigid registration. The methodology was validated using an
anthropomorphic chest phantom experiment, where known treatment couch
translations and respiratory motion were simulated to assess inter- and
intra-fractional uncertainties, yielding an average accuracy of 0.83 mm for
couch translations up to 20 mm. Analysis of clinical Cherenkov data from ten
breast cancer patients showed an inter-fraction setup variation of 3.7 plus
minus 2.4 mm relative to the first fraction and loco-regional deformations
(95th percentile) of up to 3.3 plus minus 1.9 mm. This study presents a
Cherenkov-based approach to quantify global and local positioning variations,
demonstrating feasibility in addressing loco-regional deformations that
conventional imaging techniques fail to capture.",2024-09-09 14:48:07+00:00
AnomalyCD: A benchmark for Earth anomaly change detection with high-resolution and time-series observations,"Various Earth anomalies have destroyed the stable, balanced state, resulting
in fatalities and serious destruction of property. With the advantages of
large-scale and precise observation, high-resolution remote sensing images have
been widely used for anomaly monitoring and localization. Powered by the deep
representation, the existing methods have achieved remarkable advances,
primarily in classification and change detection techniques. However, labeled
samples are difficult to acquire due to the low probability of anomaly
occurrence, and the trained models are limited to fixed anomaly categories,
which hinders the application for anomalies with few samples or unknown
anomalies. In this paper, to tackle this problem, we propose the anomaly change
detection (AnomalyCD) technique, which accepts time-series observations and
learns to identify anomalous changes by learning from the historical normal
change pattern. Compared to the existing techniques, AnomalyCD processes an
unfixed number of time steps and can localize the various anomalies in a
unified manner, without human supervision. To benchmark AnomalyCD, we
constructed a high-resolution dataset with time-series images dedicated to
various Earth anomalies (the AnomalyCDD dataset). AnomalyCDD contains
high-resolution (from 0.15 to 2.39 m/pixel), time-series (from 3 to 7 time
steps), and large-scale images (1927.93 km2 in total) collected globally
Furthermore, we developed a zero-shot baseline model (AnomalyCDM), which
implements the AnomalyCD technique by extracting a general representation from
the segment anything model (SAM) and conducting temporal comparison to
distinguish the anomalous changes from normal changes. AnomalyCDM is designed
as a two-stage workflow to enhance the efficiency, and has the ability to
process the unseen images directly, without retraining for each scene.",2024-09-09 14:47:57+00:00
RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation,"Regulatory documents, issued by governmental regulatory bodies, establish
rules, guidelines, and standards that organizations must adhere to for legal
compliance. These documents, characterized by their length, complexity and
frequent updates, are challenging to interpret, requiring significant
allocation of time and expertise on the part of organizations to ensure ongoing
compliance.Regulatory Natural Language Processing (RegNLP) is a
multidisciplinary subfield aimed at simplifying access to and interpretation of
regulatory rules and obligations. We define an Automated Question-Passage
Generation task for RegNLP, create the ObliQA dataset containing 27,869
questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation
document collection, design a baseline Regulatory Information Retrieval and
Answer Generation system, and evaluate it with RePASs, a novel evaluation
metric that tests whether generated answers accurately capture all relevant
obligations and avoid contradictions.",2024-09-09 14:44:19+00:00
Evaluation of real-time transcriptions using end-to-end ASR models,"Automatic Speech Recognition (ASR) or Speech-to-text (STT) has greatly
evolved in the last few years. Traditional architectures based on pipelines
have been replaced by joint end-to-end (E2E) architectures that simplify and
streamline the model training process. In addition, new AI training methods,
such as weak-supervised learning have reduced the need for high-quality audio
datasets for model training. However, despite all these advancements, little to
no research has been done on real-time transcription. In real-time scenarios,
the audio is not pre-recorded, and the input audio must be fragmented to be
processed by the ASR systems. To achieve real-time requirements, these
fragments must be as short as possible to reduce latency. However, audio cannot
be split at any point as dividing an utterance into two separate fragments will
generate an incorrect transcription. Also, shorter fragments provide less
context for the ASR model. For this reason, it is necessary to design and test
different splitting algorithms to optimize the quality and delay of the
resulting transcription. In this paper, three audio splitting algorithms are
evaluated with different ASR models to determine their impact on both the
quality of the transcription and the end-to-end delay. The algorithms are
fragmentation at fixed intervals, voice activity detection (VAD), and
fragmentation with feedback. The results are compared to the performance of the
same model, without audio fragmentation, to determine the effects of this
division. The results show that VAD fragmentation provides the best quality
with the highest delay, whereas fragmentation at fixed intervals provides the
lowest quality and the lowest delay. The newly proposed feedback algorithm
exchanges a 2-4% increase in WER for a reduction of 1.5-2s delay, respectively,
to the VAD splitting.",2024-09-09 14:41:57+00:00
Zero-shot Outlier Detection via Prior-data Fitted Networks: Model Selection Bygone!,"Outlier detection (OD) has a vast literature as it finds numerous
applications in environmental monitoring, cybersecurity, finance, and medicine
to name a few. Being an inherently unsupervised task, model selection is a key
bottleneck for OD (both algorithm and hyperparameter selection) without label
supervision. There is a long list of techniques to choose from -- both
classical algorithms and deep neural architectures -- and while several studies
report their hyperparameter sensitivity, the literature is quite slim on
unsupervised model selection -- limiting the effective use of OD in practice.
In this paper we present FoMo-0D, for zero/0-shot OD exploring a transformative
new direction that bypasses the hurdle of model selection altogether (!), thus
breaking new ground. The fundamental idea behind FoMo-0D is the Prior-data
Fitted Networks, recently introduced by Muller et al.(2022), which trains a
Transformer model on a large body of synthetically generated data from a prior
data distribution. In essence, FoMo-0D is a pretrained Foundation Model for
zero/0-shot OD on tabular data, which can directly predict the (outlier/inlier)
label of any test data at inference time, by merely a single forward pass --
making obsolete the need for choosing an algorithm/architecture, tuning its
associated hyperparameters, and even training any model parameters when given a
new OD dataset. Extensive experiments on 57 public benchmark datasets against
26 baseline methods show that FoMo-0D performs statistically no different from
the top 2nd baseline, while significantly outperforming the majority of the
baselines, with an average inference time of 7.7 ms per test sample.",2024-09-09 14:41:24+00:00
Unlearning or Concealment? A Critical Analysis and Evaluation Metrics for Unlearning in Diffusion Models,"Recent research has seen significant interest in methods for concept removal
and targeted forgetting in diffusion models. In this paper, we conduct a
comprehensive white-box analysis to expose significant vulnerabilities in
existing diffusion model unlearning methods. We show that the objective
functions used for unlearning in the existing methods lead to decoupling of the
targeted concepts (meant to be forgotten) for the corresponding prompts. This
is concealment and not actual unlearning, which was the original goal. The
ineffectiveness of current methods stems primarily from their narrow focus on
reducing generation probabilities for specific prompt sets, neglecting the
diverse modalities of intermediate guidance employed during the inference
process. The paper presents a rigorous theoretical and empirical examination of
four commonly used techniques for unlearning in diffusion models. We introduce
two new evaluation metrics: Concept Retrieval Score (CRS) and Concept
Confidence Score (CCS). These metrics are based on a successful adversarial
attack setup that can recover forgotten concepts from unlearned diffusion
models. The CRS measures the similarity between the latent representations of
the unlearned and fully trained models after unlearning. It reports the extent
of retrieval of the forgotten concepts with increasing amount of guidance. The
CCS quantifies the confidence of the model in assigning the target concept to
the manipulated data. It reports the probability of the unlearned model's
generations to be aligned with the original domain knowledge with increasing
amount of guidance. Evaluating existing unlearning methods with our proposed
stringent metrics for diffusion models reveals significant shortcomings in
their ability to truly unlearn concepts. Source Code:
https://respailab.github.io/unlearning-or-concealment",2024-09-09 14:38:31+00:00
Robust Real-time Segmentation of Bio-Morphological Features in Human Cherenkov Imaging during Radiotherapy via Deep Learning,"Cherenkov imaging enables real-time visualization of megavoltage X-ray or
electron beam delivery to the patient during Radiation Therapy (RT).
Bio-morphological features, such as vasculature, seen in these images are
patient-specific signatures that can be used for verification of positioning
and motion management that are essential to precise RT treatment. However until
now, no concerted analysis of this biological feature-based tracking was
utilized because of the slow speed and accuracy of conventional image
processing for feature segmentation. This study demonstrated the first deep
learning framework for such an application, achieving video frame rate
processing. To address the challenge of limited annotation of these features in
Cherenkov images, a transfer learning strategy was applied. A fundus
photography dataset including 20,529 patch retina images with ground-truth
vessel annotation was used to pre-train a ResNet segmentation framework.
Subsequently, a small Cherenkov dataset (1,483 images from 212 treatment
fractions of 19 breast cancer patients) with known annotated vasculature masks
was used to fine-tune the model for accurate segmentation prediction. This deep
learning framework achieved consistent and rapid segmentation of
Cherenkov-imaged bio-morphological features on another 19 patients, including
subcutaneous veins, scars, and pigmented skin. Average segmentation by the
model achieved Dice score of 0.85 and required less than 0.7 milliseconds
processing time per instance. The model demonstrated outstanding consistency
against input image variances and speed compared to conventional manual
segmentation methods, laying the foundation for online segmentation in
real-time monitoring in a prospective setting.",2024-09-09 14:37:33+00:00
K-Fold Causal BART for CATE Estimation,"This research aims to propose and evaluate a novel model named K-Fold Causal
Bayesian Additive Regression Trees (K-Fold Causal BART) for improved estimation
of Average Treatment Effects (ATE) and Conditional Average Treatment Effects
(CATE). The study employs synthetic and semi-synthetic datasets, including the
widely recognized Infant Health and Development Program (IHDP) benchmark
dataset, to validate the model's performance. Despite promising results in
synthetic scenarios, the IHDP dataset reveals that the proposed model is not
state-of-the-art for ATE and CATE estimation. Nonetheless, the research
provides several novel insights: 1. The ps-BART model is likely the preferred
choice for CATE and ATE estimation due to better generalization compared to the
other benchmark models - including the Bayesian Causal Forest (BCF) model,
which is considered by many the current best model for CATE estimation, 2. The
BCF model's performance deteriorates significantly with increasing treatment
effect heterogeneity, while the ps-BART model remains robust, 3. Models tend to
be overconfident in CATE uncertainty quantification when treatment effect
heterogeneity is low, 4. A second K-Fold method is unnecessary for avoiding
overfitting in CATE estimation, as it adds computational costs without
improving performance, 5. Detailed analysis reveals the importance of
understanding dataset characteristics and using nuanced evaluation methods, 6.
The conclusion of Curth et al. (2021) that indirect strategies for CATE
estimation are superior for the IHDP dataset is contradicted by the results of
this research. These findings challenge existing assumptions and suggest
directions for future research to enhance causal inference methodologies.",2024-09-09 14:36:33+00:00
Real-Time Human Action Recognition on Embedded Platforms,"With advancements in computer vision and deep learning, video-based human
action recognition (HAR) has become practical. However, due to the complexity
of the computation pipeline, running HAR on live video streams incurs excessive
delays on embedded platforms. This work tackles the real-time performance
challenges of HAR with four contributions: 1) an experimental study identifying
a standard Optical Flow (OF) extraction technique as the latency bottleneck in
a state-of-the-art HAR pipeline, 2) an exploration of the latency-accuracy
tradeoff between the standard and deep learning approaches to OF extraction,
which highlights the need for a novel, efficient motion feature extractor, 3)
the design of Integrated Motion Feature Extractor (IMFE), a novel single-shot
neural network architecture for motion feature extraction with drastic
improvement in latency, 4) the development of RT-HARE, a real-time HAR system
tailored for embedded platforms. Experimental results on an Nvidia Jetson
Xavier NX platform demonstrated that RT-HARE realizes real-time HAR at a video
frame rate of 30 frames per second while delivering high levels of recognition
accuracy.",2024-09-09 14:35:23+00:00
Self-Supervised State Space Model for Real-Time Traffic Accident Prediction Using eKAN Networks,"Accurate prediction of traffic accidents across different times and regions
is vital for public safety. However, existing methods face two key challenges:
1) Generalization: Current models rely heavily on manually constructed
multi-view structures, like POI distributions and road network densities, which
are labor-intensive and difficult to scale across cities. 2) Real-Time
Performance: While some methods improve accuracy with complex architectures,
they often incur high computational costs, limiting their real-time
applicability. To address these challenges, we propose SSL-eKamba, an efficient
self-supervised framework for traffic accident prediction. To enhance
generalization, we design two self-supervised auxiliary tasks that adaptively
improve traffic pattern representation through spatiotemporal discrepancy
awareness. For real-time performance, we introduce eKamba, an efficient model
that redesigns the Kolmogorov-Arnold Network (KAN) architecture. This involves
using learnable univariate functions for input activation and applying a
selective mechanism (Selective SSM) to capture multi-variate correlations,
thereby improving computational efficiency. Extensive experiments on two
real-world datasets demonstrate that SSL-eKamba consistently outperforms
state-of-the-art baselines. This framework may also offer new insights for
other spatiotemporal tasks. Our source code is publicly available at
http://github.com/KevinT618/SSL-eKamba.",2024-09-09 14:25:51+00:00
Adversarial Attacks on Data Attribution,"Data attribution aims to quantify the contribution of individual training
data points to the outputs of an AI model, which has been used to measure the
value of training data and compensate data providers. Given the impact on
financial decisions and compensation mechanisms, a critical question arises
concerning the adversarial robustness of data attribution methods. However,
there has been little to no systematic research addressing this issue. In this
work, we aim to bridge this gap by detailing a threat model with clear
assumptions about the adversary's goal and capabilities, and by proposing
principled adversarial attack methods on data attribution. We present two such
methods, Shadow Attack and Outlier Attack, both of which generate manipulated
datasets to adversarially inflate the compensation. The Shadow Attack leverages
knowledge about the data distribution in the AI applications, and derives
adversarial perturbations through ""shadow training"", a technique commonly used
in membership inference attacks. In contrast, the Outlier Attack does not
assume any knowledge about the data distribution and relies solely on black-box
queries to the target model's predictions. It exploits an inductive bias
present in many data attribution methods - outlier data points are more likely
to be influential - and employs adversarial examples to generate manipulated
datasets. Empirically, in image classification and text generation tasks, the
Shadow Attack can inflate the data-attribution-based compensation by at least
200%, while the Outlier Attack achieves compensation inflation ranging from
185% to as much as 643%.",2024-09-09 14:23:19+00:00
Interactive incremental learning of generalizable skills with local trajectory modulation,"The problem of generalization in learning from demonstration (LfD) has
received considerable attention over the years, particularly within the context
of movement primitives, where a number of approaches have emerged. Recently,
two important approaches have gained recognition. While one leverages
via-points to adapt skills locally by modulating demonstrated trajectories,
another relies on so-called task-parameterized models that encode movements
with respect to different coordinate systems, using a product of probabilities
for generalization. While the former are well-suited to precise, local
modulations, the latter aim at generalizing over large regions of the workspace
and often involve multiple objects. Addressing the quality of generalization by
leveraging both approaches simultaneously has received little attention. In
this work, we propose an interactive imitation learning framework that
simultaneously leverages local and global modulations of trajectory
distributions. Building on the kernelized movement primitives (KMP) framework,
we introduce novel mechanisms for skill modulation from direct human corrective
feedback. Our approach particularly exploits the concept of via-points to
incrementally and interactively 1) improve the model accuracy locally, 2) add
new objects to the task during execution and 3) extend the skill into regions
where demonstrations were not provided. We evaluate our method on a bearing
ring-loading task using a torque-controlled, 7-DoF, DLR SARA robot.",2024-09-09 14:22:19+00:00
Replay Consolidation with Label Propagation for Continual Object Detection,"Object Detection is a highly relevant computer vision problem with many
applications such as robotics and autonomous driving. Continual Learning~(CL)
considers a setting where a model incrementally learns new information while
retaining previously acquired knowledge. This is particularly challenging since
Deep Learning models tend to catastrophically forget old knowledge while
training on new data. In particular, Continual Learning for Object
Detection~(CLOD) poses additional difficulties compared to CL for
Classification. In CLOD, images from previous tasks may contain unknown classes
that could reappear labeled in future tasks. These missing annotations cause
task interference issues for replay-based approaches. As a result, most works
in the literature have focused on distillation-based approaches. However, these
approaches are effective only when there is a strong overlap of classes across
tasks. To address the issues of current methodologies, we propose a novel
technique to solve CLOD called Replay Consolidation with Label Propagation for
Object Detection (RCLPOD). Based on the replay method, our solution avoids task
interference issues by enhancing the buffer memory samples. Our method is
evaluated against existing techniques in CLOD literature, demonstrating its
superior performance on established benchmarks like VOC and COCO.",2024-09-09 14:16:27+00:00
Prototype-Driven Multi-Feature Generation for Visible-Infrared Person Re-identification,"The primary challenges in visible-infrared person re-identification arise
from the differences between visible (vis) and infrared (ir) images, including
inter-modal and intra-modal variations. These challenges are further
complicated by varying viewpoints and irregular movements. Existing methods
often rely on horizontal partitioning to align part-level features, which can
introduce inaccuracies and have limited effectiveness in reducing modality
discrepancies. In this paper, we propose a novel Prototype-Driven Multi-feature
generation framework (PDM) aimed at mitigating cross-modal discrepancies by
constructing diversified features and mining latent semantically similar
features for modal alignment. PDM comprises two key components: Multi-Feature
Generation Module (MFGM) and Prototype Learning Module (PLM). The MFGM
generates diversity features closely distributed from modality-shared features
to represent pedestrians. Additionally, the PLM utilizes learnable prototypes
to excavate latent semantic similarities among local features between visible
and infrared modalities, thereby facilitating cross-modal instance-level
alignment. We introduce the cosine heterogeneity loss to enhance prototype
diversity for extracting rich local features. Extensive experiments conducted
on the SYSU-MM01 and LLCM datasets demonstrate that our approach achieves
state-of-the-art performance. Our codes are available at
https://github.com/mmunhappy/ICASSP2025-PDM.",2024-09-09 14:12:23+00:00
3D-SAR Tomography and Machine Learning for High-Resolution Tree Height Estimation,"Accurately estimating forest biomass is crucial for global carbon cycle
modelling and climate change mitigation. Tree height, a key factor in biomass
calculations, can be measured using Synthetic Aperture Radar (SAR) technology.
This study applies machine learning to extract forest height data from two SAR
products: Single Look Complex (SLC) images and tomographic cubes, in
preparation for the ESA Biomass Satellite mission. We use the TomoSense
dataset, containing SAR and LiDAR data from Germany's Eifel National Park, to
develop and evaluate height estimation models. Our approach includes classical
methods, deep learning with a 3D U-Net, and Bayesian-optimized techniques. By
testing various SAR frequencies and polarimetries, we establish a baseline for
future height and biomass modelling. Best-performing models predict forest
height to be within 2.82m mean absolute error for canopies around 30m,
advancing our ability to measure global carbon stocks and support climate
action.",2024-09-09 14:07:38+00:00
Optimal Projections for Classification with Naive Bayes,"In the Naive Bayes classification model the class conditional densities are
estimated as the products of their marginal densities along the cardinal basis
directions. We study the problem of obtaining an alternative basis for this
factorisation with the objective of enhancing the discriminatory power of the
associated classification model. We formulate the problem as a projection
pursuit to find the optimal linear projection on which to perform
classification. Optimality is determined based on the multinomial likelihood
within which probabilities are estimated using the Naive Bayes factorisation of
the projected data. Projection pursuit offers the added benefits of dimension
reduction and visualisation. We discuss an intuitive connection with class
conditional independent components analysis, and show how this is realised
visually in practical applications. The performance of the resulting
classification models is investigated using a large collection of (162)
publicly available benchmark data sets and in comparison with relevant
alternatives. We find that the proposed approach substantially outperforms
other popular probabilistic discriminant analysis models and is highly
competitive with Support Vector Machines.",2024-09-09 14:05:30+00:00
Renormalized Connection for Scale-preferred Object Detection in Satellite Imagery,"Satellite imagery, due to its long-range imaging, brings with it a variety of
scale-preferred tasks, such as the detection of tiny/small objects, making the
precise localization and detection of small objects of interest a challenging
task. In this article, we design a Knowledge Discovery Network (KDN) to
implement the renormalization group theory in terms of efficient feature
extraction. Renormalized connection (RC) on the KDN enables ``synergistic
focusing'' of multi-scale features. Based on our observations of KDN, we
abstract a class of RCs with different connection strengths, called n21C, and
generalize it to FPN-based multi-branch detectors. In a series of FPN
experiments on the scale-preferred tasks, we found that the
``divide-and-conquer'' idea of FPN severely hampers the detector's learning in
the right direction due to the large number of large-scale negative samples and
interference from background noise. Moreover, these negative samples cannot be
eliminated by the focal loss function. The RCs extends the multi-level
feature's ``divide-and-conquer'' mechanism of the FPN-based detectors to a wide
range of scale-preferred tasks, and enables synergistic effects of multi-level
features on the specific learning goal. In addition, interference activations
in two aspects are greatly reduced and the detector learns in a more correct
direction. Extensive experiments of 17 well-designed detection architectures
embedded with n21s on five different levels of scale-preferred tasks validate
the effectiveness and efficiency of the RCs. Especially the simplest linear
form of RC, E421C performs well in all tasks and it satisfies the scaling
property of RGT. We hope that our approach will transfer a large number of
well-designed detectors from the computer vision community to the remote
sensing community.",2024-09-09 13:56:22+00:00
Forward KL Regularized Preference Optimization for Aligning Diffusion Policies,"Diffusion models have achieved remarkable success in sequential
decision-making by leveraging the highly expressive model capabilities in
policy learning. A central problem for learning diffusion policies is to align
the policy output with human intents in various tasks. To achieve this,
previous methods conduct return-conditioned policy generation or Reinforcement
Learning (RL)-based policy optimization, while they both rely on pre-defined
reward functions. In this work, we propose a novel framework, Forward KL
regularized Preference optimization for aligning Diffusion policies, to align
the diffusion policy with preferences directly. We first train a diffusion
policy from the offline dataset without considering the preference, and then
align the policy to the preference data via direct preference optimization.
During the alignment phase, we formulate direct preference learning in a
diffusion policy, where the forward KL regularization is employed in preference
optimization to avoid generating out-of-distribution actions. We conduct
extensive experiments for MetaWorld manipulation and D4RL tasks. The results
show our method exhibits superior alignment with preferences and outperforms
previous state-of-the-art algorithms.",2024-09-09 13:56:03+00:00
Joint Input and Output Coordination for Class-Incremental Learning,"Incremental learning is nontrivial due to severe catastrophic forgetting.
Although storing a small amount of data on old tasks during incremental
learning is a feasible solution, current strategies still do not 1) adequately
address the class bias problem, and 2) alleviate the mutual interference
between new and old tasks, and 3) consider the problem of class bias within
tasks. This motivates us to propose a joint input and output coordination
(JIOC) mechanism to address these issues. This mechanism assigns different
weights to different categories of data according to the gradient of the output
score, and uses knowledge distillation (KD) to reduce the mutual interference
between the outputs of old and new tasks. The proposed mechanism is general and
flexible, and can be incorporated into different incremental learning
approaches that use memory storage. Extensive experiments show that our
mechanism can significantly improve their performance.",2024-09-09 13:55:07+00:00
G-NeLF: Memory- and Data-Efficient Hybrid Neural Light Field for Novel View Synthesis,"Following the burgeoning interest in implicit neural representation, Neural
Light Field (NeLF) has been introduced to predict the color of a ray directly.
Unlike Neural Radiance Field (NeRF), NeLF does not create a point-wise
representation by predicting color and volume density for each point in space.
However, the current NeLF methods face a challenge as they need to train a NeRF
model first and then synthesize over 10K views to train NeLF for improved
performance. Additionally, the rendering quality of NeLF methods is lower
compared to NeRF methods. In this paper, we propose G-NeLF, a versatile
grid-based NeLF approach that utilizes spatial-aware features to unleash the
potential of the neural network's inference capability, and consequently
overcome the difficulties of NeLF training. Specifically, we employ a
spatial-aware feature sequence derived from a meticulously crafted grid as the
ray's representation. Drawing from our empirical studies on the adaptability of
multi-resolution hash tables, we introduce a novel grid-based ray
representation for NeLF that can represent the entire space with a very limited
number of parameters. To better utilize the sequence feature, we design a
lightweight ray color decoder that simulates the ray propagation process,
enabling a more efficient inference of the ray's color. G-NeLF can be trained
without necessitating significant storage overhead and with the model size of
only 0.95 MB to surpass previous state-of-the-art NeLF. Moreover, compared with
grid-based NeRF methods, e.g., Instant-NGP, we only utilize one-tenth of its
parameters to achieve higher performance. Our code will be released upon
acceptance.",2024-09-09 13:52:58+00:00
Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection,"Most unsupervised anomaly detection methods based on representations of
normal samples to distinguish anomalies have recently made remarkable progress.
However, existing methods only learn a single decision boundary for
distinguishing the samples within the training dataset, neglecting the
variation in feature distribution for normal samples even in the same category
in the real world. Furthermore, it was not considered that a distribution bias
still exists between the test set and the train set. Therefore, we propose an
Adapted-MoE which contains a routing network and a series of expert models to
handle multiple distributions of same-category samples by divide and conquer.
Specifically, we propose a routing network based on representation learning to
route same-category samples into the subclasses feature space. Then, a series
of expert models are utilized to learn the representation of various normal
samples and construct several independent decision boundaries. We propose the
test-time adaption to eliminate the bias between the unseen test sample
representation and the feature distribution learned by the expert model. Our
experiments are conducted on a dataset that provides multiple subclasses from
three categories, namely Texture AD benchmark. The Adapted-MoE significantly
improves the performance of the baseline model, achieving 2.18%-7.20% and
1.57%-16.30% increase in I-AUROC and P-AUROC, which outperforms the current
state-of-the-art methods. Our code is available at https://github.com/.",2024-09-09 13:49:09+00:00
CustomContrast: A Multilevel Contrastive Perspective For Subject-Driven Text-to-Image Customization,"Subject-driven text-to-image (T2I) customization has drawn significant
interest in academia and industry. This task enables pre-trained models to
generate novel images based on unique subjects. Existing studies adopt a
self-reconstructive perspective, focusing on capturing all details of a single
image, which will misconstrue the specific image's irrelevant attributes (e.g.,
view, pose, and background) as the subject intrinsic attributes. This
misconstruction leads to both overfitting or underfitting of irrelevant and
intrinsic attributes of the subject, i.e., these attributes are
over-represented or under-represented simultaneously, causing a trade-off
between similarity and controllability. In this study, we argue an ideal
subject representation can be achieved by a cross-differential perspective,
i.e., decoupling subject intrinsic attributes from irrelevant attributes via
contrastive learning, which allows the model to focus more on intrinsic
attributes through intra-consistency (features of the same subject are
spatially closer) and inter-distinctiveness (features of different subjects
have distinguished differences). Specifically, we propose CustomContrast, a
novel framework, which includes a Multilevel Contrastive Learning (MCL)
paradigm and a Multimodal Feature Injection (MFI) Encoder. The MCL paradigm is
used to extract intrinsic features of subjects from high-level semantics to
low-level appearance through crossmodal semantic contrastive learning and
multiscale appearance contrastive learning. To facilitate contrastive learning,
we introduce the MFI encoder to capture cross-modal representations. Extensive
experiments show the effectiveness of CustomContrast in subject similarity and
text controllability.",2024-09-09 13:39:47+00:00
Normalizing Energy Consumption for Hardware-Independent Evaluation,"The increasing use of machine learning (ML) models in signal processing has
raised concerns about their environmental impact, particularly during
resource-intensive training phases. In this study, we present a novel
methodology for normalizing energy consumption across different hardware
platforms to facilitate fair and consistent comparisons. We evaluate different
normalization strategies by measuring the energy used to train different ML
architectures on different GPUs, focusing on audio tagging tasks. Our approach
shows that the number of reference points, the type of regression and the
inclusion of computational metrics significantly influences the normalization
process. We find that the appropriate selection of two reference points
provides robust normalization, while incorporating the number of floating-point
operations and parameters improves the accuracy of energy consumption
predictions. By supporting more accurate energy consumption evaluation, our
methodology promotes the development of environmentally sustainable ML
practices.",2024-09-09 13:38:00+00:00
When resampling/reweighting improves feature learning in imbalanced classification?: A toy-model study,"A toy model of binary classification is studied with the aim of clarifying
the class-wise resampling/reweighting effect on the feature learning
performance under the presence of class imbalance. In the analysis, a
high-dimensional limit of the feature is taken while keeping the dataset size
ratio against the feature dimension finite and the non-rigorous replica method
from statistical mechanics is employed. The result shows that there exists a
case in which the no resampling/reweighting situation gives the best feature
learning performance irrespectively of the choice of losses or classifiers,
supporting recent findings in Cao et al. (2019); Kang et al. (2019). It is also
revealed that the key of the result is the symmetry of the loss and the problem
setting. Inspired by this, we propose a further simplified model exhibiting the
same property for the multiclass setting. These clarify when the class-wise
resampling/reweighting becomes effective in imbalanced classification.",2024-09-09 13:31:00+00:00
SynMorph: Generating Synthetic Face Morphing Dataset with Mated Samples,"Face morphing attack detection (MAD) algorithms have become essential to
overcome the vulnerability of face recognition systems. To solve the lack of
large-scale and public-available datasets due to privacy concerns and
restrictions, in this work we propose a new method to generate a synthetic face
morphing dataset with 2450 identities and more than 100k morphs. The proposed
synthetic face morphing dataset is unique for its high-quality samples,
different types of morphing algorithms, and the generalization for both single
and differential morphing attack detection algorithms. For experiments, we
apply face image quality assessment and vulnerability analysis to evaluate the
proposed synthetic face morphing dataset from the perspective of biometric
sample quality and morphing attack potential on face recognition systems. The
results are benchmarked with an existing SOTA synthetic dataset and a
representative non-synthetic and indicate improvement compared with the SOTA.
Additionally, we design different protocols and study the applicability of
using the proposed synthetic dataset on training morphing attack detection
algorithms.",2024-09-09 13:29:53+00:00
UAVDB: Trajectory-Guided Adaptable Bounding Boxes for UAV Detection,"With the rapid development of drone technology, accurate detection of
Unmanned Aerial Vehicles (UAVs) has become essential for applications such as
surveillance, security, and airspace management. In this paper, we propose a
novel trajectory-guided method, the Patch Intensity Convergence (PIC)
technique, which generates high-fidelity bounding boxes for UAV detection tasks
and no need for the effort required for labeling. The PIC technique forms the
foundation for developing UAVDB, a database explicitly created for UAV
detection. Unlike existing datasets, which often use low-resolution footage or
focus on UAVs in simple backgrounds, UAVDB employs high-resolution video to
capture UAVs at various scales, ranging from hundreds of pixels to nearly
single-digit sizes. This broad-scale variation enables comprehensive evaluation
of detection algorithms across different UAV sizes and distances. Applying the
PIC technique, we can also efficiently generate detection datasets from
trajectory or positional data, even without size information. We extensively
benchmark UAVDB using YOLOv8 series detectors, offering a detailed performance
analysis. Our findings highlight UAVDB's potential as a vital database for
advancing UAV detection, particularly in high-resolution and long-distance
tracking scenarios.",2024-09-09 13:27:53+00:00
ExDDI: Explaining Drug-Drug Interaction Predictions with Natural Language,"Predicting unknown drug-drug interactions (DDIs) is crucial for improving
medication safety. Previous efforts in DDI prediction have typically focused on
binary classification or predicting DDI categories, with the absence of
explanatory insights that could enhance trust in these predictions. In this
work, we propose to generate natural language explanations for DDI predictions,
enabling the model to reveal the underlying pharmacodynamics and
pharmacokinetics mechanisms simultaneously as making the prediction. To do
this, we have collected DDI explanations from DDInter and DrugBank and
developed various models for extensive experiments and analysis. Our models can
provide accurate explanations for unknown DDIs between known drugs. This paper
contributes new tools to the field of DDI prediction and lays a solid
foundation for further research on generating explanations for DDI predictions.",2024-09-09 13:23:14+00:00
MemoRAG: Moving towards Next-Gen RAG Via Memory-Inspired Knowledge Discovery,"Retrieval-Augmented Generation (RAG) leverages retrieval tools to access
external databases, thereby enhancing the generation quality of large language
models (LLMs) through optimized context. However, the existing retrieval
methods are constrained inherently, as they can only perform relevance matching
between explicitly stated queries and well-formed knowledge, but unable to
handle tasks involving ambiguous information needs or unstructured knowledge.
Consequently, existing RAG systems are primarily effective for straightforward
question-answering tasks. In this work, we propose MemoRAG, a novel
retrieval-augmented generation paradigm empowered by long-term memory. MemoRAG
adopts a dual-system architecture. On the one hand, it employs a light but
long-range LLM to form the global memory of database. Once a task is presented,
it generates draft answers, cluing the retrieval tools to locate useful
information within the database. On the other hand, it leverages an expensive
but expressive LLM, which generates the ultimate answer based on the retrieved
information. Building on this general framework, we further optimize MemoRAG's
performance by enhancing its cluing mechanism and memorization capacity. In our
experiment, MemoRAG achieves superior performance across a variety of
evaluation tasks, including both complex ones where conventional RAG fails and
straightforward ones where RAG is commonly applied.",2024-09-09 13:20:31+00:00
DSDFormer: An Innovative Transformer-Mamba Framework for Robust High-Precision Driver Distraction Identification,"Driver distraction remains a leading cause of traffic accidents, posing a
critical threat to road safety globally. As intelligent transportation systems
evolve, accurate and real-time identification of driver distraction has become
essential. However, existing methods struggle to capture both global contextual
and fine-grained local features while contending with noisy labels in training
datasets. To address these challenges, we propose DSDFormer, a novel framework
that integrates the strengths of Transformer and Mamba architectures through a
Dual State Domain Attention (DSDA) mechanism, enabling a balance between
long-range dependencies and detailed feature extraction for robust driver
behavior recognition. Additionally, we introduce Temporal Reasoning Confident
Learning (TRCL), an unsupervised approach that refines noisy labels by
leveraging spatiotemporal correlations in video sequences. Our model achieves
state-of-the-art performance on the AUC-V1, AUC-V2, and 100-Driver datasets and
demonstrates real-time processing efficiency on the NVIDIA Jetson AGX Orin
platform. Extensive experimental results confirm that DSDFormer and TRCL
significantly improve both the accuracy and robustness of driver distraction
detection, offering a scalable solution to enhance road safety.",2024-09-09 13:16:15+00:00
Interpretable Responsibility Sharing as a Heuristic for Task and Motion Planning,"This article introduces a novel heuristic for Task and Motion Planning (TAMP)
named Interpretable Responsibility Sharing (IRS), which enhances planning
efficiency in domestic robots by leveraging human-constructed environments and
inherent biases. Utilizing auxiliary objects (e.g., trays and pitchers), which
are commonly found in household settings, IRS systematically incorporates these
elements to simplify and optimize task execution. The heuristic is rooted in
the novel concept of Responsibility Sharing (RS), where auxiliary objects share
the task's responsibility with the embodied agent, dividing complex tasks into
manageable sub-problems. This division not only reflects human usage patterns
but also aids robots in navigating and manipulating within human spaces more
effectively. By integrating Optimized Rule Synthesis (ORS) for decision-making,
IRS ensures that the use of auxiliary objects is both strategic and
context-aware, thereby improving the interpretability and effectiveness of
robotic planning. Experiments conducted across various household tasks
demonstrate that IRS significantly outperforms traditional methods by reducing
the effort required in task execution and enhancing the overall decision-making
process. This approach not only aligns with human intuitive methods but also
offers a scalable solution adaptable to diverse domestic environments. Code is
available at https://github.com/asyncs/IRS.",2024-09-09 13:15:53+00:00
Latent 3D Brain MRI Counterfactual,"The number of samples in structural brain MRI studies is often too small to
properly train deep learning models. Generative models show promise in
addressing this issue by effectively learning the data distribution and
generating high-fidelity MRI. However, they struggle to produce diverse,
high-quality data outside the distribution defined by the training data. One
way to address the issue is using causal models developed for 3D volume
counterfactuals. However, accurately modeling causality in high-dimensional
spaces is a challenge so that these models generally generate 3D brain MRIS of
lower quality. To address these challenges, we propose a two-stage method that
constructs a Structural Causal Model (SCM) within the latent space. In the
first stage, we employ a VQ-VAE to learn a compact embedding of the MRI volume.
Subsequently, we integrate our causal model into this latent space and execute
a three-step counterfactual procedure using a closed-form Generalized Linear
Model (GLM). Our experiments conducted on real-world high-resolution MRI data
(1mm) demonstrate that our method can generate high-quality 3D MRI
counterfactuals.",2024-09-09 13:15:03+00:00
Approximation Bounds for Recurrent Neural Networks with Application to Regression,"We study the approximation capacity of deep ReLU recurrent neural networks
(RNNs) and explore the convergence properties of nonparametric least squares
regression using RNNs. We derive upper bounds on the approximation error of
RNNs for H\""older smooth functions, in the sense that the output at each time
step of an RNN can approximate a H\""older function that depends only on past
and current information, termed a past-dependent function. This allows a
carefully constructed RNN to simultaneously approximate a sequence of
past-dependent H\""older functions. We apply these approximation results to
derive non-asymptotic upper bounds for the prediction error of the empirical
risk minimizer in regression problem. Our error bounds achieve minimax optimal
rate under both exponentially $\beta$-mixing and i.i.d. data assumptions,
improving upon existing ones. Our results provide statistical guarantees on the
performance of RNNs.",2024-09-09 13:02:50+00:00
Learning to Model Graph Structural Information on MLPs via Graph Structure Self-Contrasting,"Recent years have witnessed great success in handling graph-related tasks
with Graph Neural Networks (GNNs). However, most existing GNNs are based on
message passing to perform feature aggregation and transformation, where the
structural information is explicitly involved in the forward propagation by
coupling with node features through graph convolution at each layer. As a
result, subtle feature noise or structure perturbation may cause severe error
propagation, resulting in extremely poor robustness. In this paper, we rethink
the roles played by graph structural information in graph data training and
identify that message passing is not the only path to modeling structural
information. Inspired by this, we propose a simple but effective Graph
Structure Self-Contrasting (GSSC) framework that learns graph structural
information without message passing. The proposed framework is based purely on
Multi-Layer Perceptrons (MLPs), where the structural information is only
implicitly incorporated as prior knowledge to guide the computation of
supervision signals, substituting the explicit message propagation as in GNNs.
Specifically, it first applies structural sparsification to remove potentially
uninformative or noisy edges in the neighborhood, and then performs structural
self-contrasting in the sparsified neighborhood to learn robust node
representations. Finally, structural sparsification and self-contrasting are
formulated as a bi-level optimization problem and solved in a unified
framework. Extensive experiments have qualitatively and quantitatively
demonstrated that the GSSC framework can produce truly encouraging performance
with better generalization and robustness than other leading competitors.",2024-09-09 12:56:02+00:00
On the Convergence of Sigmoid and tanh Fuzzy General Grey Cognitive Maps,"Fuzzy General Grey Cognitive Map (FGGCM) and Fuzzy Grey Cognitive Map (FGCM)
are extensions of Fuzzy Cognitive Map (FCM) in terms of uncertainty. FGGCM
allows for the processing of general grey number with multiple intervals,
enabling FCM to better address uncertain situations. Although the convergence
of FCM and FGCM has been discussed in many literature, the convergence of FGGCM
has not been thoroughly explored. This paper aims to fill this research gap.
First, metrics for the general grey number space and its vector space is given
and proved using the Minkowski inequality. By utilizing the characteristic that
Cauchy sequences are convergent sequences, the completeness of these two space
is demonstrated. On this premise, utilizing Banach fixed point theorem and
Browder-Gohde-Kirk fixed point theorem, combined with Lagrange's mean value
theorem and Cauchy's inequality, deduces the sufficient conditions for FGGCM to
converge to a unique fixed point when using tanh and sigmoid functions as
activation functions. The sufficient conditions for the kernels and greyness of
FGGCM to converge to a unique fixed point are also provided separately.
Finally, based on Web Experience and Civil engineering FCM, designed
corresponding FGGCM with sigmoid and tanh as activation functions by modifying
the weights to general grey numbers. By comparing with the convergence theorems
of FCM and FGCM, the effectiveness of the theorems proposed in this paper was
verified. It was also demonstrated that the convergence theorems of FCM are
special cases of the theorems proposed in this paper. The study for convergence
of FGGCM is of great significance for guiding the learning algorithm of FGGCM,
which is needed for designing FGGCM with specific fixed points, lays a solid
theoretical foundation for the application of FGGCM in fields such as control,
prediction, and decision support systems.",2024-09-09 12:46:03+00:00
LEROjD: Lidar Extended Radar-Only Object Detection,"Accurate 3D object detection is vital for automated driving. While lidar
sensors are well suited for this task, they are expensive and have limitations
in adverse weather conditions. 3+1D imaging radar sensors offer a
cost-effective, robust alternative but face challenges due to their low
resolution and high measurement noise. Existing 3+1D imaging radar datasets
include radar and lidar data, enabling cross-modal model improvements. Although
lidar should not be used during inference, it can aid the training of
radar-only object detectors. We explore two strategies to transfer knowledge
from the lidar to the radar domain and radar-only object detectors: 1.
multi-stage training with sequential lidar point cloud thin-out, and 2.
cross-modal knowledge distillation. In the multi-stage process, three thin-out
methods are examined. Our results show significant performance gains of up to
4.2 percentage points in mean Average Precision with multi-stage training and
up to 3.9 percentage points with knowledge distillation by initializing the
student with the teacher's weights. The main benefit of these approaches is
their applicability to other 3D object detection networks without altering
their architecture, as we show by analyzing it on two different object
detectors. Our code is available at https://github.com/rst-tu-dortmund/lerojd",2024-09-09 12:43:25+00:00
CauseJudger: Identifying the Cause with LLMs for Abductive Logical Reasoning,"Large language models (LLMs) have been utilized in solving diverse reasoning
tasks, encompassing common sense, arithmetic and deduction tasks. However, with
difficulties of reversing thinking patterns and irrelevant premises, how to
determine the authenticity of the cause in abductive logical reasoning remains
underexplored. Inspired by hypothesis and verification method and
identification of irrelevant information in human thinking process, we propose
a new framework for LLMs abductive logical reasoning called CauseJudger (CJ),
which identifies the authenticity of possible cause by transforming thinking
from reverse to forward and removing irrelevant information. In addition, we
construct an abductive logical reasoning dataset for decision task called
CauseLogics, which contains 200,000 tasks of varying reasoning lengths. Our
experiments show the efficiency of CJ with overall experiments and ablation
experiments as well as case studies on our dataset and reconstructed public
dataset. Notably, CJ's implementation is efficient, requiring only two calls to
LLM. Its impact is profound: when using gpt-3.5, CJ achieves a maximum
correctness improvement of 41% compared to Zero-Shot-CoT. Moreover, with gpt-4,
CJ attains an accuracy exceeding 90% across all datasets.",2024-09-09 12:30:43+00:00
Seeing Through the Mask: Rethinking Adversarial Examples for CAPTCHAs,"Modern CAPTCHAs rely heavily on vision tasks that are supposedly hard for
computers but easy for humans. However, advances in image recognition models
pose a significant threat to such CAPTCHAs. These models can easily be fooled
by generating some well-hidden ""random"" noise and adding it to the image, or
hiding objects in the image. However, these methods are model-specific and thus
can not aid CAPTCHAs in fooling all models. We show in this work that by
allowing for more significant changes to the images while preserving the
semantic information and keeping it solvable by humans, we can fool many
state-of-the-art models. Specifically, we demonstrate that by adding masks of
various intensities the Accuracy @ 1 (Acc@1) drops by more than 50%-points for
all models, and supposedly robust models such as vision transformers see an
Acc@1 drop of 80%-points.
  These masks can therefore effectively fool modern image classifiers, thus
showing that machines have not caught up with humans -- yet.",2024-09-09 12:29:53+00:00
SciAgents: Automating scientific discovery through multi-agent intelligent graph reasoning,"A key challenge in artificial intelligence is the creation of systems capable
of autonomously advancing scientific understanding by exploring novel domains,
identifying complex patterns, and uncovering previously unseen connections in
vast scientific data. In this work, we present SciAgents, an approach that
leverages three core concepts: (1) the use of large-scale ontological knowledge
graphs to organize and interconnect diverse scientific concepts, (2) a suite of
large language models (LLMs) and data retrieval tools, and (3) multi-agent
systems with in-situ learning capabilities. Applied to biologically inspired
materials, SciAgents reveals hidden interdisciplinary relationships that were
previously considered unrelated, achieving a scale, precision, and exploratory
power that surpasses traditional human-driven research methods. The framework
autonomously generates and refines research hypotheses, elucidating underlying
mechanisms, design principles, and unexpected material properties. By
integrating these capabilities in a modular fashion, the intelligent system
yields material discoveries, critique and improve existing hypotheses, retrieve
up-to-date data about existing research, and highlights their strengths and
limitations. Our case studies demonstrate scalable capabilities to combine
generative AI, ontological representations, and multi-agent modeling,
harnessing a `swarm of intelligence' similar to biological systems. This
provides new avenues for materials discovery and accelerates the development of
advanced materials by unlocking Nature's design principles.",2024-09-09 12:25:10+00:00
Seeing is Believing? Enhancing Vision-Language Navigation using Visual Perturbations,"Autonomous navigation for an embodied agent guided by natural language
instructions remains a formidable challenge in vision-and-language navigation
(VLN). Despite remarkable recent progress in learning fine-grained and
multifarious visual representations, the tendency to overfit to the training
environments leads to unsatisfactory generalization performance. In this work,
we present a versatile Multi-Branch Architecture (MBA) aimed at exploring and
exploiting diverse visual inputs. Specifically, we introduce three distinct
visual variants: ground-truth depth images, visual inputs integrated with
incongruent views, and those infused with random noise to enrich the diversity
of visual input representation and prevent overfitting to the original RGB
observations. To adaptively fuse these varied inputs, the proposed MBA extend a
base agent model into a multi-branch variant, where each branch processes a
different visual input. Surprisingly, even random noise can further enhance
navigation performance in unseen environments. Extensive experiments conducted
on three VLN benchmarks (R2R, REVERIE, SOON) demonstrate that our proposed
method equals or even surpasses state-of-the-art results. The source code will
be publicly available.",2024-09-09 12:17:38+00:00
Exploring Rich Subjective Quality Information for Image Quality Assessment in the Wild,"Traditional in the wild image quality assessment (IQA) models are generally
trained with the quality labels of mean opinion score (MOS), while missing the
rich subjective quality information contained in the quality ratings, for
example, the standard deviation of opinion scores (SOS) or even distribution of
opinion scores (DOS). In this paper, we propose a novel IQA method named
RichIQA to explore the rich subjective rating information beyond MOS to predict
image quality in the wild. RichIQA is characterized by two key novel designs:
(1) a three-stage image quality prediction network which exploits the powerful
feature representation capability of the Convolutional vision Transformer (CvT)
and mimics the short-term and long-term memory mechanisms of human brain; (2) a
multi-label training strategy in which rich subjective quality information like
MOS, SOS and DOS are concurrently used to train the quality prediction network.
Powered by these two novel designs, RichIQA is able to predict the image
quality in terms of a distribution, from which the mean image quality can be
subsequently obtained. Extensive experimental results verify that the
three-stage network is tailored to predict rich quality information, while the
multi-label training strategy can fully exploit the potentials within
subjective quality rating and enhance the prediction performance and
generalizability of the network. RichIQA outperforms state-of-the-art
competitors on multiple large-scale in the wild IQA databases with rich
subjective rating labels. The code of RichIQA will be made publicly available
on GitHub.",2024-09-09 12:00:17+00:00
CoBo: Collaborative Learning via Bilevel Optimization,"Collaborative learning is an important tool to train multiple clients more
effectively by enabling communication among clients. Identifying helpful
clients, however, presents challenging and often introduces significant
overhead. In this paper, we model client-selection and model-training as two
interconnected optimization problems, proposing a novel bilevel optimization
problem for collaborative learning. We introduce CoBo, a scalable and elastic,
SGD-type alternating optimization algorithm that efficiently addresses these
problem with theoretical convergence guarantees. Empirically, CoBo achieves
superior performance, surpassing popular personalization algorithms by 9.3% in
accuracy on a task with high heterogeneity, involving datasets distributed
among 80 clients.",2024-09-09 11:59:42+00:00
HMAFlow: Learning More Accurate Optical Flow via Hierarchical Motion Field Alignment,"Optical flow estimation is a fundamental and long-standing visual task. In
this work, we present a novel method, dubbed HMAFlow, to improve optical flow
estimation in these tough scenes, especially with small objects. The proposed
model mainly consists of two core components: a Hierarchical Motion Field
Alignment (HMA) module and a Correlation Self-Attention (CSA) module. In
addition, we rebuild 4D cost volumes by employing a Multi-Scale Correlation
Search (MCS) layer and replacing average pooling in common cost volumes with an
search strategy using multiple search ranges. Experimental results demonstrate
that our model achieves the best generalization performance in comparison to
other state-of-the-art methods. Specifically, compared with RAFT, our method
achieves relative error reductions of 14.2% and 3.4% on the clean pass and
final pass of the Sintel online benchmark, respectively. On the KITTI test
benchmark, HMAFlow surpasses RAFT and GMA in the Fl-all metric by a relative
margin of 6.8% and 7.7%, respectively. To facilitate future research, our code
will be made available at https://github.com/BooTurbo/HMAFlow.",2024-09-09 11:43:35+00:00
An encoding of argumentation problems using quadratic unconstrained binary optimization,"In this paper, we develop a way to encode several NP-Complete problems in
Abstract Argumentation to Quadratic Unconstrained Binary Optimization (QUBO)
problems. In this form, a solution for a QUBO problem involves minimizing a
quadratic function over binary variables (0/1), where the coefficients can be
represented by a symmetric square matrix (or an equivalent upper triangular
version). With the QUBO formulation, exploiting new computing architectures,
such as Quantum and Digital Annealers, is possible. A more conventional
approach consists of developing approximate solvers, which, in this case, are
used to tackle the intrinsic complexity. We performed tests to prove the
correctness and applicability of classical problems in Argumentation and
enforcement of argument sets. We compared our approach to two other approximate
solvers in the literature during tests. In the final experimentation, we used a
Simulated Annealing algorithm on a local machine. Also, we tested a Quantum
Annealer from the D-Wave Ocean SDK and the Leap Quantum Cloud Service.",2024-09-09 11:29:46+00:00
Harmonic Reasoning in Large Language Models,"Large Language Models (LLMs) are becoming very popular and are used for many
different purposes, including creative tasks in the arts. However, these models
sometimes have trouble with specific reasoning tasks, especially those that
involve logical thinking and counting. This paper looks at how well LLMs
understand and reason when dealing with musical tasks like figuring out notes
from intervals and identifying chords and scales. We tested GPT-3.5 and GPT-4o
to see how they handle these tasks. Our results show that while LLMs do well
with note intervals, they struggle with more complicated tasks like recognizing
chords and scales. This points out clear limits in current LLM abilities and
shows where we need to make them better, which could help improve how they
think and work in both artistic and other complex areas. We also provide an
automatically generated benchmark data set for the described tasks.",2024-09-09 11:28:02+00:00
"Interpolation, Extrapolation, Hyperpolation: Generalising into new dimensions","This paper introduces the concept of hyperpolation: a way of generalising
from a limited set of data points that is a peer to the more familiar concepts
of interpolation and extrapolation. Hyperpolation is the task of estimating the
value of a function at new locations that lie outside the subspace (or
manifold) of the existing data. We shall see that hyperpolation is possible and
explore its links to creativity in the arts and sciences. We will also examine
the role of hyperpolation in machine learning and suggest that the lack of
fundamental creativity in current AI systems is deeply connected to their
limited ability to hyperpolate.",2024-09-09 11:13:32+00:00
A general reduced-order neural operator for spatio-temporal predictive learning on complex spatial domains,"Predictive learning for spatio-temporal processes (PL-STP) on complex spatial
domains plays a critical role in various scientific and engineering fields,
with its essence being the construction of operators between
infinite-dimensional function spaces. This paper focuses on the unequal-domain
mappings in PL-STP and categorising them into increase-domain and
decrease-domain mapping. Recent advances in deep learning have revealed the
great potential of neural operators (NOs) to learn operators directly from
observational data. However, existing NOs require input space and output space
to be the same domain, which pose challenges in ensuring predictive accuracy
and stability for unequal-domain mappings. To this end, this study presents a
general reduced-order neural operator named Reduced-Order Neural Operator on
Riemannian Manifolds (RO-NORM), which consists of two parts: the unequal-domain
encoder/decoder and the same-domain approximator. Motivated by the variable
separation in classical modal decomposition, the unequal-domain encoder/decoder
uses the pre-computed bases to reformulate the spatio-temporal function as a
sum of products between spatial (or temporal) bases and corresponding
temporally (or spatially) distributed weight functions, thus the original
unequal-domain mapping can be converted into a same-domain mapping.
Consequently, the same-domain approximator NORM is applied to model the
transformed mapping. The performance of our proposed method has been evaluated
on six benchmark cases, including parametric PDEs, engineering and biomedical
applications, and compared with four baseline algorithms: DeepONet,
POD-DeepONet, PCA-Net, and vanilla NORM. The experimental results demonstrate
the superiority of RO-NORM in prediction accuracy and training efficiency for
PL-STP.",2024-09-09 11:02:27+00:00
Optimizing VarLiNGAM for Scalable and Efficient Time Series Causal Discovery,"Causal discovery is designed to identify causal relationships in data, a task
that has become increasingly complex due to the computational demands of
traditional methods such as VarLiNGAM, which combines Vector Autoregressive
Model with Linear Non-Gaussian Acyclic Model for time series data.
  This study is dedicated to optimising causal discovery specifically for time
series data, which is common in practical applications. Time series causal
discovery is particularly challenging due to the need to account for temporal
dependencies and potential time lag effects. By designing a specialised dataset
generator and reducing the computational complexity of the VarLiNGAM model from
\( O(m^3 \cdot n) \) to \( O(m^3 + m^2 \cdot n) \), this study significantly
improves the feasibility of processing large datasets. The proposed methods
have been validated on advanced computational platforms and tested across
simulated, real-world, and large-scale datasets, showcasing enhanced efficiency
and performance. The optimised algorithm achieved 7 to 13 times speedup
compared with the original algorithm and around 4.5 times speedup compared with
the GPU-accelerated version on large-scale datasets with feature sizes between
200 and 400.
  Our methods aim to push the boundaries of current causal discovery
capabilities, making them more robust, scalable, and applicable to real-world
scenarios, thus facilitating breakthroughs in various fields such as healthcare
and finance.",2024-09-09 10:52:58+00:00
Using machine learning for fault detection in lighthouse light sensors,"Lighthouses play a crucial role in ensuring maritime safety by signaling
hazardous areas such as dangerous coastlines, shoals, reefs, and rocks, along
with aiding harbor entries and aerial navigation. This is achieved through the
use of photoresistor sensors that activate or deactivate based on the time of
day. However, a significant issue is the potential malfunction of these
sensors, leading to the gradual misalignment of the light's operational timing.
This paper introduces an innovative machine learning-based approach for
automatically detecting such malfunctions. We evaluate four distinct
algorithms: decision trees, random forest, extreme gradient boosting, and
multi-layer perceptron. Our findings indicate that the multi-layer perceptron
is the most effective, capable of detecting timing discrepancies as small as
10-15 minutes. This accuracy makes it a highly efficient tool for automating
the detection of faults in lighthouse light sensors.",2024-09-09 10:47:41+00:00
An Atmospheric Correction Integrated LULC Segmentation Model for High-Resolution Satellite Imagery,"The integration of fine-scale multispectral imagery with deep learning models
has revolutionized land use and land cover (LULC) classification. However, the
atmospheric effects present in Top-of-Atmosphere sensor measured Digital Number
values must be corrected to retrieve accurate Bottom-of-Atmosphere surface
reflectance for reliable analysis. This study employs look-up-table-based
radiative transfer simulations to estimate the atmospheric path reflectance and
transmittance for atmospherically correcting high-resolution CARTOSAT-3
Multispectral (MX) imagery for several Indian cities. The corrected surface
reflectance data were subsequently used in supervised and semi-supervised
segmentation models, demonstrating stability in multi-class (buildings, roads,
trees and water bodies) LULC segmentation accuracy, particularly in scenarios
with sparsely labelled data.",2024-09-09 10:47:39+00:00
Alt-MoE: Multimodal Alignment via Alternating Optimization of Multi-directional MoE with Unimodal Models,"Recent Large Multi-Modal Models (LMMs) have made significant advancements in
multi-modal alignment by employing lightweight connection modules to facilitate
the representation and fusion of knowledge from existing pre-trained uni-modal
models. However, these methods still rely on modality-specific and
direction-specific connectors, leading to compartmentalized knowledge
representations and reduced computational efficiency, which limits the model's
ability to form unified multi-modal representations. To address these issues,
we introduce a novel training framework, Alt-MoE, which employs the Mixture of
Experts (MoE) as a unified multi-directional connector across modalities, and
employs a multi-step sequential alternating unidirectional alignment strategy,
which converges to bidirectional alignment over iterations. The extensive
empirical studies revealed the following key points: 1) Alt-MoE achieves
competitive results by integrating diverse knowledge representations from
uni-modal models. This approach seamlessly fuses the specialized expertise of
existing high-performance uni-modal models, effectively synthesizing their
domain-specific knowledge into a cohesive multi-modal representation. 2)
Alt-MoE efficiently scales to new tasks and modalities without altering its
model architecture or training strategy. Furthermore, Alt-MoE operates in
latent space, supporting vector pre-storage and real-time retrieval via
lightweight multi-directional MoE, thereby facilitating massive data
processing. Our methodology has been validated on several well-performing
uni-modal models (LLAMA3, Qwen2, and DINOv2), achieving competitive results on
a wide range of downstream tasks and datasets.",2024-09-09 10:40:50+00:00
A Taxonomy of Miscompressions: Preparing Image Forensics for Neural Compression,"Neural compression has the potential to revolutionize lossy image
compression. Based on generative models, recent schemes achieve unprecedented
compression rates at high perceptual quality but compromise semantic fidelity.
Details of decompressed images may appear optically flawless but semantically
different from the originals, making compression errors difficult or impossible
to detect. We explore the problem space and propose a provisional taxonomy of
miscompressions. It defines three types of 'what happens' and has a binary
'high impact' flag indicating miscompressions that alter symbols. We discuss
how the taxonomy can facilitate risk communication and research into
mitigations.",2024-09-09 10:36:19+00:00
Elsevier Arena: Human Evaluation of Chemistry/Biology/Health Foundational Large Language Models,"The quality and capabilities of large language models cannot be currently
fully assessed with automated, benchmark evaluations. Instead, human
evaluations that expand on traditional qualitative techniques from natural
language generation literature are required. One recent best-practice consists
in using A/B-testing frameworks, which capture preferences of human evaluators
for specific models. In this paper we describe a human evaluation experiment
focused on the biomedical domain (health, biology, chemistry/pharmacology)
carried out at Elsevier. In it a large but not massive (8.8B parameter)
decoder-only foundational transformer trained on a relatively small (135B
tokens) but highly curated collection of Elsevier datasets is compared to
OpenAI's GPT-3.5-turbo and Meta's foundational 7B parameter Llama 2 model
against multiple criteria. Results indicate -- even if IRR scores were
generally low -- a preference towards GPT-3.5-turbo, and hence towards models
that possess conversational abilities, are very large and were trained on very
large datasets. But at the same time, indicate that for less massive models
training on smaller but well-curated training sets can potentially give rise to
viable alternatives in the biomedical domain.",2024-09-09 10:30:00+00:00
CRADLE-VAE: Enhancing Single-Cell Gene Perturbation Modeling with Counterfactual Reasoning-based Artifact Disentanglement,"Predicting cellular responses to various perturbations is a critical focus in
drug discovery and personalized therapeutics, with deep learning models playing
a significant role in this endeavor. Single-cell datasets contain technical
artifacts that may hinder the predictability of such models, which poses
quality control issues highly regarded in this area. To address this, we
propose CRADLE-VAE, a causal generative framework tailored for single-cell gene
perturbation modeling, enhanced with counterfactual reasoning-based artifact
disentanglement. Throughout training, CRADLE-VAE models the underlying latent
distribution of technical artifacts and perturbation effects present in
single-cell datasets. It employs counterfactual reasoning to effectively
disentangle such artifacts by modulating the latent basal spaces and learns
robust features for generating cellular response data with improved quality.
Experimental results demonstrate that this approach improves not only treatment
effect estimation performance but also generative quality as well. The
CRADLE-VAE codebase is publicly available at
https://github.com/dmis-lab/CRADLE-VAE.",2024-09-09 10:29:28+00:00
Advancing Machine Learning for Stellar Activity and Exoplanet Period Rotation,"This study applied machine learning models to estimate stellar rotation
periods from corrected light curve data obtained by the NASA Kepler mission.
Traditional methods often struggle to estimate rotation periods accurately due
to noise and variability in the light curve data. The workflow involved using
initial period estimates from the LS-Periodogram and Transit Least Squares
techniques, followed by splitting the data into training, validation, and
testing sets. We employed several machine learning algorithms, including
Decision Tree, Random Forest, K-Nearest Neighbors, and Gradient Boosting, and
also utilized a Voting Ensemble approach to improve prediction accuracy and
robustness.
  The analysis included data from multiple Kepler IDs, providing detailed
metrics on orbital periods and planet radii. Performance evaluation showed that
the Voting Ensemble model yielded the most accurate results, with an RMSE
approximately 50\% lower than the Decision Tree model and 17\% better than the
K-Nearest Neighbors model. The Random Forest model performed comparably to the
Voting Ensemble, indicating high accuracy. In contrast, the Gradient Boosting
model exhibited a worse RMSE compared to the other approaches. Comparisons of
the predicted rotation periods to the photometric reference periods showed
close alignment, suggesting the machine learning models achieved high
prediction accuracy. The results indicate that machine learning, particularly
ensemble methods, can effectively solve the problem of accurately estimating
stellar rotation periods, with significant implications for advancing the study
of exoplanets and stellar astrophysics.",2024-09-09 10:25:13+00:00
Retrofitting Temporal Graph Neural Networks with Transformer,"Temporal graph neural networks (TGNNs) outperform regular GNNs by
incorporating time information into graph-based operations. However, TGNNs
adopt specialized models (e.g., TGN, TGAT, and APAN ) and require tailored
training frameworks (e.g., TGL and ETC). In this paper, we propose TF-TGN,
which uses Transformer decoder as the backbone model for TGNN to enjoy
Transformer's codebase for efficient training. In particular, Transformer
achieves tremendous success for language modeling, and thus the community
developed high-performance kernels (e.g., flash-attention and memory-efficient
attention) and efficient distributed training schemes (e.g., PyTorch FSDP,
DeepSpeed, and Megatron-LM). We observe that TGNN resembles language modeling,
i.e., the message aggregation operation between chronologically occurring nodes
and their temporal neighbors in TGNNs can be structured as sequence modeling.
Beside this similarity, we also incorporate a series of algorithm designs
including suffix infilling, temporal graph attention with self-loop, and causal
masking self-attention to make TF-TGN work. During training, existing systems
are slow in transforming the graph topology and conducting graph sampling. As
such, we propose methods to parallelize the CSR format conversion and graph
sampling. We also adapt Transformer codebase to train TF-TGN efficiently with
multiple GPUs. We experiment with 9 graphs and compare with 2 state-of-the-art
TGNN training frameworks. The results show that TF-TGN can accelerate training
by over 2.20 while providing comparable or even superior accuracy to existing
SOTA TGNNs. TF-TGN is available at https://github.com/qianghuangwhu/TF-TGN.",2024-09-09 10:11:25+00:00
Reinforcement Learning for Variational Quantum Circuits Design,"Variational Quantum Algorithms have emerged as promising tools for solving
optimization problems on quantum computers. These algorithms leverage a
parametric quantum circuit called ansatz, where its parameters are adjusted by
a classical optimizer with the goal of optimizing a certain cost function.
However, a significant challenge lies in designing effective circuits for
addressing specific problems. In this study, we leverage the powerful and
flexible Reinforcement Learning paradigm to train an agent capable of
autonomously generating quantum circuits that can be used as ansatzes in
variational algorithms to solve optimization problems. The agent is trained on
diverse problem instances, including Maximum Cut, Maximum Clique and Minimum
Vertex Cover, built from different graph topologies and sizes. Our analysis of
the circuits generated by the agent and the corresponding solutions shows that
the proposed method is able to generate effective ansatzes. While our goal is
not to propose any new specific ansatz, we observe how the agent has discovered
a novel family of ansatzes effective for Maximum Cut problems, which we call
$R_{yz}$-connected. We study the characteristics of one of these ansatzes by
comparing it against state-of-the-art quantum algorithms across instances of
varying graph topologies, sizes, and problem types. Our results indicate that
the $R_{yz}$-connected circuit achieves high approximation ratios for Maximum
Cut problems, further validating our proposed agent. In conclusion, our study
highlights the potential of Reinforcement Learning techniques in assisting
researchers to design effective quantum circuits which could have applications
in a wide number of tasks.",2024-09-09 10:07:12+00:00
PVP-Recon: Progressive View Planning via Warping Consistency for Sparse-View Surface Reconstruction,"Neural implicit representations have revolutionized dense multi-view surface
reconstruction, yet their performance significantly diminishes with sparse
input views. A few pioneering works have sought to tackle the challenge of
sparse-view reconstruction by leveraging additional geometric priors or
multi-scene generalizability. However, they are still hindered by the imperfect
choice of input views, using images under empirically determined viewpoints to
provide considerable overlap. We propose PVP-Recon, a novel and effective
sparse-view surface reconstruction method that progressively plans the next
best views to form an optimal set of sparse viewpoints for image capturing.
PVP-Recon starts initial surface reconstruction with as few as 3 views and
progressively adds new views which are determined based on a novel warping
score that reflects the information gain of each newly added view. This
progressive view planning progress is interleaved with a neural SDF-based
reconstruction module that utilizes multi-resolution hash features, enhanced by
a progressive training scheme and a directional Hessian loss. Quantitative and
qualitative experiments on three benchmark datasets show that our framework
achieves high-quality reconstruction with a constrained input budget and
outperforms existing baselines.",2024-09-09 10:06:34+00:00
Proto-OOD: Enhancing OOD Object Detection with Prototype Feature Similarity,"The limited training samples for object detectors commonly result in low
accuracy out-of-distribution (OOD) object detection. We have observed that
feature vectors of the same class tend to cluster tightly in feature space,
whereas those of different classes are more scattered. This insight motivates
us to leverage feature similarity for OOD detection. Drawing on the concept of
prototypes prevalent in few-shot learning, we introduce a novel network
architecture, Proto-OOD, designed for this purpose. Proto-OOD enhances
prototype representativeness through contrastive loss and identifies OOD data
by assessing the similarity between input features and prototypes. It employs a
negative embedding generator to create negative embedding, which are then used
to train the similarity module. Proto-OOD achieves significantly lower FPR95 in
MS-COCO dataset and higher mAP for Pascal VOC dataset, when utilizing Pascal
VOC as ID dataset and MS-COCO as OOD dataset. Additionally, we identify
limitations in existing evaluation metrics and propose an enhanced evaluation
protocol.",2024-09-09 09:48:27+00:00
DriveScape: Towards High-Resolution Controllable Multi-View Driving Video Generation,"Recent advancements in generative models have provided promising solutions
for synthesizing realistic driving videos, which are crucial for training
autonomous driving perception models. However, existing approaches often
struggle with multi-view video generation due to the challenges of integrating
3D information while maintaining spatial-temporal consistency and effectively
learning from a unified model. We propose DriveScape, an end-to-end framework
for multi-view, 3D condition-guided video generation, capable of producing 1024
x 576 high-resolution videos at 10Hz. Unlike other methods limited to 2Hz due
to the 3D box annotation frame rate, DriveScape overcomes this with its ability
to operate under sparse conditions. Our Bi-Directional Modulated Transformer
(BiMot) ensures precise alignment of 3D structural information, maintaining
spatial-temporal consistency. DriveScape excels in video generation
performance, achieving state-of-the-art results on the nuScenes dataset with an
FID score of 8.34 and an FVD score of 76.39. Our project homepage:
https://metadrivescape.github.io/papers_project/drivescapev1/index.html",2024-09-09 09:43:17+00:00
Beyond Flatland: A Geometric Take on Matching Methods for Treatment Effect Estimation,"Matching is a popular approach in causal inference to estimate treatment
effects by pairing treated and control units that are most similar in terms of
their covariate information. However, classic matching methods completely
ignore the geometry of the data manifold, which is crucial to define a
meaningful distance for matching, and struggle when covariates are noisy and
high-dimensional. In this work, we propose GeoMatching, a matching method to
estimate treatment effects that takes into account the intrinsic data geometry
induced by existing causal mechanisms among the confounding variables. First,
we learn a low-dimensional, latent Riemannian manifold that accounts for
uncertainty and geometry of the original input data. Second, we estimate
treatment effects via matching in the latent space based on the learned latent
Riemannian metric. We provide theoretical insights and empirical results in
synthetic and real-world scenarios, demonstrating that GeoMatching yields more
effective treatment effect estimators, even as we increase input
dimensionality, in the presence of outliers, or in semi-supervised scenarios.",2024-09-09 09:39:47+00:00
Visualizing Extensions of Argumentation Frameworks as Layered Graphs,"The visualization of argumentation frameworks (AFs) is crucial for enabling a
wide applicability of argumentative tools. However, their visualization is
often considered only as an accompanying part of tools for computing semantics
and standard graphical representations are used. We introduce a new
visualization technique that draws an AF, together with an extension (as part
of the input), as a 3-layer graph layout. Our technique supports the user to
more easily explore the visualized AF, better understand extensions, and verify
algorithms for computing semantics. To optimize the visual clarity and
aesthetics of this layout, we propose to minimize edge crossings in our 3-layer
drawing. We do so by an exact ILP-based approach, but also propose a fast
heuristic pipeline. Via a quantitative evaluation, we show that the heuristic
is feasible even for large instances, while producing at most twice as many
crossings as an optimal drawing in most cases.",2024-09-09 09:29:53+00:00
Machine Learning Based Optimal Design of Fibrillar Adhesives,"Fibrillar adhesion, observed in animals like beetles, spiders, and geckos,
relies on nanoscopic or microscopic fibrils to enhance surface adhesion via
'contact splitting.' This concept has inspired engineering applications across
robotics, transportation, and medicine. Recent studies suggest that functional
grading of fibril properties can improve adhesion, but this is a complex design
challenge that has only been explored in simplified geometries. While machine
learning (ML) has gained traction in adhesive design, no previous attempts have
targeted fibril-array scale optimization. In this study, we propose an ML-based
tool that optimizes the distribution of fibril compliance to maximize adhesive
strength. Our tool, featuring two deep neural networks (DNNs), recovers
previous design results for simple geometries and introduces novel solutions
for complex configurations. The Predictor DNN estimates adhesive strength based
on random compliance distributions, while the Designer DNN optimizes compliance
for maximum strength using gradient-based optimization. Our method
significantly reduces test error and accelerates the optimization process,
offering a high-performance solution for designing fibrillar adhesives and
micro-architected materials aimed at fracture resistance by achieving equal
load sharing (ELS).",2024-09-09 09:26:48+00:00
Validation of Practicality for CSI Sensing Utilizing Machine Learning,"In this study, we leveraged Channel State Information (CSI), commonly
utilized in WLAN communication, as training data to develop and evaluate five
distinct machine learning models for recognizing human postures: standing,
sitting, and lying down. The models we employed were: (i) Linear Discriminant
Analysis, (ii) Naive Bayes-Support Vector Machine, (iii) Kernel-Support Vector
Machine, (iv) Random Forest, and (v) Deep Learning. We systematically analyzed
how the accuracy of these models varied with different amounts of training
data. Additionally, to assess their spatial generalization capabilities, we
evaluated the models' performance in a setting distinct from the one used for
data collection. The experimental findings indicated that while two models --
(ii) Naive Bayes-Support Vector Machine and (v) Deep Learning -- achieved 85%
or more accuracy in the original setting, their accuracy dropped to
approximately 30% when applied in a different environment. These results
underscore that although CSI-based machine learning models can attain high
accuracy within a consistent spatial structure, their performance diminishes
considerably with changes in spatial conditions, highlighting a significant
challenge in their generalization capabilities.",2024-09-09 09:25:08+00:00
EndoOmni: Zero-Shot Cross-Dataset Depth Estimation in Endoscopy by Robust Self-Learning from Noisy Labels,"Single-image depth estimation is essential for endoscopy tasks such as
localization, reconstruction, and augmented reality. Most existing methods in
surgical scenes focus on in-domain depth estimation, limiting their real-world
applicability. This constraint stems from the scarcity and inferior labeling
quality of medical data for training. In this work, we present EndoOmni, the
first foundation model for zero-shot cross-domain depth estimation for
endoscopy. To harness the potential of diverse training data, we refine the
advanced self-learning paradigm that employs a teacher model to generate
pseudo-labels, guiding a student model trained on large-scale labeled and
unlabeled data. To address training disturbance caused by inherent noise in
depth labels, we propose a robust training framework that leverages both depth
labels and estimated confidence from the teacher model to jointly guide the
student model training. Moreover, we propose a weighted scale-and-shift
invariant loss to adaptively adjust learning weights based on label confidence,
thus imposing learning bias towards cleaner label pixels while reducing the
influence of highly noisy pixels. Experiments on zero-shot relative depth
estimation show that our EndoOmni improves state-of-the-art methods in medical
imaging for 41\% and existing foundation models for 25\% in terms of absolute
relative error on specific dataset. Furthermore, our model provides strong
initialization for fine-tuning to metric depth estimation, maintaining superior
performance in both in-domain and out-of-domain scenarios. The source code will
be publicly available.",2024-09-09 08:46:45+00:00
SVFit: Parameter-Efficient Fine-Tuning of Large Pre-Trained Models Using Singular Values,"Large pre-trained models (LPMs) have demonstrated exceptional performance in
diverse natural language processing and computer vision tasks. However, fully
fine-tuning these models poses substantial memory challenges, particularly in
resource-constrained environments. Parameter-efficient fine-tuning (PEFT)
methods, such as LoRA, mitigate this issue by adjusting only a small subset of
parameters. Nevertheless, these methods typically employ random initialization
for low-rank matrices, which can lead to inefficiencies in gradient descent and
diminished generalizability due to suboptimal starting points. To address these
limitations, we propose SVFit, a novel PEFT approach that leverages singular
value decomposition (SVD) to initialize low-rank matrices using critical
singular values as trainable parameters. Specifically, SVFit performs SVD on
the pre-trained weight matrix to obtain the best rank-r approximation matrix,
emphasizing the most critical singular values that capture over 99% of the
matrix's information. These top-r singular values are then used as trainable
parameters to scale the fundamental subspaces of the matrix, facilitating rapid
domain adaptation. Extensive experiments across various pre-trained models in
natural language understanding, text-to-image generation, and image
classification tasks reveal that SVFit outperforms LoRA while requiring 16
times fewer trainable parameters.",2024-09-09 08:44:53+00:00
Semifactual Explanations for Reinforcement Learning,"Reinforcement Learning (RL) is a learning paradigm in which the agent learns
from its environment through trial and error. Deep reinforcement learning (DRL)
algorithms represent the agent's policies using neural networks, making their
decisions difficult to interpret. Explaining the behaviour of DRL agents is
necessary to advance user trust, increase engagement, and facilitate
integration with real-life tasks. Semifactual explanations aim to explain an
outcome by providing ""even if"" scenarios, such as ""even if the car were moving
twice as slowly, it would still have to swerve to avoid crashing"". Semifactuals
help users understand the effects of different factors on the outcome and
support the optimisation of resources. While extensively studied in psychology
and even utilised in supervised learning, semifactuals have not been used to
explain the decisions of RL systems. In this work, we develop a first approach
to generating semifactual explanations for RL agents. We start by defining five
properties of desirable semifactual explanations in RL and then introducing
SGRL-Rewind and SGRL-Advance, the first algorithms for generating semifactual
explanations in RL. We evaluate the algorithms in two standard RL environments
and find that they generate semifactuals that are easier to reach, represent
the agent's policy better, and are more diverse compared to baselines. Lastly,
we conduct and analyse a user study to assess the participant's perception of
semifactual explanations of the agent's actions.",2024-09-09 08:37:47+00:00
State-Novelty Guided Action Persistence in Deep Reinforcement Learning,"While a powerful and promising approach, deep reinforcement learning (DRL)
still suffers from sample inefficiency, which can be notably improved by
resorting to more sophisticated techniques to address the
exploration-exploitation dilemma. One such technique relies on action
persistence (i.e., repeating an action over multiple steps). However, previous
work exploiting action persistence either applies a fixed strategy or learns
additional value functions (or policy) for selecting the repetition number. In
this paper, we propose a novel method to dynamically adjust the action
persistence based on the current exploration status of the state space. In such
a way, our method does not require training of additional value functions or
policy. Moreover, the use of a smooth scheduling of the repeat probability
allows a more effective balance between exploration and exploitation.
Furthermore, our method can be seamlessly integrated into various basic
exploration strategies to incorporate temporal persistence. Finally, extensive
experiments on different DMControl tasks demonstrate that our state-novelty
guided action persistence method significantly improves the sample efficiency.",2024-09-09 08:34:22+00:00
Assessing SPARQL capabilities of Large Language Models,"The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs)
offers significant synergistic potential for knowledge-driven applications. One
possible integration is the interpretation and generation of formal languages,
such as those used in the Semantic Web, with SPARQL being a core technology for
accessing KGs. In this paper, we focus on measuring out-of-the box capabilities
of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries
applying a quantitative approach.
  We implemented various benchmarking tasks in the LLM-KG-Bench framework for
automated execution and evaluation with several LLMs. The tasks assess
capabilities along the dimensions of syntax, semantic read, semantic create,
and the role of knowledge graph prompt inclusion.
  With this new benchmarking tasks, we evaluated a selection of GPT, Gemini,
and Claude models. Our findings indicate that working with SPARQL SELECT
queries is still challenging for LLMs and heavily depends on the specific LLM
as well as the complexity of the task. While fixing basic syntax errors seems
to pose no problems for the best of the current LLMs evaluated, creating
semantically correct SPARQL SELECT queries is difficult in several cases.",2024-09-09 08:29:39+00:00
TextToucher: Fine-Grained Text-to-Touch Generation,"Tactile sensation plays a crucial role in the development of multi-modal
large models and embodied intelligence. To collect tactile data with minimal
cost as possible, a series of studies have attempted to generate tactile images
by vision-to-touch image translation. However, compared to text modality,
visual modality-driven tactile generation cannot accurately depict human
tactile sensation. In this work, we analyze the characteristics of tactile
images in detail from two granularities: object-level (tactile texture, tactile
shape), and sensor-level (gel status). We model these granularities of
information through text descriptions and propose a fine-grained Text-to-Touch
generation method (TextToucher) to generate high-quality tactile samples.
Specifically, we introduce a multimodal large language model to build the text
sentences about object-level tactile information and employ a set of learnable
text prompts to represent the sensor-level tactile information. To better guide
the tactile generation process with the built text information, we fuse the
dual grains of text information and explore various dual-grain text
conditioning methods within the diffusion transformer architecture.
Furthermore, we propose a Contrastive Text-Touch Pre-training (CTTP) metric to
precisely evaluate the quality of text-driven generated tactile data. Extensive
experiments demonstrate the superiority of our TextToucher method. The source
codes will be available at \url{https://github.com/TtuHamg/TextToucher}.",2024-09-09 08:26:47+00:00
Distribution Discrepancy and Feature Heterogeneity for Active 3D Object Detection,"LiDAR-based 3D object detection is a critical technology for the development
of autonomous driving and robotics. However, the high cost of data annotation
limits its advancement. We propose a novel and effective active learning (AL)
method called Distribution Discrepancy and Feature Heterogeneity (DDFH), which
simultaneously considers geometric features and model embeddings, assessing
information from both the instance-level and frame-level perspectives.
Distribution Discrepancy evaluates the difference and novelty of instances
within the unlabeled and labeled distributions, enabling the model to learn
efficiently with limited data. Feature Heterogeneity ensures the heterogeneity
of intra-frame instance features, maintaining feature diversity while avoiding
redundant or similar instances, thus minimizing annotation costs. Finally,
multiple indicators are efficiently aggregated using Quantile Transform,
providing a unified measure of informativeness. Extensive experiments
demonstrate that DDFH outperforms the current state-of-the-art (SOTA) methods
on the KITTI and Waymo datasets, effectively reducing the bounding box
annotation cost by 56.3% and showing robustness when working with both
one-stage and two-stage models.",2024-09-09 08:26:11+00:00
AD-Net: Attention-based dilated convolutional residual network with guided decoder for robust skin lesion segmentation,"In computer-aided diagnosis tools employed for skin cancer treatment and
early diagnosis, skin lesion segmentation is important. However, achieving
precise segmentation is challenging due to inherent variations in appearance,
contrast, texture, and blurry lesion boundaries. This research presents a
robust approach utilizing a dilated convolutional residual network, which
incorporates an attention-based spatial feature enhancement block (ASFEB) and
employs a guided decoder strategy. In each dilated convolutional residual
block, dilated convolution is employed to broaden the receptive field with
varying dilation rates. To improve the spatial feature information of the
encoder, we employed an attention-based spatial feature enhancement block in
the skip connections. The ASFEB in our proposed method combines feature maps
obtained from average and maximum-pooling operations. These combined features
are then weighted using the active outcome of global average pooling and
convolution operations. Additionally, we have incorporated a guided decoder
strategy, where each decoder block is optimized using an individual loss
function to enhance the feature learning process in the proposed AD-Net. The
proposed AD-Net presents a significant benefit by necessitating fewer model
parameters compared to its peer methods. This reduction in parameters directly
impacts the number of labeled data required for training, facilitating faster
convergence during the training process. The effectiveness of the proposed
AD-Net was evaluated using four public benchmark datasets. We conducted a
Wilcoxon signed-rank test to verify the efficiency of the AD-Net. The outcomes
suggest that our method surpasses other cutting-edge methods in performance,
even without the implementation of data augmentation strategies.",2024-09-09 08:21:17+00:00
CipherDM: Secure Three-Party Inference for Diffusion Model Sampling,"Diffusion Models (DMs) achieve state-of-the-art synthesis results in image
generation and have been applied to various fields. However, DMs sometimes
seriously violate user privacy during usage, making the protection of privacy
an urgent issue. Using traditional privacy computing schemes like Secure
Multi-Party Computation (MPC) directly in DMs faces significant computation and
communication challenges. To address these issues, we propose CipherDM, the
first novel, versatile and universal framework applying MPC technology to DMs
for secure sampling, which can be widely implemented on multiple DM based
tasks. We thoroughly analyze sampling latency breakdown, find time-consuming
parts and design corresponding secure MPC protocols for computing nonlinear
activations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular
architectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers.
Compared to direct implementation on SPU, our approach improves running time by
approximately 1.084\times \sim 2.328\times, and reduces communication costs by
approximately 1.212\times \sim 1.791\times.",2024-09-09 08:16:17+00:00
From Words to Poses: Enhancing Novel Object Pose Estimation with Vision Language Models,"Robots are increasingly envisioned to interact in real-world scenarios, where
they must continuously adapt to new situations. To detect and grasp novel
objects, zero-shot pose estimators determine poses without prior knowledge.
Recently, vision language models (VLMs) have shown considerable advances in
robotics applications by establishing an understanding between language input
and image input. In our work, we take advantage of VLMs zero-shot capabilities
and translate this ability to 6D object pose estimation. We propose a novel
framework for promptable zero-shot 6D object pose estimation using language
embeddings. The idea is to derive a coarse location of an object based on the
relevancy map of a language-embedded NeRF reconstruction and to compute the
pose estimate with a point cloud registration method. Additionally, we provide
an analysis of LERF's suitability for open-set object pose estimation. We
examine hyperparameters, such as activation thresholds for relevancy maps and
investigate the zero-shot capabilities on an instance- and category-level.
Furthermore, we plan to conduct robotic grasping experiments in a real-world
setting.",2024-09-09 08:15:39+00:00
KRONC: Keypoint-based Robust Camera Optimization for 3D Car Reconstruction,"The three-dimensional representation of objects or scenes starting from a set
of images has been a widely discussed topic for years and has gained additional
attention after the diffusion of NeRF-based approaches. However, an
underestimated prerequisite is the knowledge of camera poses or, more
specifically, the estimation of the extrinsic calibration parameters. Although
excellent general-purpose Structure-from-Motion methods are available as a
pre-processing step, their computational load is high and they require a lot of
frames to guarantee sufficient overlapping among the views. This paper
introduces KRONC, a novel approach aimed at inferring view poses by leveraging
prior knowledge about the object to reconstruct and its representation through
semantic keypoints. With a focus on vehicle scenes, KRONC is able to estimate
the position of the views as a solution to a light optimization problem
targeting the convergence of keypoints' back-projections to a singular point.
To validate the method, a specific dataset of real-world car scenes has been
collected. Experiments confirm KRONC's ability to generate excellent estimates
of camera poses starting from very coarse initialization. Results are
comparable with Structure-from-Motion methods with huge savings in computation.
Code and data will be made publicly available.",2024-09-09 08:08:05+00:00
A Survey of Multimodal Composite Editing and Retrieval,"In the real world, where information is abundant and diverse across different
modalities, understanding and utilizing various data types to improve retrieval
systems is a key focus of research. Multimodal composite retrieval integrates
diverse modalities such as text, image and audio, etc. to provide more
accurate, personalized, and contextually relevant results. To facilitate a
deeper understanding of this promising direction, this survey explores
multimodal composite editing and retrieval in depth, covering image-text
composite editing, image-text composite retrieval, and other multimodal
composite retrieval. In this survey, we systematically organize the application
scenarios, methods, benchmarks, experiments, and future directions. Multimodal
learning is a hot topic in large model era, and have also witnessed some
surveys in multimodal learning and vision-language models with transformers
published in the PAMI journal. To the best of our knowledge, this survey is the
first comprehensive review of the literature on multimodal composite retrieval,
which is a timely complement of multimodal fusion to existing reviews. To help
readers' quickly track this field, we build the project page for this survey,
which can be found at
https://github.com/fuxianghuang1/Multimodal-Composite-Editing-and-Retrieval.",2024-09-09 08:06:50+00:00
HyperSMOTE: A Hypergraph-based Oversampling Approach for Imbalanced Node Classifications,"Hypergraphs are increasingly utilized in both unimodal and multimodal data
scenarios due to their superior ability to model and extract higher-order
relationships among nodes, compared to traditional graphs. However, current
hypergraph models are encountering challenges related to imbalanced data, as
this imbalance can lead to biases in the model towards the more prevalent
classes. While the existing techniques, such as GraphSMOTE, have improved
classification accuracy for minority samples in graph data, they still fall
short when addressing the unique structure of hypergraphs. Inspired by SMOTE
concept, we propose HyperSMOTE as a solution to alleviate the class imbalance
issue in hypergraph learning. This method involves a two-step process:
initially synthesizing minority class nodes, followed by the nodes integration
into the original hypergraph. We synthesize new nodes based on samples from
minority classes and their neighbors. At the same time, in order to solve the
problem on integrating the new node into the hypergraph, we train a decoder
based on the original hypergraph incidence matrix to adaptively associate the
augmented node to hyperedges. We conduct extensive evaluation on multiple
single-modality datasets, such as Cora, Cora-CA and Citeseer, as well as
multimodal conversation dataset MELD to verify the effectiveness of HyperSMOTE,
showing an average performance gain of 3.38% and 2.97% on accuracy,
respectively.",2024-09-09 08:01:28+00:00
Sequential Posterior Sampling with Diffusion Models,"Diffusion models have quickly risen in popularity for their ability to model
complex distributions and perform effective posterior sampling. Unfortunately,
the iterative nature of these generative models makes them computationally
expensive and unsuitable for real-time sequential inverse problems such as
ultrasound imaging. Considering the strong temporal structure across sequences
of frames, we propose a novel approach that models the transition dynamics to
improve the efficiency of sequential diffusion posterior sampling in
conditional image synthesis. Through modeling sequence data using a video
vision transformer (ViViT) transition model based on previous diffusion
outputs, we can initialize the reverse diffusion trajectory at a lower noise
scale, greatly reducing the number of iterations required for convergence. We
demonstrate the effectiveness of our approach on a real-world dataset of high
frame rate cardiac ultrasound images and show that it achieves the same
performance as a full diffusion trajectory while accelerating inference
25$\times$, enabling real-time posterior sampling. Furthermore, we show that
the addition of a transition model improves the PSNR up to 8\% in cases with
severe motion. Our method opens up new possibilities for real-time applications
of diffusion models in imaging and other domains requiring real-time inference.",2024-09-09 07:55:59+00:00
FacialFlowNet: Advancing Facial Optical Flow Estimation with a Diverse Dataset and a Decomposed Model,"Facial movements play a crucial role in conveying altitude and intentions,
and facial optical flow provides a dynamic and detailed representation of it.
However, the scarcity of datasets and a modern baseline hinders the progress in
facial optical flow research. This paper proposes FacialFlowNet (FFN), a novel
large-scale facial optical flow dataset, and the Decomposed Facial Flow Model
(DecFlow), the first method capable of decomposing facial flow. FFN comprises
9,635 identities and 105,970 image pairs, offering unprecedented diversity for
detailed facial and head motion analysis. DecFlow features a facial
semantic-aware encoder and a decomposed flow decoder, excelling in accurately
estimating and decomposing facial flow into head and expression components.
Comprehensive experiments demonstrate that FFN significantly enhances the
accuracy of facial flow estimation across various optical flow methods,
achieving up to an 11% reduction in Endpoint Error (EPE) (from 3.91 to 3.48).
Moreover, DecFlow, when coupled with FFN, outperforms existing methods in both
synthetic and real-world scenarios, enhancing facial expression analysis. The
decomposed expression flow achieves a substantial accuracy improvement of 18%
(from 69.1% to 82.1%) in micro-expressions recognition. These contributions
represent a significant advancement in facial motion analysis and optical flow
estimation. Codes and datasets can be found.",2024-09-09 07:49:13+00:00
Shaking Up VLMs: Comparing Transformers and Structured State Space Models for Vision & Language Modeling,"This study explores replacing Transformers in Visual Language Models (VLMs)
with Mamba, a recent structured state space model (SSM) that demonstrates
promising performance in sequence modeling. We test models up to 3B parameters
under controlled conditions, showing that Mamba-based VLMs outperforms
Transformers-based VLMs in captioning, question answering, and reading
comprehension. However, we find that Transformers achieve greater performance
in visual grounding and the performance gap widens with scale. We explore two
hypotheses to explain this phenomenon: 1) the effect of task-agnostic visual
encoding on the updates of the hidden states, and 2) the difficulty in
performing visual grounding from the perspective of in-context multimodal
retrieval. Our results indicate that a task-aware encoding yields minimal
performance gains on grounding, however, Transformers significantly outperform
Mamba at in-context multimodal retrieval. Overall, Mamba shows promising
performance on tasks where the correct output relies on a summary of the image
but struggles when retrieval of explicit information from the context is
required.",2024-09-09 07:49:09+00:00
TAVP: Task-Adaptive Visual Prompt for Cross-domain Few-shot Segmentation,"Under the backdrop of large-scale pre-training, large visual models (LVM)
have demonstrated significant potential in image understanding. The recent
emergence of the Segment Anything Model (SAM) has brought a qualitative shift
in the field of image segmentation, supporting flexible interactive cues and
strong learning capabilities. However, its performance often falls short in
cross-domain and few-shot applications. Transferring prior knowledge from
foundation models to new applications while preserving learning capabilities is
worth exploring. This work proposes a task-adaptive prompt framework based on
SAM, a new paradigm for Cross-dominan few-shot segmentation (CD-FSS). First, a
Multi-level Feature Fusion (MFF) was used for integrated feature extraction.
Besides, an additional Class Domain Task-Adaptive Auto-Prompt (CDTAP) module
was combined with the segmentation branch for class-domain agnostic feature
extraction and high-quality learnable prompt production. This significant
advancement uses a unique generative approach to prompts alongside a
comprehensive model structure and specialized prototype computation. While
ensuring that the prior knowledge of SAM is not discarded, the new branch
disentangles category and domain information through prototypes, guiding it in
adapting the CD-FSS. We have achieved the best results on three benchmarks
compared to the recent state-of-the-art (SOTA) methods. Comprehensive
experiments showed that after task-specific and weighted guidance, the abundant
feature information of SAM can be better learned for CD-FSS.",2024-09-09 07:43:58+00:00
A Novel Representation of Periodic Pattern and Its Application to Untrained Anomaly Detection,"There are a variety of industrial products that possess periodic textures or
surfaces, such as carbon fiber textiles and display panels. Traditional
image-based quality inspection methods for these products require identifying
the periodic patterns from normal images (without anomaly and noise) and
subsequently detecting anomaly pixels with inconsistent appearances. However,
it remains challenging to accurately extract the periodic pattern from a single
image in the presence of unknown anomalies and measurement noise. To deal with
this challenge, this paper proposes a novel self-representation of the periodic
image defined on a set of continuous parameters. In this way, periodic pattern
learning can be embedded into a joint optimization framework, which is named
periodic-sparse decomposition, with simultaneously modeling the sparse
anomalies and Gaussian noise. Finally, for the real-world industrial images
that may not strictly satisfy the periodic assumption, we propose a novel
pixel-level anomaly scoring strategy to enhance the performance of anomaly
detection. Both simulated and real-world case studies demonstrate the
effectiveness of the proposed methodology for periodic pattern learning and
anomaly detection.",2024-09-09 07:34:08+00:00
Decoupling Contact for Fine-Grained Motion Style Transfer,"Motion style transfer changes the style of a motion while retaining its
content and is useful in computer animations and games. Contact is an essential
component of motion style transfer that should be controlled explicitly in
order to express the style vividly while enhancing motion naturalness and
quality. However, it is unknown how to decouple and control contact to achieve
fine-grained control in motion style transfer. In this paper, we present a
novel style transfer method for fine-grained control over contacts while
achieving both motion naturalness and spatial-temporal variations of style.
Based on our empirical evidence, we propose controlling contact indirectly
through the hip velocity, which can be further decomposed into the trajectory
and contact timing, respectively. To this end, we propose a new model that
explicitly models the correlations between motions and trajectory/contact
timing/style, allowing us to decouple and control each separately. Our approach
is built around a motion manifold, where hip controls can be easily integrated
into a Transformer-based decoder. It is versatile in that it can generate
motions directly as well as be used as post-processing for existing methods to
improve quality and contact controllability. In addition, we propose a new
metric that measures a correlation pattern of motions based on our empirical
evidence, aligning well with human perception in terms of motion naturalness.
Based on extensive evaluation, our method outperforms existing methods in terms
of style expressivity and motion quality.",2024-09-09 07:33:14+00:00
Towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models,"The development of LLMs has greatly enhanced the intelligence and fluency of
question answering, while the emergence of retrieval enhancement has enabled
models to better utilize external information. However, the presence of noise
and errors in retrieved information poses challenges to the robustness of LLMs.
In this work, to evaluate the model's performance under multiple interferences,
we first construct a dataset based on machine reading comprehension datasets
simulating various scenarios, including critical information absence, noise,
and conflicts. To address the issue of model accuracy decline caused by noisy
external information, we propose a data augmentation-based fine-tuning method
to enhance LLM's robustness against noise. Additionally, contrastive learning
approach is utilized to preserve the model's discrimination capability of
external information. We have conducted experiments on both existing LLMs and
our approach, the results are evaluated by GPT-4, which indicates that our
proposed methods improve model robustness while strengthening the model's
discrimination capability.",2024-09-09 07:32:30+00:00
Look One and More: Distilling Hybrid Order Relational Knowledge for Cross-Resolution Image Recognition,"In spite of great success in many image recognition tasks achieved by recent
deep models, directly applying them to recognize low-resolution images may
suffer from low accuracy due to the missing of informative details during
resolution degradation. However, these images are still recognizable for
subjects who are familiar with the corresponding high-resolution ones. Inspired
by that, we propose a teacher-student learning approach to facilitate
low-resolution image recognition via hybrid order relational knowledge
distillation. The approach refers to three streams: the teacher stream is
pretrained to recognize high-resolution images in high accuracy, the student
stream is learned to identify low-resolution images by mimicking the teacher's
behaviors, and the extra assistant stream is introduced as bridge to help
knowledge transfer across the teacher to the student. To extract sufficient
knowledge for reducing the loss in accuracy, the learning of student is
supervised with multiple losses, which preserves the similarities in various
order relational structures. In this way, the capability of recovering missing
details of familiar low-resolution images can be effectively enhanced, leading
to a better knowledge transfer. Extensive experiments on metric learning,
low-resolution image classification and low-resolution face recognition tasks
show the effectiveness of our approach, while taking reduced models.",2024-09-09 07:32:18+00:00
Deep Learning for Video Anomaly Detection: A Review,"Video anomaly detection (VAD) aims to discover behaviors or events deviating
from the normality in videos. As a long-standing task in the field of computer
vision, VAD has witnessed much good progress. In the era of deep learning, with
the explosion of architectures of continuously growing capability and capacity,
a great variety of deep learning based methods are constantly emerging for the
VAD task, greatly improving the generalization ability of detection algorithms
and broadening the application scenarios. Therefore, such a multitude of
methods and a large body of literature make a comprehensive survey a pressing
necessity. In this paper, we present an extensive and comprehensive research
review, covering the spectrum of five different categories, namely,
semi-supervised, weakly supervised, fully supervised, unsupervised and open-set
supervised VAD, and we also delve into the latest VAD works based on
pre-trained large models, remedying the limitations of past reviews in terms of
only focusing on semi-supervised VAD and small model based methods. For the VAD
task with different levels of supervision, we construct a well-organized
taxonomy, profoundly discuss the characteristics of different types of methods,
and show their performance comparisons. In addition, this review involves the
public datasets, open-source codes, and evaluation metrics covering all the
aforementioned VAD tasks. Finally, we provide several important research
directions for the VAD community.",2024-09-09 07:31:16+00:00
Boosting CLIP Adaptation for Image Quality Assessment via Meta-Prompt Learning and Gradient Regularization,"Image Quality Assessment (IQA) remains an unresolved challenge in the field
of computer vision, due to complex distortion conditions, diverse image
content, and limited data availability. The existing Blind IQA (BIQA) methods
heavily rely on extensive human annotations to train models, which is both
labor-intensive and costly due to the demanding nature of creating IQA
datasets. To mitigate the dependence on labeled samples, this paper introduces
a novel Gradient-Regulated Meta-Prompt IQA Framework (GRMP-IQA). This framework
aims to fast adapt the powerful visual-language pre-trained model, CLIP, to
downstream IQA tasks, significantly improving accuracy in scenarios with
limited data. Specifically, the GRMP-IQA comprises two key modules: Meta-Prompt
Pre-training Module and Quality-Aware Gradient Regularization. The Meta Prompt
Pre-training Module leverages a meta-learning paradigm to pre-train soft
prompts with shared meta-knowledge across different distortions, enabling rapid
adaptation to various IQA tasks. On the other hand, the Quality-Aware Gradient
Regularization is designed to adjust the update gradients during fine-tuning,
focusing the model's attention on quality-relevant features and preventing
overfitting to semantic information. Extensive experiments on five standard
BIQA datasets demonstrate the superior performance to the state-of-the-art BIQA
methods under limited data setting, i.e., achieving SRCC values of 0.836 (vs.
0.760 on LIVEC) and 0.853 (vs. 0.812 on KonIQ). Notably, utilizing just 20\% of
the training data, our GRMP-IQA outperforms most existing fully supervised BIQA
methods.",2024-09-09 07:26:21+00:00
Prim2Room: Layout-Controllable Room Mesh Generation from Primitives,"We propose Prim2Room, a novel framework for controllable room mesh generation
leveraging 2D layout conditions and 3D primitive retrieval to facilitate
precise 3D layout specification. Diverging from existing methods that lack
control and precision, our approach allows for detailed customization of
room-scale environments. To overcome the limitations of previous methods, we
introduce an adaptive viewpoint selection algorithm that allows the system to
generate the furniture texture and geometry from more favorable views than
predefined camera trajectories. Additionally, we employ non-rigid depth
registration to ensure alignment between generated objects and their
corresponding primitive while allowing for shape variations to maintain
diversity. Our method not only enhances the accuracy and aesthetic appeal of
generated 3D scenes but also provides a user-friendly platform for detailed
room design.",2024-09-09 07:25:47+00:00
PersonaTalk: Bring Attention to Your Persona in Visual Dubbing,"For audio-driven visual dubbing, it remains a considerable challenge to
uphold and highlight speaker's persona while synthesizing accurate lip
synchronization. Existing methods fall short of capturing speaker's unique
speaking style or preserving facial details. In this paper, we present
PersonaTalk, an attention-based two-stage framework, including geometry
construction and face rendering, for high-fidelity and personalized visual
dubbing. In the first stage, we propose a style-aware audio encoding module
that injects speaking style into audio features through a cross-attention
layer. The stylized audio features are then used to drive speaker's template
geometry to obtain lip-synced geometries. In the second stage, a dual-attention
face renderer is introduced to render textures for the target geometries. It
consists of two parallel cross-attention layers, namely Lip-Attention and
Face-Attention, which respectively sample textures from different reference
frames to render the entire face. With our innovative design, intricate facial
details can be well preserved. Comprehensive experiments and user studies
demonstrate our advantages over other state-of-the-art methods in terms of
visual quality, lip-sync accuracy and persona preservation. Furthermore, as a
person-generic framework, PersonaTalk can achieve competitive performance as
state-of-the-art person-specific methods. Project Page:
https://grisoon.github.io/PersonaTalk/.",2024-09-09 07:23:28+00:00
Memoryless Multimodal Anomaly Detection via Student-Teacher Network and Signed Distance Learning,"Unsupervised anomaly detection is a challenging computer vision task, in
which 2D-based anomaly detection methods have been extensively studied.
However, multimodal anomaly detection based on RGB images and 3D point clouds
requires further investigation. The existing methods are mainly inspired by
memory bank based methods commonly used in 2D-based anomaly detection, which
may cost extra memory for storing mutimodal features. In present study, a novel
memoryless method MDSS is proposed for multimodal anomaly detection, which
employs a light-weighted student-teacher network and a signed distance function
to learn from RGB images and 3D point clouds respectively, and complements the
anomaly information from the two modalities. Specifically, a student-teacher
network is trained with normal RGB images and masks generated from point clouds
by a dynamic loss, and the anomaly score map could be obtained from the
discrepancy between the output of student and teacher. Furthermore, the signed
distance function learns from normal point clouds to predict the signed
distances between points and surface, and the obtained signed distances are
used to generate anomaly score map. Subsequently, the anomaly score maps are
aligned to generate the final anomaly score map for detection. The experimental
results indicate that MDSS is comparable but more stable than the SOTA memory
bank based method Shape-guided, and furthermore performs better than other
baseline methods.",2024-09-09 07:18:09+00:00
Ethereum Fraud Detection via Joint Transaction Language Model and Graph Representation Learning,"Ethereum faces growing fraud threats. Current fraud detection methods,
whether employing graph neural networks or sequence models, fail to consider
the semantic information and similarity patterns within transactions. Moreover,
these approaches do not leverage the potential synergistic benefits of
combining both types of models. To address these challenges, we propose
TLMG4Eth that combines a transaction language model with graph-based methods to
capture semantic, similarity, and structural features of transaction data in
Ethereum. We first propose a transaction language model that converts numerical
transaction data into meaningful transaction sentences, enabling the model to
learn explicit transaction semantics. Then, we propose a transaction attribute
similarity graph to learn transaction similarity information, enabling us to
capture intuitive insights into transaction anomalies. Additionally, we
construct an account interaction graph to capture the structural information of
the account transaction network. We employ a deep multi-head attention network
to fuse transaction semantic and similarity embeddings, and ultimately propose
a joint training approach for the multi-head attention network and the account
interaction graph to obtain the synergistic benefits of both.",2024-09-09 07:13:44+00:00
KARGEN: Knowledge-enhanced Automated Radiology Report Generation Using Large Language Models,"Harnessing the robust capabilities of Large Language Models (LLMs) for
narrative generation, logical reasoning, and common-sense knowledge
integration, this study delves into utilizing LLMs to enhance automated
radiology report generation (R2Gen). Despite the wealth of knowledge within
LLMs, efficiently triggering relevant knowledge within these large models for
specific tasks like R2Gen poses a critical research challenge. This paper
presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration
framework based on LLMs. Utilizing a frozen LLM to generate reports, the
framework integrates a knowledge graph to unlock chest disease-related
knowledge within the LLM to enhance the clinical utility of generated reports.
This is achieved by leveraging the knowledge graph to distill disease-related
features in a designed way. Since a radiology report encompasses both normal
and disease-related findings, the extracted graph-enhanced disease-related
features are integrated with regional image features, attending to both
aspects. We explore two fusion methods to automatically prioritize and select
the most relevant features. The fused features are employed by LLM to generate
reports that are more sensitive to diseases and of improved quality. Our
approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets.",2024-09-09 06:57:22+00:00
FedBrain-Distill: Communication-Efficient Federated Brain Tumor Classification Using Ensemble Knowledge Distillation on Non-IID Data,"Brain is one the most complex organs in the human body. Due to its
complexity, classification of brain tumors still poses a significant challenge,
making brain tumors a particularly serious medical issue. Techniques such as
Machine Learning (ML) coupled with Magnetic Resonance Imaging (MRI) have paved
the way for doctors and medical institutions to classify different types of
tumors. However, these techniques suffer from limitations that violate patients
privacy. Federated Learning (FL) has recently been introduced to solve such an
issue, but the FL itself suffers from limitations like communication costs and
dependencies on model architecture, forcing all models to have identical
architectures. In this paper, we propose FedBrain-Distill, an approach that
leverages Knowledge Distillation (KD) in an FL setting that maintains the users
privacy and ensures the independence of FL clients in terms of model
architecture. FedBrain-Distill uses an ensemble of teachers that distill their
knowledge to a simple student model. The evaluation of FedBrain-Distill
demonstrated high-accuracy results for both Independent and Identically
Distributed (IID) and non-IID data with substantial low communication costs on
the real-world Figshare brain tumor dataset. It is worth mentioning that we
used Dirichlet distribution to partition the data into IID and non-IID data.
All the implementation details are accessible through our Github repository.",2024-09-09 06:42:17+00:00
BAMDP Shaping: a Unified Theoretical Framework for Intrinsic Motivation and Reward Shaping,"Intrinsic motivation (IM) and reward shaping are common methods for guiding
the exploration of reinforcement learning (RL) agents by adding pseudo-rewards.
Designing these rewards is challenging, however, and they can
counter-intuitively harm performance. To address this, we characterize them as
reward shaping in Bayes-Adaptive Markov Decision Processes (BAMDPs), which
formalizes the value of exploration by formulating the RL process as updating a
prior over possible MDPs through experience. RL algorithms can be viewed as
BAMDP policies; instead of attempting to find optimal algorithms by solving
BAMDPs directly, we use it at a theoretical framework for understanding how
pseudo-rewards guide suboptimal algorithms. By decomposing BAMDP state value
into the value of the information collected plus the prior value of the
physical state, we show how psuedo-rewards can help by compensating for RL
algorithms' misestimation of these two terms, yielding a new typology of IM and
reward shaping approaches. We carefully extend the potential-based shaping
theorem to BAMDPs to prove that when pseudo-rewards are BAMDP Potential-based
shaping Functions (BAMPFs), they preserve optimal, or approximately optimal,
behavior of RL algorithms; otherwise, they can corrupt even optimal learners.
We finally give guidance on how to design or convert existing pseudo-rewards to
BAMPFs by expressing assumptions about the environment as potential functions
on BAMDP states.",2024-09-09 06:39:56+00:00
Attention Based Machine Learning Methods for Data Reduction with Guaranteed Error Bounds,"Scientific applications in fields such as high energy physics, computational
fluid dynamics, and climate science generate vast amounts of data at high
velocities. This exponential growth in data production is surpassing the
advancements in computing power, network capabilities, and storage capacities.
To address this challenge, data compression or reduction techniques are
crucial. These scientific datasets have underlying data structures that consist
of structured and block structured multidimensional meshes where each grid
point corresponds to a tensor. It is important that data reduction techniques
leverage strong spatial and temporal correlations that are ubiquitous in these
applications. Additionally, applications such as CFD, process tensors
comprising hundred plus species and their attributes at each grid point.
Reduction techniques should be able to leverage interrelationships between the
elements in each tensor. In this paper, we propose an attention-based
hierarchical compression method utilizing a block-wise compression setup. We
introduce an attention-based hyper-block autoencoder to capture inter-block
correlations, followed by a block-wise encoder to capture block-specific
information. A PCA-based post-processing step is employed to guarantee error
bounds for each data block. Our method effectively captures both spatiotemporal
and inter-variable correlations within and between data blocks. Compared to the
state-of-the-art SZ3, our method achieves up to 8 times higher compression
ratio on the multi-variable S3D dataset. When evaluated on single-variable
setups using the E3SM and XGC datasets, our method still achieves up to 3 times
and 2 times higher compression ratio, respectively.",2024-09-09 06:35:24+00:00
IndicVoices-R: Unlocking a Massive Multilingual Multi-speaker Speech Corpus for Scaling Indian TTS,"Recent advancements in text-to-speech (TTS) synthesis show that large-scale
models trained with extensive web data produce highly natural-sounding output.
However, such data is scarce for Indian languages due to the lack of
high-quality, manually subtitled data on platforms like LibriVox or YouTube. To
address this gap, we enhance existing large-scale ASR datasets containing
natural conversations collected in low-quality environments to generate
high-quality TTS training data. Our pipeline leverages the cross-lingual
generalization of denoising and speech enhancement models trained on English
and applied to Indian languages. This results in IndicVoices-R (IV-R), the
largest multilingual Indian TTS dataset derived from an ASR dataset, with 1,704
hours of high-quality speech from 10,496 speakers across 22 Indian languages.
IV-R matches the quality of gold-standard TTS datasets like LJSpeech, LibriTTS,
and IndicTTS. We also introduce the IV-R Benchmark, the first to assess
zero-shot, few-shot, and many-shot speaker generalization capabilities of TTS
models on Indian voices, ensuring diversity in age, gender, and style. We
demonstrate that fine-tuning an English pre-trained model on a combined dataset
of high-quality IndicTTS and our IV-R dataset results in better zero-shot
speaker generalization compared to fine-tuning on the IndicTTS dataset alone.
Further, our evaluation reveals limited zero-shot generalization for Indian
voices in TTS models trained on prior datasets, which we improve by fine-tuning
the model on our data containing diverse set of speakers across language
families. We open-source all data and code, releasing the first TTS model for
all 22 official Indian languages.",2024-09-09 06:28:47+00:00
Recursive Nested Filtering for Efficient Amortized Bayesian Experimental Design,"This paper introduces the Inside-Out Nested Particle Filter (IO-NPF), a
novel, fully recursive, algorithm for amortized sequential Bayesian
experimental design in the non-exchangeable setting. We frame policy
optimization as maximum likelihood estimation in a non-Markovian state-space
model, achieving (at most) $\mathcal{O}(T^2)$ computational complexity in the
number of experiments. We provide theoretical convergence guarantees and
introduce a backward sampling algorithm to reduce trajectory degeneracy. IO-NPF
offers a practical, extensible, and provably consistent approach to sequential
Bayesian experimental design, demonstrating improved efficiency over existing
methods.",2024-09-09 06:27:54+00:00
Driving with Prior Maps: Unified Vector Prior Encoding for Autonomous Vehicle Mapping,"High-Definition Maps (HD maps) are essential for the precise navigation and
decision-making of autonomous vehicles, yet their creation and upkeep present
significant cost and timeliness challenges. The online construction of HD maps
using on-board sensors has emerged as a promising solution; however, these
methods can be impeded by incomplete data due to occlusions and inclement
weather. This paper proposes the PriorDrive framework to addresses these
limitations by harnessing the power of prior maps, significantly enhancing the
robustness and accuracy of online HD map construction. Our approach integrates
a variety of prior maps, such as OpenStreetMap's Standard Definition Maps (SD
maps), outdated HD maps from vendors, and locally constructed maps from
historical vehicle data. To effectively encode this prior information into
online mapping models, we introduce a Hybrid Prior Representation (HPQuery)
that standardizes the representation of diverse map elements. At the core of
PriorDrive is the Unified Vector Encoder (UVE), which employs a dual encoding
mechanism to process vector data. The intra-vector encoder captures
fine-grained local features, while the inter-vector encoder integrates global
context. Furthermore, we propose a segment-level and point-level pre-training
strategy that enables the UVE to learn the prior distribution of vector data,
thereby improving the encoder's generalizability and performance. Through
extensive testing on the nuScenes dataset, we demonstrate that PriorDrive is
highly compatible with various online mapping models and substantially improves
map prediction capabilities. The integration of prior maps through the
PriorDrive framework offers a robust solution to the challenges of
single-perception data, paving the way for more reliable autonomous vehicle
navigation.",2024-09-09 06:17:46+00:00
On the Convergence Analysis of Over-Parameterized Variational Autoencoders: A Neural Tangent Kernel Perspective,"Variational Auto-Encoders (VAEs) have emerged as powerful probabilistic
models for generative tasks. However, their convergence properties have not
been rigorously proven. The challenge of proving convergence is inherently
difficult due to the highly non-convex nature of the training objective and the
implementation of a Stochastic Neural Network (SNN) within VAE architectures.
This paper addresses these challenges by characterizing the optimization
trajectory of SNNs utilized in VAEs through the lens of Neural Tangent Kernel
(NTK) techniques. These techniques govern the optimization and generalization
behaviors of ultra-wide neural networks. We provide a mathematical proof of VAE
convergence under mild assumptions, thus advancing the theoretical
understanding of VAE optimization dynamics. Furthermore, we establish a novel
connection between the optimization problem faced by over-parameterized SNNs
and the Kernel Ridge Regression (KRR) problem. Our findings not only contribute
to the theoretical foundation of VAEs but also open new avenues for
investigating the optimization of generative models using advanced kernel
methods. Our theoretical claims are verified by experimental simulations.",2024-09-09 06:10:31+00:00
TriplePlay: Enhancing Federated Learning with CLIP for Non-IID Data and Resource Efficiency,"The rapid advancement and increasing complexity of pretrained models,
exemplified by CLIP, offer significant opportunities as well as challenges for
Federated Learning (FL), a critical component of privacy-preserving artificial
intelligence. This research delves into the intricacies of integrating large
foundation models like CLIP within FL frameworks to enhance privacy,
efficiency, and adaptability across heterogeneous data landscapes. It
specifically addresses the challenges posed by non-IID data distributions, the
computational and communication overheads of leveraging such complex models,
and the skewed representation of classes within datasets. We propose
TriplePlay, a framework that integrates CLIP as an adapter to enhance FL's
adaptability and performance across diverse data distributions. This approach
addresses the long-tail distribution challenge to ensure fairness while
reducing resource demands through quantization and low-rank adaptation
techniques.Our simulation results demonstrate that TriplePlay effectively
decreases GPU usage costs and speeds up the learning process, achieving
convergence with reduced communication overhead.",2024-09-09 06:04:42+00:00
GDFlow: Anomaly Detection with NCDE-based Normalizing Flow for Advanced Driver Assistance System,"For electric vehicles, the Adaptive Cruise Control (ACC) in Advanced Driver
Assistance Systems (ADAS) is designed to assist braking based on driving
conditions, road inclines, predefined deceleration strengths, and user braking
patterns. However, the driving data collected during the development of ADAS
are generally limited and lack diversity. This deficiency leads to late or
aggressive braking for different users. Crucially, it is necessary to
effectively identify anomalies, such as unexpected or inconsistent braking
patterns in ADAS, especially given the challenge of working with unlabelled,
limited, and noisy datasets from real-world electric vehicles. In order to
tackle the aforementioned challenges in ADAS, we propose Graph Neural
Controlled Differential Equation Normalizing Flow (GDFlow), a model that
leverages Normalizing Flow (NF) with Neural Controlled Differential Equations
(NCDE) to learn the distribution of normal driving patterns continuously.
Compared to the traditional clustering or anomaly detection algorithms, our
approach effectively captures the spatio-temporal information from different
sensor data and more accurately models continuous changes in driving patterns.
Additionally, we introduce a quantile-based maximum likelihood objective to
improve the likelihood estimate of the normal data near the boundary of the
distribution, enhancing the model's ability to distinguish between normal and
anomalous patterns. We validate GDFlow using real-world electric vehicle
driving data that we collected from Hyundai IONIQ5 and GV80EV, achieving
state-of-the-art performance compared to six baselines across four dataset
configurations of different vehicle types and drivers. Furthermore, our model
outperforms the latest anomaly detection methods across four time series
benchmark datasets. Our approach demonstrates superior efficiency in inference
time compared to existing methods.",2024-09-09 06:04:41+00:00
Robust Non-adaptive Group Testing under Errors in Group Membership Specifications,"Given $p$ samples, each of which may or may not be defective, group testing
(GT) aims to determine their defect status by performing tests on $n < p$
`groups', where a group is formed by mixing a subset of the $p$ samples.
Assuming that the number of defective samples is very small compared to $p$, GT
algorithms have provided excellent recovery of the status of all $p$ samples
with even a small number of groups. Most existing methods, however, assume that
the group memberships are accurately specified. This assumption may not always
be true in all applications, due to various resource constraints. Such errors
could occur, eg, when a technician, preparing the groups in a laboratory,
unknowingly mixes together an incorrect subset of samples as compared to what
was specified. We develop a new GT method, the Debiased Robust Lasso Test
Method (DRLT), that handles such group membership specification errors. The
proposed DRLT method is based on an approach to debias, or reduce the inherent
bias in, estimates produced by Lasso, a popular and effective sparse regression
technique. We also provide theoretical upper bounds on the reconstruction error
produced by our estimator. Our approach is then combined with two carefully
designed hypothesis tests respectively for (i) the identification of defective
samples in the presence of errors in group membership specifications, and (ii)
the identification of groups with erroneous membership specifications. The DRLT
approach extends the literature on bias mitigation of statistical estimators
such as the LASSO, to handle the important case when some of the measurements
contain outliers, due to factors such as group membership specification errors.
We present numerical results which show that our approach outperforms several
baselines and robust regression techniques for identification of defective
samples as well as erroneously specified groups.",2024-09-09 06:03:23+00:00
Graffin: Stand for Tails in Imbalanced Node Classification,"Graph representation learning (GRL) models have succeeded in many scenarios.
Real-world graphs have imbalanced distribution, such as node labels and
degrees, which leaves a critical challenge to GRL. Imbalanced inputs can lead
to imbalanced outputs. However, most existing works ignore it and assume that
the distribution of input graphs is balanced, which cannot align with real
situations, resulting in worse model performance on tail data. The domination
of head data makes tail data underrepresented when training graph neural
networks (GNNs). Thus, we propose Graffin, a pluggable tail data augmentation
module, to address the above issues. Inspired by recurrent neural networks
(RNNs), Graffin flows head features into tail data through graph serialization
techniques to alleviate the imbalance of tail representation. The local and
global structures are fused to form the node representation under the combined
effect of neighborhood and sequence information, which enriches the semantics
of tail data. We validate the performance of Graffin on four real-world
datasets in node classification tasks. Results show that Graffin can improve
the adaptation to tail data without significantly degrading the overall model
performance.",2024-09-09 05:31:51+00:00
Early-exit Convolutional Neural Networks,"This paper is aimed at developing a method that reduces the computational
cost of convolutional neural networks (CNN) during inference. Conventionally,
the input data pass through a fixed neural network architecture. However, easy
examples can be classified at early stages of processing and conventional
networks do not take this into account. In this paper, we introduce 'Early-exit
CNNs', EENets for short, which adapt their computational cost based on the
input by stopping the inference process at certain exit locations. In EENets,
there are a number of exit blocks each of which consists of a confidence branch
and a softmax branch. The confidence branch computes the confidence score of
exiting (i.e. stopping the inference process) at that location; while the
softmax branch outputs a classification probability vector. Both branches are
learnable and their parameters are separate. During training of EENets, in
addition to the classical classification loss, the computational cost of
inference is taken into account as well. As a result, the network adapts its
many confidence branches to the inputs so that less computation is spent for
easy examples. Inference works as in conventional feed-forward networks,
however, when the output of a confidence branch is larger than a certain
threshold, the inference stops for that specific example. The idea of EENets is
applicable to available CNN architectures such as ResNets. Through
comprehensive experiments on MNIST, SVHN, CIFAR10 and Tiny-ImageNet datasets,
we show that early-exit (EE) ResNets achieve similar accuracy with their non-EE
versions while reducing the computational cost to 20% of the original. Code is
available at https://github.com/eksuas/eenets.pytorch",2024-09-09 05:29:38+00:00
A Multi-Modal Deep Learning Based Approach for House Price Prediction,"Accurate prediction of house price, a vital aspect of the residential real
estate sector, is of substantial interest for a wide range of stakeholders.
However, predicting house prices is a complex task due to the significant
variability influenced by factors such as house features, location,
neighborhood, and many others. Despite numerous attempts utilizing a wide array
of algorithms, including recent deep learning techniques, to predict house
prices accurately, existing approaches have fallen short of considering a wide
range of factors such as textual and visual features. This paper addresses this
gap by comprehensively incorporating attributes, such as features, textual
descriptions, geo-spatial neighborhood, and house images, typically showcased
in real estate listings in a house price prediction system. Specifically, we
propose a multi-modal deep learning approach that leverages different types of
data to learn more accurate representation of the house. In particular, we
learn a joint embedding of raw house attributes, geo-spatial neighborhood, and
most importantly from textual description and images representing the house;
and finally use a downstream regression model to predict the house price from
this jointly learned embedding vector. Our experimental results with a
real-world dataset show that the text embedding of the house advertisement
description and image embedding of the house pictures in addition to raw
attributes and geo-spatial embedding, can significantly improve the house price
prediction accuracy. The relevant source code and dataset are publicly
accessible at the following URL: https://github.com/4P0N/mhpp",2024-09-09 05:26:33+00:00
Lagrangian Hashing for Compressed Neural Field Representations,"We present Lagrangian Hashing, a representation for neural fields combining
the characteristics of fast training NeRF methods that rely on Eulerian grids
(i.e.~InstantNGP), with those that employ points equipped with features as a
way to represent information (e.g. 3D Gaussian Splatting or PointNeRF). We
achieve this by incorporating a point-based representation into the
high-resolution layers of the hierarchical hash tables of an InstantNGP
representation. As our points are equipped with a field of influence, our
representation can be interpreted as a mixture of Gaussians stored within the
hash table. We propose a loss that encourages the movement of our Gaussians
towards regions that require more representation budget to be sufficiently well
represented. Our main finding is that our representation allows the
reconstruction of signals using a more compact representation without
compromising quality.",2024-09-09 05:25:15+00:00
KAN-Based Fusion of Dual-Domain for Audio-Driven Facial Landmarks Generation,"Audio-driven talking face generation is a widely researched topic due to its
high applicability. Reconstructing a talking face using audio significantly
contributes to fields such as education, healthcare, online conversations,
virtual assistants, and virtual reality. Early studies often focused solely on
changing the mouth movements, which resulted in outcomes with limited practical
applications. Recently, researchers have proposed a new approach of
constructing the entire face, including face pose, neck, and shoulders. To
achieve this, they need to generate through landmarks. However, creating stable
landmarks that align well with the audio is a challenge. In this paper, we
propose the KFusion of Dual-Domain model, a robust model that generates
landmarks from audio. We separate the audio into two distinct domains to learn
emotional information and facial context, then use a fusion mechanism based on
the KAN model. Our model demonstrates high efficiency compared to recent
models. This will lay the groundwork for the development of the audio-driven
talking face generation problem in the future.",2024-09-09 05:20:02+00:00
"Complex Emotion Recognition System using basic emotions via Facial Expression, EEG, and ECG Signals: a review","The Complex Emotion Recognition System (CERS) deciphers complex emotional
states by examining combinations of basic emotions expressed, their
interconnections, and the dynamic variations. Through the utilization of
advanced algorithms, CERS provides profound insights into emotional dynamics,
facilitating a nuanced understanding and customized responses. The attainment
of such a level of emotional recognition in machines necessitates the knowledge
distillation and the comprehension of novel concepts akin to human cognition.
The development of AI systems for discerning complex emotions poses a
substantial challenge with significant implications for affective computing.
Furthermore, obtaining a sizable dataset for CERS proves to be a daunting task
due to the intricacies involved in capturing subtle emotions, necessitating
specialized methods for data collection and processing. Incorporating
physiological signals such as Electrocardiogram (ECG) and Electroencephalogram
(EEG) can notably enhance CERS by furnishing valuable insights into the user's
emotional state, enhancing the quality of datasets, and fortifying system
dependability. A comprehensive literature review was conducted in this study to
assess the efficacy of machine learning, deep learning, and meta-learning
approaches in both basic and complex emotion recognition utilizing EEG, ECG
signals, and facial expression datasets. The chosen research papers offer
perspectives on potential applications, clinical implications, and results of
CERSs, with the objective of promoting their acceptance and integration into
clinical decision-making processes. This study highlights research gaps and
challenges in understanding CERSs, encouraging further investigation by
relevant studies and organizations. Lastly, the significance of meta-learning
approaches in improving CERS performance and guiding future research endeavors
is underscored.",2024-09-09 05:06:10+00:00
NeIn: Telling What You Don't Want,"Negation is a fundamental linguistic concept used by humans to convey
information that they do not desire. Despite this, there has been minimal
research specifically focused on negation within vision-language tasks. This
lack of research means that vision-language models (VLMs) may struggle to
understand negation, implying that they struggle to provide accurate results.
One barrier to achieving human-level intelligence is the lack of a standard
collection by which research into negation can be evaluated. This paper
presents the first large-scale dataset, Negative Instruction (NeIn), for
studying negation within the vision-language domain. Our dataset comprises
530,694 quadruples, i.e., source image, original caption, negative sentence,
and target image in total, including 495,694 queries for training and 35,000
queries for benchmarking across multiple vision-language tasks. Specifically,
we automatically generate NeIn based on a large, existing vision-language
dataset, MS-COCO, via two steps: generation and filtering. During the
generation phase, we leverage two VLMs, BLIP and MagicBrush, to generate the
target image and a negative clause that expresses the content of the source
image. In the subsequent filtering phase, we apply BLIP to remove erroneous
samples. Additionally, we introduce an evaluation protocol for negation
understanding of image editing models. Extensive experiments using our dataset
across multiple VLMs for instruction-based image editing tasks demonstrate that
even recent state-of-the-art VLMs struggle to understand negative queries. The
project page is: https://tanbuinhat.github.io/NeIn/",2024-09-09 04:54:34+00:00
ICPR 2024 Competition on Safe Segmentation of Drive Scenes in Unstructured Traffic and Adverse Weather Conditions,"The ICPR 2024 Competition on Safe Segmentation of Drive Scenes in
Unstructured Traffic and Adverse Weather Conditions served as a rigorous
platform to evaluate and benchmark state-of-the-art semantic segmentation
models under challenging conditions for autonomous driving. Over several
months, participants were provided with the IDD-AW dataset, consisting of 5000
high-quality RGB-NIR image pairs, each annotated at the pixel level and
captured under adverse weather conditions such as rain, fog, low light, and
snow. A key aspect of the competition was the use and improvement of the Safe
mean Intersection over Union (Safe mIoU) metric, designed to penalize unsafe
incorrect predictions that could be overlooked by traditional mIoU. This
innovative metric emphasized the importance of safety in developing autonomous
driving systems. The competition showed significant advancements in the field,
with participants demonstrating models that excelled in semantic segmentation
and prioritized safety and robustness in unstructured and adverse conditions.
The results of the competition set new benchmarks in the domain, highlighting
the critical role of safety in deploying autonomous vehicles in real-world
scenarios. The contributions from this competition are expected to drive
further innovation in autonomous driving technology, addressing the critical
challenges of operating in diverse and unpredictable environments.",2024-09-09 04:42:57+00:00
Sample-Efficient Bayesian Optimization with Transfer Learning for Heterogeneous Search Spaces,"Bayesian optimization (BO) is a powerful approach to sample-efficient
optimization of black-box functions. However, in settings with very few
function evaluations, a successful application of BO may require transferring
information from historical experiments. These related experiments may not have
exactly the same tunable parameters (search spaces), motivating the need for BO
with transfer learning for heterogeneous search spaces. In this paper, we
propose two methods for this setting. The first approach leverages a Gaussian
process (GP) model with a conditional kernel to transfer information between
different search spaces. Our second approach treats the missing parameters as
hyperparameters of the GP model that can be inferred jointly with the other GP
hyperparameters or set to fixed values. We show that these two methods perform
well on several benchmark problems.",2024-09-09 04:36:06+00:00
FIF-UNet: An Efficient UNet Using Feature Interaction and Fusion for Medical Image Segmentation,"Nowadays, pre-trained encoders are widely used in medical image segmentation
because of their ability to capture complex feature representations. However,
the existing models fail to effectively utilize the rich features obtained by
the pre-trained encoder, resulting in suboptimal segmentation results. In this
work, a novel U-shaped model, called FIF-UNet, is proposed to address the above
issue, including three plug-and-play modules. A channel spatial interaction
module (CSI) is proposed to obtain informative features by establishing the
interaction between encoder stages and corresponding decoder stages. A cascaded
conv-SE module (CoSE) is designed to enhance the representation of critical
features by adaptively assigning importance weights on different feature
channels. A multi-level fusion module (MLF) is proposed to fuse the multi-scale
features from the decoder stages, ensuring accurate and robust final
segmentation. Comprehensive experiments on the Synapse and ACDC datasets
demonstrate that the proposed FIF-UNet outperforms existing state-of-the-art
methods, which achieves the highest average DICE of 86.05% and 92.58%,
respectively.",2024-09-09 04:34:47+00:00
Machine Anomalous Sound Detection Using Spectral-temporal Modulation Representations Derived from Machine-specific Filterbanks,"Early detection of factory machinery malfunctions is crucial in industrial
applications. In machine anomalous sound detection (ASD), different machines
exhibit unique vibration-frequency ranges based on their physical properties.
Meanwhile, the human auditory system is adept at tracking both temporal and
spectral dynamics of machine sounds. Consequently, integrating the
computational auditory models of the human auditory system with
machine-specific properties can be an effective approach to machine ASD. We
first quantified the frequency importances of four types of machines using the
Fisher ratio (F-ratio). The quantified frequency importances were then used to
design machine-specific non-uniform filterbanks (NUFBs), which extract the log
non-uniform spectrum (LNS) feature. The designed NUFBs have a narrower
bandwidth and higher filter distribution density in frequency regions with
relatively high F-ratios. Finally, spectral and temporal modulation
representations derived from the LNS feature were proposed. These proposed LNS
feature and modulation representations are input into an autoencoder
neural-network-based detector for ASD. The quantification results from the
training set of the Malfunctioning Industrial Machine Investigation and
Inspection dataset with a signal-to-noise (SNR) of 6 dB reveal that the
distinguishing information between normal and anomalous sounds of different
machines is encoded non-uniformly in the frequency domain. By highlighting
these important frequency regions using NUFBs, the LNS feature can
significantly enhance performance using the metric of AUC (area under the
receiver operating characteristic curve) under various SNR conditions.
Furthermore, modulation representations can further improve performance.
Specifically, temporal modulation is effective for fans, pumps, and sliders,
while spectral modulation is particularly effective for valves.",2024-09-09 04:27:17+00:00
